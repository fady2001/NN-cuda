{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      "tensor([[-1.0158, -1.1004, -1.1869],\n",
      "        [-0.9717, -1.1563, -1.1812],\n",
      "        [-1.0406, -1.0731, -1.1880],\n",
      "        [-1.0262, -1.0985, -1.1767]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.1553728580474854\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a custom neural network class\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        \n",
    "        # Define the network layers\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) # First linear layer\n",
    "        self.activation1 = nn.ReLU() # Activation function after the first layer\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size) # Second linear layer\n",
    "        self.softmax = nn.Softmax(dim=1) # Softmax layer for the output\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) # LogSoftmax layer for the output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        x = self.logsoftmax(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "input_size = 10\n",
    "hidden_size = 5\n",
    "output_size = 3\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Create a loss function\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Create an optimizer\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define a batch of inputs and targets\n",
    "batch_size = 4\n",
    "input_data = torch.randn(batch_size, input_size) # Random input tensor with batch size\n",
    "targets = torch.randint(0, output_size, (batch_size,)) # Random target tensor for each input in the batch\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(input_data)\n",
    "\n",
    "# Compute loss\n",
    "loss = criterion(outputs, targets)\n",
    "\n",
    "# Backward pass\n",
    "# loss.backward()\n",
    "\n",
    "# Update weights\n",
    "# optimizer.step()\n",
    "\n",
    "# Optionally, print output and loss\n",
    "print(f\"Outputs:\\n{outputs}\")\n",
    "print(f\"Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random array and save it to a file .npy\n",
    "# import numpy as np\n",
    "\n",
    "# B = 1000\n",
    "# N = 100\n",
    "# M = 30\n",
    "# X = np.random.rand(B, N).astype(np.float32)\n",
    "# W = np.random.rand(M,N).astype(np.float32)\n",
    "# bias = np.random.rand(M).astype(np.float32)\n",
    "# np.save('../with-torch-tests/linear-layer/X.npy', X)\n",
    "# np.save('../with-torch-tests/linear-layer/W.npy', W)\n",
    "# np.save('../with-torch-tests/linear-layer/bias.npy', bias)\n",
    "\n",
    "# l = nn.Linear(N,M)\n",
    "# l.weight.data = torch.from_numpy(W)\n",
    "# l.bias.data = torch.from_numpy(bias)\n",
    "# X_torch = torch.from_numpy(X)\n",
    "# Y = l(X_torch)\n",
    "# np.save('../with-torch-tests/linear-layer/Y.npy', Y.detach().numpy())\n",
    "# print(Y[0,0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(160.7092, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the input data\n",
    "ln1b = np.load('../with-torch-tests/all-model-cpu/ln1b.npy')\n",
    "ln1w = np.load('../with-torch-tests/all-model-cpu/ln1w.npy')\n",
    "ln2b = np.load('../with-torch-tests/all-model-cpu/ln2b.npy')\n",
    "ln2w = np.load('../with-torch-tests/all-model-cpu/ln2w.npy')\n",
    "target = np.load('../with-torch-tests/all-model-cpu/target.npy')\n",
    "X_c = np.load('../with-torch-tests/all-model-cpu/X_c.npy')\n",
    "\n",
    "# get sizes\n",
    "B,N = X_c.shape\n",
    "H1,N = ln1w.shape\n",
    "l1 = nn.Linear(N,H1)\n",
    "l1.weight.data = torch.from_numpy(ln1w).to(torch.float32)\n",
    "l1.bias.data = torch.from_numpy(ln1b).to(torch.float32)\n",
    "\n",
    "\n",
    "H2,_ = ln2w.shape\n",
    "l2 = nn.Linear(H1,H2)\n",
    "l2.weight.data = torch.from_numpy(ln2w).to(torch.float32)\n",
    "l2.bias.data = torch.from_numpy(ln2b).to(torch.float32)\n",
    "\n",
    "X = torch.from_numpy(X_c).to(torch.float32)\n",
    "Y1 = l1(X)\n",
    "y1_relu = F.relu(Y1)\n",
    "Y2 = l2(y1_relu)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "loss = criterion(Y2, torch.from_numpy(target).long())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  143.35977172851562\n",
      "Forward\n",
      "False\n",
      "False\n",
      "False\n",
      "Back\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Updated weights\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "def pp(a1,a2):\n",
    "            print(a1[0,0:5])\n",
    "            print(a2[0,0:5])\n",
    "class DataLoaderModule:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.a1 = np.load(f'{self.data_path}/a1.npy')\n",
    "        self.da1 = np.load(f'{self.data_path}/da1.npy')\n",
    "        self.dln1 = np.load(f'{self.data_path}/dln1.npy')\n",
    "        self.dln2 = np.load(f'{self.data_path}/dln2.npy')\n",
    "        self.dsm = np.load(f'{self.data_path}/dsm.npy')\n",
    "        self.ln1 = np.load(f'{self.data_path}/ln1.npy')\n",
    "        self.ln1b_grad = np.load(f'{self.data_path}/ln1b_grad.npy')\n",
    "        self.ln1b = np.load(f'{self.data_path}/ln1b.npy')\n",
    "        self.ln1w_grad = np.load(f'{self.data_path}/ln1w_grad.npy')\n",
    "        self.ln1w = np.load(f'{self.data_path}/ln1w.npy')\n",
    "        self.ln2 = np.load(f'{self.data_path}/ln2.npy')\n",
    "        self.ln2b_grad = np.load(f'{self.data_path}/ln2b_grad.npy')\n",
    "        self.ln2b = np.load(f'{self.data_path}/ln2b.npy')\n",
    "        self.ln2w_grad = np.load(f'{self.data_path}/ln2w_grad.npy')\n",
    "        self.ln2w = np.load(f'{self.data_path}/ln2w.npy')\n",
    "        \n",
    "        # pp(self.ln1w, self.ln1w)\n",
    "        \n",
    "        self.target = np.load(f'{self.data_path}/target.npy')\n",
    "        self.X_c = np.load(f'{self.data_path}/X_c.npy')\n",
    "        self.updated_ln1b = np.load(f'{self.data_path}/updated_ln1b.npy')\n",
    "        self.updated_ln1w = np.load(f'{self.data_path}/updated_ln1w.npy')\n",
    "        self.updated_ln2b = np.load(f'{self.data_path}/updated_ln2b.npy')\n",
    "        self.updated_ln2w = np.load(f'{self.data_path}/updated_ln2w.npy')\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ln1w, ln1b, ln2w, ln2b):\n",
    "        super(Model, self).__init__()\n",
    "        N, H1 = ln1w.shape\n",
    "        H2, _ = ln2w.shape\n",
    "        \n",
    "        self.l1 = nn.Linear(N, H1)\n",
    "        self.l1.weight.data = torch.from_numpy(ln1w).float()\n",
    "        self.l1.bias.data = torch.from_numpy(ln1b).float()\n",
    "\n",
    "        self.l2 = nn.Linear(H1, H2)\n",
    "        self.l2.weight.data = torch.from_numpy(ln2w).float()\n",
    "        self.l2.bias.data = torch.from_numpy(ln2b).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.l1(x)\n",
    "        y1_relu = F.relu(y1)\n",
    "        y2 = self.l2(y1_relu)\n",
    "        return y1, y1_relu, y2\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, data_loader, criterion, optimizer):\n",
    "        self.model = model\n",
    "        self.data_loader = data_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def train(self):\n",
    "        X = torch.from_numpy(self.data_loader.X_c).float().requires_grad_(True)\n",
    "        target = torch.from_numpy(self.data_loader.target).long()\n",
    "        \n",
    "        y1, y1_relu, y2 = self.model(X)\n",
    "\n",
    "        # Retain gradients\n",
    "        y1.retain_grad()\n",
    "        y1_relu.retain_grad()\n",
    "        y2.retain_grad()\n",
    "\n",
    "        loss = self.criterion(y2, target)\n",
    "        print(\"loss \", loss.item())\n",
    "\n",
    "        # Forward pass comparison\n",
    "        print(\"Forward\")\n",
    "        print(np.allclose(y1.detach().numpy(), self.data_loader.ln1, atol=1e-6))\n",
    "        print(np.allclose(y1_relu.detach().numpy(), self.data_loader.a1, atol=1e-6))\n",
    "        print(np.allclose(y2.detach().numpy(), self.data_loader.ln2, atol=1e-4))\n",
    "\n",
    "        # Backward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Compare the gradients\n",
    "        print(\"Back\")\n",
    "        print(np.allclose(y2.grad.numpy(), self.data_loader.dsm, atol=1e-4))\n",
    "        print(np.allclose(y1_relu.grad.numpy(), self.data_loader.dln2, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.weight.grad.numpy(), self.data_loader.ln2w_grad, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.bias.grad.numpy(), self.data_loader.ln2b_grad, atol=1e-4))\n",
    "        print(np.allclose(y1.grad.numpy(), self.data_loader.da1, atol=1e-4))\n",
    "        print(np.allclose(self.model.l1.weight.grad.numpy(), self.data_loader.ln1w_grad, atol=1e-4))\n",
    "        print(np.allclose(self.model.l1.bias.grad.numpy(), self.data_loader.ln1b_grad, atol=1e-4))\n",
    "        \n",
    "        \n",
    "        # optimzer \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # print the updated weights\n",
    "        print(\"Updated weights\")\n",
    "        print(np.allclose(self.model.l1.weight.detach().numpy(), self.data_loader.updated_ln1w, atol=1e-2))\n",
    "        # print first elements in both \n",
    "        \n",
    "        # pp(self.model.l1.weight.detach().numpy(), self.data_loader.updated_ln1w)\n",
    "        \n",
    "        print(np.allclose(self.model.l1.bias.detach().numpy(), self.data_loader.updated_ln1b, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.weight.detach().numpy(), self.data_loader.updated_ln2w, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.bias.detach().numpy(), self.data_loader.updated_ln2b, atol=1e-4))\n",
    "def main():\n",
    "    data_loader = DataLoaderModule('../with-torch-tests/all-model')\n",
    "    \n",
    "    model = Model(data_loader.ln1w, data_loader.ln1b, data_loader.ln2w, data_loader.ln2b)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "     \n",
    "    trainer = Trainer(model, data_loader, criterion, optimizer)\n",
    "    trainer.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2802037   0.1930291   0.14813042 -0.9187077   0.39928705]\n",
      "Epoch: 0, Batch: 0, Loss: 97.19432830810547\n",
      "Epoch: 0, Batch: 1, Loss: 66.95410919189453\n",
      "Epoch: 0, Batch: 2, Loss: 59.67728805541992\n",
      "Epoch: 0, Batch: 3, Loss: 82.90585327148438\n",
      "Epoch: 0, Batch: 4, Loss: 65.7928237915039\n",
      "Epoch: 0, Batch: 5, Loss: 50.17757034301758\n",
      "Epoch: 0, Batch: 6, Loss: 49.98326873779297\n",
      "Epoch: 0, Batch: 7, Loss: 41.84203338623047\n",
      "Epoch: 0, Batch: 8, Loss: 56.48233413696289\n",
      "Epoch: 0, Batch: 9, Loss: 38.407981872558594\n",
      "Epoch: 0, Batch: 10, Loss: 46.286460876464844\n",
      "Epoch: 0, Batch: 11, Loss: 43.79452133178711\n",
      "Epoch: 0, Batch: 12, Loss: 60.71184539794922\n",
      "Epoch: 0, Batch: 13, Loss: 58.39667510986328\n",
      "Epoch: 0, Batch: 14, Loss: 47.78764343261719\n",
      "Epoch: 0, Batch: 15, Loss: 37.67105484008789\n",
      "Epoch: 0, Batch: 16, Loss: 33.71868133544922\n",
      "Epoch: 0, Batch: 17, Loss: 46.95947265625\n",
      "Epoch: 0, Batch: 18, Loss: 36.661094665527344\n",
      "Epoch: 0, Batch: 19, Loss: 34.5337028503418\n",
      "Epoch: 0, Batch: 20, Loss: 42.7694091796875\n",
      "Epoch: 0, Batch: 21, Loss: 42.78813171386719\n",
      "Epoch: 0, Batch: 22, Loss: 48.999046325683594\n",
      "Epoch: 0, Batch: 23, Loss: 36.26732635498047\n",
      "Epoch: 0, Batch: 24, Loss: 35.88791275024414\n",
      "Epoch: 0, Batch: 25, Loss: 44.03208923339844\n",
      "Epoch: 0, Batch: 26, Loss: 31.94886016845703\n",
      "Epoch: 0, Batch: 27, Loss: 38.17277526855469\n",
      "Epoch: 0, Batch: 28, Loss: 34.043487548828125\n",
      "Epoch: 0, Batch: 29, Loss: 39.833709716796875\n",
      "Epoch: 0, Batch: 30, Loss: 27.99110221862793\n",
      "Epoch: 0, Batch: 31, Loss: 29.857633590698242\n",
      "Epoch: 0, Batch: 32, Loss: 31.00811767578125\n",
      "Epoch: 0, Batch: 33, Loss: 37.14630126953125\n",
      "Epoch: 0, Batch: 34, Loss: 32.11554718017578\n",
      "Epoch: 0, Batch: 35, Loss: 21.331993103027344\n",
      "Epoch: 0, Batch: 36, Loss: 21.992029190063477\n",
      "Epoch: 0, Batch: 37, Loss: 35.17664337158203\n",
      "Epoch: 0, Batch: 38, Loss: 37.6987419128418\n",
      "Epoch: 0, Batch: 39, Loss: 34.045230865478516\n",
      "Epoch: 0, Batch: 40, Loss: 28.9855899810791\n",
      "Epoch: 0, Batch: 41, Loss: 22.849348068237305\n",
      "Epoch: 0, Batch: 42, Loss: 38.002017974853516\n",
      "Epoch: 0, Batch: 43, Loss: 22.82770538330078\n",
      "Epoch: 0, Batch: 44, Loss: 24.592527389526367\n",
      "Epoch: 0, Batch: 45, Loss: 26.885217666625977\n",
      "Epoch: 0, Batch: 46, Loss: 27.451223373413086\n",
      "Epoch: 0, Batch: 47, Loss: 30.2889461517334\n",
      "Epoch: 0, Batch: 48, Loss: 27.441755294799805\n",
      "Epoch: 0, Batch: 49, Loss: 17.052745819091797\n",
      "Epoch: 0, Batch: 50, Loss: 23.975730895996094\n",
      "Epoch: 0, Batch: 51, Loss: 19.74342155456543\n",
      "Epoch: 0, Batch: 52, Loss: 28.7141170501709\n",
      "Epoch: 0, Batch: 53, Loss: 22.869338989257812\n",
      "Epoch: 0, Batch: 54, Loss: 26.98814582824707\n",
      "Epoch: 0, Batch: 55, Loss: 19.678653717041016\n",
      "Epoch: 0, Batch: 56, Loss: 26.133573532104492\n",
      "Epoch: 0, Batch: 57, Loss: 26.172653198242188\n",
      "Epoch: 0, Batch: 58, Loss: 31.177364349365234\n",
      "Epoch: 0, Batch: 59, Loss: 27.85593032836914\n",
      "Epoch: 0, Batch: 60, Loss: 22.435441970825195\n",
      "Epoch: 0, Batch: 61, Loss: 24.021297454833984\n",
      "Epoch: 0, Batch: 62, Loss: 29.144512176513672\n",
      "Epoch: 0, Batch: 63, Loss: 29.929166793823242\n",
      "Epoch: 0, Batch: 64, Loss: 23.033000946044922\n",
      "Epoch: 0, Batch: 65, Loss: 26.179550170898438\n",
      "Epoch: 0, Batch: 66, Loss: 25.387235641479492\n",
      "Epoch: 0, Batch: 67, Loss: 17.490863800048828\n",
      "Epoch: 0, Batch: 68, Loss: 20.68940544128418\n",
      "Epoch: 0, Batch: 69, Loss: 23.794811248779297\n",
      "Epoch: 0, Batch: 70, Loss: 27.60496711730957\n",
      "Epoch: 0, Batch: 71, Loss: 25.435497283935547\n",
      "Epoch: 0, Batch: 72, Loss: 25.51138687133789\n",
      "Epoch: 0, Batch: 73, Loss: 36.99687576293945\n",
      "Epoch: 0, Batch: 74, Loss: 21.209014892578125\n",
      "Epoch: 0, Batch: 75, Loss: 16.65961456298828\n",
      "Epoch: 0, Batch: 76, Loss: 14.696279525756836\n",
      "Epoch: 0, Batch: 77, Loss: 21.962690353393555\n",
      "Epoch: 0, Batch: 78, Loss: 16.983938217163086\n",
      "Epoch: 0, Batch: 79, Loss: 23.99123191833496\n",
      "Epoch: 0, Batch: 80, Loss: 22.420307159423828\n",
      "Epoch: 0, Batch: 81, Loss: 25.823074340820312\n",
      "Epoch: 0, Batch: 82, Loss: 22.913726806640625\n",
      "Epoch: 0, Batch: 83, Loss: 20.8866024017334\n",
      "Epoch: 0, Batch: 84, Loss: 28.58863067626953\n",
      "Epoch: 0, Batch: 85, Loss: 23.067001342773438\n",
      "Epoch: 0, Batch: 86, Loss: 17.773967742919922\n",
      "Epoch: 0, Batch: 87, Loss: 22.924213409423828\n",
      "Epoch: 0, Batch: 88, Loss: 20.46139907836914\n",
      "Epoch: 0, Batch: 89, Loss: 14.627979278564453\n",
      "Epoch: 0, Batch: 90, Loss: 24.23477554321289\n",
      "Epoch: 0, Batch: 91, Loss: 20.45703125\n",
      "Epoch: 0, Batch: 92, Loss: 17.870271682739258\n",
      "Epoch: 0, Batch: 93, Loss: 28.89588737487793\n",
      "Epoch: 0, Batch: 94, Loss: 18.507930755615234\n",
      "Epoch: 0, Batch: 95, Loss: 15.93298625946045\n",
      "Epoch: 0, Batch: 96, Loss: 21.85260581970215\n",
      "Epoch: 0, Batch: 97, Loss: 25.299095153808594\n",
      "Epoch: 0, Batch: 98, Loss: 19.954713821411133\n",
      "Epoch: 0, Batch: 99, Loss: 12.97757625579834\n",
      "Epoch: 0, Batch: 100, Loss: 18.38945960998535\n",
      "Epoch: 0, Batch: 101, Loss: 30.83267593383789\n",
      "Epoch: 0, Batch: 102, Loss: 21.068357467651367\n",
      "Epoch: 0, Batch: 103, Loss: 20.75194549560547\n",
      "Epoch: 0, Batch: 104, Loss: 20.610313415527344\n",
      "Epoch: 0, Batch: 105, Loss: 10.994998931884766\n",
      "Epoch: 0, Batch: 106, Loss: 21.241573333740234\n",
      "Epoch: 0, Batch: 107, Loss: 21.192995071411133\n",
      "Epoch: 0, Batch: 108, Loss: 11.621281623840332\n",
      "Epoch: 0, Batch: 109, Loss: 20.21230125427246\n",
      "Epoch: 0, Batch: 110, Loss: 11.97659683227539\n",
      "Epoch: 0, Batch: 111, Loss: 23.1403751373291\n",
      "Epoch: 0, Batch: 112, Loss: 15.837594985961914\n",
      "Epoch: 0, Batch: 113, Loss: 26.050094604492188\n",
      "Epoch: 0, Batch: 114, Loss: 12.966240882873535\n",
      "Epoch: 0, Batch: 115, Loss: 27.99448585510254\n",
      "Epoch: 0, Batch: 116, Loss: 18.055200576782227\n",
      "Epoch: 0, Batch: 117, Loss: 13.440180778503418\n",
      "Epoch: 0, Batch: 118, Loss: 11.794647216796875\n",
      "Epoch: 0, Batch: 119, Loss: 16.456375122070312\n",
      "Epoch: 0, Batch: 120, Loss: 19.850337982177734\n",
      "Epoch: 0, Batch: 121, Loss: 19.3426513671875\n",
      "Epoch: 0, Batch: 122, Loss: 30.20025634765625\n",
      "Epoch: 0, Batch: 123, Loss: 26.90116310119629\n",
      "Epoch: 0, Batch: 124, Loss: 19.398778915405273\n",
      "Epoch: 0, Batch: 125, Loss: 16.38317108154297\n",
      "Epoch: 0, Batch: 126, Loss: 13.720500946044922\n",
      "Epoch: 0, Batch: 127, Loss: 18.295856475830078\n",
      "Epoch: 0, Batch: 128, Loss: 16.79319953918457\n",
      "Epoch: 0, Batch: 129, Loss: 19.643972396850586\n",
      "Epoch: 0, Batch: 130, Loss: 10.687347412109375\n",
      "Epoch: 0, Batch: 131, Loss: 17.5535831451416\n",
      "Epoch: 0, Batch: 132, Loss: 18.994049072265625\n",
      "Epoch: 0, Batch: 133, Loss: 19.25075912475586\n",
      "Epoch: 0, Batch: 134, Loss: 15.039313316345215\n",
      "Epoch: 0, Batch: 135, Loss: 22.995311737060547\n",
      "Epoch: 0, Batch: 136, Loss: 21.558818817138672\n",
      "Epoch: 0, Batch: 137, Loss: 18.41234016418457\n",
      "Epoch: 0, Batch: 138, Loss: 16.130382537841797\n",
      "Epoch: 0, Batch: 139, Loss: 18.985939025878906\n",
      "Epoch: 0, Batch: 140, Loss: 12.955178260803223\n",
      "Epoch: 0, Batch: 141, Loss: 21.697830200195312\n",
      "Epoch: 0, Batch: 142, Loss: 16.303695678710938\n",
      "Epoch: 0, Batch: 143, Loss: 14.596962928771973\n",
      "Epoch: 0, Batch: 144, Loss: 17.888296127319336\n",
      "Epoch: 0, Batch: 145, Loss: 7.366018295288086\n",
      "Epoch: 0, Batch: 146, Loss: 12.480788230895996\n",
      "Epoch: 0, Batch: 147, Loss: 22.36162567138672\n",
      "Epoch: 0, Batch: 148, Loss: 19.846837997436523\n",
      "Epoch: 0, Batch: 149, Loss: 15.307616233825684\n",
      "Epoch: 0, Batch: 150, Loss: 14.105727195739746\n",
      "Epoch: 0, Batch: 151, Loss: 11.684651374816895\n",
      "Epoch: 0, Batch: 152, Loss: 16.961135864257812\n",
      "Epoch: 0, Batch: 153, Loss: 14.229110717773438\n",
      "Epoch: 0, Batch: 154, Loss: 16.371976852416992\n",
      "Epoch: 0, Batch: 155, Loss: 18.629150390625\n",
      "Epoch: 0, Batch: 156, Loss: 15.096510887145996\n",
      "Epoch: 0, Batch: 157, Loss: 9.152677536010742\n",
      "Epoch: 0, Batch: 158, Loss: 18.840450286865234\n",
      "Epoch: 0, Batch: 159, Loss: 20.291120529174805\n",
      "Epoch: 0, Batch: 160, Loss: 16.455211639404297\n",
      "Epoch: 0, Batch: 161, Loss: 16.426544189453125\n",
      "Epoch: 0, Batch: 162, Loss: 11.774627685546875\n",
      "Epoch: 0, Batch: 163, Loss: 10.170181274414062\n",
      "Epoch: 0, Batch: 164, Loss: 13.377344131469727\n",
      "Epoch: 0, Batch: 165, Loss: 11.042309761047363\n",
      "Epoch: 0, Batch: 166, Loss: 14.367149353027344\n",
      "Epoch: 0, Batch: 167, Loss: 18.62073516845703\n",
      "Epoch: 0, Batch: 168, Loss: 13.739114761352539\n",
      "Epoch: 0, Batch: 169, Loss: 20.976106643676758\n",
      "Epoch: 0, Batch: 170, Loss: 10.048602104187012\n",
      "Epoch: 0, Batch: 171, Loss: 13.05595874786377\n",
      "Epoch: 0, Batch: 172, Loss: 21.26613426208496\n",
      "Epoch: 0, Batch: 173, Loss: 16.90364646911621\n",
      "Epoch: 0, Batch: 174, Loss: 15.412958145141602\n",
      "Epoch: 0, Batch: 175, Loss: 12.674565315246582\n",
      "Epoch: 0, Batch: 176, Loss: 21.160924911499023\n",
      "Epoch: 0, Batch: 177, Loss: 16.168720245361328\n",
      "Epoch: 0, Batch: 178, Loss: 20.486228942871094\n",
      "Epoch: 0, Batch: 179, Loss: 18.402347564697266\n",
      "Epoch: 0, Batch: 180, Loss: 19.12282371520996\n",
      "Epoch: 0, Batch: 181, Loss: 16.003917694091797\n",
      "Epoch: 0, Batch: 182, Loss: 23.31447982788086\n",
      "Epoch: 0, Batch: 183, Loss: 19.208040237426758\n",
      "Epoch: 0, Batch: 184, Loss: 10.86030101776123\n",
      "Epoch: 0, Batch: 185, Loss: 11.037402153015137\n",
      "Epoch: 0, Batch: 186, Loss: 10.827356338500977\n",
      "Epoch: 0, Batch: 187, Loss: 7.809762477874756\n",
      "Epoch: 0, Batch: 188, Loss: 16.20863914489746\n",
      "Epoch: 0, Batch: 189, Loss: 12.089502334594727\n",
      "Epoch: 0, Batch: 190, Loss: 17.23930549621582\n",
      "Epoch: 0, Batch: 191, Loss: 20.306045532226562\n",
      "Epoch: 0, Batch: 192, Loss: 15.129545211791992\n",
      "Epoch: 0, Batch: 193, Loss: 9.712750434875488\n",
      "Epoch: 0, Batch: 194, Loss: 12.644956588745117\n",
      "Epoch: 0, Batch: 195, Loss: 16.169105529785156\n",
      "Epoch: 0, Batch: 196, Loss: 13.125664710998535\n",
      "Epoch: 0, Batch: 197, Loss: 13.628812789916992\n",
      "Epoch: 0, Batch: 198, Loss: 14.963835716247559\n",
      "Epoch: 0, Batch: 199, Loss: 10.83527660369873\n",
      "Epoch: 0, Batch: 200, Loss: 6.9029011726379395\n",
      "Epoch: 0, Batch: 201, Loss: 23.178543090820312\n",
      "Epoch: 0, Batch: 202, Loss: 18.219451904296875\n",
      "Epoch: 0, Batch: 203, Loss: 16.278423309326172\n",
      "Epoch: 0, Batch: 204, Loss: 19.53521728515625\n",
      "Epoch: 0, Batch: 205, Loss: 17.999168395996094\n",
      "Epoch: 0, Batch: 206, Loss: 16.19245147705078\n",
      "Epoch: 0, Batch: 207, Loss: 12.53092098236084\n",
      "Epoch: 0, Batch: 208, Loss: 15.717126846313477\n",
      "Epoch: 0, Batch: 209, Loss: 18.030017852783203\n",
      "Epoch: 0, Batch: 210, Loss: 14.771524429321289\n",
      "Epoch: 0, Batch: 211, Loss: 11.89664363861084\n",
      "Epoch: 0, Batch: 212, Loss: 15.684561729431152\n",
      "Epoch: 0, Batch: 213, Loss: 13.525487899780273\n",
      "Epoch: 0, Batch: 214, Loss: 17.35121726989746\n",
      "Epoch: 0, Batch: 215, Loss: 16.22859001159668\n",
      "Epoch: 0, Batch: 216, Loss: 10.809307098388672\n",
      "Epoch: 0, Batch: 217, Loss: 12.684889793395996\n",
      "Epoch: 0, Batch: 218, Loss: 17.246543884277344\n",
      "Epoch: 0, Batch: 219, Loss: 12.478930473327637\n",
      "Epoch: 0, Batch: 220, Loss: 11.07972526550293\n",
      "Epoch: 0, Batch: 221, Loss: 8.917034149169922\n",
      "Epoch: 0, Batch: 222, Loss: 11.058454513549805\n",
      "Epoch: 0, Batch: 223, Loss: 10.525589942932129\n",
      "Epoch: 0, Batch: 224, Loss: 10.290109634399414\n",
      "Epoch: 0, Batch: 225, Loss: 18.557594299316406\n",
      "Epoch: 0, Batch: 226, Loss: 15.656747817993164\n",
      "Epoch: 0, Batch: 227, Loss: 13.872320175170898\n",
      "Epoch: 0, Batch: 228, Loss: 10.626618385314941\n",
      "Epoch: 0, Batch: 229, Loss: 14.623143196105957\n",
      "Epoch: 0, Batch: 230, Loss: 14.626087188720703\n",
      "Epoch: 0, Batch: 231, Loss: 10.577141761779785\n",
      "Epoch: 0, Batch: 232, Loss: 15.103521347045898\n",
      "Epoch: 0, Batch: 233, Loss: 14.663681030273438\n",
      "Epoch: 0, Batch: 234, Loss: 11.469640731811523\n",
      "Epoch: 0, Batch: 235, Loss: 8.849775314331055\n",
      "Epoch: 0, Batch: 236, Loss: 14.88595962524414\n",
      "Epoch: 0, Batch: 237, Loss: 6.03218936920166\n",
      "Epoch: 0, Batch: 238, Loss: 7.4669647216796875\n",
      "Epoch: 0, Batch: 239, Loss: 9.115148544311523\n",
      "Epoch: 0, Batch: 240, Loss: 12.6482572555542\n",
      "Epoch: 0, Batch: 241, Loss: 9.639909744262695\n",
      "Epoch: 0, Batch: 242, Loss: 11.007455825805664\n",
      "Epoch: 0, Batch: 243, Loss: 17.428211212158203\n",
      "Epoch: 0, Batch: 244, Loss: 19.210086822509766\n",
      "Epoch: 0, Batch: 245, Loss: 12.606657981872559\n",
      "Epoch: 0, Batch: 246, Loss: 20.31999397277832\n",
      "Epoch: 0, Batch: 247, Loss: 13.479704856872559\n",
      "Epoch: 0, Batch: 248, Loss: 5.88689661026001\n",
      "Epoch: 0, Batch: 249, Loss: 16.23456573486328\n",
      "Epoch: 0, Batch: 250, Loss: 13.157905578613281\n",
      "Epoch: 0, Batch: 251, Loss: 14.70775032043457\n",
      "Epoch: 0, Batch: 252, Loss: 12.720946311950684\n",
      "Epoch: 0, Batch: 253, Loss: 12.106155395507812\n",
      "Epoch: 0, Batch: 254, Loss: 8.617130279541016\n",
      "Epoch: 0, Batch: 255, Loss: 11.481888771057129\n",
      "Epoch: 0, Batch: 256, Loss: 15.472570419311523\n",
      "Epoch: 0, Batch: 257, Loss: 11.1304292678833\n",
      "Epoch: 0, Batch: 258, Loss: 20.43128204345703\n",
      "Epoch: 0, Batch: 259, Loss: 5.758121490478516\n",
      "Epoch: 0, Batch: 260, Loss: 6.541878700256348\n",
      "Epoch: 0, Batch: 261, Loss: 7.500694274902344\n",
      "Epoch: 0, Batch: 262, Loss: 18.520183563232422\n",
      "Epoch: 0, Batch: 263, Loss: 14.197778701782227\n",
      "Epoch: 0, Batch: 264, Loss: 14.234078407287598\n",
      "Epoch: 0, Batch: 265, Loss: 18.11035919189453\n",
      "Epoch: 0, Batch: 266, Loss: 12.59327507019043\n",
      "Epoch: 0, Batch: 267, Loss: 15.657998085021973\n",
      "Epoch: 0, Batch: 268, Loss: 10.550488471984863\n",
      "Epoch: 0, Batch: 269, Loss: 9.308349609375\n",
      "Epoch: 0, Batch: 270, Loss: 11.781722068786621\n",
      "Epoch: 0, Batch: 271, Loss: 12.972396850585938\n",
      "Epoch: 0, Batch: 272, Loss: 11.175992012023926\n",
      "Epoch: 0, Batch: 273, Loss: 9.511740684509277\n",
      "Epoch: 0, Batch: 274, Loss: 12.705767631530762\n",
      "Epoch: 0, Batch: 275, Loss: 5.802454948425293\n",
      "Epoch: 0, Batch: 276, Loss: 21.457983016967773\n",
      "Epoch: 0, Batch: 277, Loss: 15.77385139465332\n",
      "Epoch: 0, Batch: 278, Loss: 18.958660125732422\n",
      "Epoch: 0, Batch: 279, Loss: 16.894094467163086\n",
      "Epoch: 0, Batch: 280, Loss: 23.093017578125\n",
      "Epoch: 0, Batch: 281, Loss: 16.589801788330078\n",
      "Epoch: 0, Batch: 282, Loss: 14.55825138092041\n",
      "Epoch: 0, Batch: 283, Loss: 7.794244289398193\n",
      "Epoch: 0, Batch: 284, Loss: 12.877291679382324\n",
      "Epoch: 0, Batch: 285, Loss: 11.047276496887207\n",
      "Epoch: 0, Batch: 286, Loss: 9.632776260375977\n",
      "Epoch: 0, Batch: 287, Loss: 17.932226181030273\n",
      "Epoch: 0, Batch: 288, Loss: 19.265731811523438\n",
      "Epoch: 0, Batch: 289, Loss: 12.911771774291992\n",
      "Epoch: 0, Batch: 290, Loss: 9.507463455200195\n",
      "Epoch: 0, Batch: 291, Loss: 10.060399055480957\n",
      "Epoch: 0, Batch: 292, Loss: 12.638511657714844\n",
      "Epoch: 0, Batch: 293, Loss: 12.64785099029541\n",
      "Epoch: 0, Batch: 294, Loss: 6.969013214111328\n",
      "Epoch: 0, Batch: 295, Loss: 17.1081600189209\n",
      "Epoch: 0, Batch: 296, Loss: 11.225725173950195\n",
      "Epoch: 0, Batch: 297, Loss: 11.164710998535156\n",
      "Epoch: 0, Batch: 298, Loss: 8.690093040466309\n",
      "Epoch: 0, Batch: 299, Loss: 13.557721138000488\n",
      "Epoch: 0, Batch: 300, Loss: 10.53261947631836\n",
      "Epoch: 0, Batch: 301, Loss: 12.893097877502441\n",
      "Epoch: 0, Batch: 302, Loss: 6.705817699432373\n",
      "Epoch: 0, Batch: 303, Loss: 8.787985801696777\n",
      "Epoch: 0, Batch: 304, Loss: 17.709026336669922\n",
      "Epoch: 0, Batch: 305, Loss: 11.018060684204102\n",
      "Epoch: 0, Batch: 306, Loss: 11.332977294921875\n",
      "Epoch: 0, Batch: 307, Loss: 9.273374557495117\n",
      "Epoch: 0, Batch: 308, Loss: 11.222173690795898\n",
      "Epoch: 0, Batch: 309, Loss: 10.765299797058105\n",
      "Epoch: 0, Batch: 310, Loss: 17.42251205444336\n",
      "Epoch: 0, Batch: 311, Loss: 7.627589225769043\n",
      "Epoch: 0, Batch: 312, Loss: 14.7673978805542\n",
      "Epoch: 0, Batch: 313, Loss: 8.898879051208496\n",
      "Epoch: 0, Batch: 314, Loss: 14.676342964172363\n",
      "Epoch: 0, Batch: 315, Loss: 4.053244590759277\n",
      "Epoch: 0, Batch: 316, Loss: 11.004949569702148\n",
      "Epoch: 0, Batch: 317, Loss: 17.860620498657227\n",
      "Epoch: 0, Batch: 318, Loss: 8.398661613464355\n",
      "Epoch: 0, Batch: 319, Loss: 10.237059593200684\n",
      "Epoch: 0, Batch: 320, Loss: 8.560318946838379\n",
      "Epoch: 0, Batch: 321, Loss: 7.316400527954102\n",
      "Epoch: 0, Batch: 322, Loss: 7.400662422180176\n",
      "Epoch: 0, Batch: 323, Loss: 9.163625717163086\n",
      "Epoch: 0, Batch: 324, Loss: 14.019354820251465\n",
      "Epoch: 0, Batch: 325, Loss: 10.033875465393066\n",
      "Epoch: 0, Batch: 326, Loss: 15.934678077697754\n",
      "Epoch: 0, Batch: 327, Loss: 7.767860412597656\n",
      "Epoch: 0, Batch: 328, Loss: 20.012664794921875\n",
      "Epoch: 0, Batch: 329, Loss: 4.3524909019470215\n",
      "Epoch: 0, Batch: 330, Loss: 11.118316650390625\n",
      "Epoch: 0, Batch: 331, Loss: 7.860363483428955\n",
      "Epoch: 0, Batch: 332, Loss: 12.169240951538086\n",
      "Epoch: 0, Batch: 333, Loss: 9.336329460144043\n",
      "Epoch: 0, Batch: 334, Loss: 11.40815258026123\n",
      "Epoch: 0, Batch: 335, Loss: 12.243748664855957\n",
      "Epoch: 0, Batch: 336, Loss: 12.993821144104004\n",
      "Epoch: 0, Batch: 337, Loss: 10.918054580688477\n",
      "Epoch: 0, Batch: 338, Loss: 6.2131195068359375\n",
      "Epoch: 0, Batch: 339, Loss: 10.720812797546387\n",
      "Epoch: 0, Batch: 340, Loss: 14.081258773803711\n",
      "Epoch: 0, Batch: 341, Loss: 13.75129222869873\n",
      "Epoch: 0, Batch: 342, Loss: 13.440141677856445\n",
      "Epoch: 0, Batch: 343, Loss: 13.903806686401367\n",
      "Epoch: 0, Batch: 344, Loss: 7.291521072387695\n",
      "Epoch: 0, Batch: 345, Loss: 22.71745491027832\n",
      "Epoch: 0, Batch: 346, Loss: 10.980202674865723\n",
      "Epoch: 0, Batch: 347, Loss: 16.83588409423828\n",
      "Epoch: 0, Batch: 348, Loss: 10.625678062438965\n",
      "Epoch: 0, Batch: 349, Loss: 7.681143283843994\n",
      "Epoch: 0, Batch: 350, Loss: 12.243997573852539\n",
      "Epoch: 0, Batch: 351, Loss: 10.469167709350586\n",
      "Epoch: 0, Batch: 352, Loss: 15.100383758544922\n",
      "Epoch: 0, Batch: 353, Loss: 12.585214614868164\n",
      "Epoch: 0, Batch: 354, Loss: 15.955755233764648\n",
      "Epoch: 0, Batch: 355, Loss: 8.757259368896484\n",
      "Epoch: 0, Batch: 356, Loss: 5.566354274749756\n",
      "Epoch: 0, Batch: 357, Loss: 8.593034744262695\n",
      "Epoch: 0, Batch: 358, Loss: 16.30120086669922\n",
      "Epoch: 0, Batch: 359, Loss: 12.183897972106934\n",
      "Epoch: 0, Batch: 360, Loss: 8.468113899230957\n",
      "Epoch: 0, Batch: 361, Loss: 5.232247829437256\n",
      "Epoch: 0, Batch: 362, Loss: 14.47964096069336\n",
      "Epoch: 0, Batch: 363, Loss: 12.36396598815918\n",
      "Epoch: 0, Batch: 364, Loss: 15.263890266418457\n",
      "Epoch: 0, Batch: 365, Loss: 9.490915298461914\n",
      "Epoch: 0, Batch: 366, Loss: 9.427131652832031\n",
      "Epoch: 0, Batch: 367, Loss: 7.192691802978516\n",
      "Epoch: 0, Batch: 368, Loss: 10.808300018310547\n",
      "Epoch: 0, Batch: 369, Loss: 9.537187576293945\n",
      "Epoch: 0, Batch: 370, Loss: 11.42410945892334\n",
      "Epoch: 0, Batch: 371, Loss: 11.560587882995605\n",
      "Epoch: 0, Batch: 372, Loss: 8.735050201416016\n",
      "Epoch: 0, Batch: 373, Loss: 9.259041786193848\n",
      "Epoch: 0, Batch: 374, Loss: 12.249797821044922\n",
      "Epoch: 0, Batch: 375, Loss: 6.95557975769043\n",
      "Epoch: 0, Batch: 376, Loss: 7.204998016357422\n",
      "Epoch: 0, Batch: 377, Loss: 19.320465087890625\n",
      "Epoch: 0, Batch: 378, Loss: 8.978602409362793\n",
      "Epoch: 0, Batch: 379, Loss: 7.493923187255859\n",
      "Epoch: 0, Batch: 380, Loss: 9.768716812133789\n",
      "Epoch: 0, Batch: 381, Loss: 9.075128555297852\n",
      "Epoch: 0, Batch: 382, Loss: 17.837627410888672\n",
      "Epoch: 0, Batch: 383, Loss: 11.8795804977417\n",
      "Epoch: 0, Batch: 384, Loss: 8.016640663146973\n",
      "Epoch: 0, Batch: 385, Loss: 15.827917098999023\n",
      "Epoch: 0, Batch: 386, Loss: 5.341442584991455\n",
      "Epoch: 0, Batch: 387, Loss: 7.517928123474121\n",
      "Epoch: 0, Batch: 388, Loss: 8.398685455322266\n",
      "Epoch: 0, Batch: 389, Loss: 10.86622142791748\n",
      "Epoch: 0, Batch: 390, Loss: 12.576504707336426\n",
      "Epoch: 0, Batch: 391, Loss: 10.041082382202148\n",
      "Epoch: 0, Batch: 392, Loss: 6.84433650970459\n",
      "Epoch: 0, Batch: 393, Loss: 6.6304850578308105\n",
      "Epoch: 0, Batch: 394, Loss: 9.263431549072266\n",
      "Epoch: 0, Batch: 395, Loss: 10.371969223022461\n",
      "Epoch: 0, Batch: 396, Loss: 8.724832534790039\n",
      "Epoch: 0, Batch: 397, Loss: 5.982488632202148\n",
      "Epoch: 0, Batch: 398, Loss: 11.463030815124512\n",
      "Epoch: 0, Batch: 399, Loss: 6.503868103027344\n",
      "Epoch: 0, Batch: 400, Loss: 13.184845924377441\n",
      "Epoch: 0, Batch: 401, Loss: 6.1899614334106445\n",
      "Epoch: 0, Batch: 402, Loss: 5.00299072265625\n",
      "Epoch: 0, Batch: 403, Loss: 13.286758422851562\n",
      "Epoch: 0, Batch: 404, Loss: 7.330204486846924\n",
      "Epoch: 0, Batch: 405, Loss: 5.783622741699219\n",
      "Epoch: 0, Batch: 406, Loss: 11.311999320983887\n",
      "Epoch: 0, Batch: 407, Loss: 10.91904067993164\n",
      "Epoch: 0, Batch: 408, Loss: 7.06991720199585\n",
      "Epoch: 0, Batch: 409, Loss: 7.440796375274658\n",
      "Epoch: 0, Batch: 410, Loss: 10.871328353881836\n",
      "Epoch: 0, Batch: 411, Loss: 13.955045700073242\n",
      "Epoch: 0, Batch: 412, Loss: 8.496997833251953\n",
      "Epoch: 0, Batch: 413, Loss: 8.474725723266602\n",
      "Epoch: 0, Batch: 414, Loss: 16.612993240356445\n",
      "Epoch: 0, Batch: 415, Loss: 7.883810043334961\n",
      "Epoch: 0, Batch: 416, Loss: 9.262625694274902\n",
      "Epoch: 0, Batch: 417, Loss: 14.231833457946777\n",
      "Epoch: 0, Batch: 418, Loss: 10.960976600646973\n",
      "Epoch: 0, Batch: 419, Loss: 13.652409553527832\n",
      "Epoch: 0, Batch: 420, Loss: 11.616518020629883\n",
      "Epoch: 0, Batch: 421, Loss: 5.440555572509766\n",
      "Epoch: 0, Batch: 422, Loss: 11.860688209533691\n",
      "Epoch: 0, Batch: 423, Loss: 8.545065879821777\n",
      "Epoch: 0, Batch: 424, Loss: 8.225403785705566\n",
      "Epoch: 0, Batch: 425, Loss: 9.052305221557617\n",
      "Epoch: 0, Batch: 426, Loss: 7.536815166473389\n",
      "Epoch: 0, Batch: 427, Loss: 12.727309226989746\n",
      "Epoch: 0, Batch: 428, Loss: 3.869919776916504\n",
      "Epoch: 0, Batch: 429, Loss: 9.228845596313477\n",
      "Epoch: 0, Batch: 430, Loss: 8.886445999145508\n",
      "Epoch: 0, Batch: 431, Loss: 7.370664119720459\n",
      "Epoch: 0, Batch: 432, Loss: 10.628832817077637\n",
      "Epoch: 0, Batch: 433, Loss: 14.161154747009277\n",
      "Epoch: 0, Batch: 434, Loss: 9.102082252502441\n",
      "Epoch: 0, Batch: 435, Loss: 6.24526834487915\n",
      "Epoch: 0, Batch: 436, Loss: 9.743717193603516\n",
      "Epoch: 0, Batch: 437, Loss: 11.335699081420898\n",
      "Epoch: 0, Batch: 438, Loss: 8.450783729553223\n",
      "Epoch: 0, Batch: 439, Loss: 8.939802169799805\n",
      "Epoch: 0, Batch: 440, Loss: 6.011126518249512\n",
      "Epoch: 0, Batch: 441, Loss: 6.193546772003174\n",
      "Epoch: 0, Batch: 442, Loss: 9.537980079650879\n",
      "Epoch: 0, Batch: 443, Loss: 9.715980529785156\n",
      "Epoch: 0, Batch: 444, Loss: 8.5480318069458\n",
      "Epoch: 0, Batch: 445, Loss: 13.794232368469238\n",
      "Epoch: 0, Batch: 446, Loss: 8.819120407104492\n",
      "Epoch: 0, Batch: 447, Loss: 9.14341926574707\n",
      "Epoch: 0, Batch: 448, Loss: 9.352622985839844\n",
      "Epoch: 0, Batch: 449, Loss: 14.578275680541992\n",
      "Epoch: 0, Batch: 450, Loss: 6.186977386474609\n",
      "Epoch: 0, Batch: 451, Loss: 6.926327228546143\n",
      "Epoch: 0, Batch: 452, Loss: 8.064849853515625\n",
      "Epoch: 0, Batch: 453, Loss: 9.117936134338379\n",
      "Epoch: 0, Batch: 454, Loss: 8.873438835144043\n",
      "Epoch: 0, Batch: 455, Loss: 8.264147758483887\n",
      "Epoch: 0, Batch: 456, Loss: 7.710809230804443\n",
      "Epoch: 0, Batch: 457, Loss: 7.360219478607178\n",
      "Epoch: 0, Batch: 458, Loss: 12.25967788696289\n",
      "Epoch: 0, Batch: 459, Loss: 7.726175308227539\n",
      "Epoch: 0, Batch: 460, Loss: 8.31991195678711\n",
      "Epoch: 0, Batch: 461, Loss: 6.904913902282715\n",
      "Epoch: 0, Batch: 462, Loss: 9.175580978393555\n",
      "Epoch: 0, Batch: 463, Loss: 10.304984092712402\n",
      "Epoch: 0, Batch: 464, Loss: 7.5154805183410645\n",
      "Epoch: 0, Batch: 465, Loss: 12.300191879272461\n",
      "Epoch: 0, Batch: 466, Loss: 7.212819576263428\n",
      "Epoch: 0, Batch: 467, Loss: 10.775617599487305\n",
      "Epoch: 0, Batch: 468, Loss: 8.288281440734863\n",
      "Epoch: 0, Batch: 469, Loss: 11.699728012084961\n",
      "Epoch: 0, Batch: 470, Loss: 6.608694553375244\n",
      "Epoch: 0, Batch: 471, Loss: 7.101083755493164\n",
      "Epoch: 0, Batch: 472, Loss: 6.935366153717041\n",
      "Epoch: 0, Batch: 473, Loss: 10.72415542602539\n",
      "Epoch: 0, Batch: 474, Loss: 11.004851341247559\n",
      "Epoch: 0, Batch: 475, Loss: 9.993165969848633\n",
      "Epoch: 0, Batch: 476, Loss: 9.613564491271973\n",
      "Epoch: 0, Batch: 477, Loss: 10.92165756225586\n",
      "Epoch: 0, Batch: 478, Loss: 5.1649394035339355\n",
      "Epoch: 0, Batch: 479, Loss: 10.327735900878906\n",
      "Epoch: 0, Batch: 480, Loss: 4.225121974945068\n",
      "Epoch: 0, Batch: 481, Loss: 7.0642523765563965\n",
      "Epoch: 0, Batch: 482, Loss: 9.811296463012695\n",
      "Epoch: 0, Batch: 483, Loss: 12.882840156555176\n",
      "Epoch: 0, Batch: 484, Loss: 9.497064590454102\n",
      "Epoch: 0, Batch: 485, Loss: 6.83523416519165\n",
      "Epoch: 0, Batch: 486, Loss: 7.171875\n",
      "Epoch: 0, Batch: 487, Loss: 5.886592388153076\n",
      "Epoch: 0, Batch: 488, Loss: 7.2899909019470215\n",
      "Epoch: 0, Batch: 489, Loss: 9.900927543640137\n",
      "Epoch: 0, Batch: 490, Loss: 7.217599868774414\n",
      "Epoch: 0, Batch: 491, Loss: 11.22747802734375\n",
      "Epoch: 0, Batch: 492, Loss: 5.886486530303955\n",
      "Epoch: 0, Batch: 493, Loss: 8.790693283081055\n",
      "Epoch: 0, Batch: 494, Loss: 15.915289878845215\n",
      "Epoch: 0, Batch: 495, Loss: 11.35434341430664\n",
      "Epoch: 0, Batch: 496, Loss: 7.639726161956787\n",
      "Epoch: 0, Batch: 497, Loss: 7.295396327972412\n",
      "Epoch: 0, Batch: 498, Loss: 9.199604034423828\n",
      "Epoch: 0, Batch: 499, Loss: 9.07763957977295\n",
      "Epoch: 0, Batch: 500, Loss: 5.8236894607543945\n",
      "Epoch: 0, Batch: 501, Loss: 11.186126708984375\n",
      "Epoch: 0, Batch: 502, Loss: 13.43144416809082\n",
      "Epoch: 0, Batch: 503, Loss: 7.561407566070557\n",
      "Epoch: 0, Batch: 504, Loss: 4.740046977996826\n",
      "Epoch: 0, Batch: 505, Loss: 8.566730499267578\n",
      "Epoch: 0, Batch: 506, Loss: 6.9390363693237305\n",
      "Epoch: 0, Batch: 507, Loss: 4.448655128479004\n",
      "Epoch: 0, Batch: 508, Loss: 10.415285110473633\n",
      "Epoch: 0, Batch: 509, Loss: 7.448448181152344\n",
      "Epoch: 0, Batch: 510, Loss: 5.906558036804199\n",
      "Epoch: 0, Batch: 511, Loss: 9.850110054016113\n",
      "Epoch: 0, Batch: 512, Loss: 6.555863857269287\n",
      "Epoch: 0, Batch: 513, Loss: 8.937305450439453\n",
      "Epoch: 0, Batch: 514, Loss: 7.867376327514648\n",
      "Epoch: 0, Batch: 515, Loss: 2.4572739601135254\n",
      "Epoch: 0, Batch: 516, Loss: 10.209428787231445\n",
      "Epoch: 0, Batch: 517, Loss: 11.662297248840332\n",
      "Epoch: 0, Batch: 518, Loss: 4.744769096374512\n",
      "Epoch: 0, Batch: 519, Loss: 7.304800510406494\n",
      "Epoch: 0, Batch: 520, Loss: 10.374044418334961\n",
      "Epoch: 0, Batch: 521, Loss: 10.525409698486328\n",
      "Epoch: 0, Batch: 522, Loss: 4.791104793548584\n",
      "Epoch: 0, Batch: 523, Loss: 9.463861465454102\n",
      "Epoch: 0, Batch: 524, Loss: 10.491660118103027\n",
      "Epoch: 0, Batch: 525, Loss: 9.261678695678711\n",
      "Epoch: 0, Batch: 526, Loss: 7.007800102233887\n",
      "Epoch: 0, Batch: 527, Loss: 6.9199042320251465\n",
      "Epoch: 0, Batch: 528, Loss: 5.616093158721924\n",
      "Epoch: 0, Batch: 529, Loss: 18.046295166015625\n",
      "Epoch: 0, Batch: 530, Loss: 9.906754493713379\n",
      "Epoch: 0, Batch: 531, Loss: 8.590689659118652\n",
      "Epoch: 0, Batch: 532, Loss: 11.340107917785645\n",
      "Epoch: 0, Batch: 533, Loss: 5.143531799316406\n",
      "Epoch: 0, Batch: 534, Loss: 11.835430145263672\n",
      "Epoch: 0, Batch: 535, Loss: 5.085435390472412\n",
      "Epoch: 0, Batch: 536, Loss: 9.062851905822754\n",
      "Epoch: 0, Batch: 537, Loss: 6.519943714141846\n",
      "Epoch: 0, Batch: 538, Loss: 9.2649507522583\n",
      "Epoch: 0, Batch: 539, Loss: 13.363874435424805\n",
      "Epoch: 0, Batch: 540, Loss: 14.432257652282715\n",
      "Epoch: 0, Batch: 541, Loss: 5.003804683685303\n",
      "Epoch: 0, Batch: 542, Loss: 9.998489379882812\n",
      "Epoch: 0, Batch: 543, Loss: 11.580903053283691\n",
      "Epoch: 0, Batch: 544, Loss: 10.142036437988281\n",
      "Epoch: 0, Batch: 545, Loss: 15.73922348022461\n",
      "Epoch: 0, Batch: 546, Loss: 11.112543106079102\n",
      "Epoch: 0, Batch: 547, Loss: 6.365079879760742\n",
      "Epoch: 0, Batch: 548, Loss: 7.778269290924072\n",
      "Epoch: 0, Batch: 549, Loss: 7.620056629180908\n",
      "Epoch: 0, Batch: 550, Loss: 11.73180866241455\n",
      "Epoch: 0, Batch: 551, Loss: 8.728435516357422\n",
      "Epoch: 0, Batch: 552, Loss: 3.9134654998779297\n",
      "Epoch: 0, Batch: 553, Loss: 3.8429360389709473\n",
      "Epoch: 0, Batch: 554, Loss: 6.787362098693848\n",
      "Epoch: 0, Batch: 555, Loss: 7.2921142578125\n",
      "Epoch: 0, Batch: 556, Loss: 12.893099784851074\n",
      "Epoch: 0, Batch: 557, Loss: 10.523913383483887\n",
      "Epoch: 0, Batch: 558, Loss: 9.533880233764648\n",
      "Epoch: 0, Batch: 559, Loss: 8.29342269897461\n",
      "Epoch: 0, Batch: 560, Loss: 4.394369602203369\n",
      "Epoch: 0, Batch: 561, Loss: 16.965585708618164\n",
      "Epoch: 0, Batch: 562, Loss: 5.838510513305664\n",
      "Epoch: 0, Batch: 563, Loss: 10.31179141998291\n",
      "Epoch: 0, Batch: 564, Loss: 7.602936744689941\n",
      "Epoch: 0, Batch: 565, Loss: 6.325873374938965\n",
      "Epoch: 0, Batch: 566, Loss: 11.822361946105957\n",
      "Epoch: 0, Batch: 567, Loss: 4.608619689941406\n",
      "Epoch: 0, Batch: 568, Loss: 9.166999816894531\n",
      "Epoch: 0, Batch: 569, Loss: 4.995494842529297\n",
      "Epoch: 0, Batch: 570, Loss: 11.466854095458984\n",
      "Epoch: 0, Batch: 571, Loss: 12.113801002502441\n",
      "Epoch: 0, Batch: 572, Loss: 9.336532592773438\n",
      "Epoch: 0, Batch: 573, Loss: 4.543315887451172\n",
      "Epoch: 0, Batch: 574, Loss: 7.563342094421387\n",
      "Epoch: 0, Batch: 575, Loss: 6.497504711151123\n",
      "Epoch: 0, Batch: 576, Loss: 6.439908504486084\n",
      "Epoch: 0, Batch: 577, Loss: 9.546608924865723\n",
      "Epoch: 0, Batch: 578, Loss: 7.530943870544434\n",
      "Epoch: 0, Batch: 579, Loss: 15.612998962402344\n",
      "Epoch: 0, Batch: 580, Loss: 12.347116470336914\n",
      "Epoch: 0, Batch: 581, Loss: 5.837584972381592\n",
      "Epoch: 0, Batch: 582, Loss: 11.104851722717285\n",
      "Epoch: 0, Batch: 583, Loss: 11.068632125854492\n",
      "Epoch: 0, Batch: 584, Loss: 3.917092800140381\n",
      "Epoch: 0, Batch: 585, Loss: 3.2928264141082764\n",
      "Epoch: 0, Batch: 586, Loss: 8.959667205810547\n",
      "Epoch: 0, Batch: 587, Loss: 9.867313385009766\n",
      "Epoch: 0, Batch: 588, Loss: 10.854860305786133\n",
      "Epoch: 0, Batch: 589, Loss: 6.689851760864258\n",
      "Epoch: 0, Batch: 590, Loss: 10.332914352416992\n",
      "Epoch: 0, Batch: 591, Loss: 10.644890785217285\n",
      "Epoch: 0, Batch: 592, Loss: 8.237950325012207\n",
      "Epoch: 0, Batch: 593, Loss: 9.40058422088623\n",
      "Epoch: 0, Batch: 594, Loss: 3.4347939491271973\n",
      "Epoch: 0, Batch: 595, Loss: 3.7046473026275635\n",
      "Epoch: 0, Batch: 596, Loss: 8.910292625427246\n",
      "Epoch: 0, Batch: 597, Loss: 8.670289993286133\n",
      "Epoch: 0, Batch: 598, Loss: 9.032978057861328\n",
      "Epoch: 0, Batch: 599, Loss: 4.432275772094727\n",
      "Epoch: 0, Batch: 600, Loss: 7.183972358703613\n",
      "Epoch: 0, Batch: 601, Loss: 9.87288761138916\n",
      "Epoch: 0, Batch: 602, Loss: 14.206747055053711\n",
      "Epoch: 0, Batch: 603, Loss: 6.539061069488525\n",
      "Epoch: 0, Batch: 604, Loss: 7.063144683837891\n",
      "Epoch: 0, Batch: 605, Loss: 4.911840438842773\n",
      "Epoch: 0, Batch: 606, Loss: 6.885486602783203\n",
      "Epoch: 0, Batch: 607, Loss: 10.521249771118164\n",
      "Epoch: 0, Batch: 608, Loss: 6.886234283447266\n",
      "Epoch: 0, Batch: 609, Loss: 7.069177627563477\n",
      "Epoch: 0, Batch: 610, Loss: 10.317890167236328\n",
      "Epoch: 0, Batch: 611, Loss: 6.666544437408447\n",
      "Epoch: 0, Batch: 612, Loss: 8.078353881835938\n",
      "Epoch: 0, Batch: 613, Loss: 5.342152118682861\n",
      "Epoch: 0, Batch: 614, Loss: 6.594152927398682\n",
      "Epoch: 0, Batch: 615, Loss: 11.231038093566895\n",
      "Epoch: 0, Batch: 616, Loss: 4.557583808898926\n",
      "Epoch: 0, Batch: 617, Loss: 5.1148481369018555\n",
      "Epoch: 0, Batch: 618, Loss: 6.438088417053223\n",
      "Epoch: 0, Batch: 619, Loss: 6.7372846603393555\n",
      "Epoch: 0, Batch: 620, Loss: 10.027261734008789\n",
      "Epoch: 0, Batch: 621, Loss: 6.288264274597168\n",
      "Epoch: 0, Batch: 622, Loss: 6.9337849617004395\n",
      "Epoch: 0, Batch: 623, Loss: 5.224511623382568\n",
      "Epoch: 0, Batch: 624, Loss: 7.165163516998291\n",
      "Epoch: 0, Batch: 625, Loss: 7.934986591339111\n",
      "Epoch: 0, Batch: 626, Loss: 5.054781913757324\n",
      "Epoch: 0, Batch: 627, Loss: 14.255290031433105\n",
      "Epoch: 0, Batch: 628, Loss: 9.104724884033203\n",
      "Epoch: 0, Batch: 629, Loss: 4.4602131843566895\n",
      "Epoch: 0, Batch: 630, Loss: 6.547325134277344\n",
      "Epoch: 0, Batch: 631, Loss: 7.487457275390625\n",
      "Epoch: 0, Batch: 632, Loss: 9.259624481201172\n",
      "Epoch: 0, Batch: 633, Loss: 11.339630126953125\n",
      "Epoch: 0, Batch: 634, Loss: 4.978424072265625\n",
      "Epoch: 0, Batch: 635, Loss: 9.464529037475586\n",
      "Epoch: 0, Batch: 636, Loss: 5.440692901611328\n",
      "Epoch: 0, Batch: 637, Loss: 8.053396224975586\n",
      "Epoch: 0, Batch: 638, Loss: 9.671545028686523\n",
      "Epoch: 0, Batch: 639, Loss: 3.1281614303588867\n",
      "Epoch: 0, Batch: 640, Loss: 3.0566630363464355\n",
      "Epoch: 0, Batch: 641, Loss: 6.630472660064697\n",
      "Epoch: 0, Batch: 642, Loss: 5.414389610290527\n",
      "Epoch: 0, Batch: 643, Loss: 13.2605619430542\n",
      "Epoch: 0, Batch: 644, Loss: 8.82448959350586\n",
      "Epoch: 0, Batch: 645, Loss: 10.528904914855957\n",
      "Epoch: 0, Batch: 646, Loss: 11.947925567626953\n",
      "Epoch: 0, Batch: 647, Loss: 8.646662712097168\n",
      "Epoch: 0, Batch: 648, Loss: 9.419360160827637\n",
      "Epoch: 0, Batch: 649, Loss: 7.497335433959961\n",
      "Epoch: 0, Batch: 650, Loss: 11.192093849182129\n",
      "Epoch: 0, Batch: 651, Loss: 10.014717102050781\n",
      "Epoch: 0, Batch: 652, Loss: 13.553693771362305\n",
      "Epoch: 0, Batch: 653, Loss: 9.75136947631836\n",
      "Epoch: 0, Batch: 654, Loss: 9.388330459594727\n",
      "Epoch: 0, Batch: 655, Loss: 5.875087261199951\n",
      "Epoch: 0, Batch: 656, Loss: 9.341798782348633\n",
      "Epoch: 0, Batch: 657, Loss: 3.0520310401916504\n",
      "Epoch: 0, Batch: 658, Loss: 6.383359909057617\n",
      "Epoch: 0, Batch: 659, Loss: 10.507262229919434\n",
      "Epoch: 0, Batch: 660, Loss: 13.11034107208252\n",
      "Epoch: 0, Batch: 661, Loss: 7.666614055633545\n",
      "Epoch: 0, Batch: 662, Loss: 4.119901180267334\n",
      "Epoch: 0, Batch: 663, Loss: 10.242260932922363\n",
      "Epoch: 0, Batch: 664, Loss: 7.0466084480285645\n",
      "Epoch: 0, Batch: 665, Loss: 13.671958923339844\n",
      "Epoch: 0, Batch: 666, Loss: 2.2621257305145264\n",
      "Epoch: 0, Batch: 667, Loss: 10.011832237243652\n",
      "Epoch: 0, Batch: 668, Loss: 9.833683013916016\n",
      "Epoch: 0, Batch: 669, Loss: 4.382185459136963\n",
      "Epoch: 0, Batch: 670, Loss: 13.464764595031738\n",
      "Epoch: 0, Batch: 671, Loss: 10.707836151123047\n",
      "Epoch: 0, Batch: 672, Loss: 10.678560256958008\n",
      "Epoch: 0, Batch: 673, Loss: 7.210010528564453\n",
      "Epoch: 0, Batch: 674, Loss: 8.189493179321289\n",
      "Epoch: 0, Batch: 675, Loss: 5.628764629364014\n",
      "Epoch: 0, Batch: 676, Loss: 13.947632789611816\n",
      "Epoch: 0, Batch: 677, Loss: 9.363018035888672\n",
      "Epoch: 0, Batch: 678, Loss: 5.700057029724121\n",
      "Epoch: 0, Batch: 679, Loss: 8.457985877990723\n",
      "Epoch: 0, Batch: 680, Loss: 5.780606269836426\n",
      "Epoch: 0, Batch: 681, Loss: 8.659013748168945\n",
      "Epoch: 0, Batch: 682, Loss: 9.510570526123047\n",
      "Epoch: 0, Batch: 683, Loss: 4.618284702301025\n",
      "Epoch: 0, Batch: 684, Loss: 4.784834384918213\n",
      "Epoch: 0, Batch: 685, Loss: 6.221455097198486\n",
      "Epoch: 0, Batch: 686, Loss: 9.765155792236328\n",
      "Epoch: 0, Batch: 687, Loss: 6.443795680999756\n",
      "Epoch: 0, Batch: 688, Loss: 6.552335739135742\n",
      "Epoch: 0, Batch: 689, Loss: 5.436015605926514\n",
      "Epoch: 0, Batch: 690, Loss: 9.32520580291748\n",
      "Epoch: 0, Batch: 691, Loss: 10.047279357910156\n",
      "Epoch: 0, Batch: 692, Loss: 4.729160785675049\n",
      "Epoch: 0, Batch: 693, Loss: 4.624688148498535\n",
      "Epoch: 0, Batch: 694, Loss: 6.807467460632324\n",
      "Epoch: 0, Batch: 695, Loss: 9.3900146484375\n",
      "Epoch: 0, Batch: 696, Loss: 8.647479057312012\n",
      "Epoch: 0, Batch: 697, Loss: 5.816099166870117\n",
      "Epoch: 0, Batch: 698, Loss: 11.016548156738281\n",
      "Epoch: 0, Batch: 699, Loss: 6.076340198516846\n",
      "Epoch: 0, Batch: 700, Loss: 12.142242431640625\n",
      "Epoch: 0, Batch: 701, Loss: 9.053743362426758\n",
      "Epoch: 0, Batch: 702, Loss: 8.517106056213379\n",
      "Epoch: 0, Batch: 703, Loss: 2.3330578804016113\n",
      "Epoch: 0, Batch: 704, Loss: 10.570197105407715\n",
      "Epoch: 0, Batch: 705, Loss: 5.712630271911621\n",
      "Epoch: 0, Batch: 706, Loss: 9.960229873657227\n",
      "Epoch: 0, Batch: 707, Loss: 5.43592643737793\n",
      "Epoch: 0, Batch: 708, Loss: 5.628958225250244\n",
      "Epoch: 0, Batch: 709, Loss: 13.320808410644531\n",
      "Epoch: 0, Batch: 710, Loss: 5.8398542404174805\n",
      "Epoch: 0, Batch: 711, Loss: 5.502135276794434\n",
      "Epoch: 0, Batch: 712, Loss: 5.722259521484375\n",
      "Epoch: 0, Batch: 713, Loss: 5.481069564819336\n",
      "Epoch: 0, Batch: 714, Loss: 6.796398639678955\n",
      "Epoch: 0, Batch: 715, Loss: 5.631617546081543\n",
      "Epoch: 0, Batch: 716, Loss: 10.93388557434082\n",
      "Epoch: 0, Batch: 717, Loss: 5.227910995483398\n",
      "Epoch: 0, Batch: 718, Loss: 6.916319847106934\n",
      "Epoch: 0, Batch: 719, Loss: 6.4960198402404785\n",
      "Epoch: 0, Batch: 720, Loss: 7.224080562591553\n",
      "Epoch: 0, Batch: 721, Loss: 9.480611801147461\n",
      "Epoch: 0, Batch: 722, Loss: 4.706512451171875\n",
      "Epoch: 0, Batch: 723, Loss: 5.574103355407715\n",
      "Epoch: 0, Batch: 724, Loss: 5.736891746520996\n",
      "Epoch: 0, Batch: 725, Loss: 5.3961005210876465\n",
      "Epoch: 0, Batch: 726, Loss: 5.460465431213379\n",
      "Epoch: 0, Batch: 727, Loss: 7.548612594604492\n",
      "Epoch: 0, Batch: 728, Loss: 7.073306083679199\n",
      "Epoch: 0, Batch: 729, Loss: 5.790584564208984\n",
      "Epoch: 0, Batch: 730, Loss: 6.166856288909912\n",
      "Epoch: 0, Batch: 731, Loss: 12.27499771118164\n",
      "Epoch: 0, Batch: 732, Loss: 5.342196464538574\n",
      "Epoch: 0, Batch: 733, Loss: 10.9906644821167\n",
      "Epoch: 0, Batch: 734, Loss: 9.34952163696289\n",
      "Epoch: 0, Batch: 735, Loss: 2.832158088684082\n",
      "Epoch: 0, Batch: 736, Loss: 4.605415344238281\n",
      "Epoch: 0, Batch: 737, Loss: 4.250309467315674\n",
      "Epoch: 0, Batch: 738, Loss: 6.152853488922119\n",
      "Epoch: 0, Batch: 739, Loss: 4.9653520584106445\n",
      "Epoch: 0, Batch: 740, Loss: 5.116180896759033\n",
      "Epoch: 0, Batch: 741, Loss: 6.232769966125488\n",
      "Epoch: 0, Batch: 742, Loss: 2.9745023250579834\n",
      "Epoch: 0, Batch: 743, Loss: 7.249389171600342\n",
      "Epoch: 0, Batch: 744, Loss: 7.706927299499512\n",
      "Epoch: 0, Batch: 745, Loss: 5.716936111450195\n",
      "Epoch: 0, Batch: 746, Loss: 5.7083330154418945\n",
      "Epoch: 0, Batch: 747, Loss: 7.310375690460205\n",
      "Epoch: 0, Batch: 748, Loss: 9.229816436767578\n",
      "Epoch: 0, Batch: 749, Loss: 8.46092414855957\n",
      "Epoch: 0, Batch: 750, Loss: 9.487730026245117\n",
      "Epoch: 0, Batch: 751, Loss: 6.76054573059082\n",
      "Epoch: 0, Batch: 752, Loss: 6.515865802764893\n",
      "Epoch: 0, Batch: 753, Loss: 3.177212715148926\n",
      "Epoch: 0, Batch: 754, Loss: 5.896238327026367\n",
      "Epoch: 0, Batch: 755, Loss: 4.4099040031433105\n",
      "Epoch: 0, Batch: 756, Loss: 8.087397575378418\n",
      "Epoch: 0, Batch: 757, Loss: 4.9137983322143555\n",
      "Epoch: 0, Batch: 758, Loss: 4.430307388305664\n",
      "Epoch: 0, Batch: 759, Loss: 10.859113693237305\n",
      "Epoch: 0, Batch: 760, Loss: 6.101373195648193\n",
      "Epoch: 0, Batch: 761, Loss: 3.4033594131469727\n",
      "Epoch: 0, Batch: 762, Loss: 3.7039642333984375\n",
      "Epoch: 0, Batch: 763, Loss: 7.868292808532715\n",
      "Epoch: 0, Batch: 764, Loss: 11.711912155151367\n",
      "Epoch: 0, Batch: 765, Loss: 7.858364582061768\n",
      "Epoch: 0, Batch: 766, Loss: 5.816229343414307\n",
      "Epoch: 0, Batch: 767, Loss: 5.378438949584961\n",
      "Epoch: 0, Batch: 768, Loss: 6.111072063446045\n",
      "Epoch: 0, Batch: 769, Loss: 6.673783302307129\n",
      "Epoch: 0, Batch: 770, Loss: 6.142519950866699\n",
      "Epoch: 0, Batch: 771, Loss: 8.894193649291992\n",
      "Epoch: 0, Batch: 772, Loss: 2.9085025787353516\n",
      "Epoch: 0, Batch: 773, Loss: 4.642123222351074\n",
      "Epoch: 0, Batch: 774, Loss: 10.212089538574219\n",
      "Epoch: 0, Batch: 775, Loss: 4.939382553100586\n",
      "Epoch: 0, Batch: 776, Loss: 9.984200477600098\n",
      "Epoch: 0, Batch: 777, Loss: 7.155447959899902\n",
      "Epoch: 0, Batch: 778, Loss: 4.785300254821777\n",
      "Epoch: 0, Batch: 779, Loss: 4.602473735809326\n",
      "Epoch: 0, Batch: 780, Loss: 2.696361541748047\n",
      "Epoch: 0, Batch: 781, Loss: 10.514500617980957\n",
      "Epoch: 0, Batch: 782, Loss: 8.333780288696289\n",
      "Epoch: 0, Batch: 783, Loss: 7.177046775817871\n",
      "Epoch: 0, Batch: 784, Loss: 4.843581199645996\n",
      "Epoch: 0, Batch: 785, Loss: 5.216979503631592\n",
      "Epoch: 0, Batch: 786, Loss: 3.0348095893859863\n",
      "Epoch: 0, Batch: 787, Loss: 9.520326614379883\n",
      "Epoch: 0, Batch: 788, Loss: 7.202781677246094\n",
      "Epoch: 0, Batch: 789, Loss: 8.765691757202148\n",
      "Epoch: 0, Batch: 790, Loss: 6.3239521980285645\n",
      "Epoch: 0, Batch: 791, Loss: 4.619924068450928\n",
      "Epoch: 0, Batch: 792, Loss: 5.195046424865723\n",
      "Epoch: 0, Batch: 793, Loss: 7.247214317321777\n",
      "Epoch: 0, Batch: 794, Loss: 8.757513046264648\n",
      "Epoch: 0, Batch: 795, Loss: 6.3483686447143555\n",
      "Epoch: 0, Batch: 796, Loss: 10.986532211303711\n",
      "Epoch: 0, Batch: 797, Loss: 2.417837619781494\n",
      "Epoch: 0, Batch: 798, Loss: 11.176410675048828\n",
      "Epoch: 0, Batch: 799, Loss: 5.639015197753906\n",
      "Epoch: 0, Batch: 800, Loss: 13.269754409790039\n",
      "Epoch: 0, Batch: 801, Loss: 11.092122077941895\n",
      "Epoch: 0, Batch: 802, Loss: 4.525393486022949\n",
      "Epoch: 0, Batch: 803, Loss: 4.747114658355713\n",
      "Epoch: 0, Batch: 804, Loss: 8.355535507202148\n",
      "Epoch: 0, Batch: 805, Loss: 9.683415412902832\n",
      "Epoch: 0, Batch: 806, Loss: 3.505934715270996\n",
      "Epoch: 0, Batch: 807, Loss: 4.083096981048584\n",
      "Epoch: 0, Batch: 808, Loss: 7.442279815673828\n",
      "Epoch: 0, Batch: 809, Loss: 7.823768615722656\n",
      "Epoch: 0, Batch: 810, Loss: 5.344948768615723\n",
      "Epoch: 0, Batch: 811, Loss: 8.55465316772461\n",
      "Epoch: 0, Batch: 812, Loss: 5.156126976013184\n",
      "Epoch: 0, Batch: 813, Loss: 8.50496768951416\n",
      "Epoch: 0, Batch: 814, Loss: 3.944364070892334\n",
      "Epoch: 0, Batch: 815, Loss: 12.524230003356934\n",
      "Epoch: 0, Batch: 816, Loss: 6.182002067565918\n",
      "Epoch: 0, Batch: 817, Loss: 3.0853233337402344\n",
      "Epoch: 0, Batch: 818, Loss: 2.8868818283081055\n",
      "Epoch: 0, Batch: 819, Loss: 16.610231399536133\n",
      "Epoch: 0, Batch: 820, Loss: 8.715615272521973\n",
      "Epoch: 0, Batch: 821, Loss: 7.765577793121338\n",
      "Epoch: 0, Batch: 822, Loss: 3.465876579284668\n",
      "Epoch: 0, Batch: 823, Loss: 10.498376846313477\n",
      "Epoch: 0, Batch: 824, Loss: 3.0530190467834473\n",
      "Epoch: 0, Batch: 825, Loss: 5.595372676849365\n",
      "Epoch: 0, Batch: 826, Loss: 8.262981414794922\n",
      "Epoch: 0, Batch: 827, Loss: 3.6062729358673096\n",
      "Epoch: 0, Batch: 828, Loss: 6.763615131378174\n",
      "Epoch: 0, Batch: 829, Loss: 6.469728469848633\n",
      "Epoch: 0, Batch: 830, Loss: 6.189480304718018\n",
      "Epoch: 0, Batch: 831, Loss: 7.444219589233398\n",
      "Epoch: 0, Batch: 832, Loss: 9.262552261352539\n",
      "Epoch: 0, Batch: 833, Loss: 7.440462112426758\n",
      "Epoch: 0, Batch: 834, Loss: 4.237860679626465\n",
      "Epoch: 0, Batch: 835, Loss: 8.384392738342285\n",
      "Epoch: 0, Batch: 836, Loss: 1.7957344055175781\n",
      "Epoch: 0, Batch: 837, Loss: 4.252682209014893\n",
      "Epoch: 0, Batch: 838, Loss: 2.627274751663208\n",
      "Epoch: 0, Batch: 839, Loss: 5.1774444580078125\n",
      "Epoch: 0, Batch: 840, Loss: 6.197990417480469\n",
      "Epoch: 0, Batch: 841, Loss: 6.769708633422852\n",
      "Epoch: 0, Batch: 842, Loss: 7.17662239074707\n",
      "Epoch: 0, Batch: 843, Loss: 3.1281814575195312\n",
      "Epoch: 0, Batch: 844, Loss: 6.075747966766357\n",
      "Epoch: 0, Batch: 845, Loss: 6.589602470397949\n",
      "Epoch: 0, Batch: 846, Loss: 6.6736955642700195\n",
      "Epoch: 0, Batch: 847, Loss: 9.524438858032227\n",
      "Epoch: 0, Batch: 848, Loss: 4.08046293258667\n",
      "Epoch: 0, Batch: 849, Loss: 2.3669490814208984\n",
      "Epoch: 0, Batch: 850, Loss: 4.504302501678467\n",
      "Epoch: 0, Batch: 851, Loss: 5.909536361694336\n",
      "Epoch: 0, Batch: 852, Loss: 9.994918823242188\n",
      "Epoch: 0, Batch: 853, Loss: 4.385462284088135\n",
      "Epoch: 0, Batch: 854, Loss: 6.036169052124023\n",
      "Epoch: 0, Batch: 855, Loss: 4.077080726623535\n",
      "Epoch: 0, Batch: 856, Loss: 4.20009183883667\n",
      "Epoch: 0, Batch: 857, Loss: 5.02931022644043\n",
      "Epoch: 0, Batch: 858, Loss: 9.83989143371582\n",
      "Epoch: 0, Batch: 859, Loss: 6.508563995361328\n",
      "Epoch: 0, Batch: 860, Loss: 5.784191608428955\n",
      "Epoch: 0, Batch: 861, Loss: 6.274191856384277\n",
      "Epoch: 0, Batch: 862, Loss: 8.479195594787598\n",
      "Epoch: 0, Batch: 863, Loss: 2.5079267024993896\n",
      "Epoch: 0, Batch: 864, Loss: 4.346510887145996\n",
      "Epoch: 0, Batch: 865, Loss: 4.78693962097168\n",
      "Epoch: 0, Batch: 866, Loss: 4.380960464477539\n",
      "Epoch: 0, Batch: 867, Loss: 7.813265800476074\n",
      "Epoch: 0, Batch: 868, Loss: 3.727099657058716\n",
      "Epoch: 0, Batch: 869, Loss: 4.446286201477051\n",
      "Epoch: 0, Batch: 870, Loss: 9.572469711303711\n",
      "Epoch: 0, Batch: 871, Loss: 7.452518939971924\n",
      "Epoch: 0, Batch: 872, Loss: 7.263655185699463\n",
      "Epoch: 0, Batch: 873, Loss: 3.556816339492798\n",
      "Epoch: 0, Batch: 874, Loss: 6.891849517822266\n",
      "Epoch: 0, Batch: 875, Loss: 6.408961296081543\n",
      "Epoch: 0, Batch: 876, Loss: 3.1870384216308594\n",
      "Epoch: 0, Batch: 877, Loss: 8.16275691986084\n",
      "Epoch: 0, Batch: 878, Loss: 7.195567607879639\n",
      "Epoch: 0, Batch: 879, Loss: 7.558331489562988\n",
      "Epoch: 0, Batch: 880, Loss: 3.3670132160186768\n",
      "Epoch: 0, Batch: 881, Loss: 9.049459457397461\n",
      "Epoch: 0, Batch: 882, Loss: 13.04470157623291\n",
      "Epoch: 0, Batch: 883, Loss: 5.881573677062988\n",
      "Epoch: 0, Batch: 884, Loss: 5.639811992645264\n",
      "Epoch: 0, Batch: 885, Loss: 7.190553665161133\n",
      "Epoch: 0, Batch: 886, Loss: 8.679178237915039\n",
      "Epoch: 0, Batch: 887, Loss: 6.518833637237549\n",
      "Epoch: 0, Batch: 888, Loss: 1.3648815155029297\n",
      "Epoch: 0, Batch: 889, Loss: 9.679356575012207\n",
      "Epoch: 0, Batch: 890, Loss: 4.374481201171875\n",
      "Epoch: 0, Batch: 891, Loss: 4.896177768707275\n",
      "Epoch: 0, Batch: 892, Loss: 4.117053031921387\n",
      "Epoch: 0, Batch: 893, Loss: 2.6655304431915283\n",
      "Epoch: 0, Batch: 894, Loss: 2.6533823013305664\n",
      "Epoch: 0, Batch: 895, Loss: 3.950230360031128\n",
      "Epoch: 0, Batch: 896, Loss: 5.9299540519714355\n",
      "Epoch: 0, Batch: 897, Loss: 8.475862503051758\n",
      "Epoch: 0, Batch: 898, Loss: 4.097217082977295\n",
      "Epoch: 0, Batch: 899, Loss: 7.717731475830078\n",
      "Epoch: 0, Batch: 900, Loss: 3.6283886432647705\n",
      "Epoch: 0, Batch: 901, Loss: 8.54880142211914\n",
      "Epoch: 0, Batch: 902, Loss: 7.218169212341309\n",
      "Epoch: 0, Batch: 903, Loss: 7.061388969421387\n",
      "Epoch: 0, Batch: 904, Loss: 5.841385364532471\n",
      "Epoch: 0, Batch: 905, Loss: 5.392787456512451\n",
      "Epoch: 0, Batch: 906, Loss: 6.320647239685059\n",
      "Epoch: 0, Batch: 907, Loss: 6.080068111419678\n",
      "Epoch: 0, Batch: 908, Loss: 4.402572154998779\n",
      "Epoch: 0, Batch: 909, Loss: 7.987309455871582\n",
      "Epoch: 0, Batch: 910, Loss: 4.745358943939209\n",
      "Epoch: 0, Batch: 911, Loss: 5.996502876281738\n",
      "Epoch: 0, Batch: 912, Loss: 8.569567680358887\n",
      "Epoch: 0, Batch: 913, Loss: 6.561010360717773\n",
      "Epoch: 0, Batch: 914, Loss: 8.625799179077148\n",
      "Epoch: 0, Batch: 915, Loss: 4.799138069152832\n",
      "Epoch: 0, Batch: 916, Loss: 4.5354695320129395\n",
      "Epoch: 0, Batch: 917, Loss: 8.395301818847656\n",
      "Epoch: 0, Batch: 918, Loss: 6.142076015472412\n",
      "Epoch: 0, Batch: 919, Loss: 8.36024284362793\n",
      "Epoch: 0, Batch: 920, Loss: 5.221941947937012\n",
      "Epoch: 0, Batch: 921, Loss: 5.3712077140808105\n",
      "Epoch: 0, Batch: 922, Loss: 7.05811071395874\n",
      "Epoch: 0, Batch: 923, Loss: 6.958263397216797\n",
      "Epoch: 0, Batch: 924, Loss: 8.102815628051758\n",
      "Epoch: 0, Batch: 925, Loss: 5.946551322937012\n",
      "Epoch: 0, Batch: 926, Loss: 4.3243889808654785\n",
      "Epoch: 0, Batch: 927, Loss: 5.068621635437012\n",
      "Epoch: 0, Batch: 928, Loss: 9.21962833404541\n",
      "Epoch: 0, Batch: 929, Loss: 5.2571306228637695\n",
      "Epoch: 0, Batch: 930, Loss: 7.230408668518066\n",
      "Epoch: 0, Batch: 931, Loss: 5.210141658782959\n",
      "Epoch: 0, Batch: 932, Loss: 6.104877471923828\n",
      "Epoch: 0, Batch: 933, Loss: 2.756969451904297\n",
      "Epoch: 0, Batch: 934, Loss: 3.927520751953125\n",
      "Epoch: 0, Batch: 935, Loss: 10.279383659362793\n",
      "Epoch: 0, Batch: 936, Loss: 7.99288272857666\n",
      "Epoch: 0, Batch: 937, Loss: 7.035484790802002\n",
      "Epoch: 0, Batch: 938, Loss: 1.8158650398254395\n",
      "Epoch: 0, Batch: 939, Loss: 4.215510845184326\n",
      "Epoch: 0, Batch: 940, Loss: 6.988053321838379\n",
      "Epoch: 0, Batch: 941, Loss: 1.6096374988555908\n",
      "Epoch: 0, Batch: 942, Loss: 9.5410737991333\n",
      "Epoch: 0, Batch: 943, Loss: 5.136918067932129\n",
      "Epoch: 0, Batch: 944, Loss: 5.329623699188232\n",
      "Epoch: 0, Batch: 945, Loss: 2.7092983722686768\n",
      "Epoch: 0, Batch: 946, Loss: 7.373180389404297\n",
      "Epoch: 0, Batch: 947, Loss: 1.5387871265411377\n",
      "Epoch: 0, Batch: 948, Loss: 4.57013463973999\n",
      "Epoch: 0, Batch: 949, Loss: 4.224353790283203\n",
      "Epoch: 0, Batch: 950, Loss: 5.241177558898926\n",
      "Epoch: 0, Batch: 951, Loss: 1.7461810111999512\n",
      "Epoch: 0, Batch: 952, Loss: 5.828892707824707\n",
      "Epoch: 0, Batch: 953, Loss: 7.0691680908203125\n",
      "Epoch: 0, Batch: 954, Loss: 3.9653854370117188\n",
      "Epoch: 0, Batch: 955, Loss: 7.32948637008667\n",
      "Epoch: 0, Batch: 956, Loss: 5.566628456115723\n",
      "Epoch: 0, Batch: 957, Loss: 6.716125011444092\n",
      "Epoch: 0, Batch: 958, Loss: 8.40440845489502\n",
      "Epoch: 0, Batch: 959, Loss: 8.769051551818848\n",
      "Epoch: 0, Batch: 960, Loss: 5.001504898071289\n",
      "Epoch: 0, Batch: 961, Loss: 3.0873188972473145\n",
      "Epoch: 0, Batch: 962, Loss: 5.31087589263916\n",
      "Epoch: 0, Batch: 963, Loss: 9.00343132019043\n",
      "Epoch: 0, Batch: 964, Loss: 4.390912055969238\n",
      "Epoch: 0, Batch: 965, Loss: 10.020575523376465\n",
      "Epoch: 0, Batch: 966, Loss: 9.626609802246094\n",
      "Epoch: 0, Batch: 967, Loss: 3.83988618850708\n",
      "Epoch: 0, Batch: 968, Loss: 7.829306602478027\n",
      "Epoch: 0, Batch: 969, Loss: 3.5024144649505615\n",
      "Epoch: 0, Batch: 970, Loss: 3.6693663597106934\n",
      "Epoch: 0, Batch: 971, Loss: 1.9560749530792236\n",
      "Epoch: 0, Batch: 972, Loss: 11.305964469909668\n",
      "Epoch: 0, Batch: 973, Loss: 9.638211250305176\n",
      "Epoch: 0, Batch: 974, Loss: 1.752700686454773\n",
      "Epoch: 0, Batch: 975, Loss: 4.519562721252441\n",
      "Epoch: 0, Batch: 976, Loss: 5.449332237243652\n",
      "Epoch: 0, Batch: 977, Loss: 2.950464963912964\n",
      "Epoch: 0, Batch: 978, Loss: 6.050266265869141\n",
      "Epoch: 0, Batch: 979, Loss: 5.46873140335083\n",
      "Epoch: 0, Batch: 980, Loss: 6.4855523109436035\n",
      "Epoch: 0, Batch: 981, Loss: 6.587937831878662\n",
      "Epoch: 0, Batch: 982, Loss: 6.9426398277282715\n",
      "Epoch: 0, Batch: 983, Loss: 3.399808168411255\n",
      "Epoch: 0, Batch: 984, Loss: 5.8814473152160645\n",
      "Epoch: 0, Batch: 985, Loss: 3.8324198722839355\n",
      "Epoch: 0, Batch: 986, Loss: 2.974205732345581\n",
      "Epoch: 0, Batch: 987, Loss: 6.829207420349121\n",
      "Epoch: 0, Batch: 988, Loss: 5.825406074523926\n",
      "Epoch: 0, Batch: 989, Loss: 8.317689895629883\n",
      "Epoch: 0, Batch: 990, Loss: 8.569796562194824\n",
      "Epoch: 0, Batch: 991, Loss: 15.548429489135742\n",
      "Epoch: 0, Batch: 992, Loss: 4.269614219665527\n",
      "Epoch: 0, Batch: 993, Loss: 5.499242782592773\n",
      "Epoch: 0, Batch: 994, Loss: 3.766726016998291\n",
      "Epoch: 0, Batch: 995, Loss: 5.189301013946533\n",
      "Epoch: 0, Batch: 996, Loss: 6.153554916381836\n",
      "Epoch: 0, Batch: 997, Loss: 4.675692081451416\n",
      "Epoch: 0, Batch: 998, Loss: 7.914340496063232\n",
      "Epoch: 0, Batch: 999, Loss: 5.127537727355957\n",
      "Epoch: 1, Batch: 0, Loss: 3.0692408084869385\n",
      "Epoch: 1, Batch: 1, Loss: 5.137968063354492\n",
      "Epoch: 1, Batch: 2, Loss: 6.622781753540039\n",
      "Epoch: 1, Batch: 3, Loss: 2.941176414489746\n",
      "Epoch: 1, Batch: 4, Loss: 6.122215747833252\n",
      "Epoch: 1, Batch: 5, Loss: 4.561553478240967\n",
      "Epoch: 1, Batch: 6, Loss: 2.961195230484009\n",
      "Epoch: 1, Batch: 7, Loss: 5.037652015686035\n",
      "Epoch: 1, Batch: 8, Loss: 3.2812061309814453\n",
      "Epoch: 1, Batch: 9, Loss: 4.383380889892578\n",
      "Epoch: 1, Batch: 10, Loss: 9.324153900146484\n",
      "Epoch: 1, Batch: 11, Loss: 3.0929980278015137\n",
      "Epoch: 1, Batch: 12, Loss: 7.4117231369018555\n",
      "Epoch: 1, Batch: 13, Loss: 5.6398515701293945\n",
      "Epoch: 1, Batch: 14, Loss: 5.7646565437316895\n",
      "Epoch: 1, Batch: 15, Loss: 6.888631820678711\n",
      "Epoch: 1, Batch: 16, Loss: 5.709353446960449\n",
      "Epoch: 1, Batch: 17, Loss: 7.085633754730225\n",
      "Epoch: 1, Batch: 18, Loss: 2.560155153274536\n",
      "Epoch: 1, Batch: 19, Loss: 2.7228751182556152\n",
      "Epoch: 1, Batch: 20, Loss: 6.712955474853516\n",
      "Epoch: 1, Batch: 21, Loss: 3.6792712211608887\n",
      "Epoch: 1, Batch: 22, Loss: 5.962608337402344\n",
      "Epoch: 1, Batch: 23, Loss: 3.4419760704040527\n",
      "Epoch: 1, Batch: 24, Loss: 4.9163007736206055\n",
      "Epoch: 1, Batch: 25, Loss: 2.631988048553467\n",
      "Epoch: 1, Batch: 26, Loss: 5.812685489654541\n",
      "Epoch: 1, Batch: 27, Loss: 8.090943336486816\n",
      "Epoch: 1, Batch: 28, Loss: 3.255679130554199\n",
      "Epoch: 1, Batch: 29, Loss: 7.159938335418701\n",
      "Epoch: 1, Batch: 30, Loss: 3.0144693851470947\n",
      "Epoch: 1, Batch: 31, Loss: 2.3173904418945312\n",
      "Epoch: 1, Batch: 32, Loss: 6.191976547241211\n",
      "Epoch: 1, Batch: 33, Loss: 6.635544776916504\n",
      "Epoch: 1, Batch: 34, Loss: 2.020763397216797\n",
      "Epoch: 1, Batch: 35, Loss: 4.705074310302734\n",
      "Epoch: 1, Batch: 36, Loss: 3.3082454204559326\n",
      "Epoch: 1, Batch: 37, Loss: 4.058996200561523\n",
      "Epoch: 1, Batch: 38, Loss: 7.362371921539307\n",
      "Epoch: 1, Batch: 39, Loss: 4.124096870422363\n",
      "Epoch: 1, Batch: 40, Loss: 5.500064849853516\n",
      "Epoch: 1, Batch: 41, Loss: 3.7975709438323975\n",
      "Epoch: 1, Batch: 42, Loss: 5.96541690826416\n",
      "Epoch: 1, Batch: 43, Loss: 4.619275093078613\n",
      "Epoch: 1, Batch: 44, Loss: 8.1221923828125\n",
      "Epoch: 1, Batch: 45, Loss: 4.102603912353516\n",
      "Epoch: 1, Batch: 46, Loss: 3.2681005001068115\n",
      "Epoch: 1, Batch: 47, Loss: 5.532019138336182\n",
      "Epoch: 1, Batch: 48, Loss: 5.060712814331055\n",
      "Epoch: 1, Batch: 49, Loss: 3.021801233291626\n",
      "Epoch: 1, Batch: 50, Loss: 5.3790283203125\n",
      "Epoch: 1, Batch: 51, Loss: 3.400123357772827\n",
      "Epoch: 1, Batch: 52, Loss: 7.026162147521973\n",
      "Epoch: 1, Batch: 53, Loss: 4.595892906188965\n",
      "Epoch: 1, Batch: 54, Loss: 6.646804332733154\n",
      "Epoch: 1, Batch: 55, Loss: 4.198945045471191\n",
      "Epoch: 1, Batch: 56, Loss: 7.118025302886963\n",
      "Epoch: 1, Batch: 57, Loss: 5.205912113189697\n",
      "Epoch: 1, Batch: 58, Loss: 3.9991602897644043\n",
      "Epoch: 1, Batch: 59, Loss: 10.192052841186523\n",
      "Epoch: 1, Batch: 60, Loss: 2.3704309463500977\n",
      "Epoch: 1, Batch: 61, Loss: 5.923337936401367\n",
      "Epoch: 1, Batch: 62, Loss: 6.112944602966309\n",
      "Epoch: 1, Batch: 63, Loss: 8.73958969116211\n",
      "Epoch: 1, Batch: 64, Loss: 4.561149597167969\n",
      "Epoch: 1, Batch: 65, Loss: 4.785886764526367\n",
      "Epoch: 1, Batch: 66, Loss: 8.9407958984375\n",
      "Epoch: 1, Batch: 67, Loss: 5.325011253356934\n",
      "Epoch: 1, Batch: 68, Loss: 4.987738609313965\n",
      "Epoch: 1, Batch: 69, Loss: 3.8950459957122803\n",
      "Epoch: 1, Batch: 70, Loss: 7.03137731552124\n",
      "Epoch: 1, Batch: 71, Loss: 7.888073444366455\n",
      "Epoch: 1, Batch: 72, Loss: 6.378474712371826\n",
      "Epoch: 1, Batch: 73, Loss: 8.068733215332031\n",
      "Epoch: 1, Batch: 74, Loss: 4.468179702758789\n",
      "Epoch: 1, Batch: 75, Loss: 3.2094807624816895\n",
      "Epoch: 1, Batch: 76, Loss: 2.2824618816375732\n",
      "Epoch: 1, Batch: 77, Loss: 4.292858600616455\n",
      "Epoch: 1, Batch: 78, Loss: 1.0236215591430664\n",
      "Epoch: 1, Batch: 79, Loss: 5.409456253051758\n",
      "Epoch: 1, Batch: 80, Loss: 2.908557891845703\n",
      "Epoch: 1, Batch: 81, Loss: 4.740058898925781\n",
      "Epoch: 1, Batch: 82, Loss: 5.894143581390381\n",
      "Epoch: 1, Batch: 83, Loss: 3.4785192012786865\n",
      "Epoch: 1, Batch: 84, Loss: 5.3376545906066895\n",
      "Epoch: 1, Batch: 85, Loss: 8.15631103515625\n",
      "Epoch: 1, Batch: 86, Loss: 4.5329670906066895\n",
      "Epoch: 1, Batch: 87, Loss: 5.127072811126709\n",
      "Epoch: 1, Batch: 88, Loss: 4.463428974151611\n",
      "Epoch: 1, Batch: 89, Loss: 0.8638543486595154\n",
      "Epoch: 1, Batch: 90, Loss: 4.836788177490234\n",
      "Epoch: 1, Batch: 91, Loss: 5.655708312988281\n",
      "Epoch: 1, Batch: 92, Loss: 2.630560874938965\n",
      "Epoch: 1, Batch: 93, Loss: 9.891019821166992\n",
      "Epoch: 1, Batch: 94, Loss: 4.230067253112793\n",
      "Epoch: 1, Batch: 95, Loss: 3.89768123626709\n",
      "Epoch: 1, Batch: 96, Loss: 4.394103050231934\n",
      "Epoch: 1, Batch: 97, Loss: 5.275911331176758\n",
      "Epoch: 1, Batch: 98, Loss: 5.769327640533447\n",
      "Epoch: 1, Batch: 99, Loss: 1.836575984954834\n",
      "Epoch: 1, Batch: 100, Loss: 3.8773088455200195\n",
      "Epoch: 1, Batch: 101, Loss: 8.116267204284668\n",
      "Epoch: 1, Batch: 102, Loss: 3.9840097427368164\n",
      "Epoch: 1, Batch: 103, Loss: 3.4429211616516113\n",
      "Epoch: 1, Batch: 104, Loss: 7.1961774826049805\n",
      "Epoch: 1, Batch: 105, Loss: 3.0234897136688232\n",
      "Epoch: 1, Batch: 106, Loss: 4.654077053070068\n",
      "Epoch: 1, Batch: 107, Loss: 5.086470603942871\n",
      "Epoch: 1, Batch: 108, Loss: 3.3127493858337402\n",
      "Epoch: 1, Batch: 109, Loss: 4.597931385040283\n",
      "Epoch: 1, Batch: 110, Loss: 3.9019646644592285\n",
      "Epoch: 1, Batch: 111, Loss: 3.0933587551116943\n",
      "Epoch: 1, Batch: 112, Loss: 3.601177215576172\n",
      "Epoch: 1, Batch: 113, Loss: 7.412139415740967\n",
      "Epoch: 1, Batch: 114, Loss: 1.9603036642074585\n",
      "Epoch: 1, Batch: 115, Loss: 9.261495590209961\n",
      "Epoch: 1, Batch: 116, Loss: 5.865095138549805\n",
      "Epoch: 1, Batch: 117, Loss: 1.8901891708374023\n",
      "Epoch: 1, Batch: 118, Loss: 2.2495007514953613\n",
      "Epoch: 1, Batch: 119, Loss: 4.249322891235352\n",
      "Epoch: 1, Batch: 120, Loss: 2.3893587589263916\n",
      "Epoch: 1, Batch: 121, Loss: 4.225039958953857\n",
      "Epoch: 1, Batch: 122, Loss: 5.774378776550293\n",
      "Epoch: 1, Batch: 123, Loss: 8.765020370483398\n",
      "Epoch: 1, Batch: 124, Loss: 4.270276069641113\n",
      "Epoch: 1, Batch: 125, Loss: 5.002414703369141\n",
      "Epoch: 1, Batch: 126, Loss: 6.090240955352783\n",
      "Epoch: 1, Batch: 127, Loss: 2.6033873558044434\n",
      "Epoch: 1, Batch: 128, Loss: 3.0777230262756348\n",
      "Epoch: 1, Batch: 129, Loss: 5.473695278167725\n",
      "Epoch: 1, Batch: 130, Loss: 3.1507694721221924\n",
      "Epoch: 1, Batch: 131, Loss: 4.396742343902588\n",
      "Epoch: 1, Batch: 132, Loss: 3.8153610229492188\n",
      "Epoch: 1, Batch: 133, Loss: 2.315743923187256\n",
      "Epoch: 1, Batch: 134, Loss: 6.743686199188232\n",
      "Epoch: 1, Batch: 135, Loss: 6.132015228271484\n",
      "Epoch: 1, Batch: 136, Loss: 7.388279438018799\n",
      "Epoch: 1, Batch: 137, Loss: 3.8973889350891113\n",
      "Epoch: 1, Batch: 138, Loss: 3.7490234375\n",
      "Epoch: 1, Batch: 139, Loss: 3.010957956314087\n",
      "Epoch: 1, Batch: 140, Loss: 2.6035642623901367\n",
      "Epoch: 1, Batch: 141, Loss: 5.3578643798828125\n",
      "Epoch: 1, Batch: 142, Loss: 5.251467704772949\n",
      "Epoch: 1, Batch: 143, Loss: 6.050497531890869\n",
      "Epoch: 1, Batch: 144, Loss: 3.8558802604675293\n",
      "Epoch: 1, Batch: 145, Loss: 0.6318550705909729\n",
      "Epoch: 1, Batch: 146, Loss: 2.909708023071289\n",
      "Epoch: 1, Batch: 147, Loss: 7.701972961425781\n",
      "Epoch: 1, Batch: 148, Loss: 7.02009391784668\n",
      "Epoch: 1, Batch: 149, Loss: 4.234679698944092\n",
      "Epoch: 1, Batch: 150, Loss: 4.583817481994629\n",
      "Epoch: 1, Batch: 151, Loss: 3.2414917945861816\n",
      "Epoch: 1, Batch: 152, Loss: 4.20533561706543\n",
      "Epoch: 1, Batch: 153, Loss: 2.9202628135681152\n",
      "Epoch: 1, Batch: 154, Loss: 6.471231460571289\n",
      "Epoch: 1, Batch: 155, Loss: 5.691727638244629\n",
      "Epoch: 1, Batch: 156, Loss: 4.373114109039307\n",
      "Epoch: 1, Batch: 157, Loss: 1.123732566833496\n",
      "Epoch: 1, Batch: 158, Loss: 5.000913619995117\n",
      "Epoch: 1, Batch: 159, Loss: 8.713386535644531\n",
      "Epoch: 1, Batch: 160, Loss: 6.452362060546875\n",
      "Epoch: 1, Batch: 161, Loss: 8.194963455200195\n",
      "Epoch: 1, Batch: 162, Loss: 4.304407119750977\n",
      "Epoch: 1, Batch: 163, Loss: 2.283325433731079\n",
      "Epoch: 1, Batch: 164, Loss: 4.5647735595703125\n",
      "Epoch: 1, Batch: 165, Loss: 2.682361602783203\n",
      "Epoch: 1, Batch: 166, Loss: 1.9011149406433105\n",
      "Epoch: 1, Batch: 167, Loss: 5.868029594421387\n",
      "Epoch: 1, Batch: 168, Loss: 5.627495288848877\n",
      "Epoch: 1, Batch: 169, Loss: 4.883854389190674\n",
      "Epoch: 1, Batch: 170, Loss: 3.963780641555786\n",
      "Epoch: 1, Batch: 171, Loss: 2.102133274078369\n",
      "Epoch: 1, Batch: 172, Loss: 9.042469024658203\n",
      "Epoch: 1, Batch: 173, Loss: 5.6267499923706055\n",
      "Epoch: 1, Batch: 174, Loss: 5.315992832183838\n",
      "Epoch: 1, Batch: 175, Loss: 4.1589460372924805\n",
      "Epoch: 1, Batch: 176, Loss: 6.191148281097412\n",
      "Epoch: 1, Batch: 177, Loss: 4.649496078491211\n",
      "Epoch: 1, Batch: 178, Loss: 6.681544303894043\n",
      "Epoch: 1, Batch: 179, Loss: 5.129321575164795\n",
      "Epoch: 1, Batch: 180, Loss: 6.519950866699219\n",
      "Epoch: 1, Batch: 181, Loss: 2.1633400917053223\n",
      "Epoch: 1, Batch: 182, Loss: 9.150035858154297\n",
      "Epoch: 1, Batch: 183, Loss: 5.171122074127197\n",
      "Epoch: 1, Batch: 184, Loss: 1.4247870445251465\n",
      "Epoch: 1, Batch: 185, Loss: 2.812286376953125\n",
      "Epoch: 1, Batch: 186, Loss: 0.5613217353820801\n",
      "Epoch: 1, Batch: 187, Loss: 2.937609910964966\n",
      "Epoch: 1, Batch: 188, Loss: 2.875614881515503\n",
      "Epoch: 1, Batch: 189, Loss: 4.433321952819824\n",
      "Epoch: 1, Batch: 190, Loss: 4.546745300292969\n",
      "Epoch: 1, Batch: 191, Loss: 9.577522277832031\n",
      "Epoch: 1, Batch: 192, Loss: 6.209498882293701\n",
      "Epoch: 1, Batch: 193, Loss: 2.885655641555786\n",
      "Epoch: 1, Batch: 194, Loss: 2.0250167846679688\n",
      "Epoch: 1, Batch: 195, Loss: 4.694428443908691\n",
      "Epoch: 1, Batch: 196, Loss: 4.172438621520996\n",
      "Epoch: 1, Batch: 197, Loss: 4.095776081085205\n",
      "Epoch: 1, Batch: 198, Loss: 5.307493209838867\n",
      "Epoch: 1, Batch: 199, Loss: 3.5370094776153564\n",
      "Epoch: 1, Batch: 200, Loss: 2.1536355018615723\n",
      "Epoch: 1, Batch: 201, Loss: 6.999162673950195\n",
      "Epoch: 1, Batch: 202, Loss: 4.650181770324707\n",
      "Epoch: 1, Batch: 203, Loss: 5.828880310058594\n",
      "Epoch: 1, Batch: 204, Loss: 5.922412395477295\n",
      "Epoch: 1, Batch: 205, Loss: 7.399950981140137\n",
      "Epoch: 1, Batch: 206, Loss: 7.974268436431885\n",
      "Epoch: 1, Batch: 207, Loss: 3.6037325859069824\n",
      "Epoch: 1, Batch: 208, Loss: 5.332716464996338\n",
      "Epoch: 1, Batch: 209, Loss: 6.286334991455078\n",
      "Epoch: 1, Batch: 210, Loss: 3.9162049293518066\n",
      "Epoch: 1, Batch: 211, Loss: 2.6456637382507324\n",
      "Epoch: 1, Batch: 212, Loss: 6.452050685882568\n",
      "Epoch: 1, Batch: 213, Loss: 3.259598731994629\n",
      "Epoch: 1, Batch: 214, Loss: 8.503246307373047\n",
      "Epoch: 1, Batch: 215, Loss: 6.619948387145996\n",
      "Epoch: 1, Batch: 216, Loss: 3.785212516784668\n",
      "Epoch: 1, Batch: 217, Loss: 7.070468425750732\n",
      "Epoch: 1, Batch: 218, Loss: 5.219478607177734\n",
      "Epoch: 1, Batch: 219, Loss: 4.736333847045898\n",
      "Epoch: 1, Batch: 220, Loss: 3.337587594985962\n",
      "Epoch: 1, Batch: 221, Loss: 2.943936347961426\n",
      "Epoch: 1, Batch: 222, Loss: 4.093975067138672\n",
      "Epoch: 1, Batch: 223, Loss: 4.29131555557251\n",
      "Epoch: 1, Batch: 224, Loss: 4.574891090393066\n",
      "Epoch: 1, Batch: 225, Loss: 5.813576698303223\n",
      "Epoch: 1, Batch: 226, Loss: 5.807206153869629\n",
      "Epoch: 1, Batch: 227, Loss: 3.8960392475128174\n",
      "Epoch: 1, Batch: 228, Loss: 3.1324238777160645\n",
      "Epoch: 1, Batch: 229, Loss: 4.793358325958252\n",
      "Epoch: 1, Batch: 230, Loss: 6.019777297973633\n",
      "Epoch: 1, Batch: 231, Loss: 2.257545232772827\n",
      "Epoch: 1, Batch: 232, Loss: 5.050409317016602\n",
      "Epoch: 1, Batch: 233, Loss: 7.149569511413574\n",
      "Epoch: 1, Batch: 234, Loss: 2.4439351558685303\n",
      "Epoch: 1, Batch: 235, Loss: 2.1595065593719482\n",
      "Epoch: 1, Batch: 236, Loss: 5.405444622039795\n",
      "Epoch: 1, Batch: 237, Loss: 1.881852388381958\n",
      "Epoch: 1, Batch: 238, Loss: 2.2160792350769043\n",
      "Epoch: 1, Batch: 239, Loss: 2.6397626399993896\n",
      "Epoch: 1, Batch: 240, Loss: 3.66988468170166\n",
      "Epoch: 1, Batch: 241, Loss: 0.8420938849449158\n",
      "Epoch: 1, Batch: 242, Loss: 5.149994850158691\n",
      "Epoch: 1, Batch: 243, Loss: 4.107537269592285\n",
      "Epoch: 1, Batch: 244, Loss: 6.646677017211914\n",
      "Epoch: 1, Batch: 245, Loss: 5.164877414703369\n",
      "Epoch: 1, Batch: 246, Loss: 12.506271362304688\n",
      "Epoch: 1, Batch: 247, Loss: 3.475330352783203\n",
      "Epoch: 1, Batch: 248, Loss: 1.1208101511001587\n",
      "Epoch: 1, Batch: 249, Loss: 6.663671970367432\n",
      "Epoch: 1, Batch: 250, Loss: 4.067510604858398\n",
      "Epoch: 1, Batch: 251, Loss: 3.3629708290100098\n",
      "Epoch: 1, Batch: 252, Loss: 5.947638034820557\n",
      "Epoch: 1, Batch: 253, Loss: 3.603046178817749\n",
      "Epoch: 1, Batch: 254, Loss: 2.2936549186706543\n",
      "Epoch: 1, Batch: 255, Loss: 3.052947521209717\n",
      "Epoch: 1, Batch: 256, Loss: 6.391543865203857\n",
      "Epoch: 1, Batch: 257, Loss: 6.831089496612549\n",
      "Epoch: 1, Batch: 258, Loss: 8.080658912658691\n",
      "Epoch: 1, Batch: 259, Loss: 2.652858257293701\n",
      "Epoch: 1, Batch: 260, Loss: 2.9258346557617188\n",
      "Epoch: 1, Batch: 261, Loss: 1.9973505735397339\n",
      "Epoch: 1, Batch: 262, Loss: 8.403554916381836\n",
      "Epoch: 1, Batch: 263, Loss: 6.029033184051514\n",
      "Epoch: 1, Batch: 264, Loss: 7.2367706298828125\n",
      "Epoch: 1, Batch: 265, Loss: 7.8739142417907715\n",
      "Epoch: 1, Batch: 266, Loss: 5.114526748657227\n",
      "Epoch: 1, Batch: 267, Loss: 6.83219051361084\n",
      "Epoch: 1, Batch: 268, Loss: 5.225527763366699\n",
      "Epoch: 1, Batch: 269, Loss: 3.3961946964263916\n",
      "Epoch: 1, Batch: 270, Loss: 4.293120384216309\n",
      "Epoch: 1, Batch: 271, Loss: 4.71214485168457\n",
      "Epoch: 1, Batch: 272, Loss: 3.198068141937256\n",
      "Epoch: 1, Batch: 273, Loss: 3.3808658123016357\n",
      "Epoch: 1, Batch: 274, Loss: 5.362953186035156\n",
      "Epoch: 1, Batch: 275, Loss: 1.9580421447753906\n",
      "Epoch: 1, Batch: 276, Loss: 10.371443748474121\n",
      "Epoch: 1, Batch: 277, Loss: 7.229366779327393\n",
      "Epoch: 1, Batch: 278, Loss: 6.588130950927734\n",
      "Epoch: 1, Batch: 279, Loss: 6.386800289154053\n",
      "Epoch: 1, Batch: 280, Loss: 10.027961730957031\n",
      "Epoch: 1, Batch: 281, Loss: 7.415463447570801\n",
      "Epoch: 1, Batch: 282, Loss: 5.545315265655518\n",
      "Epoch: 1, Batch: 283, Loss: 2.9366023540496826\n",
      "Epoch: 1, Batch: 284, Loss: 4.421543598175049\n",
      "Epoch: 1, Batch: 285, Loss: 4.531444549560547\n",
      "Epoch: 1, Batch: 286, Loss: 2.0701074600219727\n",
      "Epoch: 1, Batch: 287, Loss: 9.38522720336914\n",
      "Epoch: 1, Batch: 288, Loss: 8.64712905883789\n",
      "Epoch: 1, Batch: 289, Loss: 1.4086545705795288\n",
      "Epoch: 1, Batch: 290, Loss: 5.7502336502075195\n",
      "Epoch: 1, Batch: 291, Loss: 2.6267623901367188\n",
      "Epoch: 1, Batch: 292, Loss: 3.7290210723876953\n",
      "Epoch: 1, Batch: 293, Loss: 7.1004157066345215\n",
      "Epoch: 1, Batch: 294, Loss: 3.865489959716797\n",
      "Epoch: 1, Batch: 295, Loss: 5.118433952331543\n",
      "Epoch: 1, Batch: 296, Loss: 4.847835540771484\n",
      "Epoch: 1, Batch: 297, Loss: 4.064574718475342\n",
      "Epoch: 1, Batch: 298, Loss: 3.8922877311706543\n",
      "Epoch: 1, Batch: 299, Loss: 7.853756904602051\n",
      "Epoch: 1, Batch: 300, Loss: 3.185659408569336\n",
      "Epoch: 1, Batch: 301, Loss: 5.142213344573975\n",
      "Epoch: 1, Batch: 302, Loss: 4.021406173706055\n",
      "Epoch: 1, Batch: 303, Loss: 4.309666633605957\n",
      "Epoch: 1, Batch: 304, Loss: 7.881478309631348\n",
      "Epoch: 1, Batch: 305, Loss: 5.921245574951172\n",
      "Epoch: 1, Batch: 306, Loss: 4.63726806640625\n",
      "Epoch: 1, Batch: 307, Loss: 2.5947155952453613\n",
      "Epoch: 1, Batch: 308, Loss: 4.674498081207275\n",
      "Epoch: 1, Batch: 309, Loss: 4.862985134124756\n",
      "Epoch: 1, Batch: 310, Loss: 7.819733142852783\n",
      "Epoch: 1, Batch: 311, Loss: 2.1692121028900146\n",
      "Epoch: 1, Batch: 312, Loss: 4.685462474822998\n",
      "Epoch: 1, Batch: 313, Loss: 5.112369060516357\n",
      "Epoch: 1, Batch: 314, Loss: 6.28446626663208\n",
      "Epoch: 1, Batch: 315, Loss: 1.2472858428955078\n",
      "Epoch: 1, Batch: 316, Loss: 3.850189685821533\n",
      "Epoch: 1, Batch: 317, Loss: 8.51309871673584\n",
      "Epoch: 1, Batch: 318, Loss: 1.6143277883529663\n",
      "Epoch: 1, Batch: 319, Loss: 3.2168185710906982\n",
      "Epoch: 1, Batch: 320, Loss: 3.0897862911224365\n",
      "Epoch: 1, Batch: 321, Loss: 3.2798922061920166\n",
      "Epoch: 1, Batch: 322, Loss: 2.6646311283111572\n",
      "Epoch: 1, Batch: 323, Loss: 1.293455719947815\n",
      "Epoch: 1, Batch: 324, Loss: 6.003401279449463\n",
      "Epoch: 1, Batch: 325, Loss: 4.614765644073486\n",
      "Epoch: 1, Batch: 326, Loss: 10.054282188415527\n",
      "Epoch: 1, Batch: 327, Loss: 3.1098897457122803\n",
      "Epoch: 1, Batch: 328, Loss: 9.283442497253418\n",
      "Epoch: 1, Batch: 329, Loss: 0.6403305530548096\n",
      "Epoch: 1, Batch: 330, Loss: 4.4704766273498535\n",
      "Epoch: 1, Batch: 331, Loss: 1.9390175342559814\n",
      "Epoch: 1, Batch: 332, Loss: 5.8299174308776855\n",
      "Epoch: 1, Batch: 333, Loss: 4.128518104553223\n",
      "Epoch: 1, Batch: 334, Loss: 5.302878379821777\n",
      "Epoch: 1, Batch: 335, Loss: 4.768429756164551\n",
      "Epoch: 1, Batch: 336, Loss: 4.60999870300293\n",
      "Epoch: 1, Batch: 337, Loss: 7.710742950439453\n",
      "Epoch: 1, Batch: 338, Loss: 1.5507800579071045\n",
      "Epoch: 1, Batch: 339, Loss: 3.7696750164031982\n",
      "Epoch: 1, Batch: 340, Loss: 7.1943817138671875\n",
      "Epoch: 1, Batch: 341, Loss: 5.069018840789795\n",
      "Epoch: 1, Batch: 342, Loss: 5.7054643630981445\n",
      "Epoch: 1, Batch: 343, Loss: 5.428896903991699\n",
      "Epoch: 1, Batch: 344, Loss: 1.6533091068267822\n",
      "Epoch: 1, Batch: 345, Loss: 12.753211975097656\n",
      "Epoch: 1, Batch: 346, Loss: 5.038977146148682\n",
      "Epoch: 1, Batch: 347, Loss: 7.887880802154541\n",
      "Epoch: 1, Batch: 348, Loss: 4.431008815765381\n",
      "Epoch: 1, Batch: 349, Loss: 3.561699390411377\n",
      "Epoch: 1, Batch: 350, Loss: 5.974184989929199\n",
      "Epoch: 1, Batch: 351, Loss: 5.26891565322876\n",
      "Epoch: 1, Batch: 352, Loss: 2.9927573204040527\n",
      "Epoch: 1, Batch: 353, Loss: 5.975996494293213\n",
      "Epoch: 1, Batch: 354, Loss: 5.4982781410217285\n",
      "Epoch: 1, Batch: 355, Loss: 4.2907586097717285\n",
      "Epoch: 1, Batch: 356, Loss: 2.1371383666992188\n",
      "Epoch: 1, Batch: 357, Loss: 2.2283108234405518\n",
      "Epoch: 1, Batch: 358, Loss: 7.298696041107178\n",
      "Epoch: 1, Batch: 359, Loss: 5.152129173278809\n",
      "Epoch: 1, Batch: 360, Loss: 4.85850191116333\n",
      "Epoch: 1, Batch: 361, Loss: 2.4431257247924805\n",
      "Epoch: 1, Batch: 362, Loss: 8.456031799316406\n",
      "Epoch: 1, Batch: 363, Loss: 4.144806861877441\n",
      "Epoch: 1, Batch: 364, Loss: 6.674441337585449\n",
      "Epoch: 1, Batch: 365, Loss: 3.907231569290161\n",
      "Epoch: 1, Batch: 366, Loss: 2.936049461364746\n",
      "Epoch: 1, Batch: 367, Loss: 2.6499736309051514\n",
      "Epoch: 1, Batch: 368, Loss: 5.663027763366699\n",
      "Epoch: 1, Batch: 369, Loss: 3.3250393867492676\n",
      "Epoch: 1, Batch: 370, Loss: 5.116420269012451\n",
      "Epoch: 1, Batch: 371, Loss: 6.467812538146973\n",
      "Epoch: 1, Batch: 372, Loss: 4.898021221160889\n",
      "Epoch: 1, Batch: 373, Loss: 4.375330448150635\n",
      "Epoch: 1, Batch: 374, Loss: 5.267612934112549\n",
      "Epoch: 1, Batch: 375, Loss: 3.376034736633301\n",
      "Epoch: 1, Batch: 376, Loss: 1.6440354585647583\n",
      "Epoch: 1, Batch: 377, Loss: 7.965281009674072\n",
      "Epoch: 1, Batch: 378, Loss: 4.4898176193237305\n",
      "Epoch: 1, Batch: 379, Loss: 3.4686689376831055\n",
      "Epoch: 1, Batch: 380, Loss: 3.0842792987823486\n",
      "Epoch: 1, Batch: 381, Loss: 6.413522720336914\n",
      "Epoch: 1, Batch: 382, Loss: 9.807456970214844\n",
      "Epoch: 1, Batch: 383, Loss: 5.303561687469482\n",
      "Epoch: 1, Batch: 384, Loss: 2.8793110847473145\n",
      "Epoch: 1, Batch: 385, Loss: 7.855012893676758\n",
      "Epoch: 1, Batch: 386, Loss: 1.7529281377792358\n",
      "Epoch: 1, Batch: 387, Loss: 2.7418339252471924\n",
      "Epoch: 1, Batch: 388, Loss: 3.645965337753296\n",
      "Epoch: 1, Batch: 389, Loss: 6.899219512939453\n",
      "Epoch: 1, Batch: 390, Loss: 5.42065954208374\n",
      "Epoch: 1, Batch: 391, Loss: 4.634530544281006\n",
      "Epoch: 1, Batch: 392, Loss: 3.261777639389038\n",
      "Epoch: 1, Batch: 393, Loss: 3.1942572593688965\n",
      "Epoch: 1, Batch: 394, Loss: 3.766148567199707\n",
      "Epoch: 1, Batch: 395, Loss: 4.432862281799316\n",
      "Epoch: 1, Batch: 396, Loss: 3.926809787750244\n",
      "Epoch: 1, Batch: 397, Loss: 2.8538455963134766\n",
      "Epoch: 1, Batch: 398, Loss: 3.4798502922058105\n",
      "Epoch: 1, Batch: 399, Loss: 1.9983713626861572\n",
      "Epoch: 1, Batch: 400, Loss: 6.142757415771484\n",
      "Epoch: 1, Batch: 401, Loss: 1.5810511112213135\n",
      "Epoch: 1, Batch: 402, Loss: 2.617532968521118\n",
      "Epoch: 1, Batch: 403, Loss: 4.299696922302246\n",
      "Epoch: 1, Batch: 404, Loss: 2.3871521949768066\n",
      "Epoch: 1, Batch: 405, Loss: 2.652538776397705\n",
      "Epoch: 1, Batch: 406, Loss: 4.304903984069824\n",
      "Epoch: 1, Batch: 407, Loss: 5.9527506828308105\n",
      "Epoch: 1, Batch: 408, Loss: 3.806943416595459\n",
      "Epoch: 1, Batch: 409, Loss: 3.282625913619995\n",
      "Epoch: 1, Batch: 410, Loss: 5.8201904296875\n",
      "Epoch: 1, Batch: 411, Loss: 5.712873458862305\n",
      "Epoch: 1, Batch: 412, Loss: 3.710198163986206\n",
      "Epoch: 1, Batch: 413, Loss: 3.8830015659332275\n",
      "Epoch: 1, Batch: 414, Loss: 7.841807842254639\n",
      "Epoch: 1, Batch: 415, Loss: 3.1756811141967773\n",
      "Epoch: 1, Batch: 416, Loss: 4.59031867980957\n",
      "Epoch: 1, Batch: 417, Loss: 5.932189464569092\n",
      "Epoch: 1, Batch: 418, Loss: 4.779167175292969\n",
      "Epoch: 1, Batch: 419, Loss: 5.852142333984375\n",
      "Epoch: 1, Batch: 420, Loss: 4.269875526428223\n",
      "Epoch: 1, Batch: 421, Loss: 2.893739700317383\n",
      "Epoch: 1, Batch: 422, Loss: 3.5030148029327393\n",
      "Epoch: 1, Batch: 423, Loss: 2.972069263458252\n",
      "Epoch: 1, Batch: 424, Loss: 2.707172393798828\n",
      "Epoch: 1, Batch: 425, Loss: 2.7003304958343506\n",
      "Epoch: 1, Batch: 426, Loss: 4.394007682800293\n",
      "Epoch: 1, Batch: 427, Loss: 6.918330192565918\n",
      "Epoch: 1, Batch: 428, Loss: 2.4083762168884277\n",
      "Epoch: 1, Batch: 429, Loss: 3.66261625289917\n",
      "Epoch: 1, Batch: 430, Loss: 3.1937601566314697\n",
      "Epoch: 1, Batch: 431, Loss: 4.182723522186279\n",
      "Epoch: 1, Batch: 432, Loss: 4.374177932739258\n",
      "Epoch: 1, Batch: 433, Loss: 5.082578659057617\n",
      "Epoch: 1, Batch: 434, Loss: 4.988313674926758\n",
      "Epoch: 1, Batch: 435, Loss: 3.832390069961548\n",
      "Epoch: 1, Batch: 436, Loss: 4.074934959411621\n",
      "Epoch: 1, Batch: 437, Loss: 4.9033050537109375\n",
      "Epoch: 1, Batch: 438, Loss: 2.4248194694519043\n",
      "Epoch: 1, Batch: 439, Loss: 4.913726329803467\n",
      "Epoch: 1, Batch: 440, Loss: 3.6910226345062256\n",
      "Epoch: 1, Batch: 441, Loss: 2.9199793338775635\n",
      "Epoch: 1, Batch: 442, Loss: 3.2260377407073975\n",
      "Epoch: 1, Batch: 443, Loss: 5.259053707122803\n",
      "Epoch: 1, Batch: 444, Loss: 4.931351661682129\n",
      "Epoch: 1, Batch: 445, Loss: 5.741742134094238\n",
      "Epoch: 1, Batch: 446, Loss: 3.26165771484375\n",
      "Epoch: 1, Batch: 447, Loss: 2.665949583053589\n",
      "Epoch: 1, Batch: 448, Loss: 2.3101189136505127\n",
      "Epoch: 1, Batch: 449, Loss: 7.938480377197266\n",
      "Epoch: 1, Batch: 450, Loss: 2.41288423538208\n",
      "Epoch: 1, Batch: 451, Loss: 4.548582077026367\n",
      "Epoch: 1, Batch: 452, Loss: 2.0995328426361084\n",
      "Epoch: 1, Batch: 453, Loss: 4.658015727996826\n",
      "Epoch: 1, Batch: 454, Loss: 4.336949348449707\n",
      "Epoch: 1, Batch: 455, Loss: 4.715604782104492\n",
      "Epoch: 1, Batch: 456, Loss: 3.715397834777832\n",
      "Epoch: 1, Batch: 457, Loss: 3.816044807434082\n",
      "Epoch: 1, Batch: 458, Loss: 5.326683521270752\n",
      "Epoch: 1, Batch: 459, Loss: 3.2394938468933105\n",
      "Epoch: 1, Batch: 460, Loss: 3.840221405029297\n",
      "Epoch: 1, Batch: 461, Loss: 2.584488868713379\n",
      "Epoch: 1, Batch: 462, Loss: 4.484167575836182\n",
      "Epoch: 1, Batch: 463, Loss: 5.671294212341309\n",
      "Epoch: 1, Batch: 464, Loss: 2.835961103439331\n",
      "Epoch: 1, Batch: 465, Loss: 6.262253761291504\n",
      "Epoch: 1, Batch: 466, Loss: 3.142019033432007\n",
      "Epoch: 1, Batch: 467, Loss: 4.377609729766846\n",
      "Epoch: 1, Batch: 468, Loss: 2.8556079864501953\n",
      "Epoch: 1, Batch: 469, Loss: 6.438058376312256\n",
      "Epoch: 1, Batch: 470, Loss: 4.768143177032471\n",
      "Epoch: 1, Batch: 471, Loss: 2.53779673576355\n",
      "Epoch: 1, Batch: 472, Loss: 2.6465439796447754\n",
      "Epoch: 1, Batch: 473, Loss: 5.6109819412231445\n",
      "Epoch: 1, Batch: 474, Loss: 7.391482353210449\n",
      "Epoch: 1, Batch: 475, Loss: 5.101234436035156\n",
      "Epoch: 1, Batch: 476, Loss: 3.7193033695220947\n",
      "Epoch: 1, Batch: 477, Loss: 4.874386310577393\n",
      "Epoch: 1, Batch: 478, Loss: 1.476353406906128\n",
      "Epoch: 1, Batch: 479, Loss: 4.2185959815979\n",
      "Epoch: 1, Batch: 480, Loss: 0.9298430681228638\n",
      "Epoch: 1, Batch: 481, Loss: 3.447979211807251\n",
      "Epoch: 1, Batch: 482, Loss: 3.529226541519165\n",
      "Epoch: 1, Batch: 483, Loss: 7.002128601074219\n",
      "Epoch: 1, Batch: 484, Loss: 3.5786614418029785\n",
      "Epoch: 1, Batch: 485, Loss: 3.446533203125\n",
      "Epoch: 1, Batch: 486, Loss: 2.9993033409118652\n",
      "Epoch: 1, Batch: 487, Loss: 1.4183712005615234\n",
      "Epoch: 1, Batch: 488, Loss: 2.484325885772705\n",
      "Epoch: 1, Batch: 489, Loss: 5.495300769805908\n",
      "Epoch: 1, Batch: 490, Loss: 1.4138128757476807\n",
      "Epoch: 1, Batch: 491, Loss: 4.842515468597412\n",
      "Epoch: 1, Batch: 492, Loss: 3.3528029918670654\n",
      "Epoch: 1, Batch: 493, Loss: 3.471327304840088\n",
      "Epoch: 1, Batch: 494, Loss: 8.042031288146973\n",
      "Epoch: 1, Batch: 495, Loss: 5.269293785095215\n",
      "Epoch: 1, Batch: 496, Loss: 3.2301273345947266\n",
      "Epoch: 1, Batch: 497, Loss: 2.0753536224365234\n",
      "Epoch: 1, Batch: 498, Loss: 4.373442649841309\n",
      "Epoch: 1, Batch: 499, Loss: 2.940532684326172\n",
      "Epoch: 1, Batch: 500, Loss: 1.8906822204589844\n",
      "Epoch: 1, Batch: 501, Loss: 5.4736714363098145\n",
      "Epoch: 1, Batch: 502, Loss: 6.387326240539551\n",
      "Epoch: 1, Batch: 503, Loss: 4.06137752532959\n",
      "Epoch: 1, Batch: 504, Loss: 2.3253097534179688\n",
      "Epoch: 1, Batch: 505, Loss: 3.9613113403320312\n",
      "Epoch: 1, Batch: 506, Loss: 2.3845858573913574\n",
      "Epoch: 1, Batch: 507, Loss: 1.9417390823364258\n",
      "Epoch: 1, Batch: 508, Loss: 5.577827453613281\n",
      "Epoch: 1, Batch: 509, Loss: 4.870487689971924\n",
      "Epoch: 1, Batch: 510, Loss: 4.890818119049072\n",
      "Epoch: 1, Batch: 511, Loss: 3.614102840423584\n",
      "Epoch: 1, Batch: 512, Loss: 3.340904474258423\n",
      "Epoch: 1, Batch: 513, Loss: 4.59312105178833\n",
      "Epoch: 1, Batch: 514, Loss: 4.610023498535156\n",
      "Epoch: 1, Batch: 515, Loss: 0.9752588868141174\n",
      "Epoch: 1, Batch: 516, Loss: 5.1107683181762695\n",
      "Epoch: 1, Batch: 517, Loss: 4.148731708526611\n",
      "Epoch: 1, Batch: 518, Loss: 2.5247340202331543\n",
      "Epoch: 1, Batch: 519, Loss: 2.982754945755005\n",
      "Epoch: 1, Batch: 520, Loss: 3.605402946472168\n",
      "Epoch: 1, Batch: 521, Loss: 5.864742755889893\n",
      "Epoch: 1, Batch: 522, Loss: 3.0055344104766846\n",
      "Epoch: 1, Batch: 523, Loss: 5.648563385009766\n",
      "Epoch: 1, Batch: 524, Loss: 7.069024562835693\n",
      "Epoch: 1, Batch: 525, Loss: 5.659435749053955\n",
      "Epoch: 1, Batch: 526, Loss: 2.4768381118774414\n",
      "Epoch: 1, Batch: 527, Loss: 3.279292106628418\n",
      "Epoch: 1, Batch: 528, Loss: 2.1861329078674316\n",
      "Epoch: 1, Batch: 529, Loss: 9.122604370117188\n",
      "Epoch: 1, Batch: 530, Loss: 4.416937828063965\n",
      "Epoch: 1, Batch: 531, Loss: 3.015410900115967\n",
      "Epoch: 1, Batch: 532, Loss: 4.672237396240234\n",
      "Epoch: 1, Batch: 533, Loss: 1.1283221244812012\n",
      "Epoch: 1, Batch: 534, Loss: 6.942105293273926\n",
      "Epoch: 1, Batch: 535, Loss: 3.2763748168945312\n",
      "Epoch: 1, Batch: 536, Loss: 4.5400471687316895\n",
      "Epoch: 1, Batch: 537, Loss: 2.4734206199645996\n",
      "Epoch: 1, Batch: 538, Loss: 4.435754776000977\n",
      "Epoch: 1, Batch: 539, Loss: 5.978290557861328\n",
      "Epoch: 1, Batch: 540, Loss: 9.049920082092285\n",
      "Epoch: 1, Batch: 541, Loss: 1.6604304313659668\n",
      "Epoch: 1, Batch: 542, Loss: 5.072408199310303\n",
      "Epoch: 1, Batch: 543, Loss: 6.937362194061279\n",
      "Epoch: 1, Batch: 544, Loss: 5.6470208168029785\n",
      "Epoch: 1, Batch: 545, Loss: 8.38990592956543\n",
      "Epoch: 1, Batch: 546, Loss: 6.3124494552612305\n",
      "Epoch: 1, Batch: 547, Loss: 2.0188441276550293\n",
      "Epoch: 1, Batch: 548, Loss: 2.85648512840271\n",
      "Epoch: 1, Batch: 549, Loss: 3.521381378173828\n",
      "Epoch: 1, Batch: 550, Loss: 7.816283226013184\n",
      "Epoch: 1, Batch: 551, Loss: 4.404458999633789\n",
      "Epoch: 1, Batch: 552, Loss: 1.4619096517562866\n",
      "Epoch: 1, Batch: 553, Loss: 1.1171592473983765\n",
      "Epoch: 1, Batch: 554, Loss: 4.479992866516113\n",
      "Epoch: 1, Batch: 555, Loss: 3.6207141876220703\n",
      "Epoch: 1, Batch: 556, Loss: 6.574774265289307\n",
      "Epoch: 1, Batch: 557, Loss: 5.469021797180176\n",
      "Epoch: 1, Batch: 558, Loss: 4.342991828918457\n",
      "Epoch: 1, Batch: 559, Loss: 4.0023603439331055\n",
      "Epoch: 1, Batch: 560, Loss: 3.233576774597168\n",
      "Epoch: 1, Batch: 561, Loss: 9.859169006347656\n",
      "Epoch: 1, Batch: 562, Loss: 2.1037819385528564\n",
      "Epoch: 1, Batch: 563, Loss: 5.645214557647705\n",
      "Epoch: 1, Batch: 564, Loss: 4.088279724121094\n",
      "Epoch: 1, Batch: 565, Loss: 2.655445098876953\n",
      "Epoch: 1, Batch: 566, Loss: 6.317654609680176\n",
      "Epoch: 1, Batch: 567, Loss: 2.913745880126953\n",
      "Epoch: 1, Batch: 568, Loss: 4.398670196533203\n",
      "Epoch: 1, Batch: 569, Loss: 1.8674063682556152\n",
      "Epoch: 1, Batch: 570, Loss: 6.318521976470947\n",
      "Epoch: 1, Batch: 571, Loss: 5.636425971984863\n",
      "Epoch: 1, Batch: 572, Loss: 3.090852975845337\n",
      "Epoch: 1, Batch: 573, Loss: 1.5300517082214355\n",
      "Epoch: 1, Batch: 574, Loss: 3.6749134063720703\n",
      "Epoch: 1, Batch: 575, Loss: 3.9330990314483643\n",
      "Epoch: 1, Batch: 576, Loss: 2.9306211471557617\n",
      "Epoch: 1, Batch: 577, Loss: 6.725708484649658\n",
      "Epoch: 1, Batch: 578, Loss: 3.4462246894836426\n",
      "Epoch: 1, Batch: 579, Loss: 7.975454807281494\n",
      "Epoch: 1, Batch: 580, Loss: 6.109975337982178\n",
      "Epoch: 1, Batch: 581, Loss: 1.6536011695861816\n",
      "Epoch: 1, Batch: 582, Loss: 6.237308502197266\n",
      "Epoch: 1, Batch: 583, Loss: 3.7275495529174805\n",
      "Epoch: 1, Batch: 584, Loss: 2.39632511138916\n",
      "Epoch: 1, Batch: 585, Loss: 1.4654597043991089\n",
      "Epoch: 1, Batch: 586, Loss: 3.8259377479553223\n",
      "Epoch: 1, Batch: 587, Loss: 8.02757453918457\n",
      "Epoch: 1, Batch: 588, Loss: 4.7672576904296875\n",
      "Epoch: 1, Batch: 589, Loss: 2.816678285598755\n",
      "Epoch: 1, Batch: 590, Loss: 4.306252479553223\n",
      "Epoch: 1, Batch: 591, Loss: 5.354551792144775\n",
      "Epoch: 1, Batch: 592, Loss: 4.4095988273620605\n",
      "Epoch: 1, Batch: 593, Loss: 2.7342605590820312\n",
      "Epoch: 1, Batch: 594, Loss: 2.0575454235076904\n",
      "Epoch: 1, Batch: 595, Loss: 2.5086636543273926\n",
      "Epoch: 1, Batch: 596, Loss: 4.148662567138672\n",
      "Epoch: 1, Batch: 597, Loss: 4.434380531311035\n",
      "Epoch: 1, Batch: 598, Loss: 4.383905410766602\n",
      "Epoch: 1, Batch: 599, Loss: 1.7838561534881592\n",
      "Epoch: 1, Batch: 600, Loss: 3.3214709758758545\n",
      "Epoch: 1, Batch: 601, Loss: 4.797505855560303\n",
      "Epoch: 1, Batch: 602, Loss: 6.445379734039307\n",
      "Epoch: 1, Batch: 603, Loss: 2.3167314529418945\n",
      "Epoch: 1, Batch: 604, Loss: 4.529648780822754\n",
      "Epoch: 1, Batch: 605, Loss: 3.573164463043213\n",
      "Epoch: 1, Batch: 606, Loss: 2.573946952819824\n",
      "Epoch: 1, Batch: 607, Loss: 5.1861090660095215\n",
      "Epoch: 1, Batch: 608, Loss: 4.288030624389648\n",
      "Epoch: 1, Batch: 609, Loss: 4.139025688171387\n",
      "Epoch: 1, Batch: 610, Loss: 6.350996017456055\n",
      "Epoch: 1, Batch: 611, Loss: 3.708648204803467\n",
      "Epoch: 1, Batch: 612, Loss: 3.327409029006958\n",
      "Epoch: 1, Batch: 613, Loss: 1.9151300191879272\n",
      "Epoch: 1, Batch: 614, Loss: 1.8989276885986328\n",
      "Epoch: 1, Batch: 615, Loss: 6.720729827880859\n",
      "Epoch: 1, Batch: 616, Loss: 1.9452930688858032\n",
      "Epoch: 1, Batch: 617, Loss: 3.255800724029541\n",
      "Epoch: 1, Batch: 618, Loss: 3.281163215637207\n",
      "Epoch: 1, Batch: 619, Loss: 3.34199857711792\n",
      "Epoch: 1, Batch: 620, Loss: 4.646129131317139\n",
      "Epoch: 1, Batch: 621, Loss: 3.3166613578796387\n",
      "Epoch: 1, Batch: 622, Loss: 3.858675241470337\n",
      "Epoch: 1, Batch: 623, Loss: 2.658553123474121\n",
      "Epoch: 1, Batch: 624, Loss: 4.9739813804626465\n",
      "Epoch: 1, Batch: 625, Loss: 4.936481952667236\n",
      "Epoch: 1, Batch: 626, Loss: 1.5419150590896606\n",
      "Epoch: 1, Batch: 627, Loss: 9.705568313598633\n",
      "Epoch: 1, Batch: 628, Loss: 4.570980072021484\n",
      "Epoch: 1, Batch: 629, Loss: 1.6880297660827637\n",
      "Epoch: 1, Batch: 630, Loss: 2.5193417072296143\n",
      "Epoch: 1, Batch: 631, Loss: 5.217141151428223\n",
      "Epoch: 1, Batch: 632, Loss: 4.76756477355957\n",
      "Epoch: 1, Batch: 633, Loss: 5.376385688781738\n",
      "Epoch: 1, Batch: 634, Loss: 1.7686128616333008\n",
      "Epoch: 1, Batch: 635, Loss: 6.505313873291016\n",
      "Epoch: 1, Batch: 636, Loss: 2.902622699737549\n",
      "Epoch: 1, Batch: 637, Loss: 4.903346061706543\n",
      "Epoch: 1, Batch: 638, Loss: 4.5414276123046875\n",
      "Epoch: 1, Batch: 639, Loss: 1.1302728652954102\n",
      "Epoch: 1, Batch: 640, Loss: 0.5774531364440918\n",
      "Epoch: 1, Batch: 641, Loss: 3.7181904315948486\n",
      "Epoch: 1, Batch: 642, Loss: 1.6665785312652588\n",
      "Epoch: 1, Batch: 643, Loss: 7.11234188079834\n",
      "Epoch: 1, Batch: 644, Loss: 4.928473472595215\n",
      "Epoch: 1, Batch: 645, Loss: 5.871099948883057\n",
      "Epoch: 1, Batch: 646, Loss: 8.368476867675781\n",
      "Epoch: 1, Batch: 647, Loss: 4.38642692565918\n",
      "Epoch: 1, Batch: 648, Loss: 3.6116909980773926\n",
      "Epoch: 1, Batch: 649, Loss: 3.439089775085449\n",
      "Epoch: 1, Batch: 650, Loss: 6.187586784362793\n",
      "Epoch: 1, Batch: 651, Loss: 5.7713212966918945\n",
      "Epoch: 1, Batch: 652, Loss: 8.562346458435059\n",
      "Epoch: 1, Batch: 653, Loss: 3.6479978561401367\n",
      "Epoch: 1, Batch: 654, Loss: 5.077516555786133\n",
      "Epoch: 1, Batch: 655, Loss: 2.3823013305664062\n",
      "Epoch: 1, Batch: 656, Loss: 5.407691478729248\n",
      "Epoch: 1, Batch: 657, Loss: 0.6835084557533264\n",
      "Epoch: 1, Batch: 658, Loss: 3.3137967586517334\n",
      "Epoch: 1, Batch: 659, Loss: 7.103477478027344\n",
      "Epoch: 1, Batch: 660, Loss: 7.946419715881348\n",
      "Epoch: 1, Batch: 661, Loss: 2.073805332183838\n",
      "Epoch: 1, Batch: 662, Loss: 1.7463150024414062\n",
      "Epoch: 1, Batch: 663, Loss: 5.267554759979248\n",
      "Epoch: 1, Batch: 664, Loss: 4.982272148132324\n",
      "Epoch: 1, Batch: 665, Loss: 7.540566444396973\n",
      "Epoch: 1, Batch: 666, Loss: 1.0178297758102417\n",
      "Epoch: 1, Batch: 667, Loss: 5.445240497589111\n",
      "Epoch: 1, Batch: 668, Loss: 5.1069183349609375\n",
      "Epoch: 1, Batch: 669, Loss: 3.1693201065063477\n",
      "Epoch: 1, Batch: 670, Loss: 8.529413223266602\n",
      "Epoch: 1, Batch: 671, Loss: 5.127361297607422\n",
      "Epoch: 1, Batch: 672, Loss: 5.376332759857178\n",
      "Epoch: 1, Batch: 673, Loss: 3.0893099308013916\n",
      "Epoch: 1, Batch: 674, Loss: 4.5464253425598145\n",
      "Epoch: 1, Batch: 675, Loss: 2.292259454727173\n",
      "Epoch: 1, Batch: 676, Loss: 4.692958831787109\n",
      "Epoch: 1, Batch: 677, Loss: 4.926947593688965\n",
      "Epoch: 1, Batch: 678, Loss: 3.3383703231811523\n",
      "Epoch: 1, Batch: 679, Loss: 4.640296459197998\n",
      "Epoch: 1, Batch: 680, Loss: 3.5774378776550293\n",
      "Epoch: 1, Batch: 681, Loss: 3.6366050243377686\n",
      "Epoch: 1, Batch: 682, Loss: 5.76723575592041\n",
      "Epoch: 1, Batch: 683, Loss: 2.2967567443847656\n",
      "Epoch: 1, Batch: 684, Loss: 2.3887217044830322\n",
      "Epoch: 1, Batch: 685, Loss: 1.9266928434371948\n",
      "Epoch: 1, Batch: 686, Loss: 6.2396135330200195\n",
      "Epoch: 1, Batch: 687, Loss: 2.539423942565918\n",
      "Epoch: 1, Batch: 688, Loss: 3.3867990970611572\n",
      "Epoch: 1, Batch: 689, Loss: 3.094038248062134\n",
      "Epoch: 1, Batch: 690, Loss: 6.297736644744873\n",
      "Epoch: 1, Batch: 691, Loss: 4.874659538269043\n",
      "Epoch: 1, Batch: 692, Loss: 1.536222219467163\n",
      "Epoch: 1, Batch: 693, Loss: 2.052403688430786\n",
      "Epoch: 1, Batch: 694, Loss: 2.6624059677124023\n",
      "Epoch: 1, Batch: 695, Loss: 4.809114456176758\n",
      "Epoch: 1, Batch: 696, Loss: 5.523471355438232\n",
      "Epoch: 1, Batch: 697, Loss: 2.1888210773468018\n",
      "Epoch: 1, Batch: 698, Loss: 3.9559569358825684\n",
      "Epoch: 1, Batch: 699, Loss: 1.2900364398956299\n",
      "Epoch: 1, Batch: 700, Loss: 7.493851184844971\n",
      "Epoch: 1, Batch: 701, Loss: 5.544561862945557\n",
      "Epoch: 1, Batch: 702, Loss: 4.156710147857666\n",
      "Epoch: 1, Batch: 703, Loss: 0.8701692819595337\n",
      "Epoch: 1, Batch: 704, Loss: 7.187670707702637\n",
      "Epoch: 1, Batch: 705, Loss: 1.554091453552246\n",
      "Epoch: 1, Batch: 706, Loss: 5.192968845367432\n",
      "Epoch: 1, Batch: 707, Loss: 2.172360420227051\n",
      "Epoch: 1, Batch: 708, Loss: 3.092827081680298\n",
      "Epoch: 1, Batch: 709, Loss: 9.394547462463379\n",
      "Epoch: 1, Batch: 710, Loss: 2.22139835357666\n",
      "Epoch: 1, Batch: 711, Loss: 2.0731935501098633\n",
      "Epoch: 1, Batch: 712, Loss: 1.5439913272857666\n",
      "Epoch: 1, Batch: 713, Loss: 2.9877567291259766\n",
      "Epoch: 1, Batch: 714, Loss: 3.66087007522583\n",
      "Epoch: 1, Batch: 715, Loss: 2.9241080284118652\n",
      "Epoch: 1, Batch: 716, Loss: 6.623106956481934\n",
      "Epoch: 1, Batch: 717, Loss: 2.6003754138946533\n",
      "Epoch: 1, Batch: 718, Loss: 3.864075183868408\n",
      "Epoch: 1, Batch: 719, Loss: 3.2578229904174805\n",
      "Epoch: 1, Batch: 720, Loss: 3.1377596855163574\n",
      "Epoch: 1, Batch: 721, Loss: 4.681597709655762\n",
      "Epoch: 1, Batch: 722, Loss: 2.0332696437835693\n",
      "Epoch: 1, Batch: 723, Loss: 3.6190693378448486\n",
      "Epoch: 1, Batch: 724, Loss: 3.368974208831787\n",
      "Epoch: 1, Batch: 725, Loss: 2.957014560699463\n",
      "Epoch: 1, Batch: 726, Loss: 3.1164097785949707\n",
      "Epoch: 1, Batch: 727, Loss: 4.743160724639893\n",
      "Epoch: 1, Batch: 728, Loss: 2.7764413356781006\n",
      "Epoch: 1, Batch: 729, Loss: 2.009432554244995\n",
      "Epoch: 1, Batch: 730, Loss: 2.834228992462158\n",
      "Epoch: 1, Batch: 731, Loss: 7.216775894165039\n",
      "Epoch: 1, Batch: 732, Loss: 2.026176691055298\n",
      "Epoch: 1, Batch: 733, Loss: 5.252041816711426\n",
      "Epoch: 1, Batch: 734, Loss: 6.172577857971191\n",
      "Epoch: 1, Batch: 735, Loss: 0.5065671801567078\n",
      "Epoch: 1, Batch: 736, Loss: 2.1063947677612305\n",
      "Epoch: 1, Batch: 737, Loss: 2.6884021759033203\n",
      "Epoch: 1, Batch: 738, Loss: 2.9266223907470703\n",
      "Epoch: 1, Batch: 739, Loss: 2.4334092140197754\n",
      "Epoch: 1, Batch: 740, Loss: 2.231210231781006\n",
      "Epoch: 1, Batch: 741, Loss: 2.0994832515716553\n",
      "Epoch: 1, Batch: 742, Loss: 1.0936988592147827\n",
      "Epoch: 1, Batch: 743, Loss: 3.7515957355499268\n",
      "Epoch: 1, Batch: 744, Loss: 3.634385108947754\n",
      "Epoch: 1, Batch: 745, Loss: 2.6132404804229736\n",
      "Epoch: 1, Batch: 746, Loss: 1.9564549922943115\n",
      "Epoch: 1, Batch: 747, Loss: 4.738740921020508\n",
      "Epoch: 1, Batch: 748, Loss: 6.263199806213379\n",
      "Epoch: 1, Batch: 749, Loss: 4.506906032562256\n",
      "Epoch: 1, Batch: 750, Loss: 4.505647659301758\n",
      "Epoch: 1, Batch: 751, Loss: 3.786992311477661\n",
      "Epoch: 1, Batch: 752, Loss: 2.7761759757995605\n",
      "Epoch: 1, Batch: 753, Loss: 1.2002490758895874\n",
      "Epoch: 1, Batch: 754, Loss: 4.200876712799072\n",
      "Epoch: 1, Batch: 755, Loss: 2.149538516998291\n",
      "Epoch: 1, Batch: 756, Loss: 5.024096965789795\n",
      "Epoch: 1, Batch: 757, Loss: 3.0076141357421875\n",
      "Epoch: 1, Batch: 758, Loss: 2.6224489212036133\n",
      "Epoch: 1, Batch: 759, Loss: 6.483770847320557\n",
      "Epoch: 1, Batch: 760, Loss: 4.435970783233643\n",
      "Epoch: 1, Batch: 761, Loss: 2.017866849899292\n",
      "Epoch: 1, Batch: 762, Loss: 1.5232967138290405\n",
      "Epoch: 1, Batch: 763, Loss: 5.050548553466797\n",
      "Epoch: 1, Batch: 764, Loss: 6.708915710449219\n",
      "Epoch: 1, Batch: 765, Loss: 4.57822322845459\n",
      "Epoch: 1, Batch: 766, Loss: 2.887178897857666\n",
      "Epoch: 1, Batch: 767, Loss: 2.890535593032837\n",
      "Epoch: 1, Batch: 768, Loss: 2.750823736190796\n",
      "Epoch: 1, Batch: 769, Loss: 3.731492280960083\n",
      "Epoch: 1, Batch: 770, Loss: 3.497159004211426\n",
      "Epoch: 1, Batch: 771, Loss: 4.685256004333496\n",
      "Epoch: 1, Batch: 772, Loss: 1.4281450510025024\n",
      "Epoch: 1, Batch: 773, Loss: 2.8848328590393066\n",
      "Epoch: 1, Batch: 774, Loss: 5.988236427307129\n",
      "Epoch: 1, Batch: 775, Loss: 2.376830577850342\n",
      "Epoch: 1, Batch: 776, Loss: 5.176391124725342\n",
      "Epoch: 1, Batch: 777, Loss: 1.662109375\n",
      "Epoch: 1, Batch: 778, Loss: 3.027446985244751\n",
      "Epoch: 1, Batch: 779, Loss: 2.723466634750366\n",
      "Epoch: 1, Batch: 780, Loss: 1.4866716861724854\n",
      "Epoch: 1, Batch: 781, Loss: 6.746074676513672\n",
      "Epoch: 1, Batch: 782, Loss: 5.73262357711792\n",
      "Epoch: 1, Batch: 783, Loss: 3.710078239440918\n",
      "Epoch: 1, Batch: 784, Loss: 2.393787145614624\n",
      "Epoch: 1, Batch: 785, Loss: 2.2671334743499756\n",
      "Epoch: 1, Batch: 786, Loss: 0.7899906635284424\n",
      "Epoch: 1, Batch: 787, Loss: 5.216955661773682\n",
      "Epoch: 1, Batch: 788, Loss: 4.25228214263916\n",
      "Epoch: 1, Batch: 789, Loss: 3.5316591262817383\n",
      "Epoch: 1, Batch: 790, Loss: 4.197713851928711\n",
      "Epoch: 1, Batch: 791, Loss: 2.6343770027160645\n",
      "Epoch: 1, Batch: 792, Loss: 2.8405566215515137\n",
      "Epoch: 1, Batch: 793, Loss: 4.309385776519775\n",
      "Epoch: 1, Batch: 794, Loss: 4.464338302612305\n",
      "Epoch: 1, Batch: 795, Loss: 3.2537894248962402\n",
      "Epoch: 1, Batch: 796, Loss: 5.806551933288574\n",
      "Epoch: 1, Batch: 797, Loss: 1.4556993246078491\n",
      "Epoch: 1, Batch: 798, Loss: 6.690909385681152\n",
      "Epoch: 1, Batch: 799, Loss: 3.6385600566864014\n",
      "Epoch: 1, Batch: 800, Loss: 8.252280235290527\n",
      "Epoch: 1, Batch: 801, Loss: 7.829965591430664\n",
      "Epoch: 1, Batch: 802, Loss: 2.4314281940460205\n",
      "Epoch: 1, Batch: 803, Loss: 2.800877094268799\n",
      "Epoch: 1, Batch: 804, Loss: 3.378603935241699\n",
      "Epoch: 1, Batch: 805, Loss: 6.113168716430664\n",
      "Epoch: 1, Batch: 806, Loss: 2.0665204524993896\n",
      "Epoch: 1, Batch: 807, Loss: 2.4051899909973145\n",
      "Epoch: 1, Batch: 808, Loss: 5.274656772613525\n",
      "Epoch: 1, Batch: 809, Loss: 4.909212589263916\n",
      "Epoch: 1, Batch: 810, Loss: 3.172391414642334\n",
      "Epoch: 1, Batch: 811, Loss: 3.527827501296997\n",
      "Epoch: 1, Batch: 812, Loss: 2.862359046936035\n",
      "Epoch: 1, Batch: 813, Loss: 3.8985729217529297\n",
      "Epoch: 1, Batch: 814, Loss: 2.136341094970703\n",
      "Epoch: 1, Batch: 815, Loss: 7.299467086791992\n",
      "Epoch: 1, Batch: 816, Loss: 3.360940456390381\n",
      "Epoch: 1, Batch: 817, Loss: 1.3678760528564453\n",
      "Epoch: 1, Batch: 818, Loss: 1.8646422624588013\n",
      "Epoch: 1, Batch: 819, Loss: 10.800268173217773\n",
      "Epoch: 1, Batch: 820, Loss: 5.222190856933594\n",
      "Epoch: 1, Batch: 821, Loss: 3.879671096801758\n",
      "Epoch: 1, Batch: 822, Loss: 2.1534619331359863\n",
      "Epoch: 1, Batch: 823, Loss: 6.594235897064209\n",
      "Epoch: 1, Batch: 824, Loss: 1.8555262088775635\n",
      "Epoch: 1, Batch: 825, Loss: 2.2996232509613037\n",
      "Epoch: 1, Batch: 826, Loss: 6.030791759490967\n",
      "Epoch: 1, Batch: 827, Loss: 2.2041988372802734\n",
      "Epoch: 1, Batch: 828, Loss: 2.6783132553100586\n",
      "Epoch: 1, Batch: 829, Loss: 4.039056777954102\n",
      "Epoch: 1, Batch: 830, Loss: 4.253450393676758\n",
      "Epoch: 1, Batch: 831, Loss: 4.933200836181641\n",
      "Epoch: 1, Batch: 832, Loss: 5.152786731719971\n",
      "Epoch: 1, Batch: 833, Loss: 5.3584303855896\n",
      "Epoch: 1, Batch: 834, Loss: 2.4482903480529785\n",
      "Epoch: 1, Batch: 835, Loss: 5.653228282928467\n",
      "Epoch: 1, Batch: 836, Loss: 1.0002121925354004\n",
      "Epoch: 1, Batch: 837, Loss: 1.42963445186615\n",
      "Epoch: 1, Batch: 838, Loss: 1.6097544431686401\n",
      "Epoch: 1, Batch: 839, Loss: 2.184377670288086\n",
      "Epoch: 1, Batch: 840, Loss: 4.5376505851745605\n",
      "Epoch: 1, Batch: 841, Loss: 4.141802787780762\n",
      "Epoch: 1, Batch: 842, Loss: 3.7355382442474365\n",
      "Epoch: 1, Batch: 843, Loss: 2.0062081813812256\n",
      "Epoch: 1, Batch: 844, Loss: 2.4881300926208496\n",
      "Epoch: 1, Batch: 845, Loss: 3.439525604248047\n",
      "Epoch: 1, Batch: 846, Loss: 2.984807252883911\n",
      "Epoch: 1, Batch: 847, Loss: 5.3198394775390625\n",
      "Epoch: 1, Batch: 848, Loss: 1.0276380777359009\n",
      "Epoch: 1, Batch: 849, Loss: 0.6103222370147705\n",
      "Epoch: 1, Batch: 850, Loss: 1.9778053760528564\n",
      "Epoch: 1, Batch: 851, Loss: 2.1295347213745117\n",
      "Epoch: 1, Batch: 852, Loss: 6.087063312530518\n",
      "Epoch: 1, Batch: 853, Loss: 2.3122568130493164\n",
      "Epoch: 1, Batch: 854, Loss: 3.4626102447509766\n",
      "Epoch: 1, Batch: 855, Loss: 1.9914088249206543\n",
      "Epoch: 1, Batch: 856, Loss: 2.5698471069335938\n",
      "Epoch: 1, Batch: 857, Loss: 3.262037754058838\n",
      "Epoch: 1, Batch: 858, Loss: 5.702656269073486\n",
      "Epoch: 1, Batch: 859, Loss: 3.5026631355285645\n",
      "Epoch: 1, Batch: 860, Loss: 3.7196695804595947\n",
      "Epoch: 1, Batch: 861, Loss: 3.9853451251983643\n",
      "Epoch: 1, Batch: 862, Loss: 4.40699577331543\n",
      "Epoch: 1, Batch: 863, Loss: 1.1878381967544556\n",
      "Epoch: 1, Batch: 864, Loss: 2.735898017883301\n",
      "Epoch: 1, Batch: 865, Loss: 1.5074703693389893\n",
      "Epoch: 1, Batch: 866, Loss: 2.670428991317749\n",
      "Epoch: 1, Batch: 867, Loss: 4.815479278564453\n",
      "Epoch: 1, Batch: 868, Loss: 1.675630807876587\n",
      "Epoch: 1, Batch: 869, Loss: 1.9811267852783203\n",
      "Epoch: 1, Batch: 870, Loss: 6.325096130371094\n",
      "Epoch: 1, Batch: 871, Loss: 2.933096408843994\n",
      "Epoch: 1, Batch: 872, Loss: 4.087316513061523\n",
      "Epoch: 1, Batch: 873, Loss: 1.8680270910263062\n",
      "Epoch: 1, Batch: 874, Loss: 3.7853012084960938\n",
      "Epoch: 1, Batch: 875, Loss: 4.465827941894531\n",
      "Epoch: 1, Batch: 876, Loss: 1.7006174325942993\n",
      "Epoch: 1, Batch: 877, Loss: 4.409826278686523\n",
      "Epoch: 1, Batch: 878, Loss: 4.309754371643066\n",
      "Epoch: 1, Batch: 879, Loss: 5.806149482727051\n",
      "Epoch: 1, Batch: 880, Loss: 1.995694637298584\n",
      "Epoch: 1, Batch: 881, Loss: 4.308854103088379\n",
      "Epoch: 1, Batch: 882, Loss: 6.315708637237549\n",
      "Epoch: 1, Batch: 883, Loss: 3.3291969299316406\n",
      "Epoch: 1, Batch: 884, Loss: 3.3978757858276367\n",
      "Epoch: 1, Batch: 885, Loss: 5.313469886779785\n",
      "Epoch: 1, Batch: 886, Loss: 5.800358772277832\n",
      "Epoch: 1, Batch: 887, Loss: 4.300661563873291\n",
      "Epoch: 1, Batch: 888, Loss: 0.7968374490737915\n",
      "Epoch: 1, Batch: 889, Loss: 5.148643493652344\n",
      "Epoch: 1, Batch: 890, Loss: 2.305715799331665\n",
      "Epoch: 1, Batch: 891, Loss: 3.3288941383361816\n",
      "Epoch: 1, Batch: 892, Loss: 3.1416375637054443\n",
      "Epoch: 1, Batch: 893, Loss: 1.3106820583343506\n",
      "Epoch: 1, Batch: 894, Loss: 1.3364434242248535\n",
      "Epoch: 1, Batch: 895, Loss: 2.3645856380462646\n",
      "Epoch: 1, Batch: 896, Loss: 2.9209227561950684\n",
      "Epoch: 1, Batch: 897, Loss: 5.5469465255737305\n",
      "Epoch: 1, Batch: 898, Loss: 2.0748798847198486\n",
      "Epoch: 1, Batch: 899, Loss: 4.887117385864258\n",
      "Epoch: 1, Batch: 900, Loss: 2.4206786155700684\n",
      "Epoch: 1, Batch: 901, Loss: 6.294124126434326\n",
      "Epoch: 1, Batch: 902, Loss: 3.658928155899048\n",
      "Epoch: 1, Batch: 903, Loss: 4.877796649932861\n",
      "Epoch: 1, Batch: 904, Loss: 3.866675615310669\n",
      "Epoch: 1, Batch: 905, Loss: 3.425534725189209\n",
      "Epoch: 1, Batch: 906, Loss: 4.4346442222595215\n",
      "Epoch: 1, Batch: 907, Loss: 3.912388801574707\n",
      "Epoch: 1, Batch: 908, Loss: 2.4641473293304443\n",
      "Epoch: 1, Batch: 909, Loss: 5.119804859161377\n",
      "Epoch: 1, Batch: 910, Loss: 3.280250072479248\n",
      "Epoch: 1, Batch: 911, Loss: 3.572798728942871\n",
      "Epoch: 1, Batch: 912, Loss: 5.386655330657959\n",
      "Epoch: 1, Batch: 913, Loss: 4.493323802947998\n",
      "Epoch: 1, Batch: 914, Loss: 5.073731899261475\n",
      "Epoch: 1, Batch: 915, Loss: 2.910233497619629\n",
      "Epoch: 1, Batch: 916, Loss: 2.4018733501434326\n",
      "Epoch: 1, Batch: 917, Loss: 5.9574785232543945\n",
      "Epoch: 1, Batch: 918, Loss: 2.702946186065674\n",
      "Epoch: 1, Batch: 919, Loss: 4.628625392913818\n",
      "Epoch: 1, Batch: 920, Loss: 3.1420326232910156\n",
      "Epoch: 1, Batch: 921, Loss: 3.3440101146698\n",
      "Epoch: 1, Batch: 922, Loss: 4.093208312988281\n",
      "Epoch: 1, Batch: 923, Loss: 3.2923521995544434\n",
      "Epoch: 1, Batch: 924, Loss: 3.1832618713378906\n",
      "Epoch: 1, Batch: 925, Loss: 3.5304322242736816\n",
      "Epoch: 1, Batch: 926, Loss: 2.221308708190918\n",
      "Epoch: 1, Batch: 927, Loss: 3.234592914581299\n",
      "Epoch: 1, Batch: 928, Loss: 6.0514235496521\n",
      "Epoch: 1, Batch: 929, Loss: 3.4406585693359375\n",
      "Epoch: 1, Batch: 930, Loss: 4.557118892669678\n",
      "Epoch: 1, Batch: 931, Loss: 2.385831117630005\n",
      "Epoch: 1, Batch: 932, Loss: 4.423456192016602\n",
      "Epoch: 1, Batch: 933, Loss: 1.1597604751586914\n",
      "Epoch: 1, Batch: 934, Loss: 1.9671674966812134\n",
      "Epoch: 1, Batch: 935, Loss: 5.595400333404541\n",
      "Epoch: 1, Batch: 936, Loss: 3.9353060722351074\n",
      "Epoch: 1, Batch: 937, Loss: 3.3872432708740234\n",
      "Epoch: 1, Batch: 938, Loss: 0.5112138986587524\n",
      "Epoch: 1, Batch: 939, Loss: 2.946552276611328\n",
      "Epoch: 1, Batch: 940, Loss: 4.132078170776367\n",
      "Epoch: 1, Batch: 941, Loss: 1.0025252103805542\n",
      "Epoch: 1, Batch: 942, Loss: 4.654419422149658\n",
      "Epoch: 1, Batch: 943, Loss: 3.4681396484375\n",
      "Epoch: 1, Batch: 944, Loss: 3.537644386291504\n",
      "Epoch: 1, Batch: 945, Loss: 1.7908966541290283\n",
      "Epoch: 1, Batch: 946, Loss: 4.979448318481445\n",
      "Epoch: 1, Batch: 947, Loss: 0.6419321298599243\n",
      "Epoch: 1, Batch: 948, Loss: 2.5165786743164062\n",
      "Epoch: 1, Batch: 949, Loss: 3.0560660362243652\n",
      "Epoch: 1, Batch: 950, Loss: 2.9957327842712402\n",
      "Epoch: 1, Batch: 951, Loss: 1.2332110404968262\n",
      "Epoch: 1, Batch: 952, Loss: 3.9411075115203857\n",
      "Epoch: 1, Batch: 953, Loss: 5.12847900390625\n",
      "Epoch: 1, Batch: 954, Loss: 2.3651485443115234\n",
      "Epoch: 1, Batch: 955, Loss: 4.262293815612793\n",
      "Epoch: 1, Batch: 956, Loss: 2.202854871749878\n",
      "Epoch: 1, Batch: 957, Loss: 4.29356575012207\n",
      "Epoch: 1, Batch: 958, Loss: 5.164109230041504\n",
      "Epoch: 1, Batch: 959, Loss: 5.171833038330078\n",
      "Epoch: 1, Batch: 960, Loss: 2.6300594806671143\n",
      "Epoch: 1, Batch: 961, Loss: 1.3925198316574097\n",
      "Epoch: 1, Batch: 962, Loss: 2.7750890254974365\n",
      "Epoch: 1, Batch: 963, Loss: 5.218301296234131\n",
      "Epoch: 1, Batch: 964, Loss: 2.748065233230591\n",
      "Epoch: 1, Batch: 965, Loss: 5.838361740112305\n",
      "Epoch: 1, Batch: 966, Loss: 5.626405715942383\n",
      "Epoch: 1, Batch: 967, Loss: 2.537169933319092\n",
      "Epoch: 1, Batch: 968, Loss: 4.600892066955566\n",
      "Epoch: 1, Batch: 969, Loss: 1.831061840057373\n",
      "Epoch: 1, Batch: 970, Loss: 1.7926182746887207\n",
      "Epoch: 1, Batch: 971, Loss: 0.5084513425827026\n",
      "Epoch: 1, Batch: 972, Loss: 7.696364402770996\n",
      "Epoch: 1, Batch: 973, Loss: 6.7895660400390625\n",
      "Epoch: 1, Batch: 974, Loss: 0.6218896508216858\n",
      "Epoch: 1, Batch: 975, Loss: 2.6941628456115723\n",
      "Epoch: 1, Batch: 976, Loss: 3.667327880859375\n",
      "Epoch: 1, Batch: 977, Loss: 1.9367278814315796\n",
      "Epoch: 1, Batch: 978, Loss: 2.989010810852051\n",
      "Epoch: 1, Batch: 979, Loss: 3.544473886489868\n",
      "Epoch: 1, Batch: 980, Loss: 4.242801189422607\n",
      "Epoch: 1, Batch: 981, Loss: 3.6810121536254883\n",
      "Epoch: 1, Batch: 982, Loss: 3.971341133117676\n",
      "Epoch: 1, Batch: 983, Loss: 1.9088125228881836\n",
      "Epoch: 1, Batch: 984, Loss: 2.8752493858337402\n",
      "Epoch: 1, Batch: 985, Loss: 2.0228192806243896\n",
      "Epoch: 1, Batch: 986, Loss: 1.4232152700424194\n",
      "Epoch: 1, Batch: 987, Loss: 3.510892868041992\n",
      "Epoch: 1, Batch: 988, Loss: 3.999133586883545\n",
      "Epoch: 1, Batch: 989, Loss: 4.616812705993652\n",
      "Epoch: 1, Batch: 990, Loss: 5.440585136413574\n",
      "Epoch: 1, Batch: 991, Loss: 10.54375171661377\n",
      "Epoch: 1, Batch: 992, Loss: 2.5683341026306152\n",
      "Epoch: 1, Batch: 993, Loss: 2.8247809410095215\n",
      "Epoch: 1, Batch: 994, Loss: 2.0251996517181396\n",
      "Epoch: 1, Batch: 995, Loss: 3.3145768642425537\n",
      "Epoch: 1, Batch: 996, Loss: 4.224156856536865\n",
      "Epoch: 1, Batch: 997, Loss: 2.5393104553222656\n",
      "Epoch: 1, Batch: 998, Loss: 4.057032585144043\n",
      "Epoch: 1, Batch: 999, Loss: 4.091920375823975\n",
      "Epoch: 2, Batch: 0, Loss: 1.851226568222046\n",
      "Epoch: 2, Batch: 1, Loss: 2.347656011581421\n",
      "Epoch: 2, Batch: 2, Loss: 4.388198375701904\n",
      "Epoch: 2, Batch: 3, Loss: 0.8126136064529419\n",
      "Epoch: 2, Batch: 4, Loss: 3.0587446689605713\n",
      "Epoch: 2, Batch: 5, Loss: 2.3775978088378906\n",
      "Epoch: 2, Batch: 6, Loss: 2.010554552078247\n",
      "Epoch: 2, Batch: 7, Loss: 2.5461630821228027\n",
      "Epoch: 2, Batch: 8, Loss: 1.2656278610229492\n",
      "Epoch: 2, Batch: 9, Loss: 2.9558229446411133\n",
      "Epoch: 2, Batch: 10, Loss: 5.978157997131348\n",
      "Epoch: 2, Batch: 11, Loss: 1.9772602319717407\n",
      "Epoch: 2, Batch: 12, Loss: 5.4260573387146\n",
      "Epoch: 2, Batch: 13, Loss: 3.4426796436309814\n",
      "Epoch: 2, Batch: 14, Loss: 3.0132524967193604\n",
      "Epoch: 2, Batch: 15, Loss: 3.8035969734191895\n",
      "Epoch: 2, Batch: 16, Loss: 2.900390386581421\n",
      "Epoch: 2, Batch: 17, Loss: 3.338775634765625\n",
      "Epoch: 2, Batch: 18, Loss: 1.3877878189086914\n",
      "Epoch: 2, Batch: 19, Loss: 1.9464831352233887\n",
      "Epoch: 2, Batch: 20, Loss: 4.068463325500488\n",
      "Epoch: 2, Batch: 21, Loss: 2.4127964973449707\n",
      "Epoch: 2, Batch: 22, Loss: 4.319167137145996\n",
      "Epoch: 2, Batch: 23, Loss: 2.1577224731445312\n",
      "Epoch: 2, Batch: 24, Loss: 3.2742996215820312\n",
      "Epoch: 2, Batch: 25, Loss: 1.0617053508758545\n",
      "Epoch: 2, Batch: 26, Loss: 4.168727874755859\n",
      "Epoch: 2, Batch: 27, Loss: 4.8470001220703125\n",
      "Epoch: 2, Batch: 28, Loss: 1.6943674087524414\n",
      "Epoch: 2, Batch: 29, Loss: 4.166021823883057\n",
      "Epoch: 2, Batch: 30, Loss: 1.2129817008972168\n",
      "Epoch: 2, Batch: 31, Loss: 1.0183473825454712\n",
      "Epoch: 2, Batch: 32, Loss: 3.293529987335205\n",
      "Epoch: 2, Batch: 33, Loss: 4.05872917175293\n",
      "Epoch: 2, Batch: 34, Loss: 1.1804569959640503\n",
      "Epoch: 2, Batch: 35, Loss: 2.2547683715820312\n",
      "Epoch: 2, Batch: 36, Loss: 2.1675782203674316\n",
      "Epoch: 2, Batch: 37, Loss: 2.325178861618042\n",
      "Epoch: 2, Batch: 38, Loss: 5.744545936584473\n",
      "Epoch: 2, Batch: 39, Loss: 2.2107315063476562\n",
      "Epoch: 2, Batch: 40, Loss: 3.3727054595947266\n",
      "Epoch: 2, Batch: 41, Loss: 1.74175226688385\n",
      "Epoch: 2, Batch: 42, Loss: 3.7039694786071777\n",
      "Epoch: 2, Batch: 43, Loss: 2.8910651206970215\n",
      "Epoch: 2, Batch: 44, Loss: 5.794872283935547\n",
      "Epoch: 2, Batch: 45, Loss: 2.165607452392578\n",
      "Epoch: 2, Batch: 46, Loss: 1.6904786825180054\n",
      "Epoch: 2, Batch: 47, Loss: 3.409574031829834\n",
      "Epoch: 2, Batch: 48, Loss: 2.3953499794006348\n",
      "Epoch: 2, Batch: 49, Loss: 2.089979648590088\n",
      "Epoch: 2, Batch: 50, Loss: 3.186260223388672\n",
      "Epoch: 2, Batch: 51, Loss: 2.3713107109069824\n",
      "Epoch: 2, Batch: 52, Loss: 4.476083278656006\n",
      "Epoch: 2, Batch: 53, Loss: 3.5236265659332275\n",
      "Epoch: 2, Batch: 54, Loss: 3.798560619354248\n",
      "Epoch: 2, Batch: 55, Loss: 3.216172695159912\n",
      "Epoch: 2, Batch: 56, Loss: 4.774476051330566\n",
      "Epoch: 2, Batch: 57, Loss: 2.994490623474121\n",
      "Epoch: 2, Batch: 58, Loss: 1.5248656272888184\n",
      "Epoch: 2, Batch: 59, Loss: 8.006661415100098\n",
      "Epoch: 2, Batch: 60, Loss: 1.1984484195709229\n",
      "Epoch: 2, Batch: 61, Loss: 3.9060897827148438\n",
      "Epoch: 2, Batch: 62, Loss: 4.722521781921387\n",
      "Epoch: 2, Batch: 63, Loss: 5.484433174133301\n",
      "Epoch: 2, Batch: 64, Loss: 3.205362319946289\n",
      "Epoch: 2, Batch: 65, Loss: 1.8315147161483765\n",
      "Epoch: 2, Batch: 66, Loss: 6.554111480712891\n",
      "Epoch: 2, Batch: 67, Loss: 3.3410983085632324\n",
      "Epoch: 2, Batch: 68, Loss: 3.7343382835388184\n",
      "Epoch: 2, Batch: 69, Loss: 2.0847067832946777\n",
      "Epoch: 2, Batch: 70, Loss: 5.10019063949585\n",
      "Epoch: 2, Batch: 71, Loss: 5.658938884735107\n",
      "Epoch: 2, Batch: 72, Loss: 3.3926565647125244\n",
      "Epoch: 2, Batch: 73, Loss: 4.571794509887695\n",
      "Epoch: 2, Batch: 74, Loss: 2.9187045097351074\n",
      "Epoch: 2, Batch: 75, Loss: 1.6607348918914795\n",
      "Epoch: 2, Batch: 76, Loss: 1.1517540216445923\n",
      "Epoch: 2, Batch: 77, Loss: 3.245776653289795\n",
      "Epoch: 2, Batch: 78, Loss: 0.7860468626022339\n",
      "Epoch: 2, Batch: 79, Loss: 2.664048194885254\n",
      "Epoch: 2, Batch: 80, Loss: 2.0249581336975098\n",
      "Epoch: 2, Batch: 81, Loss: 2.502471923828125\n",
      "Epoch: 2, Batch: 82, Loss: 3.5528719425201416\n",
      "Epoch: 2, Batch: 83, Loss: 2.0557360649108887\n",
      "Epoch: 2, Batch: 84, Loss: 2.575368642807007\n",
      "Epoch: 2, Batch: 85, Loss: 4.6721110343933105\n",
      "Epoch: 2, Batch: 86, Loss: 2.5239787101745605\n",
      "Epoch: 2, Batch: 87, Loss: 3.4819743633270264\n",
      "Epoch: 2, Batch: 88, Loss: 2.1375327110290527\n",
      "Epoch: 2, Batch: 89, Loss: 0.23702093958854675\n",
      "Epoch: 2, Batch: 90, Loss: 1.9577139616012573\n",
      "Epoch: 2, Batch: 91, Loss: 2.8855340480804443\n",
      "Epoch: 2, Batch: 92, Loss: 1.1007838249206543\n",
      "Epoch: 2, Batch: 93, Loss: 6.697650909423828\n",
      "Epoch: 2, Batch: 94, Loss: 2.4500937461853027\n",
      "Epoch: 2, Batch: 95, Loss: 2.6570286750793457\n",
      "Epoch: 2, Batch: 96, Loss: 2.1244382858276367\n",
      "Epoch: 2, Batch: 97, Loss: 2.722677707672119\n",
      "Epoch: 2, Batch: 98, Loss: 2.95113468170166\n",
      "Epoch: 2, Batch: 99, Loss: 0.7363086938858032\n",
      "Epoch: 2, Batch: 100, Loss: 1.875769019126892\n",
      "Epoch: 2, Batch: 101, Loss: 4.78611946105957\n",
      "Epoch: 2, Batch: 102, Loss: 2.7263784408569336\n",
      "Epoch: 2, Batch: 103, Loss: 0.9547259211540222\n",
      "Epoch: 2, Batch: 104, Loss: 5.238183975219727\n",
      "Epoch: 2, Batch: 105, Loss: 2.1479718685150146\n",
      "Epoch: 2, Batch: 106, Loss: 3.238759756088257\n",
      "Epoch: 2, Batch: 107, Loss: 3.1856484413146973\n",
      "Epoch: 2, Batch: 108, Loss: 1.9842454195022583\n",
      "Epoch: 2, Batch: 109, Loss: 2.6234283447265625\n",
      "Epoch: 2, Batch: 110, Loss: 2.6074392795562744\n",
      "Epoch: 2, Batch: 111, Loss: 1.4030592441558838\n",
      "Epoch: 2, Batch: 112, Loss: 2.418161153793335\n",
      "Epoch: 2, Batch: 113, Loss: 3.9146478176116943\n",
      "Epoch: 2, Batch: 114, Loss: 0.5459998250007629\n",
      "Epoch: 2, Batch: 115, Loss: 4.60657262802124\n",
      "Epoch: 2, Batch: 116, Loss: 3.445269823074341\n",
      "Epoch: 2, Batch: 117, Loss: 1.2541102170944214\n",
      "Epoch: 2, Batch: 118, Loss: 1.038601279258728\n",
      "Epoch: 2, Batch: 119, Loss: 2.8412046432495117\n",
      "Epoch: 2, Batch: 120, Loss: 1.1697394847869873\n",
      "Epoch: 2, Batch: 121, Loss: 3.101917266845703\n",
      "Epoch: 2, Batch: 122, Loss: 3.3711354732513428\n",
      "Epoch: 2, Batch: 123, Loss: 5.2213358879089355\n",
      "Epoch: 2, Batch: 124, Loss: 2.2813587188720703\n",
      "Epoch: 2, Batch: 125, Loss: 3.336596727371216\n",
      "Epoch: 2, Batch: 126, Loss: 3.7860686779022217\n",
      "Epoch: 2, Batch: 127, Loss: 1.264607310295105\n",
      "Epoch: 2, Batch: 128, Loss: 1.9629616737365723\n",
      "Epoch: 2, Batch: 129, Loss: 3.3518199920654297\n",
      "Epoch: 2, Batch: 130, Loss: 1.6362844705581665\n",
      "Epoch: 2, Batch: 131, Loss: 2.545475721359253\n",
      "Epoch: 2, Batch: 132, Loss: 2.648408889770508\n",
      "Epoch: 2, Batch: 133, Loss: 0.8914088010787964\n",
      "Epoch: 2, Batch: 134, Loss: 4.605742931365967\n",
      "Epoch: 2, Batch: 135, Loss: 3.0353944301605225\n",
      "Epoch: 2, Batch: 136, Loss: 5.1237006187438965\n",
      "Epoch: 2, Batch: 137, Loss: 2.642198085784912\n",
      "Epoch: 2, Batch: 138, Loss: 1.121408462524414\n",
      "Epoch: 2, Batch: 139, Loss: 1.5282645225524902\n",
      "Epoch: 2, Batch: 140, Loss: 1.7543187141418457\n",
      "Epoch: 2, Batch: 141, Loss: 2.926145076751709\n",
      "Epoch: 2, Batch: 142, Loss: 3.3396315574645996\n",
      "Epoch: 2, Batch: 143, Loss: 3.084123373031616\n",
      "Epoch: 2, Batch: 144, Loss: 1.9169373512268066\n",
      "Epoch: 2, Batch: 145, Loss: 0.518580436706543\n",
      "Epoch: 2, Batch: 146, Loss: 1.7995531558990479\n",
      "Epoch: 2, Batch: 147, Loss: 4.81095027923584\n",
      "Epoch: 2, Batch: 148, Loss: 5.0004563331604\n",
      "Epoch: 2, Batch: 149, Loss: 1.096417784690857\n",
      "Epoch: 2, Batch: 150, Loss: 2.458369255065918\n",
      "Epoch: 2, Batch: 151, Loss: 1.5320101976394653\n",
      "Epoch: 2, Batch: 152, Loss: 2.339789628982544\n",
      "Epoch: 2, Batch: 153, Loss: 2.1886894702911377\n",
      "Epoch: 2, Batch: 154, Loss: 4.434892654418945\n",
      "Epoch: 2, Batch: 155, Loss: 3.3801119327545166\n",
      "Epoch: 2, Batch: 156, Loss: 2.7321290969848633\n",
      "Epoch: 2, Batch: 157, Loss: 0.46837618947029114\n",
      "Epoch: 2, Batch: 158, Loss: 2.5872554779052734\n",
      "Epoch: 2, Batch: 159, Loss: 5.207158088684082\n",
      "Epoch: 2, Batch: 160, Loss: 5.403151988983154\n",
      "Epoch: 2, Batch: 161, Loss: 6.5336737632751465\n",
      "Epoch: 2, Batch: 162, Loss: 2.11179518699646\n",
      "Epoch: 2, Batch: 163, Loss: 1.2208958864212036\n",
      "Epoch: 2, Batch: 164, Loss: 2.4749338626861572\n",
      "Epoch: 2, Batch: 165, Loss: 1.9727895259857178\n",
      "Epoch: 2, Batch: 166, Loss: 0.8463927507400513\n",
      "Epoch: 2, Batch: 167, Loss: 3.0608253479003906\n",
      "Epoch: 2, Batch: 168, Loss: 3.8122341632843018\n",
      "Epoch: 2, Batch: 169, Loss: 2.8795132637023926\n",
      "Epoch: 2, Batch: 170, Loss: 2.974392890930176\n",
      "Epoch: 2, Batch: 171, Loss: 1.2902381420135498\n",
      "Epoch: 2, Batch: 172, Loss: 6.731367588043213\n",
      "Epoch: 2, Batch: 173, Loss: 4.236445903778076\n",
      "Epoch: 2, Batch: 174, Loss: 3.201688289642334\n",
      "Epoch: 2, Batch: 175, Loss: 2.5098958015441895\n",
      "Epoch: 2, Batch: 176, Loss: 3.043818712234497\n",
      "Epoch: 2, Batch: 177, Loss: 2.486445903778076\n",
      "Epoch: 2, Batch: 178, Loss: 4.283429145812988\n",
      "Epoch: 2, Batch: 179, Loss: 3.430887460708618\n",
      "Epoch: 2, Batch: 180, Loss: 3.580146551132202\n",
      "Epoch: 2, Batch: 181, Loss: 0.9915931224822998\n",
      "Epoch: 2, Batch: 182, Loss: 4.672554969787598\n",
      "Epoch: 2, Batch: 183, Loss: 3.7926197052001953\n",
      "Epoch: 2, Batch: 184, Loss: 0.610113799571991\n",
      "Epoch: 2, Batch: 185, Loss: 1.5315052270889282\n",
      "Epoch: 2, Batch: 186, Loss: 0.346669465303421\n",
      "Epoch: 2, Batch: 187, Loss: 1.9382704496383667\n",
      "Epoch: 2, Batch: 188, Loss: 1.6437175273895264\n",
      "Epoch: 2, Batch: 189, Loss: 2.095313549041748\n",
      "Epoch: 2, Batch: 190, Loss: 2.1072769165039062\n",
      "Epoch: 2, Batch: 191, Loss: 7.234346389770508\n",
      "Epoch: 2, Batch: 192, Loss: 4.279512405395508\n",
      "Epoch: 2, Batch: 193, Loss: 2.018270969390869\n",
      "Epoch: 2, Batch: 194, Loss: 1.2912875413894653\n",
      "Epoch: 2, Batch: 195, Loss: 1.832600474357605\n",
      "Epoch: 2, Batch: 196, Loss: 2.2627291679382324\n",
      "Epoch: 2, Batch: 197, Loss: 2.4338595867156982\n",
      "Epoch: 2, Batch: 198, Loss: 3.2774159908294678\n",
      "Epoch: 2, Batch: 199, Loss: 2.041874408721924\n",
      "Epoch: 2, Batch: 200, Loss: 1.2762603759765625\n",
      "Epoch: 2, Batch: 201, Loss: 3.5891709327697754\n",
      "Epoch: 2, Batch: 202, Loss: 3.1520745754241943\n",
      "Epoch: 2, Batch: 203, Loss: 3.4262349605560303\n",
      "Epoch: 2, Batch: 204, Loss: 3.0889065265655518\n",
      "Epoch: 2, Batch: 205, Loss: 5.279508590698242\n",
      "Epoch: 2, Batch: 206, Loss: 5.432956695556641\n",
      "Epoch: 2, Batch: 207, Loss: 2.1734395027160645\n",
      "Epoch: 2, Batch: 208, Loss: 3.368518590927124\n",
      "Epoch: 2, Batch: 209, Loss: 4.067583084106445\n",
      "Epoch: 2, Batch: 210, Loss: 1.822283387184143\n",
      "Epoch: 2, Batch: 211, Loss: 1.7463531494140625\n",
      "Epoch: 2, Batch: 212, Loss: 4.405388355255127\n",
      "Epoch: 2, Batch: 213, Loss: 1.9725384712219238\n",
      "Epoch: 2, Batch: 214, Loss: 6.475438594818115\n",
      "Epoch: 2, Batch: 215, Loss: 4.308984756469727\n",
      "Epoch: 2, Batch: 216, Loss: 2.4583797454833984\n",
      "Epoch: 2, Batch: 217, Loss: 5.518218994140625\n",
      "Epoch: 2, Batch: 218, Loss: 3.2849183082580566\n",
      "Epoch: 2, Batch: 219, Loss: 3.2210090160369873\n",
      "Epoch: 2, Batch: 220, Loss: 2.5984673500061035\n",
      "Epoch: 2, Batch: 221, Loss: 1.8322207927703857\n",
      "Epoch: 2, Batch: 222, Loss: 1.8431031703948975\n",
      "Epoch: 2, Batch: 223, Loss: 2.82041597366333\n",
      "Epoch: 2, Batch: 224, Loss: 2.698489189147949\n",
      "Epoch: 2, Batch: 225, Loss: 3.5087733268737793\n",
      "Epoch: 2, Batch: 226, Loss: 3.7258870601654053\n",
      "Epoch: 2, Batch: 227, Loss: 1.9394333362579346\n",
      "Epoch: 2, Batch: 228, Loss: 1.8570854663848877\n",
      "Epoch: 2, Batch: 229, Loss: 3.3587918281555176\n",
      "Epoch: 2, Batch: 230, Loss: 3.266092300415039\n",
      "Epoch: 2, Batch: 231, Loss: 1.611939787864685\n",
      "Epoch: 2, Batch: 232, Loss: 3.164896249771118\n",
      "Epoch: 2, Batch: 233, Loss: 4.729818344116211\n",
      "Epoch: 2, Batch: 234, Loss: 1.402045488357544\n",
      "Epoch: 2, Batch: 235, Loss: 1.1895558834075928\n",
      "Epoch: 2, Batch: 236, Loss: 3.611084222793579\n",
      "Epoch: 2, Batch: 237, Loss: 1.6229079961776733\n",
      "Epoch: 2, Batch: 238, Loss: 1.970827579498291\n",
      "Epoch: 2, Batch: 239, Loss: 1.206498622894287\n",
      "Epoch: 2, Batch: 240, Loss: 1.7976799011230469\n",
      "Epoch: 2, Batch: 241, Loss: 0.5526714324951172\n",
      "Epoch: 2, Batch: 242, Loss: 3.3973772525787354\n",
      "Epoch: 2, Batch: 243, Loss: 2.200336456298828\n",
      "Epoch: 2, Batch: 244, Loss: 4.076592445373535\n",
      "Epoch: 2, Batch: 245, Loss: 3.4817070960998535\n",
      "Epoch: 2, Batch: 246, Loss: 8.825422286987305\n",
      "Epoch: 2, Batch: 247, Loss: 1.7507034540176392\n",
      "Epoch: 2, Batch: 248, Loss: 0.6896594166755676\n",
      "Epoch: 2, Batch: 249, Loss: 5.014588356018066\n",
      "Epoch: 2, Batch: 250, Loss: 1.9990040063858032\n",
      "Epoch: 2, Batch: 251, Loss: 2.0029914379119873\n",
      "Epoch: 2, Batch: 252, Loss: 4.385747909545898\n",
      "Epoch: 2, Batch: 253, Loss: 2.4422736167907715\n",
      "Epoch: 2, Batch: 254, Loss: 1.513280987739563\n",
      "Epoch: 2, Batch: 255, Loss: 1.5131021738052368\n",
      "Epoch: 2, Batch: 256, Loss: 3.9506633281707764\n",
      "Epoch: 2, Batch: 257, Loss: 4.732897758483887\n",
      "Epoch: 2, Batch: 258, Loss: 5.392816066741943\n",
      "Epoch: 2, Batch: 259, Loss: 1.662123203277588\n",
      "Epoch: 2, Batch: 260, Loss: 1.5841679573059082\n",
      "Epoch: 2, Batch: 261, Loss: 1.5733208656311035\n",
      "Epoch: 2, Batch: 262, Loss: 5.666073799133301\n",
      "Epoch: 2, Batch: 263, Loss: 4.444989204406738\n",
      "Epoch: 2, Batch: 264, Loss: 4.892663478851318\n",
      "Epoch: 2, Batch: 265, Loss: 4.629197120666504\n",
      "Epoch: 2, Batch: 266, Loss: 3.826496124267578\n",
      "Epoch: 2, Batch: 267, Loss: 3.958096981048584\n",
      "Epoch: 2, Batch: 268, Loss: 3.6237854957580566\n",
      "Epoch: 2, Batch: 269, Loss: 2.522524356842041\n",
      "Epoch: 2, Batch: 270, Loss: 2.5077390670776367\n",
      "Epoch: 2, Batch: 271, Loss: 2.987915277481079\n",
      "Epoch: 2, Batch: 272, Loss: 2.0686001777648926\n",
      "Epoch: 2, Batch: 273, Loss: 2.14931583404541\n",
      "Epoch: 2, Batch: 274, Loss: 2.4507229328155518\n",
      "Epoch: 2, Batch: 275, Loss: 1.3575780391693115\n",
      "Epoch: 2, Batch: 276, Loss: 7.430922508239746\n",
      "Epoch: 2, Batch: 277, Loss: 4.925849914550781\n",
      "Epoch: 2, Batch: 278, Loss: 3.7614622116088867\n",
      "Epoch: 2, Batch: 279, Loss: 4.218155384063721\n",
      "Epoch: 2, Batch: 280, Loss: 6.585862636566162\n",
      "Epoch: 2, Batch: 281, Loss: 4.790360450744629\n",
      "Epoch: 2, Batch: 282, Loss: 3.013209581375122\n",
      "Epoch: 2, Batch: 283, Loss: 1.825225830078125\n",
      "Epoch: 2, Batch: 284, Loss: 2.7770628929138184\n",
      "Epoch: 2, Batch: 285, Loss: 2.2516257762908936\n",
      "Epoch: 2, Batch: 286, Loss: 1.0853245258331299\n",
      "Epoch: 2, Batch: 287, Loss: 5.977259635925293\n",
      "Epoch: 2, Batch: 288, Loss: 5.768402576446533\n",
      "Epoch: 2, Batch: 289, Loss: 0.49564290046691895\n",
      "Epoch: 2, Batch: 290, Loss: 3.4595773220062256\n",
      "Epoch: 2, Batch: 291, Loss: 1.2314115762710571\n",
      "Epoch: 2, Batch: 292, Loss: 1.7640005350112915\n",
      "Epoch: 2, Batch: 293, Loss: 4.418056011199951\n",
      "Epoch: 2, Batch: 294, Loss: 3.162865161895752\n",
      "Epoch: 2, Batch: 295, Loss: 2.617804527282715\n",
      "Epoch: 2, Batch: 296, Loss: 3.158511161804199\n",
      "Epoch: 2, Batch: 297, Loss: 2.8513453006744385\n",
      "Epoch: 2, Batch: 298, Loss: 2.5863959789276123\n",
      "Epoch: 2, Batch: 299, Loss: 4.553509712219238\n",
      "Epoch: 2, Batch: 300, Loss: 1.545078158378601\n",
      "Epoch: 2, Batch: 301, Loss: 3.4539337158203125\n",
      "Epoch: 2, Batch: 302, Loss: 3.3794658184051514\n",
      "Epoch: 2, Batch: 303, Loss: 3.4258058071136475\n",
      "Epoch: 2, Batch: 304, Loss: 5.030124664306641\n",
      "Epoch: 2, Batch: 305, Loss: 3.7513070106506348\n",
      "Epoch: 2, Batch: 306, Loss: 3.484091281890869\n",
      "Epoch: 2, Batch: 307, Loss: 2.0225558280944824\n",
      "Epoch: 2, Batch: 308, Loss: 2.9354248046875\n",
      "Epoch: 2, Batch: 309, Loss: 3.0825424194335938\n",
      "Epoch: 2, Batch: 310, Loss: 5.251777172088623\n",
      "Epoch: 2, Batch: 311, Loss: 1.8408071994781494\n",
      "Epoch: 2, Batch: 312, Loss: 2.755070686340332\n",
      "Epoch: 2, Batch: 313, Loss: 3.9260683059692383\n",
      "Epoch: 2, Batch: 314, Loss: 3.6846861839294434\n",
      "Epoch: 2, Batch: 315, Loss: 0.569340705871582\n",
      "Epoch: 2, Batch: 316, Loss: 2.289654016494751\n",
      "Epoch: 2, Batch: 317, Loss: 4.825244903564453\n",
      "Epoch: 2, Batch: 318, Loss: 0.697725772857666\n",
      "Epoch: 2, Batch: 319, Loss: 1.7785873413085938\n",
      "Epoch: 2, Batch: 320, Loss: 1.763668417930603\n",
      "Epoch: 2, Batch: 321, Loss: 2.5979554653167725\n",
      "Epoch: 2, Batch: 322, Loss: 1.3031792640686035\n",
      "Epoch: 2, Batch: 323, Loss: 0.5098193883895874\n",
      "Epoch: 2, Batch: 324, Loss: 3.5160768032073975\n",
      "Epoch: 2, Batch: 325, Loss: 2.933431386947632\n",
      "Epoch: 2, Batch: 326, Loss: 7.945913791656494\n",
      "Epoch: 2, Batch: 327, Loss: 2.0962328910827637\n",
      "Epoch: 2, Batch: 328, Loss: 6.392486572265625\n",
      "Epoch: 2, Batch: 329, Loss: 0.34637266397476196\n",
      "Epoch: 2, Batch: 330, Loss: 2.533370018005371\n",
      "Epoch: 2, Batch: 331, Loss: 1.3596479892730713\n",
      "Epoch: 2, Batch: 332, Loss: 3.9101154804229736\n",
      "Epoch: 2, Batch: 333, Loss: 3.2272913455963135\n",
      "Epoch: 2, Batch: 334, Loss: 3.15972900390625\n",
      "Epoch: 2, Batch: 335, Loss: 3.9002976417541504\n",
      "Epoch: 2, Batch: 336, Loss: 2.1653895378112793\n",
      "Epoch: 2, Batch: 337, Loss: 6.53678035736084\n",
      "Epoch: 2, Batch: 338, Loss: 0.7517716884613037\n",
      "Epoch: 2, Batch: 339, Loss: 2.3338608741760254\n",
      "Epoch: 2, Batch: 340, Loss: 4.889930248260498\n",
      "Epoch: 2, Batch: 341, Loss: 3.8732306957244873\n",
      "Epoch: 2, Batch: 342, Loss: 3.7336878776550293\n",
      "Epoch: 2, Batch: 343, Loss: 3.8485782146453857\n",
      "Epoch: 2, Batch: 344, Loss: 1.1068873405456543\n",
      "Epoch: 2, Batch: 345, Loss: 9.898797988891602\n",
      "Epoch: 2, Batch: 346, Loss: 2.7853355407714844\n",
      "Epoch: 2, Batch: 347, Loss: 5.385849952697754\n",
      "Epoch: 2, Batch: 348, Loss: 3.250032901763916\n",
      "Epoch: 2, Batch: 349, Loss: 2.3348379135131836\n",
      "Epoch: 2, Batch: 350, Loss: 3.815599203109741\n",
      "Epoch: 2, Batch: 351, Loss: 4.5672712326049805\n",
      "Epoch: 2, Batch: 352, Loss: 1.8333511352539062\n",
      "Epoch: 2, Batch: 353, Loss: 4.153419494628906\n",
      "Epoch: 2, Batch: 354, Loss: 2.7794923782348633\n",
      "Epoch: 2, Batch: 355, Loss: 2.7219552993774414\n",
      "Epoch: 2, Batch: 356, Loss: 1.2655357122421265\n",
      "Epoch: 2, Batch: 357, Loss: 1.2886688709259033\n",
      "Epoch: 2, Batch: 358, Loss: 4.885246753692627\n",
      "Epoch: 2, Batch: 359, Loss: 2.698256015777588\n",
      "Epoch: 2, Batch: 360, Loss: 3.6730804443359375\n",
      "Epoch: 2, Batch: 361, Loss: 1.7028238773345947\n",
      "Epoch: 2, Batch: 362, Loss: 5.706470489501953\n",
      "Epoch: 2, Batch: 363, Loss: 1.9767141342163086\n",
      "Epoch: 2, Batch: 364, Loss: 4.375982284545898\n",
      "Epoch: 2, Batch: 365, Loss: 1.9517326354980469\n",
      "Epoch: 2, Batch: 366, Loss: 1.146911859512329\n",
      "Epoch: 2, Batch: 367, Loss: 1.8701927661895752\n",
      "Epoch: 2, Batch: 368, Loss: 4.008904457092285\n",
      "Epoch: 2, Batch: 369, Loss: 1.7331290245056152\n",
      "Epoch: 2, Batch: 370, Loss: 3.164947748184204\n",
      "Epoch: 2, Batch: 371, Loss: 3.7775301933288574\n",
      "Epoch: 2, Batch: 372, Loss: 3.5307092666625977\n",
      "Epoch: 2, Batch: 373, Loss: 3.047887086868286\n",
      "Epoch: 2, Batch: 374, Loss: 2.99582839012146\n",
      "Epoch: 2, Batch: 375, Loss: 2.36971378326416\n",
      "Epoch: 2, Batch: 376, Loss: 0.9672706723213196\n",
      "Epoch: 2, Batch: 377, Loss: 4.913003444671631\n",
      "Epoch: 2, Batch: 378, Loss: 3.124847412109375\n",
      "Epoch: 2, Batch: 379, Loss: 2.0529606342315674\n",
      "Epoch: 2, Batch: 380, Loss: 1.9399000406265259\n",
      "Epoch: 2, Batch: 381, Loss: 4.30905294418335\n",
      "Epoch: 2, Batch: 382, Loss: 7.133236408233643\n",
      "Epoch: 2, Batch: 383, Loss: 3.09578800201416\n",
      "Epoch: 2, Batch: 384, Loss: 1.9719929695129395\n",
      "Epoch: 2, Batch: 385, Loss: 5.9524431228637695\n",
      "Epoch: 2, Batch: 386, Loss: 1.2097846269607544\n",
      "Epoch: 2, Batch: 387, Loss: 1.744874119758606\n",
      "Epoch: 2, Batch: 388, Loss: 2.65535569190979\n",
      "Epoch: 2, Batch: 389, Loss: 5.152749538421631\n",
      "Epoch: 2, Batch: 390, Loss: 3.1927313804626465\n",
      "Epoch: 2, Batch: 391, Loss: 3.036912441253662\n",
      "Epoch: 2, Batch: 392, Loss: 2.456603527069092\n",
      "Epoch: 2, Batch: 393, Loss: 2.5940914154052734\n",
      "Epoch: 2, Batch: 394, Loss: 2.3733999729156494\n",
      "Epoch: 2, Batch: 395, Loss: 3.0024685859680176\n",
      "Epoch: 2, Batch: 396, Loss: 1.8931013345718384\n",
      "Epoch: 2, Batch: 397, Loss: 2.013413906097412\n",
      "Epoch: 2, Batch: 398, Loss: 2.087578058242798\n",
      "Epoch: 2, Batch: 399, Loss: 1.1080676317214966\n",
      "Epoch: 2, Batch: 400, Loss: 4.038301944732666\n",
      "Epoch: 2, Batch: 401, Loss: 0.969048023223877\n",
      "Epoch: 2, Batch: 402, Loss: 2.0645179748535156\n",
      "Epoch: 2, Batch: 403, Loss: 2.7005152702331543\n",
      "Epoch: 2, Batch: 404, Loss: 1.3682260513305664\n",
      "Epoch: 2, Batch: 405, Loss: 1.6020221710205078\n",
      "Epoch: 2, Batch: 406, Loss: 2.8328490257263184\n",
      "Epoch: 2, Batch: 407, Loss: 4.109042167663574\n",
      "Epoch: 2, Batch: 408, Loss: 3.20656681060791\n",
      "Epoch: 2, Batch: 409, Loss: 1.3298097848892212\n",
      "Epoch: 2, Batch: 410, Loss: 4.236599445343018\n",
      "Epoch: 2, Batch: 411, Loss: 3.1535661220550537\n",
      "Epoch: 2, Batch: 412, Loss: 2.3281912803649902\n",
      "Epoch: 2, Batch: 413, Loss: 2.210550308227539\n",
      "Epoch: 2, Batch: 414, Loss: 4.821895122528076\n",
      "Epoch: 2, Batch: 415, Loss: 2.208606481552124\n",
      "Epoch: 2, Batch: 416, Loss: 2.8308653831481934\n",
      "Epoch: 2, Batch: 417, Loss: 3.7413833141326904\n",
      "Epoch: 2, Batch: 418, Loss: 2.522871494293213\n",
      "Epoch: 2, Batch: 419, Loss: 4.127913951873779\n",
      "Epoch: 2, Batch: 420, Loss: 2.317870855331421\n",
      "Epoch: 2, Batch: 421, Loss: 2.3468546867370605\n",
      "Epoch: 2, Batch: 422, Loss: 1.7032203674316406\n",
      "Epoch: 2, Batch: 423, Loss: 1.4758102893829346\n",
      "Epoch: 2, Batch: 424, Loss: 1.0196681022644043\n",
      "Epoch: 2, Batch: 425, Loss: 1.5442918539047241\n",
      "Epoch: 2, Batch: 426, Loss: 3.279010534286499\n",
      "Epoch: 2, Batch: 427, Loss: 5.889047145843506\n",
      "Epoch: 2, Batch: 428, Loss: 1.5056408643722534\n",
      "Epoch: 2, Batch: 429, Loss: 2.030244827270508\n",
      "Epoch: 2, Batch: 430, Loss: 1.627393364906311\n",
      "Epoch: 2, Batch: 431, Loss: 3.232598304748535\n",
      "Epoch: 2, Batch: 432, Loss: 2.153325080871582\n",
      "Epoch: 2, Batch: 433, Loss: 3.5430965423583984\n",
      "Epoch: 2, Batch: 434, Loss: 3.6817684173583984\n",
      "Epoch: 2, Batch: 435, Loss: 2.6878817081451416\n",
      "Epoch: 2, Batch: 436, Loss: 2.6392219066619873\n",
      "Epoch: 2, Batch: 437, Loss: 2.465855598449707\n",
      "Epoch: 2, Batch: 438, Loss: 1.3867605924606323\n",
      "Epoch: 2, Batch: 439, Loss: 3.559481620788574\n",
      "Epoch: 2, Batch: 440, Loss: 2.7336437702178955\n",
      "Epoch: 2, Batch: 441, Loss: 2.0296597480773926\n",
      "Epoch: 2, Batch: 442, Loss: 1.3749210834503174\n",
      "Epoch: 2, Batch: 443, Loss: 4.132676124572754\n",
      "Epoch: 2, Batch: 444, Loss: 3.264531135559082\n",
      "Epoch: 2, Batch: 445, Loss: 3.0393877029418945\n",
      "Epoch: 2, Batch: 446, Loss: 1.943418025970459\n",
      "Epoch: 2, Batch: 447, Loss: 1.3044097423553467\n",
      "Epoch: 2, Batch: 448, Loss: 0.9351558685302734\n",
      "Epoch: 2, Batch: 449, Loss: 5.669230937957764\n",
      "Epoch: 2, Batch: 450, Loss: 0.954485297203064\n",
      "Epoch: 2, Batch: 451, Loss: 3.243623971939087\n",
      "Epoch: 2, Batch: 452, Loss: 0.8748913407325745\n",
      "Epoch: 2, Batch: 453, Loss: 3.325705051422119\n",
      "Epoch: 2, Batch: 454, Loss: 2.8712825775146484\n",
      "Epoch: 2, Batch: 455, Loss: 3.19319486618042\n",
      "Epoch: 2, Batch: 456, Loss: 2.928816080093384\n",
      "Epoch: 2, Batch: 457, Loss: 2.6494388580322266\n",
      "Epoch: 2, Batch: 458, Loss: 3.33296275138855\n",
      "Epoch: 2, Batch: 459, Loss: 2.026287317276001\n",
      "Epoch: 2, Batch: 460, Loss: 2.4651553630828857\n",
      "Epoch: 2, Batch: 461, Loss: 1.2032371759414673\n",
      "Epoch: 2, Batch: 462, Loss: 2.8906919956207275\n",
      "Epoch: 2, Batch: 463, Loss: 3.95401668548584\n",
      "Epoch: 2, Batch: 464, Loss: 1.412941813468933\n",
      "Epoch: 2, Batch: 465, Loss: 3.9761950969696045\n",
      "Epoch: 2, Batch: 466, Loss: 2.648012161254883\n",
      "Epoch: 2, Batch: 467, Loss: 2.924102544784546\n",
      "Epoch: 2, Batch: 468, Loss: 1.708735466003418\n",
      "Epoch: 2, Batch: 469, Loss: 4.406247615814209\n",
      "Epoch: 2, Batch: 470, Loss: 3.521599292755127\n",
      "Epoch: 2, Batch: 471, Loss: 1.8131804466247559\n",
      "Epoch: 2, Batch: 472, Loss: 1.3450281620025635\n",
      "Epoch: 2, Batch: 473, Loss: 4.172503471374512\n",
      "Epoch: 2, Batch: 474, Loss: 5.295244216918945\n",
      "Epoch: 2, Batch: 475, Loss: 3.0602073669433594\n",
      "Epoch: 2, Batch: 476, Loss: 2.459646463394165\n",
      "Epoch: 2, Batch: 477, Loss: 3.330544948577881\n",
      "Epoch: 2, Batch: 478, Loss: 0.7034566402435303\n",
      "Epoch: 2, Batch: 479, Loss: 2.8189327716827393\n",
      "Epoch: 2, Batch: 480, Loss: 0.36852002143859863\n",
      "Epoch: 2, Batch: 481, Loss: 1.900669813156128\n",
      "Epoch: 2, Batch: 482, Loss: 2.6701064109802246\n",
      "Epoch: 2, Batch: 483, Loss: 4.5391645431518555\n",
      "Epoch: 2, Batch: 484, Loss: 2.044922351837158\n",
      "Epoch: 2, Batch: 485, Loss: 2.403641700744629\n",
      "Epoch: 2, Batch: 486, Loss: 1.4075605869293213\n",
      "Epoch: 2, Batch: 487, Loss: 0.39523082971572876\n",
      "Epoch: 2, Batch: 488, Loss: 1.9436681270599365\n",
      "Epoch: 2, Batch: 489, Loss: 4.122485637664795\n",
      "Epoch: 2, Batch: 490, Loss: 0.6888942718505859\n",
      "Epoch: 2, Batch: 491, Loss: 3.581522226333618\n",
      "Epoch: 2, Batch: 492, Loss: 2.59867000579834\n",
      "Epoch: 2, Batch: 493, Loss: 1.932138204574585\n",
      "Epoch: 2, Batch: 494, Loss: 4.860865592956543\n",
      "Epoch: 2, Batch: 495, Loss: 3.8576443195343018\n",
      "Epoch: 2, Batch: 496, Loss: 1.8380262851715088\n",
      "Epoch: 2, Batch: 497, Loss: 1.0116647481918335\n",
      "Epoch: 2, Batch: 498, Loss: 2.6396255493164062\n",
      "Epoch: 2, Batch: 499, Loss: 1.01713228225708\n",
      "Epoch: 2, Batch: 500, Loss: 1.3284724950790405\n",
      "Epoch: 2, Batch: 501, Loss: 3.7527897357940674\n",
      "Epoch: 2, Batch: 502, Loss: 3.6266844272613525\n",
      "Epoch: 2, Batch: 503, Loss: 3.39823579788208\n",
      "Epoch: 2, Batch: 504, Loss: 1.5229161977767944\n",
      "Epoch: 2, Batch: 505, Loss: 2.42468523979187\n",
      "Epoch: 2, Batch: 506, Loss: 1.1122324466705322\n",
      "Epoch: 2, Batch: 507, Loss: 1.0209180116653442\n",
      "Epoch: 2, Batch: 508, Loss: 4.159154891967773\n",
      "Epoch: 2, Batch: 509, Loss: 3.6636011600494385\n",
      "Epoch: 2, Batch: 510, Loss: 3.9183173179626465\n",
      "Epoch: 2, Batch: 511, Loss: 2.239246129989624\n",
      "Epoch: 2, Batch: 512, Loss: 1.8874785900115967\n",
      "Epoch: 2, Batch: 513, Loss: 2.654031753540039\n",
      "Epoch: 2, Batch: 514, Loss: 3.6415610313415527\n",
      "Epoch: 2, Batch: 515, Loss: 0.7648478746414185\n",
      "Epoch: 2, Batch: 516, Loss: 3.5147910118103027\n",
      "Epoch: 2, Batch: 517, Loss: 2.458503007888794\n",
      "Epoch: 2, Batch: 518, Loss: 1.6695291996002197\n",
      "Epoch: 2, Batch: 519, Loss: 1.8276270627975464\n",
      "Epoch: 2, Batch: 520, Loss: 2.1360323429107666\n",
      "Epoch: 2, Batch: 521, Loss: 3.5969226360321045\n",
      "Epoch: 2, Batch: 522, Loss: 2.341179132461548\n",
      "Epoch: 2, Batch: 523, Loss: 3.6240878105163574\n",
      "Epoch: 2, Batch: 524, Loss: 5.505255699157715\n",
      "Epoch: 2, Batch: 525, Loss: 3.500495433807373\n",
      "Epoch: 2, Batch: 526, Loss: 1.6747362613677979\n",
      "Epoch: 2, Batch: 527, Loss: 2.4281375408172607\n",
      "Epoch: 2, Batch: 528, Loss: 1.3237775564193726\n",
      "Epoch: 2, Batch: 529, Loss: 6.127291202545166\n",
      "Epoch: 2, Batch: 530, Loss: 2.7918291091918945\n",
      "Epoch: 2, Batch: 531, Loss: 1.8073668479919434\n",
      "Epoch: 2, Batch: 532, Loss: 3.2024097442626953\n",
      "Epoch: 2, Batch: 533, Loss: 0.657867968082428\n",
      "Epoch: 2, Batch: 534, Loss: 5.071812629699707\n",
      "Epoch: 2, Batch: 535, Loss: 2.708909511566162\n",
      "Epoch: 2, Batch: 536, Loss: 2.4749369621276855\n",
      "Epoch: 2, Batch: 537, Loss: 1.8983629941940308\n",
      "Epoch: 2, Batch: 538, Loss: 2.5720090866088867\n",
      "Epoch: 2, Batch: 539, Loss: 3.219496488571167\n",
      "Epoch: 2, Batch: 540, Loss: 6.961729526519775\n",
      "Epoch: 2, Batch: 541, Loss: 0.5504851341247559\n",
      "Epoch: 2, Batch: 542, Loss: 3.223121404647827\n",
      "Epoch: 2, Batch: 543, Loss: 4.69568395614624\n",
      "Epoch: 2, Batch: 544, Loss: 4.040679931640625\n",
      "Epoch: 2, Batch: 545, Loss: 5.765655517578125\n",
      "Epoch: 2, Batch: 546, Loss: 4.397613525390625\n",
      "Epoch: 2, Batch: 547, Loss: 0.8889837265014648\n",
      "Epoch: 2, Batch: 548, Loss: 2.364201307296753\n",
      "Epoch: 2, Batch: 549, Loss: 2.3983864784240723\n",
      "Epoch: 2, Batch: 550, Loss: 5.416744232177734\n",
      "Epoch: 2, Batch: 551, Loss: 2.933828592300415\n",
      "Epoch: 2, Batch: 552, Loss: 0.8497368693351746\n",
      "Epoch: 2, Batch: 553, Loss: 0.3451489210128784\n",
      "Epoch: 2, Batch: 554, Loss: 2.945026397705078\n",
      "Epoch: 2, Batch: 555, Loss: 2.7391819953918457\n",
      "Epoch: 2, Batch: 556, Loss: 4.563488483428955\n",
      "Epoch: 2, Batch: 557, Loss: 3.748058319091797\n",
      "Epoch: 2, Batch: 558, Loss: 2.972321033477783\n",
      "Epoch: 2, Batch: 559, Loss: 2.9608325958251953\n",
      "Epoch: 2, Batch: 560, Loss: 2.8207831382751465\n",
      "Epoch: 2, Batch: 561, Loss: 6.070469856262207\n",
      "Epoch: 2, Batch: 562, Loss: 0.9696440696716309\n",
      "Epoch: 2, Batch: 563, Loss: 3.775449752807617\n",
      "Epoch: 2, Batch: 564, Loss: 2.7664847373962402\n",
      "Epoch: 2, Batch: 565, Loss: 1.6485779285430908\n",
      "Epoch: 2, Batch: 566, Loss: 3.548520803451538\n",
      "Epoch: 2, Batch: 567, Loss: 1.8075857162475586\n",
      "Epoch: 2, Batch: 568, Loss: 3.3008580207824707\n",
      "Epoch: 2, Batch: 569, Loss: 1.394585132598877\n",
      "Epoch: 2, Batch: 570, Loss: 4.226464748382568\n",
      "Epoch: 2, Batch: 571, Loss: 3.965087413787842\n",
      "Epoch: 2, Batch: 572, Loss: 1.8542532920837402\n",
      "Epoch: 2, Batch: 573, Loss: 0.915695071220398\n",
      "Epoch: 2, Batch: 574, Loss: 2.4865639209747314\n",
      "Epoch: 2, Batch: 575, Loss: 3.252458095550537\n",
      "Epoch: 2, Batch: 576, Loss: 1.6080207824707031\n",
      "Epoch: 2, Batch: 577, Loss: 5.52537202835083\n",
      "Epoch: 2, Batch: 578, Loss: 2.2087273597717285\n",
      "Epoch: 2, Batch: 579, Loss: 5.681035995483398\n",
      "Epoch: 2, Batch: 580, Loss: 3.93220591545105\n",
      "Epoch: 2, Batch: 581, Loss: 0.7508201003074646\n",
      "Epoch: 2, Batch: 582, Loss: 4.117658615112305\n",
      "Epoch: 2, Batch: 583, Loss: 1.5292861461639404\n",
      "Epoch: 2, Batch: 584, Loss: 1.9252375364303589\n",
      "Epoch: 2, Batch: 585, Loss: 0.7566530704498291\n",
      "Epoch: 2, Batch: 586, Loss: 3.062936544418335\n",
      "Epoch: 2, Batch: 587, Loss: 6.097436428070068\n",
      "Epoch: 2, Batch: 588, Loss: 2.5474605560302734\n",
      "Epoch: 2, Batch: 589, Loss: 1.6326655149459839\n",
      "Epoch: 2, Batch: 590, Loss: 2.3785648345947266\n",
      "Epoch: 2, Batch: 591, Loss: 3.438551664352417\n",
      "Epoch: 2, Batch: 592, Loss: 3.3567616939544678\n",
      "Epoch: 2, Batch: 593, Loss: 1.736114740371704\n",
      "Epoch: 2, Batch: 594, Loss: 1.5464787483215332\n",
      "Epoch: 2, Batch: 595, Loss: 2.4771409034729004\n",
      "Epoch: 2, Batch: 596, Loss: 3.3805646896362305\n",
      "Epoch: 2, Batch: 597, Loss: 2.8850369453430176\n",
      "Epoch: 2, Batch: 598, Loss: 2.952141523361206\n",
      "Epoch: 2, Batch: 599, Loss: 1.1922063827514648\n",
      "Epoch: 2, Batch: 600, Loss: 2.3120040893554688\n",
      "Epoch: 2, Batch: 601, Loss: 3.089987277984619\n",
      "Epoch: 2, Batch: 602, Loss: 4.414376735687256\n",
      "Epoch: 2, Batch: 603, Loss: 1.3408279418945312\n",
      "Epoch: 2, Batch: 604, Loss: 3.5512661933898926\n",
      "Epoch: 2, Batch: 605, Loss: 2.5702831745147705\n",
      "Epoch: 2, Batch: 606, Loss: 1.391258716583252\n",
      "Epoch: 2, Batch: 607, Loss: 3.027784824371338\n",
      "Epoch: 2, Batch: 608, Loss: 3.2725682258605957\n",
      "Epoch: 2, Batch: 609, Loss: 3.1852245330810547\n",
      "Epoch: 2, Batch: 610, Loss: 4.46208381652832\n",
      "Epoch: 2, Batch: 611, Loss: 2.6644487380981445\n",
      "Epoch: 2, Batch: 612, Loss: 1.9030109643936157\n",
      "Epoch: 2, Batch: 613, Loss: 1.0843737125396729\n",
      "Epoch: 2, Batch: 614, Loss: 0.7836929559707642\n",
      "Epoch: 2, Batch: 615, Loss: 4.276704788208008\n",
      "Epoch: 2, Batch: 616, Loss: 1.2822113037109375\n",
      "Epoch: 2, Batch: 617, Loss: 2.2215404510498047\n",
      "Epoch: 2, Batch: 618, Loss: 2.5912985801696777\n",
      "Epoch: 2, Batch: 619, Loss: 1.7773756980895996\n",
      "Epoch: 2, Batch: 620, Loss: 2.4990389347076416\n",
      "Epoch: 2, Batch: 621, Loss: 2.459540605545044\n",
      "Epoch: 2, Batch: 622, Loss: 2.528677463531494\n",
      "Epoch: 2, Batch: 623, Loss: 2.0079455375671387\n",
      "Epoch: 2, Batch: 624, Loss: 3.4026055335998535\n",
      "Epoch: 2, Batch: 625, Loss: 3.695668935775757\n",
      "Epoch: 2, Batch: 626, Loss: 0.9279208779335022\n",
      "Epoch: 2, Batch: 627, Loss: 6.620724201202393\n",
      "Epoch: 2, Batch: 628, Loss: 2.8962738513946533\n",
      "Epoch: 2, Batch: 629, Loss: 0.7123380899429321\n",
      "Epoch: 2, Batch: 630, Loss: 1.0731605291366577\n",
      "Epoch: 2, Batch: 631, Loss: 3.732327699661255\n",
      "Epoch: 2, Batch: 632, Loss: 3.3505380153656006\n",
      "Epoch: 2, Batch: 633, Loss: 2.6467580795288086\n",
      "Epoch: 2, Batch: 634, Loss: 1.1020393371582031\n",
      "Epoch: 2, Batch: 635, Loss: 5.126267910003662\n",
      "Epoch: 2, Batch: 636, Loss: 2.3432226181030273\n",
      "Epoch: 2, Batch: 637, Loss: 3.5146987438201904\n",
      "Epoch: 2, Batch: 638, Loss: 3.087855577468872\n",
      "Epoch: 2, Batch: 639, Loss: 0.3817005157470703\n",
      "Epoch: 2, Batch: 640, Loss: 0.08832807838916779\n",
      "Epoch: 2, Batch: 641, Loss: 2.5889203548431396\n",
      "Epoch: 2, Batch: 642, Loss: 1.0190157890319824\n",
      "Epoch: 2, Batch: 643, Loss: 4.509429454803467\n",
      "Epoch: 2, Batch: 644, Loss: 3.00815749168396\n",
      "Epoch: 2, Batch: 645, Loss: 4.138897895812988\n",
      "Epoch: 2, Batch: 646, Loss: 6.619112014770508\n",
      "Epoch: 2, Batch: 647, Loss: 2.8620357513427734\n",
      "Epoch: 2, Batch: 648, Loss: 2.302119731903076\n",
      "Epoch: 2, Batch: 649, Loss: 2.0978119373321533\n",
      "Epoch: 2, Batch: 650, Loss: 4.112165451049805\n",
      "Epoch: 2, Batch: 651, Loss: 4.131719589233398\n",
      "Epoch: 2, Batch: 652, Loss: 6.8977227210998535\n",
      "Epoch: 2, Batch: 653, Loss: 2.7161471843719482\n",
      "Epoch: 2, Batch: 654, Loss: 4.14087438583374\n",
      "Epoch: 2, Batch: 655, Loss: 1.3559527397155762\n",
      "Epoch: 2, Batch: 656, Loss: 4.090360641479492\n",
      "Epoch: 2, Batch: 657, Loss: 0.29064351320266724\n",
      "Epoch: 2, Batch: 658, Loss: 2.217346429824829\n",
      "Epoch: 2, Batch: 659, Loss: 6.2917585372924805\n",
      "Epoch: 2, Batch: 660, Loss: 5.727913856506348\n",
      "Epoch: 2, Batch: 661, Loss: 1.303317666053772\n",
      "Epoch: 2, Batch: 662, Loss: 0.7626830339431763\n",
      "Epoch: 2, Batch: 663, Loss: 3.6068320274353027\n",
      "Epoch: 2, Batch: 664, Loss: 4.21843957901001\n",
      "Epoch: 2, Batch: 665, Loss: 5.190351486206055\n",
      "Epoch: 2, Batch: 666, Loss: 0.6000244617462158\n",
      "Epoch: 2, Batch: 667, Loss: 4.125499248504639\n",
      "Epoch: 2, Batch: 668, Loss: 3.957158088684082\n",
      "Epoch: 2, Batch: 669, Loss: 2.625581979751587\n",
      "Epoch: 2, Batch: 670, Loss: 6.860238552093506\n",
      "Epoch: 2, Batch: 671, Loss: 3.59808349609375\n",
      "Epoch: 2, Batch: 672, Loss: 3.3131461143493652\n",
      "Epoch: 2, Batch: 673, Loss: 1.911188006401062\n",
      "Epoch: 2, Batch: 674, Loss: 2.5855441093444824\n",
      "Epoch: 2, Batch: 675, Loss: 0.8977611064910889\n",
      "Epoch: 2, Batch: 676, Loss: 2.508554220199585\n",
      "Epoch: 2, Batch: 677, Loss: 3.7885265350341797\n",
      "Epoch: 2, Batch: 678, Loss: 2.3949644565582275\n",
      "Epoch: 2, Batch: 679, Loss: 2.935415029525757\n",
      "Epoch: 2, Batch: 680, Loss: 2.5670366287231445\n",
      "Epoch: 2, Batch: 681, Loss: 2.2542967796325684\n",
      "Epoch: 2, Batch: 682, Loss: 3.754767894744873\n",
      "Epoch: 2, Batch: 683, Loss: 1.5166445970535278\n",
      "Epoch: 2, Batch: 684, Loss: 1.5894443988800049\n",
      "Epoch: 2, Batch: 685, Loss: 1.3723056316375732\n",
      "Epoch: 2, Batch: 686, Loss: 4.328094959259033\n",
      "Epoch: 2, Batch: 687, Loss: 2.3272292613983154\n",
      "Epoch: 2, Batch: 688, Loss: 2.8896265029907227\n",
      "Epoch: 2, Batch: 689, Loss: 2.1263082027435303\n",
      "Epoch: 2, Batch: 690, Loss: 4.826666355133057\n",
      "Epoch: 2, Batch: 691, Loss: 2.5622076988220215\n",
      "Epoch: 2, Batch: 692, Loss: 0.3159213364124298\n",
      "Epoch: 2, Batch: 693, Loss: 1.61591637134552\n",
      "Epoch: 2, Batch: 694, Loss: 0.9953094720840454\n",
      "Epoch: 2, Batch: 695, Loss: 2.660861015319824\n",
      "Epoch: 2, Batch: 696, Loss: 3.934244394302368\n",
      "Epoch: 2, Batch: 697, Loss: 1.3168755769729614\n",
      "Epoch: 2, Batch: 698, Loss: 2.2070417404174805\n",
      "Epoch: 2, Batch: 699, Loss: 0.7018424272537231\n",
      "Epoch: 2, Batch: 700, Loss: 5.526971817016602\n",
      "Epoch: 2, Batch: 701, Loss: 4.32897424697876\n",
      "Epoch: 2, Batch: 702, Loss: 2.989069938659668\n",
      "Epoch: 2, Batch: 703, Loss: 0.34977632761001587\n",
      "Epoch: 2, Batch: 704, Loss: 5.392739295959473\n",
      "Epoch: 2, Batch: 705, Loss: 0.5785471200942993\n",
      "Epoch: 2, Batch: 706, Loss: 3.2167110443115234\n",
      "Epoch: 2, Batch: 707, Loss: 1.3940116167068481\n",
      "Epoch: 2, Batch: 708, Loss: 1.745744228363037\n",
      "Epoch: 2, Batch: 709, Loss: 7.971848964691162\n",
      "Epoch: 2, Batch: 710, Loss: 1.323936939239502\n",
      "Epoch: 2, Batch: 711, Loss: 1.5122959613800049\n",
      "Epoch: 2, Batch: 712, Loss: 0.6976472735404968\n",
      "Epoch: 2, Batch: 713, Loss: 1.8200491666793823\n",
      "Epoch: 2, Batch: 714, Loss: 2.5034255981445312\n",
      "Epoch: 2, Batch: 715, Loss: 1.6629234552383423\n",
      "Epoch: 2, Batch: 716, Loss: 4.891283988952637\n",
      "Epoch: 2, Batch: 717, Loss: 1.8464146852493286\n",
      "Epoch: 2, Batch: 718, Loss: 3.1929404735565186\n",
      "Epoch: 2, Batch: 719, Loss: 2.086874008178711\n",
      "Epoch: 2, Batch: 720, Loss: 1.8681581020355225\n",
      "Epoch: 2, Batch: 721, Loss: 2.7966394424438477\n",
      "Epoch: 2, Batch: 722, Loss: 1.3910714387893677\n",
      "Epoch: 2, Batch: 723, Loss: 2.972247362136841\n",
      "Epoch: 2, Batch: 724, Loss: 2.428424835205078\n",
      "Epoch: 2, Batch: 725, Loss: 1.7556875944137573\n",
      "Epoch: 2, Batch: 726, Loss: 2.3659894466400146\n",
      "Epoch: 2, Batch: 727, Loss: 3.545191764831543\n",
      "Epoch: 2, Batch: 728, Loss: 2.145925760269165\n",
      "Epoch: 2, Batch: 729, Loss: 1.0615259408950806\n",
      "Epoch: 2, Batch: 730, Loss: 1.9988675117492676\n",
      "Epoch: 2, Batch: 731, Loss: 4.897285461425781\n",
      "Epoch: 2, Batch: 732, Loss: 1.1878175735473633\n",
      "Epoch: 2, Batch: 733, Loss: 3.355910539627075\n",
      "Epoch: 2, Batch: 734, Loss: 4.768208026885986\n",
      "Epoch: 2, Batch: 735, Loss: 0.16098622977733612\n",
      "Epoch: 2, Batch: 736, Loss: 1.6173396110534668\n",
      "Epoch: 2, Batch: 737, Loss: 2.0737037658691406\n",
      "Epoch: 2, Batch: 738, Loss: 1.5986287593841553\n",
      "Epoch: 2, Batch: 739, Loss: 1.5814497470855713\n",
      "Epoch: 2, Batch: 740, Loss: 1.1970140933990479\n",
      "Epoch: 2, Batch: 741, Loss: 1.215290904045105\n",
      "Epoch: 2, Batch: 742, Loss: 0.5656324028968811\n",
      "Epoch: 2, Batch: 743, Loss: 2.2390377521514893\n",
      "Epoch: 2, Batch: 744, Loss: 2.4767160415649414\n",
      "Epoch: 2, Batch: 745, Loss: 1.9640480279922485\n",
      "Epoch: 2, Batch: 746, Loss: 1.0498602390289307\n",
      "Epoch: 2, Batch: 747, Loss: 3.6807453632354736\n",
      "Epoch: 2, Batch: 748, Loss: 4.257669925689697\n",
      "Epoch: 2, Batch: 749, Loss: 3.2454473972320557\n",
      "Epoch: 2, Batch: 750, Loss: 3.353360176086426\n",
      "Epoch: 2, Batch: 751, Loss: 2.481016159057617\n",
      "Epoch: 2, Batch: 752, Loss: 1.5120513439178467\n",
      "Epoch: 2, Batch: 753, Loss: 0.5549155473709106\n",
      "Epoch: 2, Batch: 754, Loss: 2.8950376510620117\n",
      "Epoch: 2, Batch: 755, Loss: 1.228681206703186\n",
      "Epoch: 2, Batch: 756, Loss: 4.071481227874756\n",
      "Epoch: 2, Batch: 757, Loss: 2.312568187713623\n",
      "Epoch: 2, Batch: 758, Loss: 1.9623019695281982\n",
      "Epoch: 2, Batch: 759, Loss: 4.78208589553833\n",
      "Epoch: 2, Batch: 760, Loss: 3.612618923187256\n",
      "Epoch: 2, Batch: 761, Loss: 1.1710269451141357\n",
      "Epoch: 2, Batch: 762, Loss: 1.170516014099121\n",
      "Epoch: 2, Batch: 763, Loss: 3.4458632469177246\n",
      "Epoch: 2, Batch: 764, Loss: 4.612991809844971\n",
      "Epoch: 2, Batch: 765, Loss: 3.2291293144226074\n",
      "Epoch: 2, Batch: 766, Loss: 1.914312720298767\n",
      "Epoch: 2, Batch: 767, Loss: 1.6442410945892334\n",
      "Epoch: 2, Batch: 768, Loss: 1.7767046689987183\n",
      "Epoch: 2, Batch: 769, Loss: 2.8165524005889893\n",
      "Epoch: 2, Batch: 770, Loss: 2.159050703048706\n",
      "Epoch: 2, Batch: 771, Loss: 3.4936699867248535\n",
      "Epoch: 2, Batch: 772, Loss: 1.2662010192871094\n",
      "Epoch: 2, Batch: 773, Loss: 2.190483570098877\n",
      "Epoch: 2, Batch: 774, Loss: 5.009712219238281\n",
      "Epoch: 2, Batch: 775, Loss: 1.7017567157745361\n",
      "Epoch: 2, Batch: 776, Loss: 2.8999314308166504\n",
      "Epoch: 2, Batch: 777, Loss: 0.7104980945587158\n",
      "Epoch: 2, Batch: 778, Loss: 2.2431881427764893\n",
      "Epoch: 2, Batch: 779, Loss: 2.0537924766540527\n",
      "Epoch: 2, Batch: 780, Loss: 1.2068169116973877\n",
      "Epoch: 2, Batch: 781, Loss: 5.704134941101074\n",
      "Epoch: 2, Batch: 782, Loss: 4.0692548751831055\n",
      "Epoch: 2, Batch: 783, Loss: 2.3949427604675293\n",
      "Epoch: 2, Batch: 784, Loss: 1.2888237237930298\n",
      "Epoch: 2, Batch: 785, Loss: 1.043038249015808\n",
      "Epoch: 2, Batch: 786, Loss: 0.3322083055973053\n",
      "Epoch: 2, Batch: 787, Loss: 3.6594934463500977\n",
      "Epoch: 2, Batch: 788, Loss: 3.3258018493652344\n",
      "Epoch: 2, Batch: 789, Loss: 1.965630292892456\n",
      "Epoch: 2, Batch: 790, Loss: 3.047067642211914\n",
      "Epoch: 2, Batch: 791, Loss: 1.5958251953125\n",
      "Epoch: 2, Batch: 792, Loss: 1.965080976486206\n",
      "Epoch: 2, Batch: 793, Loss: 3.1250991821289062\n",
      "Epoch: 2, Batch: 794, Loss: 2.7587692737579346\n",
      "Epoch: 2, Batch: 795, Loss: 2.3463006019592285\n",
      "Epoch: 2, Batch: 796, Loss: 4.34128475189209\n",
      "Epoch: 2, Batch: 797, Loss: 1.0449316501617432\n",
      "Epoch: 2, Batch: 798, Loss: 4.608489990234375\n",
      "Epoch: 2, Batch: 799, Loss: 2.579209089279175\n",
      "Epoch: 2, Batch: 800, Loss: 5.271461486816406\n",
      "Epoch: 2, Batch: 801, Loss: 5.57572078704834\n",
      "Epoch: 2, Batch: 802, Loss: 2.0484018325805664\n",
      "Epoch: 2, Batch: 803, Loss: 2.169686794281006\n",
      "Epoch: 2, Batch: 804, Loss: 1.977778434753418\n",
      "Epoch: 2, Batch: 805, Loss: 3.9961533546447754\n",
      "Epoch: 2, Batch: 806, Loss: 1.4645819664001465\n",
      "Epoch: 2, Batch: 807, Loss: 1.8650422096252441\n",
      "Epoch: 2, Batch: 808, Loss: 4.116194725036621\n",
      "Epoch: 2, Batch: 809, Loss: 4.100594520568848\n",
      "Epoch: 2, Batch: 810, Loss: 2.1168980598449707\n",
      "Epoch: 2, Batch: 811, Loss: 2.3944356441497803\n",
      "Epoch: 2, Batch: 812, Loss: 1.4348753690719604\n",
      "Epoch: 2, Batch: 813, Loss: 2.1165623664855957\n",
      "Epoch: 2, Batch: 814, Loss: 1.203519344329834\n",
      "Epoch: 2, Batch: 815, Loss: 5.432048797607422\n",
      "Epoch: 2, Batch: 816, Loss: 2.6082944869995117\n",
      "Epoch: 2, Batch: 817, Loss: 0.6606491208076477\n",
      "Epoch: 2, Batch: 818, Loss: 1.5160889625549316\n",
      "Epoch: 2, Batch: 819, Loss: 8.725682258605957\n",
      "Epoch: 2, Batch: 820, Loss: 3.645634889602661\n",
      "Epoch: 2, Batch: 821, Loss: 2.7651517391204834\n",
      "Epoch: 2, Batch: 822, Loss: 1.2013236284255981\n",
      "Epoch: 2, Batch: 823, Loss: 4.957367897033691\n",
      "Epoch: 2, Batch: 824, Loss: 1.38099205493927\n",
      "Epoch: 2, Batch: 825, Loss: 0.7956478595733643\n",
      "Epoch: 2, Batch: 826, Loss: 4.594216346740723\n",
      "Epoch: 2, Batch: 827, Loss: 1.3734713792800903\n",
      "Epoch: 2, Batch: 828, Loss: 2.13425874710083\n",
      "Epoch: 2, Batch: 829, Loss: 2.964434862136841\n",
      "Epoch: 2, Batch: 830, Loss: 2.813769817352295\n",
      "Epoch: 2, Batch: 831, Loss: 3.5976061820983887\n",
      "Epoch: 2, Batch: 832, Loss: 3.7007977962493896\n",
      "Epoch: 2, Batch: 833, Loss: 4.2046895027160645\n",
      "Epoch: 2, Batch: 834, Loss: 1.5389631986618042\n",
      "Epoch: 2, Batch: 835, Loss: 4.45156192779541\n",
      "Epoch: 2, Batch: 836, Loss: 0.5099186897277832\n",
      "Epoch: 2, Batch: 837, Loss: 0.7151476740837097\n",
      "Epoch: 2, Batch: 838, Loss: 0.9932898283004761\n",
      "Epoch: 2, Batch: 839, Loss: 1.5833544731140137\n",
      "Epoch: 2, Batch: 840, Loss: 3.708066701889038\n",
      "Epoch: 2, Batch: 841, Loss: 2.963789939880371\n",
      "Epoch: 2, Batch: 842, Loss: 2.7747912406921387\n",
      "Epoch: 2, Batch: 843, Loss: 1.714667797088623\n",
      "Epoch: 2, Batch: 844, Loss: 1.894951343536377\n",
      "Epoch: 2, Batch: 845, Loss: 2.7440569400787354\n",
      "Epoch: 2, Batch: 846, Loss: 1.8958226442337036\n",
      "Epoch: 2, Batch: 847, Loss: 3.3670120239257812\n",
      "Epoch: 2, Batch: 848, Loss: 0.7750186920166016\n",
      "Epoch: 2, Batch: 849, Loss: 0.3133695721626282\n",
      "Epoch: 2, Batch: 850, Loss: 1.4231553077697754\n",
      "Epoch: 2, Batch: 851, Loss: 1.56212317943573\n",
      "Epoch: 2, Batch: 852, Loss: 4.479560375213623\n",
      "Epoch: 2, Batch: 853, Loss: 1.4808965921401978\n",
      "Epoch: 2, Batch: 854, Loss: 2.1617486476898193\n",
      "Epoch: 2, Batch: 855, Loss: 1.4909706115722656\n",
      "Epoch: 2, Batch: 856, Loss: 2.1382882595062256\n",
      "Epoch: 2, Batch: 857, Loss: 2.6172895431518555\n",
      "Epoch: 2, Batch: 858, Loss: 4.036422252655029\n",
      "Epoch: 2, Batch: 859, Loss: 2.393223762512207\n",
      "Epoch: 2, Batch: 860, Loss: 3.0795421600341797\n",
      "Epoch: 2, Batch: 861, Loss: 2.7489683628082275\n",
      "Epoch: 2, Batch: 862, Loss: 3.2429072856903076\n",
      "Epoch: 2, Batch: 863, Loss: 0.6034223437309265\n",
      "Epoch: 2, Batch: 864, Loss: 2.198915481567383\n",
      "Epoch: 2, Batch: 865, Loss: 0.6494909524917603\n",
      "Epoch: 2, Batch: 866, Loss: 2.0490143299102783\n",
      "Epoch: 2, Batch: 867, Loss: 3.4865760803222656\n",
      "Epoch: 2, Batch: 868, Loss: 1.1208528280258179\n",
      "Epoch: 2, Batch: 869, Loss: 1.158337116241455\n",
      "Epoch: 2, Batch: 870, Loss: 4.969393253326416\n",
      "Epoch: 2, Batch: 871, Loss: 2.0039725303649902\n",
      "Epoch: 2, Batch: 872, Loss: 3.0640194416046143\n",
      "Epoch: 2, Batch: 873, Loss: 1.3606818914413452\n",
      "Epoch: 2, Batch: 874, Loss: 2.7192673683166504\n",
      "Epoch: 2, Batch: 875, Loss: 3.7005462646484375\n",
      "Epoch: 2, Batch: 876, Loss: 1.1137208938598633\n",
      "Epoch: 2, Batch: 877, Loss: 2.781513214111328\n",
      "Epoch: 2, Batch: 878, Loss: 2.7059128284454346\n",
      "Epoch: 2, Batch: 879, Loss: 4.910268306732178\n",
      "Epoch: 2, Batch: 880, Loss: 1.1376352310180664\n",
      "Epoch: 2, Batch: 881, Loss: 2.67044997215271\n",
      "Epoch: 2, Batch: 882, Loss: 3.965444564819336\n",
      "Epoch: 2, Batch: 883, Loss: 2.6182444095611572\n",
      "Epoch: 2, Batch: 884, Loss: 2.265470027923584\n",
      "Epoch: 2, Batch: 885, Loss: 4.1601152420043945\n",
      "Epoch: 2, Batch: 886, Loss: 4.407575607299805\n",
      "Epoch: 2, Batch: 887, Loss: 3.5208969116210938\n",
      "Epoch: 2, Batch: 888, Loss: 0.8867082595825195\n",
      "Epoch: 2, Batch: 889, Loss: 3.2544445991516113\n",
      "Epoch: 2, Batch: 890, Loss: 1.7248942852020264\n",
      "Epoch: 2, Batch: 891, Loss: 2.511608123779297\n",
      "Epoch: 2, Batch: 892, Loss: 2.3919565677642822\n",
      "Epoch: 2, Batch: 893, Loss: 0.8386985063552856\n",
      "Epoch: 2, Batch: 894, Loss: 1.041505217552185\n",
      "Epoch: 2, Batch: 895, Loss: 1.5830917358398438\n",
      "Epoch: 2, Batch: 896, Loss: 1.9233496189117432\n",
      "Epoch: 2, Batch: 897, Loss: 4.224759101867676\n",
      "Epoch: 2, Batch: 898, Loss: 1.5260276794433594\n",
      "Epoch: 2, Batch: 899, Loss: 3.2456462383270264\n",
      "Epoch: 2, Batch: 900, Loss: 1.757407784461975\n",
      "Epoch: 2, Batch: 901, Loss: 4.315676689147949\n",
      "Epoch: 2, Batch: 902, Loss: 1.7317200899124146\n",
      "Epoch: 2, Batch: 903, Loss: 3.7046704292297363\n",
      "Epoch: 2, Batch: 904, Loss: 3.42260479927063\n",
      "Epoch: 2, Batch: 905, Loss: 2.1481266021728516\n",
      "Epoch: 2, Batch: 906, Loss: 3.707146644592285\n",
      "Epoch: 2, Batch: 907, Loss: 3.0208373069763184\n",
      "Epoch: 2, Batch: 908, Loss: 1.5031193494796753\n",
      "Epoch: 2, Batch: 909, Loss: 3.8683218955993652\n",
      "Epoch: 2, Batch: 910, Loss: 2.7049622535705566\n",
      "Epoch: 2, Batch: 911, Loss: 2.7211503982543945\n",
      "Epoch: 2, Batch: 912, Loss: 3.951101779937744\n",
      "Epoch: 2, Batch: 913, Loss: 3.4471826553344727\n",
      "Epoch: 2, Batch: 914, Loss: 3.050368547439575\n",
      "Epoch: 2, Batch: 915, Loss: 2.1463072299957275\n",
      "Epoch: 2, Batch: 916, Loss: 1.7827061414718628\n",
      "Epoch: 2, Batch: 917, Loss: 5.142126083374023\n",
      "Epoch: 2, Batch: 918, Loss: 1.3674721717834473\n",
      "Epoch: 2, Batch: 919, Loss: 3.2369565963745117\n",
      "Epoch: 2, Batch: 920, Loss: 1.7187485694885254\n",
      "Epoch: 2, Batch: 921, Loss: 2.4447543621063232\n",
      "Epoch: 2, Batch: 922, Loss: 2.7544634342193604\n",
      "Epoch: 2, Batch: 923, Loss: 2.1621179580688477\n",
      "Epoch: 2, Batch: 924, Loss: 2.1521778106689453\n",
      "Epoch: 2, Batch: 925, Loss: 2.5355920791625977\n",
      "Epoch: 2, Batch: 926, Loss: 1.5845458507537842\n",
      "Epoch: 2, Batch: 927, Loss: 2.50632381439209\n",
      "Epoch: 2, Batch: 928, Loss: 4.552208423614502\n",
      "Epoch: 2, Batch: 929, Loss: 2.6491775512695312\n",
      "Epoch: 2, Batch: 930, Loss: 3.321558952331543\n",
      "Epoch: 2, Batch: 931, Loss: 1.4411464929580688\n",
      "Epoch: 2, Batch: 932, Loss: 3.2130513191223145\n",
      "Epoch: 2, Batch: 933, Loss: 0.7653161883354187\n",
      "Epoch: 2, Batch: 934, Loss: 0.6677064299583435\n",
      "Epoch: 2, Batch: 935, Loss: 4.037226676940918\n",
      "Epoch: 2, Batch: 936, Loss: 2.5865297317504883\n",
      "Epoch: 2, Batch: 937, Loss: 2.2519588470458984\n",
      "Epoch: 2, Batch: 938, Loss: 0.33485883474349976\n",
      "Epoch: 2, Batch: 939, Loss: 2.6025264263153076\n",
      "Epoch: 2, Batch: 940, Loss: 2.70542573928833\n",
      "Epoch: 2, Batch: 941, Loss: 0.7323586940765381\n",
      "Epoch: 2, Batch: 942, Loss: 3.049032688140869\n",
      "Epoch: 2, Batch: 943, Loss: 2.4814884662628174\n",
      "Epoch: 2, Batch: 944, Loss: 2.6956279277801514\n",
      "Epoch: 2, Batch: 945, Loss: 1.1563185453414917\n",
      "Epoch: 2, Batch: 946, Loss: 3.7206695079803467\n",
      "Epoch: 2, Batch: 947, Loss: 0.2514461874961853\n",
      "Epoch: 2, Batch: 948, Loss: 1.7015643119812012\n",
      "Epoch: 2, Batch: 949, Loss: 1.983594298362732\n",
      "Epoch: 2, Batch: 950, Loss: 2.1434338092803955\n",
      "Epoch: 2, Batch: 951, Loss: 0.6282373070716858\n",
      "Epoch: 2, Batch: 952, Loss: 3.091811180114746\n",
      "Epoch: 2, Batch: 953, Loss: 3.74043607711792\n",
      "Epoch: 2, Batch: 954, Loss: 1.6988356113433838\n",
      "Epoch: 2, Batch: 955, Loss: 2.592784881591797\n",
      "Epoch: 2, Batch: 956, Loss: 1.1140114068984985\n",
      "Epoch: 2, Batch: 957, Loss: 2.5282082557678223\n",
      "Epoch: 2, Batch: 958, Loss: 3.059964179992676\n",
      "Epoch: 2, Batch: 959, Loss: 4.258003234863281\n",
      "Epoch: 2, Batch: 960, Loss: 1.8528817892074585\n",
      "Epoch: 2, Batch: 961, Loss: 0.7837950587272644\n",
      "Epoch: 2, Batch: 962, Loss: 1.80535089969635\n",
      "Epoch: 2, Batch: 963, Loss: 3.847539186477661\n",
      "Epoch: 2, Batch: 964, Loss: 2.030477523803711\n",
      "Epoch: 2, Batch: 965, Loss: 4.170280456542969\n",
      "Epoch: 2, Batch: 966, Loss: 3.8597030639648438\n",
      "Epoch: 2, Batch: 967, Loss: 1.8534588813781738\n",
      "Epoch: 2, Batch: 968, Loss: 3.2855610847473145\n",
      "Epoch: 2, Batch: 969, Loss: 1.1261842250823975\n",
      "Epoch: 2, Batch: 970, Loss: 0.7570066452026367\n",
      "Epoch: 2, Batch: 971, Loss: 0.27505072951316833\n",
      "Epoch: 2, Batch: 972, Loss: 5.832603454589844\n",
      "Epoch: 2, Batch: 973, Loss: 4.8113112449646\n",
      "Epoch: 2, Batch: 974, Loss: 0.27950045466423035\n",
      "Epoch: 2, Batch: 975, Loss: 2.1576435565948486\n",
      "Epoch: 2, Batch: 976, Loss: 2.8345770835876465\n",
      "Epoch: 2, Batch: 977, Loss: 1.3640791177749634\n",
      "Epoch: 2, Batch: 978, Loss: 2.2546637058258057\n",
      "Epoch: 2, Batch: 979, Loss: 2.5267112255096436\n",
      "Epoch: 2, Batch: 980, Loss: 3.2569117546081543\n",
      "Epoch: 2, Batch: 981, Loss: 2.4893102645874023\n",
      "Epoch: 2, Batch: 982, Loss: 2.552532911300659\n",
      "Epoch: 2, Batch: 983, Loss: 1.6325316429138184\n",
      "Epoch: 2, Batch: 984, Loss: 1.6901919841766357\n",
      "Epoch: 2, Batch: 985, Loss: 1.9256256818771362\n",
      "Epoch: 2, Batch: 986, Loss: 0.43065962195396423\n",
      "Epoch: 2, Batch: 987, Loss: 2.2308077812194824\n",
      "Epoch: 2, Batch: 988, Loss: 2.9011270999908447\n",
      "Epoch: 2, Batch: 989, Loss: 3.2020862102508545\n",
      "Epoch: 2, Batch: 990, Loss: 4.232938289642334\n",
      "Epoch: 2, Batch: 991, Loss: 7.299152374267578\n",
      "Epoch: 2, Batch: 992, Loss: 1.5578081607818604\n",
      "Epoch: 2, Batch: 993, Loss: 1.923326015472412\n",
      "Epoch: 2, Batch: 994, Loss: 1.3834080696105957\n",
      "Epoch: 2, Batch: 995, Loss: 2.4813342094421387\n",
      "Epoch: 2, Batch: 996, Loss: 3.130842447280884\n",
      "Epoch: 2, Batch: 997, Loss: 1.8020004034042358\n",
      "Epoch: 2, Batch: 998, Loss: 2.1516706943511963\n",
      "Epoch: 2, Batch: 999, Loss: 3.0634965896606445\n",
      "Epoch: 3, Batch: 0, Loss: 1.1771962642669678\n",
      "Epoch: 3, Batch: 1, Loss: 1.4849289655685425\n",
      "Epoch: 3, Batch: 2, Loss: 3.1289052963256836\n",
      "Epoch: 3, Batch: 3, Loss: 0.21132929623126984\n",
      "Epoch: 3, Batch: 4, Loss: 2.4679501056671143\n",
      "Epoch: 3, Batch: 5, Loss: 1.5982550382614136\n",
      "Epoch: 3, Batch: 6, Loss: 1.3720415830612183\n",
      "Epoch: 3, Batch: 7, Loss: 1.6407710313796997\n",
      "Epoch: 3, Batch: 8, Loss: 1.0162302255630493\n",
      "Epoch: 3, Batch: 9, Loss: 1.9271937608718872\n",
      "Epoch: 3, Batch: 10, Loss: 4.26368522644043\n",
      "Epoch: 3, Batch: 11, Loss: 1.0318557024002075\n",
      "Epoch: 3, Batch: 12, Loss: 4.573160648345947\n",
      "Epoch: 3, Batch: 13, Loss: 2.585092306137085\n",
      "Epoch: 3, Batch: 14, Loss: 2.241849184036255\n",
      "Epoch: 3, Batch: 15, Loss: 2.8291382789611816\n",
      "Epoch: 3, Batch: 16, Loss: 2.2522058486938477\n",
      "Epoch: 3, Batch: 17, Loss: 2.0309739112854004\n",
      "Epoch: 3, Batch: 18, Loss: 1.1024060249328613\n",
      "Epoch: 3, Batch: 19, Loss: 1.4702792167663574\n",
      "Epoch: 3, Batch: 20, Loss: 2.8352718353271484\n",
      "Epoch: 3, Batch: 21, Loss: 2.051365852355957\n",
      "Epoch: 3, Batch: 22, Loss: 3.3870232105255127\n",
      "Epoch: 3, Batch: 23, Loss: 1.360295057296753\n",
      "Epoch: 3, Batch: 24, Loss: 2.9543216228485107\n",
      "Epoch: 3, Batch: 25, Loss: 0.803768515586853\n",
      "Epoch: 3, Batch: 26, Loss: 2.624119520187378\n",
      "Epoch: 3, Batch: 27, Loss: 3.403143882751465\n",
      "Epoch: 3, Batch: 28, Loss: 0.9797354936599731\n",
      "Epoch: 3, Batch: 29, Loss: 2.570859432220459\n",
      "Epoch: 3, Batch: 30, Loss: 0.5745116472244263\n",
      "Epoch: 3, Batch: 31, Loss: 0.4876335561275482\n",
      "Epoch: 3, Batch: 32, Loss: 2.1054253578186035\n",
      "Epoch: 3, Batch: 33, Loss: 3.054490089416504\n",
      "Epoch: 3, Batch: 34, Loss: 0.8306106925010681\n",
      "Epoch: 3, Batch: 35, Loss: 0.8262161016464233\n",
      "Epoch: 3, Batch: 36, Loss: 1.5982027053833008\n",
      "Epoch: 3, Batch: 37, Loss: 1.2437716722488403\n",
      "Epoch: 3, Batch: 38, Loss: 4.786957263946533\n",
      "Epoch: 3, Batch: 39, Loss: 1.4044690132141113\n",
      "Epoch: 3, Batch: 40, Loss: 1.9724470376968384\n",
      "Epoch: 3, Batch: 41, Loss: 0.8950594067573547\n",
      "Epoch: 3, Batch: 42, Loss: 2.802942991256714\n",
      "Epoch: 3, Batch: 43, Loss: 1.9429939985275269\n",
      "Epoch: 3, Batch: 44, Loss: 4.416957855224609\n",
      "Epoch: 3, Batch: 45, Loss: 1.6343992948532104\n",
      "Epoch: 3, Batch: 46, Loss: 1.2476987838745117\n",
      "Epoch: 3, Batch: 47, Loss: 2.799180030822754\n",
      "Epoch: 3, Batch: 48, Loss: 1.6781501770019531\n",
      "Epoch: 3, Batch: 49, Loss: 1.6726617813110352\n",
      "Epoch: 3, Batch: 50, Loss: 1.932288646697998\n",
      "Epoch: 3, Batch: 51, Loss: 1.8437790870666504\n",
      "Epoch: 3, Batch: 52, Loss: 3.5024821758270264\n",
      "Epoch: 3, Batch: 53, Loss: 2.8787014484405518\n",
      "Epoch: 3, Batch: 54, Loss: 2.975632429122925\n",
      "Epoch: 3, Batch: 55, Loss: 2.4326939582824707\n",
      "Epoch: 3, Batch: 56, Loss: 3.3052852153778076\n",
      "Epoch: 3, Batch: 57, Loss: 2.353736400604248\n",
      "Epoch: 3, Batch: 58, Loss: 0.8015854954719543\n",
      "Epoch: 3, Batch: 59, Loss: 6.38169002532959\n",
      "Epoch: 3, Batch: 60, Loss: 0.7537434101104736\n",
      "Epoch: 3, Batch: 61, Loss: 3.129713535308838\n",
      "Epoch: 3, Batch: 62, Loss: 3.583881378173828\n",
      "Epoch: 3, Batch: 63, Loss: 3.807806968688965\n",
      "Epoch: 3, Batch: 64, Loss: 2.554201126098633\n",
      "Epoch: 3, Batch: 65, Loss: 1.3900338411331177\n",
      "Epoch: 3, Batch: 66, Loss: 5.218448638916016\n",
      "Epoch: 3, Batch: 67, Loss: 2.242741584777832\n",
      "Epoch: 3, Batch: 68, Loss: 2.8589425086975098\n",
      "Epoch: 3, Batch: 69, Loss: 1.443121075630188\n",
      "Epoch: 3, Batch: 70, Loss: 3.9916369915008545\n",
      "Epoch: 3, Batch: 71, Loss: 4.3344879150390625\n",
      "Epoch: 3, Batch: 72, Loss: 2.1375062465667725\n",
      "Epoch: 3, Batch: 73, Loss: 3.3388185501098633\n",
      "Epoch: 3, Batch: 74, Loss: 2.3064558506011963\n",
      "Epoch: 3, Batch: 75, Loss: 1.4130045175552368\n",
      "Epoch: 3, Batch: 76, Loss: 0.8423093557357788\n",
      "Epoch: 3, Batch: 77, Loss: 2.419572353363037\n",
      "Epoch: 3, Batch: 78, Loss: 0.3392307758331299\n",
      "Epoch: 3, Batch: 79, Loss: 1.9246268272399902\n",
      "Epoch: 3, Batch: 80, Loss: 1.6683849096298218\n",
      "Epoch: 3, Batch: 81, Loss: 1.9151698350906372\n",
      "Epoch: 3, Batch: 82, Loss: 2.512258529663086\n",
      "Epoch: 3, Batch: 83, Loss: 1.4027714729309082\n",
      "Epoch: 3, Batch: 84, Loss: 1.2595064640045166\n",
      "Epoch: 3, Batch: 85, Loss: 3.177213668823242\n",
      "Epoch: 3, Batch: 86, Loss: 1.3459376096725464\n",
      "Epoch: 3, Batch: 87, Loss: 2.8179173469543457\n",
      "Epoch: 3, Batch: 88, Loss: 1.4372217655181885\n",
      "Epoch: 3, Batch: 89, Loss: 0.1597839891910553\n",
      "Epoch: 3, Batch: 90, Loss: 0.956854522228241\n",
      "Epoch: 3, Batch: 91, Loss: 1.4228413105010986\n",
      "Epoch: 3, Batch: 92, Loss: 0.8873694539070129\n",
      "Epoch: 3, Batch: 93, Loss: 5.082098007202148\n",
      "Epoch: 3, Batch: 94, Loss: 1.7559446096420288\n",
      "Epoch: 3, Batch: 95, Loss: 1.9717289209365845\n",
      "Epoch: 3, Batch: 96, Loss: 1.5151076316833496\n",
      "Epoch: 3, Batch: 97, Loss: 1.8247578144073486\n",
      "Epoch: 3, Batch: 98, Loss: 1.785395622253418\n",
      "Epoch: 3, Batch: 99, Loss: 0.33278942108154297\n",
      "Epoch: 3, Batch: 100, Loss: 1.2951154708862305\n",
      "Epoch: 3, Batch: 101, Loss: 3.0602216720581055\n",
      "Epoch: 3, Batch: 102, Loss: 1.880412220954895\n",
      "Epoch: 3, Batch: 103, Loss: 0.355654239654541\n",
      "Epoch: 3, Batch: 104, Loss: 3.9572432041168213\n",
      "Epoch: 3, Batch: 105, Loss: 1.8092279434204102\n",
      "Epoch: 3, Batch: 106, Loss: 2.5221171379089355\n",
      "Epoch: 3, Batch: 107, Loss: 1.5963269472122192\n",
      "Epoch: 3, Batch: 108, Loss: 1.2486706972122192\n",
      "Epoch: 3, Batch: 109, Loss: 1.907068133354187\n",
      "Epoch: 3, Batch: 110, Loss: 2.009605646133423\n",
      "Epoch: 3, Batch: 111, Loss: 0.5903645157814026\n",
      "Epoch: 3, Batch: 112, Loss: 1.8975036144256592\n",
      "Epoch: 3, Batch: 113, Loss: 2.7855749130249023\n",
      "Epoch: 3, Batch: 114, Loss: 0.31824037432670593\n",
      "Epoch: 3, Batch: 115, Loss: 2.229440689086914\n",
      "Epoch: 3, Batch: 116, Loss: 2.644824981689453\n",
      "Epoch: 3, Batch: 117, Loss: 0.7754873633384705\n",
      "Epoch: 3, Batch: 118, Loss: 0.6286543011665344\n",
      "Epoch: 3, Batch: 119, Loss: 2.214484453201294\n",
      "Epoch: 3, Batch: 120, Loss: 1.0484662055969238\n",
      "Epoch: 3, Batch: 121, Loss: 2.400737762451172\n",
      "Epoch: 3, Batch: 122, Loss: 2.4723193645477295\n",
      "Epoch: 3, Batch: 123, Loss: 3.274726390838623\n",
      "Epoch: 3, Batch: 124, Loss: 1.1221998929977417\n",
      "Epoch: 3, Batch: 125, Loss: 2.5035667419433594\n",
      "Epoch: 3, Batch: 126, Loss: 2.4805140495300293\n",
      "Epoch: 3, Batch: 127, Loss: 0.713388204574585\n",
      "Epoch: 3, Batch: 128, Loss: 1.3692798614501953\n",
      "Epoch: 3, Batch: 129, Loss: 2.296518325805664\n",
      "Epoch: 3, Batch: 130, Loss: 1.3259682655334473\n",
      "Epoch: 3, Batch: 131, Loss: 2.0980539321899414\n",
      "Epoch: 3, Batch: 132, Loss: 1.9783935546875\n",
      "Epoch: 3, Batch: 133, Loss: 0.3174172639846802\n",
      "Epoch: 3, Batch: 134, Loss: 3.409762144088745\n",
      "Epoch: 3, Batch: 135, Loss: 1.907126784324646\n",
      "Epoch: 3, Batch: 136, Loss: 3.9695253372192383\n",
      "Epoch: 3, Batch: 137, Loss: 1.8905128240585327\n",
      "Epoch: 3, Batch: 138, Loss: 0.38946592807769775\n",
      "Epoch: 3, Batch: 139, Loss: 1.316231369972229\n",
      "Epoch: 3, Batch: 140, Loss: 1.6698249578475952\n",
      "Epoch: 3, Batch: 141, Loss: 2.0411226749420166\n",
      "Epoch: 3, Batch: 142, Loss: 2.2902755737304688\n",
      "Epoch: 3, Batch: 143, Loss: 2.173207998275757\n",
      "Epoch: 3, Batch: 144, Loss: 1.4013922214508057\n",
      "Epoch: 3, Batch: 145, Loss: 0.36384204030036926\n",
      "Epoch: 3, Batch: 146, Loss: 1.1407415866851807\n",
      "Epoch: 3, Batch: 147, Loss: 3.399383783340454\n",
      "Epoch: 3, Batch: 148, Loss: 3.612466812133789\n",
      "Epoch: 3, Batch: 149, Loss: 0.4399331212043762\n",
      "Epoch: 3, Batch: 150, Loss: 1.5069396495819092\n",
      "Epoch: 3, Batch: 151, Loss: 1.0951669216156006\n",
      "Epoch: 3, Batch: 152, Loss: 1.8797647953033447\n",
      "Epoch: 3, Batch: 153, Loss: 1.7861316204071045\n",
      "Epoch: 3, Batch: 154, Loss: 3.42256498336792\n",
      "Epoch: 3, Batch: 155, Loss: 2.5246355533599854\n",
      "Epoch: 3, Batch: 156, Loss: 1.958216905593872\n",
      "Epoch: 3, Batch: 157, Loss: 0.3582609295845032\n",
      "Epoch: 3, Batch: 158, Loss: 1.7413148880004883\n",
      "Epoch: 3, Batch: 159, Loss: 3.7742834091186523\n",
      "Epoch: 3, Batch: 160, Loss: 4.128663063049316\n",
      "Epoch: 3, Batch: 161, Loss: 5.258545398712158\n",
      "Epoch: 3, Batch: 162, Loss: 1.075892448425293\n",
      "Epoch: 3, Batch: 163, Loss: 0.9648268222808838\n",
      "Epoch: 3, Batch: 164, Loss: 1.5918647050857544\n",
      "Epoch: 3, Batch: 165, Loss: 1.4226047992706299\n",
      "Epoch: 3, Batch: 166, Loss: 0.6519628167152405\n",
      "Epoch: 3, Batch: 167, Loss: 2.197089195251465\n",
      "Epoch: 3, Batch: 168, Loss: 3.0364763736724854\n",
      "Epoch: 3, Batch: 169, Loss: 2.1680727005004883\n",
      "Epoch: 3, Batch: 170, Loss: 2.2074451446533203\n",
      "Epoch: 3, Batch: 171, Loss: 1.011643409729004\n",
      "Epoch: 3, Batch: 172, Loss: 5.5801191329956055\n",
      "Epoch: 3, Batch: 173, Loss: 3.689159631729126\n",
      "Epoch: 3, Batch: 174, Loss: 2.28163743019104\n",
      "Epoch: 3, Batch: 175, Loss: 1.9922826290130615\n",
      "Epoch: 3, Batch: 176, Loss: 1.8446518182754517\n",
      "Epoch: 3, Batch: 177, Loss: 1.623622179031372\n",
      "Epoch: 3, Batch: 178, Loss: 2.378436326980591\n",
      "Epoch: 3, Batch: 179, Loss: 2.8112735748291016\n",
      "Epoch: 3, Batch: 180, Loss: 2.372798204421997\n",
      "Epoch: 3, Batch: 181, Loss: 0.38563936948776245\n",
      "Epoch: 3, Batch: 182, Loss: 2.575561046600342\n",
      "Epoch: 3, Batch: 183, Loss: 3.4028480052948\n",
      "Epoch: 3, Batch: 184, Loss: 0.2216428965330124\n",
      "Epoch: 3, Batch: 185, Loss: 0.9817607402801514\n",
      "Epoch: 3, Batch: 186, Loss: 0.2648940682411194\n",
      "Epoch: 3, Batch: 187, Loss: 1.2889832258224487\n",
      "Epoch: 3, Batch: 188, Loss: 1.129180908203125\n",
      "Epoch: 3, Batch: 189, Loss: 0.9731003642082214\n",
      "Epoch: 3, Batch: 190, Loss: 1.1934870481491089\n",
      "Epoch: 3, Batch: 191, Loss: 5.799381256103516\n",
      "Epoch: 3, Batch: 192, Loss: 3.1362247467041016\n",
      "Epoch: 3, Batch: 193, Loss: 1.3696973323822021\n",
      "Epoch: 3, Batch: 194, Loss: 1.1653072834014893\n",
      "Epoch: 3, Batch: 195, Loss: 1.0528620481491089\n",
      "Epoch: 3, Batch: 196, Loss: 1.4477027654647827\n",
      "Epoch: 3, Batch: 197, Loss: 1.7041434049606323\n",
      "Epoch: 3, Batch: 198, Loss: 2.0577993392944336\n",
      "Epoch: 3, Batch: 199, Loss: 1.708284854888916\n",
      "Epoch: 3, Batch: 200, Loss: 0.7419764399528503\n",
      "Epoch: 3, Batch: 201, Loss: 1.86211097240448\n",
      "Epoch: 3, Batch: 202, Loss: 2.2221288681030273\n",
      "Epoch: 3, Batch: 203, Loss: 3.0399715900421143\n",
      "Epoch: 3, Batch: 204, Loss: 2.3472912311553955\n",
      "Epoch: 3, Batch: 205, Loss: 4.565810203552246\n",
      "Epoch: 3, Batch: 206, Loss: 3.930208683013916\n",
      "Epoch: 3, Batch: 207, Loss: 1.6528334617614746\n",
      "Epoch: 3, Batch: 208, Loss: 2.6191482543945312\n",
      "Epoch: 3, Batch: 209, Loss: 2.71614933013916\n",
      "Epoch: 3, Batch: 210, Loss: 1.2663055658340454\n",
      "Epoch: 3, Batch: 211, Loss: 1.2235138416290283\n",
      "Epoch: 3, Batch: 212, Loss: 3.7041053771972656\n",
      "Epoch: 3, Batch: 213, Loss: 1.5387604236602783\n",
      "Epoch: 3, Batch: 214, Loss: 5.61676549911499\n",
      "Epoch: 3, Batch: 215, Loss: 2.8338537216186523\n",
      "Epoch: 3, Batch: 216, Loss: 1.7240374088287354\n",
      "Epoch: 3, Batch: 217, Loss: 4.354715347290039\n",
      "Epoch: 3, Batch: 218, Loss: 2.1947829723358154\n",
      "Epoch: 3, Batch: 219, Loss: 2.3993029594421387\n",
      "Epoch: 3, Batch: 220, Loss: 2.005338191986084\n",
      "Epoch: 3, Batch: 221, Loss: 1.466834545135498\n",
      "Epoch: 3, Batch: 222, Loss: 1.0301488637924194\n",
      "Epoch: 3, Batch: 223, Loss: 2.041322708129883\n",
      "Epoch: 3, Batch: 224, Loss: 1.769059181213379\n",
      "Epoch: 3, Batch: 225, Loss: 2.6612038612365723\n",
      "Epoch: 3, Batch: 226, Loss: 2.6459994316101074\n",
      "Epoch: 3, Batch: 227, Loss: 1.156022310256958\n",
      "Epoch: 3, Batch: 228, Loss: 1.4728612899780273\n",
      "Epoch: 3, Batch: 229, Loss: 2.844423770904541\n",
      "Epoch: 3, Batch: 230, Loss: 2.259065628051758\n",
      "Epoch: 3, Batch: 231, Loss: 1.1058803796768188\n",
      "Epoch: 3, Batch: 232, Loss: 2.262965202331543\n",
      "Epoch: 3, Batch: 233, Loss: 3.9053468704223633\n",
      "Epoch: 3, Batch: 234, Loss: 1.026017427444458\n",
      "Epoch: 3, Batch: 235, Loss: 0.7356966137886047\n",
      "Epoch: 3, Batch: 236, Loss: 2.4975297451019287\n",
      "Epoch: 3, Batch: 237, Loss: 1.3037086725234985\n",
      "Epoch: 3, Batch: 238, Loss: 1.5821504592895508\n",
      "Epoch: 3, Batch: 239, Loss: 0.9671140909194946\n",
      "Epoch: 3, Batch: 240, Loss: 0.8924462199211121\n",
      "Epoch: 3, Batch: 241, Loss: 0.2903597354888916\n",
      "Epoch: 3, Batch: 242, Loss: 2.3416976928710938\n",
      "Epoch: 3, Batch: 243, Loss: 1.3349125385284424\n",
      "Epoch: 3, Batch: 244, Loss: 3.2127017974853516\n",
      "Epoch: 3, Batch: 245, Loss: 2.4450016021728516\n",
      "Epoch: 3, Batch: 246, Loss: 6.700201988220215\n",
      "Epoch: 3, Batch: 247, Loss: 1.0206328630447388\n",
      "Epoch: 3, Batch: 248, Loss: 0.5891668200492859\n",
      "Epoch: 3, Batch: 249, Loss: 4.079136371612549\n",
      "Epoch: 3, Batch: 250, Loss: 1.657299280166626\n",
      "Epoch: 3, Batch: 251, Loss: 1.3924658298492432\n",
      "Epoch: 3, Batch: 252, Loss: 3.7361667156219482\n",
      "Epoch: 3, Batch: 253, Loss: 1.711259365081787\n",
      "Epoch: 3, Batch: 254, Loss: 1.0873723030090332\n",
      "Epoch: 3, Batch: 255, Loss: 0.962188184261322\n",
      "Epoch: 3, Batch: 256, Loss: 2.5864038467407227\n",
      "Epoch: 3, Batch: 257, Loss: 3.4584949016571045\n",
      "Epoch: 3, Batch: 258, Loss: 3.924772024154663\n",
      "Epoch: 3, Batch: 259, Loss: 1.1231613159179688\n",
      "Epoch: 3, Batch: 260, Loss: 0.9551677703857422\n",
      "Epoch: 3, Batch: 261, Loss: 1.2430797815322876\n",
      "Epoch: 3, Batch: 262, Loss: 4.144451141357422\n",
      "Epoch: 3, Batch: 263, Loss: 3.0472183227539062\n",
      "Epoch: 3, Batch: 264, Loss: 3.540102005004883\n",
      "Epoch: 3, Batch: 265, Loss: 3.174337387084961\n",
      "Epoch: 3, Batch: 266, Loss: 2.9220869541168213\n",
      "Epoch: 3, Batch: 267, Loss: 2.7300190925598145\n",
      "Epoch: 3, Batch: 268, Loss: 3.066964626312256\n",
      "Epoch: 3, Batch: 269, Loss: 2.147822856903076\n",
      "Epoch: 3, Batch: 270, Loss: 1.940088152885437\n",
      "Epoch: 3, Batch: 271, Loss: 2.3300116062164307\n",
      "Epoch: 3, Batch: 272, Loss: 1.4398621320724487\n",
      "Epoch: 3, Batch: 273, Loss: 1.4702454805374146\n",
      "Epoch: 3, Batch: 274, Loss: 1.1747008562088013\n",
      "Epoch: 3, Batch: 275, Loss: 0.8904025554656982\n",
      "Epoch: 3, Batch: 276, Loss: 6.44786262512207\n",
      "Epoch: 3, Batch: 277, Loss: 3.7348408699035645\n",
      "Epoch: 3, Batch: 278, Loss: 2.8387537002563477\n",
      "Epoch: 3, Batch: 279, Loss: 2.832111120223999\n",
      "Epoch: 3, Batch: 280, Loss: 4.927154064178467\n",
      "Epoch: 3, Batch: 281, Loss: 3.5871260166168213\n",
      "Epoch: 3, Batch: 282, Loss: 1.8485562801361084\n",
      "Epoch: 3, Batch: 283, Loss: 1.4670945405960083\n",
      "Epoch: 3, Batch: 284, Loss: 1.9882394075393677\n",
      "Epoch: 3, Batch: 285, Loss: 1.3248538970947266\n",
      "Epoch: 3, Batch: 286, Loss: 0.7693840265274048\n",
      "Epoch: 3, Batch: 287, Loss: 4.501223564147949\n",
      "Epoch: 3, Batch: 288, Loss: 4.356180191040039\n",
      "Epoch: 3, Batch: 289, Loss: 0.19163310527801514\n",
      "Epoch: 3, Batch: 290, Loss: 2.3823137283325195\n",
      "Epoch: 3, Batch: 291, Loss: 0.7583562135696411\n",
      "Epoch: 3, Batch: 292, Loss: 1.061009168624878\n",
      "Epoch: 3, Batch: 293, Loss: 3.179929256439209\n",
      "Epoch: 3, Batch: 294, Loss: 2.7138044834136963\n",
      "Epoch: 3, Batch: 295, Loss: 1.871523380279541\n",
      "Epoch: 3, Batch: 296, Loss: 2.0942442417144775\n",
      "Epoch: 3, Batch: 297, Loss: 2.365906238555908\n",
      "Epoch: 3, Batch: 298, Loss: 2.0630996227264404\n",
      "Epoch: 3, Batch: 299, Loss: 3.196995735168457\n",
      "Epoch: 3, Batch: 300, Loss: 1.0697029829025269\n",
      "Epoch: 3, Batch: 301, Loss: 2.617598533630371\n",
      "Epoch: 3, Batch: 302, Loss: 2.867274284362793\n",
      "Epoch: 3, Batch: 303, Loss: 2.815852165222168\n",
      "Epoch: 3, Batch: 304, Loss: 3.6905200481414795\n",
      "Epoch: 3, Batch: 305, Loss: 2.608269453048706\n",
      "Epoch: 3, Batch: 306, Loss: 2.8121683597564697\n",
      "Epoch: 3, Batch: 307, Loss: 1.8318573236465454\n",
      "Epoch: 3, Batch: 308, Loss: 2.125183582305908\n",
      "Epoch: 3, Batch: 309, Loss: 2.462679862976074\n",
      "Epoch: 3, Batch: 310, Loss: 3.987842559814453\n",
      "Epoch: 3, Batch: 311, Loss: 1.589925765991211\n",
      "Epoch: 3, Batch: 312, Loss: 1.9992365837097168\n",
      "Epoch: 3, Batch: 313, Loss: 3.094069719314575\n",
      "Epoch: 3, Batch: 314, Loss: 2.724667549133301\n",
      "Epoch: 3, Batch: 315, Loss: 0.26989367604255676\n",
      "Epoch: 3, Batch: 316, Loss: 1.4648939371109009\n",
      "Epoch: 3, Batch: 317, Loss: 2.934464454650879\n",
      "Epoch: 3, Batch: 318, Loss: 0.4218410551548004\n",
      "Epoch: 3, Batch: 319, Loss: 1.225930094718933\n",
      "Epoch: 3, Batch: 320, Loss: 1.1539936065673828\n",
      "Epoch: 3, Batch: 321, Loss: 2.1199851036071777\n",
      "Epoch: 3, Batch: 322, Loss: 0.6985939741134644\n",
      "Epoch: 3, Batch: 323, Loss: 0.4544437527656555\n",
      "Epoch: 3, Batch: 324, Loss: 2.4934380054473877\n",
      "Epoch: 3, Batch: 325, Loss: 2.320187568664551\n",
      "Epoch: 3, Batch: 326, Loss: 6.64518928527832\n",
      "Epoch: 3, Batch: 327, Loss: 1.4135096073150635\n",
      "Epoch: 3, Batch: 328, Loss: 4.578934192657471\n",
      "Epoch: 3, Batch: 329, Loss: 0.18390172719955444\n",
      "Epoch: 3, Batch: 330, Loss: 1.4178075790405273\n",
      "Epoch: 3, Batch: 331, Loss: 0.8288998603820801\n",
      "Epoch: 3, Batch: 332, Loss: 2.913435459136963\n",
      "Epoch: 3, Batch: 333, Loss: 2.761154890060425\n",
      "Epoch: 3, Batch: 334, Loss: 2.1360459327697754\n",
      "Epoch: 3, Batch: 335, Loss: 3.5409767627716064\n",
      "Epoch: 3, Batch: 336, Loss: 1.2695664167404175\n",
      "Epoch: 3, Batch: 337, Loss: 5.473950386047363\n",
      "Epoch: 3, Batch: 338, Loss: 0.5245048403739929\n",
      "Epoch: 3, Batch: 339, Loss: 1.7654086351394653\n",
      "Epoch: 3, Batch: 340, Loss: 3.6697983741760254\n",
      "Epoch: 3, Batch: 341, Loss: 3.0213687419891357\n",
      "Epoch: 3, Batch: 342, Loss: 2.4921979904174805\n",
      "Epoch: 3, Batch: 343, Loss: 2.973285675048828\n",
      "Epoch: 3, Batch: 344, Loss: 0.8320258855819702\n",
      "Epoch: 3, Batch: 345, Loss: 8.827535629272461\n",
      "Epoch: 3, Batch: 346, Loss: 1.7997064590454102\n",
      "Epoch: 3, Batch: 347, Loss: 3.579148769378662\n",
      "Epoch: 3, Batch: 348, Loss: 2.5967979431152344\n",
      "Epoch: 3, Batch: 349, Loss: 1.8975578546524048\n",
      "Epoch: 3, Batch: 350, Loss: 3.079855442047119\n",
      "Epoch: 3, Batch: 351, Loss: 4.080281734466553\n",
      "Epoch: 3, Batch: 352, Loss: 1.3194148540496826\n",
      "Epoch: 3, Batch: 353, Loss: 2.89151668548584\n",
      "Epoch: 3, Batch: 354, Loss: 1.7276923656463623\n",
      "Epoch: 3, Batch: 355, Loss: 1.9874287843704224\n",
      "Epoch: 3, Batch: 356, Loss: 0.9080310463905334\n",
      "Epoch: 3, Batch: 357, Loss: 0.8839508295059204\n",
      "Epoch: 3, Batch: 358, Loss: 3.7609686851501465\n",
      "Epoch: 3, Batch: 359, Loss: 1.5534378290176392\n",
      "Epoch: 3, Batch: 360, Loss: 2.8901398181915283\n",
      "Epoch: 3, Batch: 361, Loss: 1.170647144317627\n",
      "Epoch: 3, Batch: 362, Loss: 3.9850258827209473\n",
      "Epoch: 3, Batch: 363, Loss: 1.203601598739624\n",
      "Epoch: 3, Batch: 364, Loss: 3.053405284881592\n",
      "Epoch: 3, Batch: 365, Loss: 1.3316775560379028\n",
      "Epoch: 3, Batch: 366, Loss: 0.3682546019554138\n",
      "Epoch: 3, Batch: 367, Loss: 1.4498529434204102\n",
      "Epoch: 3, Batch: 368, Loss: 3.223308563232422\n",
      "Epoch: 3, Batch: 369, Loss: 1.2032115459442139\n",
      "Epoch: 3, Batch: 370, Loss: 2.354349136352539\n",
      "Epoch: 3, Batch: 371, Loss: 2.8945071697235107\n",
      "Epoch: 3, Batch: 372, Loss: 2.8391740322113037\n",
      "Epoch: 3, Batch: 373, Loss: 2.5674538612365723\n",
      "Epoch: 3, Batch: 374, Loss: 2.09539794921875\n",
      "Epoch: 3, Batch: 375, Loss: 1.7907419204711914\n",
      "Epoch: 3, Batch: 376, Loss: 0.6917197108268738\n",
      "Epoch: 3, Batch: 377, Loss: 3.7395365238189697\n",
      "Epoch: 3, Batch: 378, Loss: 2.228273868560791\n",
      "Epoch: 3, Batch: 379, Loss: 1.3340591192245483\n",
      "Epoch: 3, Batch: 380, Loss: 1.3194751739501953\n",
      "Epoch: 3, Batch: 381, Loss: 3.4348230361938477\n",
      "Epoch: 3, Batch: 382, Loss: 5.483681678771973\n",
      "Epoch: 3, Batch: 383, Loss: 2.259448766708374\n",
      "Epoch: 3, Batch: 384, Loss: 0.9563466310501099\n",
      "Epoch: 3, Batch: 385, Loss: 5.249294281005859\n",
      "Epoch: 3, Batch: 386, Loss: 0.9658031463623047\n",
      "Epoch: 3, Batch: 387, Loss: 1.3103132247924805\n",
      "Epoch: 3, Batch: 388, Loss: 2.2873923778533936\n",
      "Epoch: 3, Batch: 389, Loss: 4.232932090759277\n",
      "Epoch: 3, Batch: 390, Loss: 2.396411895751953\n",
      "Epoch: 3, Batch: 391, Loss: 2.1422276496887207\n",
      "Epoch: 3, Batch: 392, Loss: 2.011997699737549\n",
      "Epoch: 3, Batch: 393, Loss: 1.645350456237793\n",
      "Epoch: 3, Batch: 394, Loss: 2.203500270843506\n",
      "Epoch: 3, Batch: 395, Loss: 1.909052848815918\n",
      "Epoch: 3, Batch: 396, Loss: 1.27471923828125\n",
      "Epoch: 3, Batch: 397, Loss: 1.5530219078063965\n",
      "Epoch: 3, Batch: 398, Loss: 1.709812879562378\n",
      "Epoch: 3, Batch: 399, Loss: 0.7007636427879333\n",
      "Epoch: 3, Batch: 400, Loss: 2.690537929534912\n",
      "Epoch: 3, Batch: 401, Loss: 0.688591718673706\n",
      "Epoch: 3, Batch: 402, Loss: 1.4807460308074951\n",
      "Epoch: 3, Batch: 403, Loss: 1.853630542755127\n",
      "Epoch: 3, Batch: 404, Loss: 0.9628857374191284\n",
      "Epoch: 3, Batch: 405, Loss: 1.294491171836853\n",
      "Epoch: 3, Batch: 406, Loss: 1.8519208431243896\n",
      "Epoch: 3, Batch: 407, Loss: 2.9321184158325195\n",
      "Epoch: 3, Batch: 408, Loss: 2.8818840980529785\n",
      "Epoch: 3, Batch: 409, Loss: 0.9407808780670166\n",
      "Epoch: 3, Batch: 410, Loss: 3.322301149368286\n",
      "Epoch: 3, Batch: 411, Loss: 1.9033297300338745\n",
      "Epoch: 3, Batch: 412, Loss: 1.5614019632339478\n",
      "Epoch: 3, Batch: 413, Loss: 1.5791925191879272\n",
      "Epoch: 3, Batch: 414, Loss: 3.584070920944214\n",
      "Epoch: 3, Batch: 415, Loss: 1.5356581211090088\n",
      "Epoch: 3, Batch: 416, Loss: 2.1740143299102783\n",
      "Epoch: 3, Batch: 417, Loss: 2.711648464202881\n",
      "Epoch: 3, Batch: 418, Loss: 1.8008837699890137\n",
      "Epoch: 3, Batch: 419, Loss: 3.0364997386932373\n",
      "Epoch: 3, Batch: 420, Loss: 1.2986536026000977\n",
      "Epoch: 3, Batch: 421, Loss: 1.6691523790359497\n",
      "Epoch: 3, Batch: 422, Loss: 1.0434272289276123\n",
      "Epoch: 3, Batch: 423, Loss: 0.9440677165985107\n",
      "Epoch: 3, Batch: 424, Loss: 0.7975002527236938\n",
      "Epoch: 3, Batch: 425, Loss: 0.942270040512085\n",
      "Epoch: 3, Batch: 426, Loss: 2.804183006286621\n",
      "Epoch: 3, Batch: 427, Loss: 4.609740257263184\n",
      "Epoch: 3, Batch: 428, Loss: 1.0456931591033936\n",
      "Epoch: 3, Batch: 429, Loss: 1.506270408630371\n",
      "Epoch: 3, Batch: 430, Loss: 1.0192240476608276\n",
      "Epoch: 3, Batch: 431, Loss: 2.5896472930908203\n",
      "Epoch: 3, Batch: 432, Loss: 1.4881160259246826\n",
      "Epoch: 3, Batch: 433, Loss: 2.4366726875305176\n",
      "Epoch: 3, Batch: 434, Loss: 2.7120728492736816\n",
      "Epoch: 3, Batch: 435, Loss: 2.101686716079712\n",
      "Epoch: 3, Batch: 436, Loss: 2.1573429107666016\n",
      "Epoch: 3, Batch: 437, Loss: 1.8235435485839844\n",
      "Epoch: 3, Batch: 438, Loss: 1.0875353813171387\n",
      "Epoch: 3, Batch: 439, Loss: 2.624077558517456\n",
      "Epoch: 3, Batch: 440, Loss: 2.0400915145874023\n",
      "Epoch: 3, Batch: 441, Loss: 1.5081454515457153\n",
      "Epoch: 3, Batch: 442, Loss: 0.8158988356590271\n",
      "Epoch: 3, Batch: 443, Loss: 3.291090726852417\n",
      "Epoch: 3, Batch: 444, Loss: 2.2338268756866455\n",
      "Epoch: 3, Batch: 445, Loss: 1.852339267730713\n",
      "Epoch: 3, Batch: 446, Loss: 1.1477108001708984\n",
      "Epoch: 3, Batch: 447, Loss: 0.9915162324905396\n",
      "Epoch: 3, Batch: 448, Loss: 0.4126288890838623\n",
      "Epoch: 3, Batch: 449, Loss: 4.152095794677734\n",
      "Epoch: 3, Batch: 450, Loss: 0.2549110949039459\n",
      "Epoch: 3, Batch: 451, Loss: 2.6354997158050537\n",
      "Epoch: 3, Batch: 452, Loss: 0.27604883909225464\n",
      "Epoch: 3, Batch: 453, Loss: 2.5866539478302\n",
      "Epoch: 3, Batch: 454, Loss: 2.135688066482544\n",
      "Epoch: 3, Batch: 455, Loss: 2.0770697593688965\n",
      "Epoch: 3, Batch: 456, Loss: 2.48004412651062\n",
      "Epoch: 3, Batch: 457, Loss: 2.140070676803589\n",
      "Epoch: 3, Batch: 458, Loss: 2.1707568168640137\n",
      "Epoch: 3, Batch: 459, Loss: 1.456996202468872\n",
      "Epoch: 3, Batch: 460, Loss: 1.8373394012451172\n",
      "Epoch: 3, Batch: 461, Loss: 1.0086450576782227\n",
      "Epoch: 3, Batch: 462, Loss: 2.429013252258301\n",
      "Epoch: 3, Batch: 463, Loss: 2.752257823944092\n",
      "Epoch: 3, Batch: 464, Loss: 0.5721999406814575\n",
      "Epoch: 3, Batch: 465, Loss: 3.171250581741333\n",
      "Epoch: 3, Batch: 466, Loss: 2.5087976455688477\n",
      "Epoch: 3, Batch: 467, Loss: 2.172396183013916\n",
      "Epoch: 3, Batch: 468, Loss: 1.2810108661651611\n",
      "Epoch: 3, Batch: 469, Loss: 3.2144899368286133\n",
      "Epoch: 3, Batch: 470, Loss: 2.9131317138671875\n",
      "Epoch: 3, Batch: 471, Loss: 1.2954742908477783\n",
      "Epoch: 3, Batch: 472, Loss: 0.7821372747421265\n",
      "Epoch: 3, Batch: 473, Loss: 3.414762020111084\n",
      "Epoch: 3, Batch: 474, Loss: 4.032569885253906\n",
      "Epoch: 3, Batch: 475, Loss: 1.981634259223938\n",
      "Epoch: 3, Batch: 476, Loss: 2.076056480407715\n",
      "Epoch: 3, Batch: 477, Loss: 2.44271183013916\n",
      "Epoch: 3, Batch: 478, Loss: 0.5157274603843689\n",
      "Epoch: 3, Batch: 479, Loss: 2.167598247528076\n",
      "Epoch: 3, Batch: 480, Loss: 0.1602901816368103\n",
      "Epoch: 3, Batch: 481, Loss: 1.4982973337173462\n",
      "Epoch: 3, Batch: 482, Loss: 2.193645477294922\n",
      "Epoch: 3, Batch: 483, Loss: 3.1562883853912354\n",
      "Epoch: 3, Batch: 484, Loss: 1.2880287170410156\n",
      "Epoch: 3, Batch: 485, Loss: 1.9732723236083984\n",
      "Epoch: 3, Batch: 486, Loss: 0.9357426166534424\n",
      "Epoch: 3, Batch: 487, Loss: 0.19334501028060913\n",
      "Epoch: 3, Batch: 488, Loss: 1.7893118858337402\n",
      "Epoch: 3, Batch: 489, Loss: 2.9758388996124268\n",
      "Epoch: 3, Batch: 490, Loss: 0.5167288780212402\n",
      "Epoch: 3, Batch: 491, Loss: 2.76239275932312\n",
      "Epoch: 3, Batch: 492, Loss: 2.0814733505249023\n",
      "Epoch: 3, Batch: 493, Loss: 1.3685345649719238\n",
      "Epoch: 3, Batch: 494, Loss: 3.6105198860168457\n",
      "Epoch: 3, Batch: 495, Loss: 2.912773609161377\n",
      "Epoch: 3, Batch: 496, Loss: 0.8292624950408936\n",
      "Epoch: 3, Batch: 497, Loss: 0.8122082352638245\n",
      "Epoch: 3, Batch: 498, Loss: 1.73636794090271\n",
      "Epoch: 3, Batch: 499, Loss: 0.4215579032897949\n",
      "Epoch: 3, Batch: 500, Loss: 0.8928465843200684\n",
      "Epoch: 3, Batch: 501, Loss: 2.884687900543213\n",
      "Epoch: 3, Batch: 502, Loss: 2.2398316860198975\n",
      "Epoch: 3, Batch: 503, Loss: 2.8850927352905273\n",
      "Epoch: 3, Batch: 504, Loss: 1.1642245054244995\n",
      "Epoch: 3, Batch: 505, Loss: 1.958678126335144\n",
      "Epoch: 3, Batch: 506, Loss: 0.5893235802650452\n",
      "Epoch: 3, Batch: 507, Loss: 0.7021299600601196\n",
      "Epoch: 3, Batch: 508, Loss: 3.2205452919006348\n",
      "Epoch: 3, Batch: 509, Loss: 3.1529552936553955\n",
      "Epoch: 3, Batch: 510, Loss: 3.4056222438812256\n",
      "Epoch: 3, Batch: 511, Loss: 1.5230755805969238\n",
      "Epoch: 3, Batch: 512, Loss: 1.0949419736862183\n",
      "Epoch: 3, Batch: 513, Loss: 1.8351304531097412\n",
      "Epoch: 3, Batch: 514, Loss: 3.049280881881714\n",
      "Epoch: 3, Batch: 515, Loss: 0.6267372369766235\n",
      "Epoch: 3, Batch: 516, Loss: 2.9712483882904053\n",
      "Epoch: 3, Batch: 517, Loss: 1.5764631032943726\n",
      "Epoch: 3, Batch: 518, Loss: 1.162362813949585\n",
      "Epoch: 3, Batch: 519, Loss: 1.1703389883041382\n",
      "Epoch: 3, Batch: 520, Loss: 1.3781009912490845\n",
      "Epoch: 3, Batch: 521, Loss: 2.5478432178497314\n",
      "Epoch: 3, Batch: 522, Loss: 1.8112062215805054\n",
      "Epoch: 3, Batch: 523, Loss: 2.751516819000244\n",
      "Epoch: 3, Batch: 524, Loss: 4.492866516113281\n",
      "Epoch: 3, Batch: 525, Loss: 2.821223020553589\n",
      "Epoch: 3, Batch: 526, Loss: 1.2493526935577393\n",
      "Epoch: 3, Batch: 527, Loss: 1.7308096885681152\n",
      "Epoch: 3, Batch: 528, Loss: 0.6087716221809387\n",
      "Epoch: 3, Batch: 529, Loss: 4.589127063751221\n",
      "Epoch: 3, Batch: 530, Loss: 2.2452635765075684\n",
      "Epoch: 3, Batch: 531, Loss: 1.1278339624404907\n",
      "Epoch: 3, Batch: 532, Loss: 2.3322556018829346\n",
      "Epoch: 3, Batch: 533, Loss: 0.5009573101997375\n",
      "Epoch: 3, Batch: 534, Loss: 3.700496196746826\n",
      "Epoch: 3, Batch: 535, Loss: 2.4664783477783203\n",
      "Epoch: 3, Batch: 536, Loss: 1.9310804605484009\n",
      "Epoch: 3, Batch: 537, Loss: 1.7802482843399048\n",
      "Epoch: 3, Batch: 538, Loss: 2.029277801513672\n",
      "Epoch: 3, Batch: 539, Loss: 1.6639050245285034\n",
      "Epoch: 3, Batch: 540, Loss: 5.859859466552734\n",
      "Epoch: 3, Batch: 541, Loss: 0.36319684982299805\n",
      "Epoch: 3, Batch: 542, Loss: 2.1160035133361816\n",
      "Epoch: 3, Batch: 543, Loss: 3.692908525466919\n",
      "Epoch: 3, Batch: 544, Loss: 2.8166160583496094\n",
      "Epoch: 3, Batch: 545, Loss: 4.497786521911621\n",
      "Epoch: 3, Batch: 546, Loss: 3.443655490875244\n",
      "Epoch: 3, Batch: 547, Loss: 0.4206576943397522\n",
      "Epoch: 3, Batch: 548, Loss: 2.132842540740967\n",
      "Epoch: 3, Batch: 549, Loss: 1.9009945392608643\n",
      "Epoch: 3, Batch: 550, Loss: 3.7921957969665527\n",
      "Epoch: 3, Batch: 551, Loss: 1.9666566848754883\n",
      "Epoch: 3, Batch: 552, Loss: 0.6313608884811401\n",
      "Epoch: 3, Batch: 553, Loss: 0.10769467055797577\n",
      "Epoch: 3, Batch: 554, Loss: 2.1233737468719482\n",
      "Epoch: 3, Batch: 555, Loss: 2.38747239112854\n",
      "Epoch: 3, Batch: 556, Loss: 3.5944411754608154\n",
      "Epoch: 3, Batch: 557, Loss: 3.0688114166259766\n",
      "Epoch: 3, Batch: 558, Loss: 2.4807374477386475\n",
      "Epoch: 3, Batch: 559, Loss: 2.3228840827941895\n",
      "Epoch: 3, Batch: 560, Loss: 2.2143731117248535\n",
      "Epoch: 3, Batch: 561, Loss: 3.660360813140869\n",
      "Epoch: 3, Batch: 562, Loss: 0.4997655153274536\n",
      "Epoch: 3, Batch: 563, Loss: 2.690187454223633\n",
      "Epoch: 3, Batch: 564, Loss: 1.810291051864624\n",
      "Epoch: 3, Batch: 565, Loss: 1.2570443153381348\n",
      "Epoch: 3, Batch: 566, Loss: 2.209925413131714\n",
      "Epoch: 3, Batch: 567, Loss: 1.085950493812561\n",
      "Epoch: 3, Batch: 568, Loss: 2.434176445007324\n",
      "Epoch: 3, Batch: 569, Loss: 1.0603954792022705\n",
      "Epoch: 3, Batch: 570, Loss: 3.415858030319214\n",
      "Epoch: 3, Batch: 571, Loss: 3.1575112342834473\n",
      "Epoch: 3, Batch: 572, Loss: 1.6576404571533203\n",
      "Epoch: 3, Batch: 573, Loss: 0.10263996571302414\n",
      "Epoch: 3, Batch: 574, Loss: 1.7608628273010254\n",
      "Epoch: 3, Batch: 575, Loss: 2.631960153579712\n",
      "Epoch: 3, Batch: 576, Loss: 1.113346815109253\n",
      "Epoch: 3, Batch: 577, Loss: 4.913849830627441\n",
      "Epoch: 3, Batch: 578, Loss: 1.5730783939361572\n",
      "Epoch: 3, Batch: 579, Loss: 4.111913681030273\n",
      "Epoch: 3, Batch: 580, Loss: 2.8994388580322266\n",
      "Epoch: 3, Batch: 581, Loss: 0.7236961126327515\n",
      "Epoch: 3, Batch: 582, Loss: 2.9389140605926514\n",
      "Epoch: 3, Batch: 583, Loss: 0.9225254058837891\n",
      "Epoch: 3, Batch: 584, Loss: 1.307375192642212\n",
      "Epoch: 3, Batch: 585, Loss: 0.46096840500831604\n",
      "Epoch: 3, Batch: 586, Loss: 2.496493101119995\n",
      "Epoch: 3, Batch: 587, Loss: 4.995152473449707\n",
      "Epoch: 3, Batch: 588, Loss: 1.5805308818817139\n",
      "Epoch: 3, Batch: 589, Loss: 1.1582787036895752\n",
      "Epoch: 3, Batch: 590, Loss: 1.6849355697631836\n",
      "Epoch: 3, Batch: 591, Loss: 2.5566723346710205\n",
      "Epoch: 3, Batch: 592, Loss: 2.717160701751709\n",
      "Epoch: 3, Batch: 593, Loss: 1.066209077835083\n",
      "Epoch: 3, Batch: 594, Loss: 0.8559794425964355\n",
      "Epoch: 3, Batch: 595, Loss: 2.2374305725097656\n",
      "Epoch: 3, Batch: 596, Loss: 3.047527551651001\n",
      "Epoch: 3, Batch: 597, Loss: 2.15909481048584\n",
      "Epoch: 3, Batch: 598, Loss: 2.065772771835327\n",
      "Epoch: 3, Batch: 599, Loss: 0.9581421613693237\n",
      "Epoch: 3, Batch: 600, Loss: 1.6149625778198242\n",
      "Epoch: 3, Batch: 601, Loss: 1.8686652183532715\n",
      "Epoch: 3, Batch: 602, Loss: 3.1384034156799316\n",
      "Epoch: 3, Batch: 603, Loss: 0.7214595675468445\n",
      "Epoch: 3, Batch: 604, Loss: 2.801767349243164\n",
      "Epoch: 3, Batch: 605, Loss: 1.9085465669631958\n",
      "Epoch: 3, Batch: 606, Loss: 0.6369404792785645\n",
      "Epoch: 3, Batch: 607, Loss: 2.060760736465454\n",
      "Epoch: 3, Batch: 608, Loss: 2.705538749694824\n",
      "Epoch: 3, Batch: 609, Loss: 2.4537737369537354\n",
      "Epoch: 3, Batch: 610, Loss: 2.886962890625\n",
      "Epoch: 3, Batch: 611, Loss: 1.9846956729888916\n",
      "Epoch: 3, Batch: 612, Loss: 0.9637651443481445\n",
      "Epoch: 3, Batch: 613, Loss: 0.7262836694717407\n",
      "Epoch: 3, Batch: 614, Loss: 0.3828377425670624\n",
      "Epoch: 3, Batch: 615, Loss: 2.9374406337738037\n",
      "Epoch: 3, Batch: 616, Loss: 0.8635551333427429\n",
      "Epoch: 3, Batch: 617, Loss: 1.1856889724731445\n",
      "Epoch: 3, Batch: 618, Loss: 2.0152781009674072\n",
      "Epoch: 3, Batch: 619, Loss: 1.136508584022522\n",
      "Epoch: 3, Batch: 620, Loss: 2.01287841796875\n",
      "Epoch: 3, Batch: 621, Loss: 2.1166341304779053\n",
      "Epoch: 3, Batch: 622, Loss: 1.5250104665756226\n",
      "Epoch: 3, Batch: 623, Loss: 1.7686748504638672\n",
      "Epoch: 3, Batch: 624, Loss: 2.2033088207244873\n",
      "Epoch: 3, Batch: 625, Loss: 2.9156432151794434\n",
      "Epoch: 3, Batch: 626, Loss: 0.7757202386856079\n",
      "Epoch: 3, Batch: 627, Loss: 5.392704010009766\n",
      "Epoch: 3, Batch: 628, Loss: 2.0480244159698486\n",
      "Epoch: 3, Batch: 629, Loss: 0.4427688717842102\n",
      "Epoch: 3, Batch: 630, Loss: 0.5201542377471924\n",
      "Epoch: 3, Batch: 631, Loss: 2.8957531452178955\n",
      "Epoch: 3, Batch: 632, Loss: 2.5479252338409424\n",
      "Epoch: 3, Batch: 633, Loss: 1.9301047325134277\n",
      "Epoch: 3, Batch: 634, Loss: 0.78023362159729\n",
      "Epoch: 3, Batch: 635, Loss: 4.5776872634887695\n",
      "Epoch: 3, Batch: 636, Loss: 2.0593957901000977\n",
      "Epoch: 3, Batch: 637, Loss: 2.780766248703003\n",
      "Epoch: 3, Batch: 638, Loss: 2.4936418533325195\n",
      "Epoch: 3, Batch: 639, Loss: 0.3008081614971161\n",
      "Epoch: 3, Batch: 640, Loss: 0.02041173353791237\n",
      "Epoch: 3, Batch: 641, Loss: 1.9390146732330322\n",
      "Epoch: 3, Batch: 642, Loss: 0.8387616872787476\n",
      "Epoch: 3, Batch: 643, Loss: 3.402029514312744\n",
      "Epoch: 3, Batch: 644, Loss: 2.220227003097534\n",
      "Epoch: 3, Batch: 645, Loss: 3.0347940921783447\n",
      "Epoch: 3, Batch: 646, Loss: 5.429636478424072\n",
      "Epoch: 3, Batch: 647, Loss: 2.253614664077759\n",
      "Epoch: 3, Batch: 648, Loss: 1.7374796867370605\n",
      "Epoch: 3, Batch: 649, Loss: 1.9865070581436157\n",
      "Epoch: 3, Batch: 650, Loss: 3.453082799911499\n",
      "Epoch: 3, Batch: 651, Loss: 3.19270658493042\n",
      "Epoch: 3, Batch: 652, Loss: 5.485757350921631\n",
      "Epoch: 3, Batch: 653, Loss: 2.060865640640259\n",
      "Epoch: 3, Batch: 654, Loss: 3.649920701980591\n",
      "Epoch: 3, Batch: 655, Loss: 0.7715109586715698\n",
      "Epoch: 3, Batch: 656, Loss: 3.434725284576416\n",
      "Epoch: 3, Batch: 657, Loss: 0.21553955972194672\n",
      "Epoch: 3, Batch: 658, Loss: 1.8943195343017578\n",
      "Epoch: 3, Batch: 659, Loss: 5.328571319580078\n",
      "Epoch: 3, Batch: 660, Loss: 4.348728656768799\n",
      "Epoch: 3, Batch: 661, Loss: 0.8941206932067871\n",
      "Epoch: 3, Batch: 662, Loss: 0.5642907023429871\n",
      "Epoch: 3, Batch: 663, Loss: 2.824110746383667\n",
      "Epoch: 3, Batch: 664, Loss: 3.534416913986206\n",
      "Epoch: 3, Batch: 665, Loss: 3.673999309539795\n",
      "Epoch: 3, Batch: 666, Loss: 0.34179502725601196\n",
      "Epoch: 3, Batch: 667, Loss: 3.073394775390625\n",
      "Epoch: 3, Batch: 668, Loss: 3.394774913787842\n",
      "Epoch: 3, Batch: 669, Loss: 2.442678213119507\n",
      "Epoch: 3, Batch: 670, Loss: 5.856143951416016\n",
      "Epoch: 3, Batch: 671, Loss: 2.6813836097717285\n",
      "Epoch: 3, Batch: 672, Loss: 2.011167526245117\n",
      "Epoch: 3, Batch: 673, Loss: 1.4411511421203613\n",
      "Epoch: 3, Batch: 674, Loss: 1.7956042289733887\n",
      "Epoch: 3, Batch: 675, Loss: 0.5108639597892761\n",
      "Epoch: 3, Batch: 676, Loss: 1.5866031646728516\n",
      "Epoch: 3, Batch: 677, Loss: 3.0539186000823975\n",
      "Epoch: 3, Batch: 678, Loss: 1.5247211456298828\n",
      "Epoch: 3, Batch: 679, Loss: 2.125473976135254\n",
      "Epoch: 3, Batch: 680, Loss: 1.9739265441894531\n",
      "Epoch: 3, Batch: 681, Loss: 1.4694809913635254\n",
      "Epoch: 3, Batch: 682, Loss: 2.55587100982666\n",
      "Epoch: 3, Batch: 683, Loss: 0.9974488615989685\n",
      "Epoch: 3, Batch: 684, Loss: 1.0353422164916992\n",
      "Epoch: 3, Batch: 685, Loss: 1.0559933185577393\n",
      "Epoch: 3, Batch: 686, Loss: 3.4071013927459717\n",
      "Epoch: 3, Batch: 687, Loss: 1.798964500427246\n",
      "Epoch: 3, Batch: 688, Loss: 2.2968733310699463\n",
      "Epoch: 3, Batch: 689, Loss: 1.6819710731506348\n",
      "Epoch: 3, Batch: 690, Loss: 4.043137073516846\n",
      "Epoch: 3, Batch: 691, Loss: 1.4763026237487793\n",
      "Epoch: 3, Batch: 692, Loss: 0.1336010992527008\n",
      "Epoch: 3, Batch: 693, Loss: 1.1526803970336914\n",
      "Epoch: 3, Batch: 694, Loss: 0.6566272377967834\n",
      "Epoch: 3, Batch: 695, Loss: 1.7332134246826172\n",
      "Epoch: 3, Batch: 696, Loss: 3.040645122528076\n",
      "Epoch: 3, Batch: 697, Loss: 0.9447704553604126\n",
      "Epoch: 3, Batch: 698, Loss: 1.6966326236724854\n",
      "Epoch: 3, Batch: 699, Loss: 0.3953205645084381\n",
      "Epoch: 3, Batch: 700, Loss: 4.397121429443359\n",
      "Epoch: 3, Batch: 701, Loss: 3.707172393798828\n",
      "Epoch: 3, Batch: 702, Loss: 2.24525785446167\n",
      "Epoch: 3, Batch: 703, Loss: 0.052263662219047546\n",
      "Epoch: 3, Batch: 704, Loss: 4.5732421875\n",
      "Epoch: 3, Batch: 705, Loss: 0.1518242210149765\n",
      "Epoch: 3, Batch: 706, Loss: 1.86921226978302\n",
      "Epoch: 3, Batch: 707, Loss: 1.153637170791626\n",
      "Epoch: 3, Batch: 708, Loss: 1.2231627702713013\n",
      "Epoch: 3, Batch: 709, Loss: 6.785065650939941\n",
      "Epoch: 3, Batch: 710, Loss: 0.8162394762039185\n",
      "Epoch: 3, Batch: 711, Loss: 1.1340835094451904\n",
      "Epoch: 3, Batch: 712, Loss: 0.34452390670776367\n",
      "Epoch: 3, Batch: 713, Loss: 1.1896570920944214\n",
      "Epoch: 3, Batch: 714, Loss: 2.0367813110351562\n",
      "Epoch: 3, Batch: 715, Loss: 0.8789979815483093\n",
      "Epoch: 3, Batch: 716, Loss: 4.165032863616943\n",
      "Epoch: 3, Batch: 717, Loss: 1.4857813119888306\n",
      "Epoch: 3, Batch: 718, Loss: 2.62442946434021\n",
      "Epoch: 3, Batch: 719, Loss: 1.671304702758789\n",
      "Epoch: 3, Batch: 720, Loss: 1.345005989074707\n",
      "Epoch: 3, Batch: 721, Loss: 2.1723811626434326\n",
      "Epoch: 3, Batch: 722, Loss: 0.925792932510376\n",
      "Epoch: 3, Batch: 723, Loss: 2.3653154373168945\n",
      "Epoch: 3, Batch: 724, Loss: 2.0104551315307617\n",
      "Epoch: 3, Batch: 725, Loss: 0.872184693813324\n",
      "Epoch: 3, Batch: 726, Loss: 1.9700062274932861\n",
      "Epoch: 3, Batch: 727, Loss: 2.7151219844818115\n",
      "Epoch: 3, Batch: 728, Loss: 1.6479307413101196\n",
      "Epoch: 3, Batch: 729, Loss: 0.6533231139183044\n",
      "Epoch: 3, Batch: 730, Loss: 1.234798550605774\n",
      "Epoch: 3, Batch: 731, Loss: 3.635870933532715\n",
      "Epoch: 3, Batch: 732, Loss: 0.8136565685272217\n",
      "Epoch: 3, Batch: 733, Loss: 2.1852447986602783\n",
      "Epoch: 3, Batch: 734, Loss: 3.725788116455078\n",
      "Epoch: 3, Batch: 735, Loss: 0.03804048150777817\n",
      "Epoch: 3, Batch: 736, Loss: 1.251989483833313\n",
      "Epoch: 3, Batch: 737, Loss: 1.7552900314331055\n",
      "Epoch: 3, Batch: 738, Loss: 0.8049089908599854\n",
      "Epoch: 3, Batch: 739, Loss: 1.2852811813354492\n",
      "Epoch: 3, Batch: 740, Loss: 0.6107378005981445\n",
      "Epoch: 3, Batch: 741, Loss: 1.0539014339447021\n",
      "Epoch: 3, Batch: 742, Loss: 0.31568339467048645\n",
      "Epoch: 3, Batch: 743, Loss: 1.7217472791671753\n",
      "Epoch: 3, Batch: 744, Loss: 2.1681745052337646\n",
      "Epoch: 3, Batch: 745, Loss: 1.7634583711624146\n",
      "Epoch: 3, Batch: 746, Loss: 0.6193287968635559\n",
      "Epoch: 3, Batch: 747, Loss: 2.963540554046631\n",
      "Epoch: 3, Batch: 748, Loss: 3.1867592334747314\n",
      "Epoch: 3, Batch: 749, Loss: 2.595266580581665\n",
      "Epoch: 3, Batch: 750, Loss: 2.70159912109375\n",
      "Epoch: 3, Batch: 751, Loss: 1.6562551259994507\n",
      "Epoch: 3, Batch: 752, Loss: 0.9710099697113037\n",
      "Epoch: 3, Batch: 753, Loss: 0.2881268560886383\n",
      "Epoch: 3, Batch: 754, Loss: 2.1652705669403076\n",
      "Epoch: 3, Batch: 755, Loss: 0.8452788591384888\n",
      "Epoch: 3, Batch: 756, Loss: 3.5573232173919678\n",
      "Epoch: 3, Batch: 757, Loss: 1.9063022136688232\n",
      "Epoch: 3, Batch: 758, Loss: 1.5479726791381836\n",
      "Epoch: 3, Batch: 759, Loss: 4.2556891441345215\n",
      "Epoch: 3, Batch: 760, Loss: 3.033834934234619\n",
      "Epoch: 3, Batch: 761, Loss: 0.6998921632766724\n",
      "Epoch: 3, Batch: 762, Loss: 1.156404972076416\n",
      "Epoch: 3, Batch: 763, Loss: 2.7223877906799316\n",
      "Epoch: 3, Batch: 764, Loss: 3.357874870300293\n",
      "Epoch: 3, Batch: 765, Loss: 2.5292303562164307\n",
      "Epoch: 3, Batch: 766, Loss: 1.5034892559051514\n",
      "Epoch: 3, Batch: 767, Loss: 1.2038421630859375\n",
      "Epoch: 3, Batch: 768, Loss: 1.2530626058578491\n",
      "Epoch: 3, Batch: 769, Loss: 2.153174638748169\n",
      "Epoch: 3, Batch: 770, Loss: 1.3411734104156494\n",
      "Epoch: 3, Batch: 771, Loss: 3.062880754470825\n",
      "Epoch: 3, Batch: 772, Loss: 1.1282423734664917\n",
      "Epoch: 3, Batch: 773, Loss: 1.6931540966033936\n",
      "Epoch: 3, Batch: 774, Loss: 3.9983983039855957\n",
      "Epoch: 3, Batch: 775, Loss: 1.350325345993042\n",
      "Epoch: 3, Batch: 776, Loss: 2.040316343307495\n",
      "Epoch: 3, Batch: 777, Loss: 0.45582515001296997\n",
      "Epoch: 3, Batch: 778, Loss: 1.7645552158355713\n",
      "Epoch: 3, Batch: 779, Loss: 1.5121753215789795\n",
      "Epoch: 3, Batch: 780, Loss: 1.0349787473678589\n",
      "Epoch: 3, Batch: 781, Loss: 4.613993167877197\n",
      "Epoch: 3, Batch: 782, Loss: 3.1275084018707275\n",
      "Epoch: 3, Batch: 783, Loss: 1.517196774482727\n",
      "Epoch: 3, Batch: 784, Loss: 0.5535837411880493\n",
      "Epoch: 3, Batch: 785, Loss: 0.7465075254440308\n",
      "Epoch: 3, Batch: 786, Loss: 0.23240283131599426\n",
      "Epoch: 3, Batch: 787, Loss: 2.8789703845977783\n",
      "Epoch: 3, Batch: 788, Loss: 2.801365375518799\n",
      "Epoch: 3, Batch: 789, Loss: 1.2201588153839111\n",
      "Epoch: 3, Batch: 790, Loss: 2.4162168502807617\n",
      "Epoch: 3, Batch: 791, Loss: 1.0575170516967773\n",
      "Epoch: 3, Batch: 792, Loss: 1.4021942615509033\n",
      "Epoch: 3, Batch: 793, Loss: 2.540884017944336\n",
      "Epoch: 3, Batch: 794, Loss: 1.9873563051223755\n",
      "Epoch: 3, Batch: 795, Loss: 1.8517614603042603\n",
      "Epoch: 3, Batch: 796, Loss: 3.507295608520508\n",
      "Epoch: 3, Batch: 797, Loss: 0.9193663597106934\n",
      "Epoch: 3, Batch: 798, Loss: 3.3190364837646484\n",
      "Epoch: 3, Batch: 799, Loss: 1.7870770692825317\n",
      "Epoch: 3, Batch: 800, Loss: 3.76535964012146\n",
      "Epoch: 3, Batch: 801, Loss: 4.244055271148682\n",
      "Epoch: 3, Batch: 802, Loss: 1.8416613340377808\n",
      "Epoch: 3, Batch: 803, Loss: 1.7760109901428223\n",
      "Epoch: 3, Batch: 804, Loss: 1.3019098043441772\n",
      "Epoch: 3, Batch: 805, Loss: 2.4886929988861084\n",
      "Epoch: 3, Batch: 806, Loss: 0.9783844351768494\n",
      "Epoch: 3, Batch: 807, Loss: 1.602612853050232\n",
      "Epoch: 3, Batch: 808, Loss: 3.4769492149353027\n",
      "Epoch: 3, Batch: 809, Loss: 3.6353461742401123\n",
      "Epoch: 3, Batch: 810, Loss: 1.620356559753418\n",
      "Epoch: 3, Batch: 811, Loss: 1.6229020357131958\n",
      "Epoch: 3, Batch: 812, Loss: 0.8281954526901245\n",
      "Epoch: 3, Batch: 813, Loss: 1.3711951971054077\n",
      "Epoch: 3, Batch: 814, Loss: 0.8834791779518127\n",
      "Epoch: 3, Batch: 815, Loss: 4.11025333404541\n",
      "Epoch: 3, Batch: 816, Loss: 2.0451571941375732\n",
      "Epoch: 3, Batch: 817, Loss: 0.44739219546318054\n",
      "Epoch: 3, Batch: 818, Loss: 1.275984287261963\n",
      "Epoch: 3, Batch: 819, Loss: 7.368391990661621\n",
      "Epoch: 3, Batch: 820, Loss: 2.5643081665039062\n",
      "Epoch: 3, Batch: 821, Loss: 2.4666061401367188\n",
      "Epoch: 3, Batch: 822, Loss: 1.013819694519043\n",
      "Epoch: 3, Batch: 823, Loss: 3.5785977840423584\n",
      "Epoch: 3, Batch: 824, Loss: 1.0832018852233887\n",
      "Epoch: 3, Batch: 825, Loss: 0.5150895118713379\n",
      "Epoch: 3, Batch: 826, Loss: 3.7973275184631348\n",
      "Epoch: 3, Batch: 827, Loss: 1.0961912870407104\n",
      "Epoch: 3, Batch: 828, Loss: 1.41841721534729\n",
      "Epoch: 3, Batch: 829, Loss: 2.4821863174438477\n",
      "Epoch: 3, Batch: 830, Loss: 2.0924644470214844\n",
      "Epoch: 3, Batch: 831, Loss: 2.8887529373168945\n",
      "Epoch: 3, Batch: 832, Loss: 2.617854595184326\n",
      "Epoch: 3, Batch: 833, Loss: 3.482450008392334\n",
      "Epoch: 3, Batch: 834, Loss: 0.9582312703132629\n",
      "Epoch: 3, Batch: 835, Loss: 3.530386209487915\n",
      "Epoch: 3, Batch: 836, Loss: 0.4270222783088684\n",
      "Epoch: 3, Batch: 837, Loss: 0.281450480222702\n",
      "Epoch: 3, Batch: 838, Loss: 0.8496360182762146\n",
      "Epoch: 3, Batch: 839, Loss: 1.3826147317886353\n",
      "Epoch: 3, Batch: 840, Loss: 2.7574667930603027\n",
      "Epoch: 3, Batch: 841, Loss: 2.247485876083374\n",
      "Epoch: 3, Batch: 842, Loss: 2.124016523361206\n",
      "Epoch: 3, Batch: 843, Loss: 1.627941608428955\n",
      "Epoch: 3, Batch: 844, Loss: 1.5234007835388184\n",
      "Epoch: 3, Batch: 845, Loss: 2.2513866424560547\n",
      "Epoch: 3, Batch: 846, Loss: 1.667823076248169\n",
      "Epoch: 3, Batch: 847, Loss: 2.2455904483795166\n",
      "Epoch: 3, Batch: 848, Loss: 0.6175644397735596\n",
      "Epoch: 3, Batch: 849, Loss: 0.11451773345470428\n",
      "Epoch: 3, Batch: 850, Loss: 1.250112533569336\n",
      "Epoch: 3, Batch: 851, Loss: 1.3242039680480957\n",
      "Epoch: 3, Batch: 852, Loss: 3.4627277851104736\n",
      "Epoch: 3, Batch: 853, Loss: 1.2598884105682373\n",
      "Epoch: 3, Batch: 854, Loss: 1.8000699281692505\n",
      "Epoch: 3, Batch: 855, Loss: 1.051164984703064\n",
      "Epoch: 3, Batch: 856, Loss: 1.5371190309524536\n",
      "Epoch: 3, Batch: 857, Loss: 2.2405409812927246\n",
      "Epoch: 3, Batch: 858, Loss: 3.132028818130493\n",
      "Epoch: 3, Batch: 859, Loss: 1.6823275089263916\n",
      "Epoch: 3, Batch: 860, Loss: 2.7547202110290527\n",
      "Epoch: 3, Batch: 861, Loss: 2.20339298248291\n",
      "Epoch: 3, Batch: 862, Loss: 2.3112385272979736\n",
      "Epoch: 3, Batch: 863, Loss: 0.3806924521923065\n",
      "Epoch: 3, Batch: 864, Loss: 1.810508131980896\n",
      "Epoch: 3, Batch: 865, Loss: 0.3394154906272888\n",
      "Epoch: 3, Batch: 866, Loss: 1.673628568649292\n",
      "Epoch: 3, Batch: 867, Loss: 2.6719064712524414\n",
      "Epoch: 3, Batch: 868, Loss: 0.874518632888794\n",
      "Epoch: 3, Batch: 869, Loss: 0.8431285619735718\n",
      "Epoch: 3, Batch: 870, Loss: 3.5060529708862305\n",
      "Epoch: 3, Batch: 871, Loss: 1.5918686389923096\n",
      "Epoch: 3, Batch: 872, Loss: 2.203190803527832\n",
      "Epoch: 3, Batch: 873, Loss: 1.0533661842346191\n",
      "Epoch: 3, Batch: 874, Loss: 1.9316785335540771\n",
      "Epoch: 3, Batch: 875, Loss: 3.054489850997925\n",
      "Epoch: 3, Batch: 876, Loss: 0.8541830778121948\n",
      "Epoch: 3, Batch: 877, Loss: 1.8527230024337769\n",
      "Epoch: 3, Batch: 878, Loss: 1.9649457931518555\n",
      "Epoch: 3, Batch: 879, Loss: 4.26496696472168\n",
      "Epoch: 3, Batch: 880, Loss: 0.6707577705383301\n",
      "Epoch: 3, Batch: 881, Loss: 2.079314947128296\n",
      "Epoch: 3, Batch: 882, Loss: 3.055724620819092\n",
      "Epoch: 3, Batch: 883, Loss: 1.8987114429473877\n",
      "Epoch: 3, Batch: 884, Loss: 1.680863380432129\n",
      "Epoch: 3, Batch: 885, Loss: 3.4703879356384277\n",
      "Epoch: 3, Batch: 886, Loss: 3.6965012550354004\n",
      "Epoch: 3, Batch: 887, Loss: 2.9760937690734863\n",
      "Epoch: 3, Batch: 888, Loss: 0.779827356338501\n",
      "Epoch: 3, Batch: 889, Loss: 2.537600040435791\n",
      "Epoch: 3, Batch: 890, Loss: 1.432636022567749\n",
      "Epoch: 3, Batch: 891, Loss: 2.0112147331237793\n",
      "Epoch: 3, Batch: 892, Loss: 1.9344041347503662\n",
      "Epoch: 3, Batch: 893, Loss: 0.36039969325065613\n",
      "Epoch: 3, Batch: 894, Loss: 0.8867694139480591\n",
      "Epoch: 3, Batch: 895, Loss: 1.1351025104522705\n",
      "Epoch: 3, Batch: 896, Loss: 1.725499153137207\n",
      "Epoch: 3, Batch: 897, Loss: 3.4980380535125732\n",
      "Epoch: 3, Batch: 898, Loss: 1.3188508749008179\n",
      "Epoch: 3, Batch: 899, Loss: 1.9155962467193604\n",
      "Epoch: 3, Batch: 900, Loss: 1.2356250286102295\n",
      "Epoch: 3, Batch: 901, Loss: 3.4068655967712402\n",
      "Epoch: 3, Batch: 902, Loss: 0.8541987538337708\n",
      "Epoch: 3, Batch: 903, Loss: 3.0713093280792236\n",
      "Epoch: 3, Batch: 904, Loss: 2.878572463989258\n",
      "Epoch: 3, Batch: 905, Loss: 1.5781075954437256\n",
      "Epoch: 3, Batch: 906, Loss: 2.9829885959625244\n",
      "Epoch: 3, Batch: 907, Loss: 2.289985418319702\n",
      "Epoch: 3, Batch: 908, Loss: 1.2506145238876343\n",
      "Epoch: 3, Batch: 909, Loss: 3.1852593421936035\n",
      "Epoch: 3, Batch: 910, Loss: 2.2745633125305176\n",
      "Epoch: 3, Batch: 911, Loss: 2.0799176692962646\n",
      "Epoch: 3, Batch: 912, Loss: 3.167159080505371\n",
      "Epoch: 3, Batch: 913, Loss: 2.989109516143799\n",
      "Epoch: 3, Batch: 914, Loss: 2.064329147338867\n",
      "Epoch: 3, Batch: 915, Loss: 1.6407930850982666\n",
      "Epoch: 3, Batch: 916, Loss: 1.4955869913101196\n",
      "Epoch: 3, Batch: 917, Loss: 4.959689140319824\n",
      "Epoch: 3, Batch: 918, Loss: 0.8279291987419128\n",
      "Epoch: 3, Batch: 919, Loss: 2.5048933029174805\n",
      "Epoch: 3, Batch: 920, Loss: 1.0842463970184326\n",
      "Epoch: 3, Batch: 921, Loss: 2.02175235748291\n",
      "Epoch: 3, Batch: 922, Loss: 1.9406719207763672\n",
      "Epoch: 3, Batch: 923, Loss: 1.7273491621017456\n",
      "Epoch: 3, Batch: 924, Loss: 1.5080777406692505\n",
      "Epoch: 3, Batch: 925, Loss: 1.9500545263290405\n",
      "Epoch: 3, Batch: 926, Loss: 1.1356850862503052\n",
      "Epoch: 3, Batch: 927, Loss: 1.975480556488037\n",
      "Epoch: 3, Batch: 928, Loss: 3.9733591079711914\n",
      "Epoch: 3, Batch: 929, Loss: 2.1723408699035645\n",
      "Epoch: 3, Batch: 930, Loss: 2.5282535552978516\n",
      "Epoch: 3, Batch: 931, Loss: 0.9266442656517029\n",
      "Epoch: 3, Batch: 932, Loss: 2.495333433151245\n",
      "Epoch: 3, Batch: 933, Loss: 0.5612002611160278\n",
      "Epoch: 3, Batch: 934, Loss: 0.1898707002401352\n",
      "Epoch: 3, Batch: 935, Loss: 3.2868032455444336\n",
      "Epoch: 3, Batch: 936, Loss: 2.0403943061828613\n",
      "Epoch: 3, Batch: 937, Loss: 1.638076663017273\n",
      "Epoch: 3, Batch: 938, Loss: 0.22424498200416565\n",
      "Epoch: 3, Batch: 939, Loss: 1.9194868803024292\n",
      "Epoch: 3, Batch: 940, Loss: 1.8964877128601074\n",
      "Epoch: 3, Batch: 941, Loss: 0.6048036813735962\n",
      "Epoch: 3, Batch: 942, Loss: 2.076268196105957\n",
      "Epoch: 3, Batch: 943, Loss: 1.9009809494018555\n",
      "Epoch: 3, Batch: 944, Loss: 2.2960236072540283\n",
      "Epoch: 3, Batch: 945, Loss: 0.8246035575866699\n",
      "Epoch: 3, Batch: 946, Loss: 2.651394844055176\n",
      "Epoch: 3, Batch: 947, Loss: 0.091179758310318\n",
      "Epoch: 3, Batch: 948, Loss: 1.4029178619384766\n",
      "Epoch: 3, Batch: 949, Loss: 1.425047516822815\n",
      "Epoch: 3, Batch: 950, Loss: 1.638068437576294\n",
      "Epoch: 3, Batch: 951, Loss: 0.4130692183971405\n",
      "Epoch: 3, Batch: 952, Loss: 2.396015167236328\n",
      "Epoch: 3, Batch: 953, Loss: 2.808774948120117\n",
      "Epoch: 3, Batch: 954, Loss: 1.432276964187622\n",
      "Epoch: 3, Batch: 955, Loss: 1.4279251098632812\n",
      "Epoch: 3, Batch: 956, Loss: 0.7139879465103149\n",
      "Epoch: 3, Batch: 957, Loss: 1.5141849517822266\n",
      "Epoch: 3, Batch: 958, Loss: 2.037334442138672\n",
      "Epoch: 3, Batch: 959, Loss: 3.763396739959717\n",
      "Epoch: 3, Batch: 960, Loss: 1.2594534158706665\n",
      "Epoch: 3, Batch: 961, Loss: 0.6566762328147888\n",
      "Epoch: 3, Batch: 962, Loss: 1.4160518646240234\n",
      "Epoch: 3, Batch: 963, Loss: 3.329190969467163\n",
      "Epoch: 3, Batch: 964, Loss: 1.7497119903564453\n",
      "Epoch: 3, Batch: 965, Loss: 3.1775155067443848\n",
      "Epoch: 3, Batch: 966, Loss: 2.760843515396118\n",
      "Epoch: 3, Batch: 967, Loss: 1.3343255519866943\n",
      "Epoch: 3, Batch: 968, Loss: 2.477283239364624\n",
      "Epoch: 3, Batch: 969, Loss: 0.7231810688972473\n",
      "Epoch: 3, Batch: 970, Loss: 0.5514688491821289\n",
      "Epoch: 3, Batch: 971, Loss: 0.18174275755882263\n",
      "Epoch: 3, Batch: 972, Loss: 4.867863178253174\n",
      "Epoch: 3, Batch: 973, Loss: 3.095297336578369\n",
      "Epoch: 3, Batch: 974, Loss: 0.18596863746643066\n",
      "Epoch: 3, Batch: 975, Loss: 1.8419195413589478\n",
      "Epoch: 3, Batch: 976, Loss: 2.250685930252075\n",
      "Epoch: 3, Batch: 977, Loss: 1.0017802715301514\n",
      "Epoch: 3, Batch: 978, Loss: 1.7646591663360596\n",
      "Epoch: 3, Batch: 979, Loss: 1.9617161750793457\n",
      "Epoch: 3, Batch: 980, Loss: 2.619152307510376\n",
      "Epoch: 3, Batch: 981, Loss: 1.9075708389282227\n",
      "Epoch: 3, Batch: 982, Loss: 1.7994756698608398\n",
      "Epoch: 3, Batch: 983, Loss: 1.4304202795028687\n",
      "Epoch: 3, Batch: 984, Loss: 1.0077483654022217\n",
      "Epoch: 3, Batch: 985, Loss: 1.8386709690093994\n",
      "Epoch: 3, Batch: 986, Loss: 0.3385485112667084\n",
      "Epoch: 3, Batch: 987, Loss: 1.579455852508545\n",
      "Epoch: 3, Batch: 988, Loss: 2.2130420207977295\n",
      "Epoch: 3, Batch: 989, Loss: 2.8497819900512695\n",
      "Epoch: 3, Batch: 990, Loss: 3.4558887481689453\n",
      "Epoch: 3, Batch: 991, Loss: 5.5181145668029785\n",
      "Epoch: 3, Batch: 992, Loss: 1.1685729026794434\n",
      "Epoch: 3, Batch: 993, Loss: 1.1200052499771118\n",
      "Epoch: 3, Batch: 994, Loss: 1.362284779548645\n",
      "Epoch: 3, Batch: 995, Loss: 2.157876968383789\n",
      "Epoch: 3, Batch: 996, Loss: 2.3820831775665283\n",
      "Epoch: 3, Batch: 997, Loss: 1.2539467811584473\n",
      "Epoch: 3, Batch: 998, Loss: 1.3418593406677246\n",
      "Epoch: 3, Batch: 999, Loss: 2.6952123641967773\n",
      "Epoch: 4, Batch: 0, Loss: 0.9205722212791443\n",
      "Epoch: 4, Batch: 1, Loss: 1.222839593887329\n",
      "Epoch: 4, Batch: 2, Loss: 2.2992305755615234\n",
      "Epoch: 4, Batch: 3, Loss: 0.029423603788018227\n",
      "Epoch: 4, Batch: 4, Loss: 1.7559906244277954\n",
      "Epoch: 4, Batch: 5, Loss: 0.9952753186225891\n",
      "Epoch: 4, Batch: 6, Loss: 0.8878990411758423\n",
      "Epoch: 4, Batch: 7, Loss: 1.068777084350586\n",
      "Epoch: 4, Batch: 8, Loss: 1.276033639907837\n",
      "Epoch: 4, Batch: 9, Loss: 1.3182220458984375\n",
      "Epoch: 4, Batch: 10, Loss: 3.4311561584472656\n",
      "Epoch: 4, Batch: 11, Loss: 0.6930691599845886\n",
      "Epoch: 4, Batch: 12, Loss: 3.8081119060516357\n",
      "Epoch: 4, Batch: 13, Loss: 1.9892385005950928\n",
      "Epoch: 4, Batch: 14, Loss: 1.7563819885253906\n",
      "Epoch: 4, Batch: 15, Loss: 2.3350915908813477\n",
      "Epoch: 4, Batch: 16, Loss: 1.9809226989746094\n",
      "Epoch: 4, Batch: 17, Loss: 1.5783575773239136\n",
      "Epoch: 4, Batch: 18, Loss: 0.9530039429664612\n",
      "Epoch: 4, Batch: 19, Loss: 1.2087849378585815\n",
      "Epoch: 4, Batch: 20, Loss: 2.0761969089508057\n",
      "Epoch: 4, Batch: 21, Loss: 1.737060785293579\n",
      "Epoch: 4, Batch: 22, Loss: 2.9634225368499756\n",
      "Epoch: 4, Batch: 23, Loss: 0.964104175567627\n",
      "Epoch: 4, Batch: 24, Loss: 2.5462489128112793\n",
      "Epoch: 4, Batch: 25, Loss: 0.6426745057106018\n",
      "Epoch: 4, Batch: 26, Loss: 1.8840886354446411\n",
      "Epoch: 4, Batch: 27, Loss: 2.1934728622436523\n",
      "Epoch: 4, Batch: 28, Loss: 0.6634332537651062\n",
      "Epoch: 4, Batch: 29, Loss: 1.816634178161621\n",
      "Epoch: 4, Batch: 30, Loss: 0.3283202350139618\n",
      "Epoch: 4, Batch: 31, Loss: 0.10877873748540878\n",
      "Epoch: 4, Batch: 32, Loss: 1.82603120803833\n",
      "Epoch: 4, Batch: 33, Loss: 2.143249750137329\n",
      "Epoch: 4, Batch: 34, Loss: 0.6289544105529785\n",
      "Epoch: 4, Batch: 35, Loss: 0.21395756304264069\n",
      "Epoch: 4, Batch: 36, Loss: 0.9766836166381836\n",
      "Epoch: 4, Batch: 37, Loss: 0.7442233562469482\n",
      "Epoch: 4, Batch: 38, Loss: 4.154200077056885\n",
      "Epoch: 4, Batch: 39, Loss: 1.0084187984466553\n",
      "Epoch: 4, Batch: 40, Loss: 0.9774179458618164\n",
      "Epoch: 4, Batch: 41, Loss: 0.4186389148235321\n",
      "Epoch: 4, Batch: 42, Loss: 2.3376007080078125\n",
      "Epoch: 4, Batch: 43, Loss: 1.599439263343811\n",
      "Epoch: 4, Batch: 44, Loss: 3.7065486907958984\n",
      "Epoch: 4, Batch: 45, Loss: 1.2720086574554443\n",
      "Epoch: 4, Batch: 46, Loss: 1.038020372390747\n",
      "Epoch: 4, Batch: 47, Loss: 2.4673852920532227\n",
      "Epoch: 4, Batch: 48, Loss: 1.2724556922912598\n",
      "Epoch: 4, Batch: 49, Loss: 1.3923988342285156\n",
      "Epoch: 4, Batch: 50, Loss: 1.5793211460113525\n",
      "Epoch: 4, Batch: 51, Loss: 1.5071771144866943\n",
      "Epoch: 4, Batch: 52, Loss: 3.0081663131713867\n",
      "Epoch: 4, Batch: 53, Loss: 2.1303768157958984\n",
      "Epoch: 4, Batch: 54, Loss: 2.5364601612091064\n",
      "Epoch: 4, Batch: 55, Loss: 1.7714976072311401\n",
      "Epoch: 4, Batch: 56, Loss: 2.8515992164611816\n",
      "Epoch: 4, Batch: 57, Loss: 1.8160706758499146\n",
      "Epoch: 4, Batch: 58, Loss: 0.565701961517334\n",
      "Epoch: 4, Batch: 59, Loss: 5.220967769622803\n",
      "Epoch: 4, Batch: 60, Loss: 0.3041457235813141\n",
      "Epoch: 4, Batch: 61, Loss: 2.734393358230591\n",
      "Epoch: 4, Batch: 62, Loss: 2.568793296813965\n",
      "Epoch: 4, Batch: 63, Loss: 2.880377769470215\n",
      "Epoch: 4, Batch: 64, Loss: 1.9813593626022339\n",
      "Epoch: 4, Batch: 65, Loss: 1.1420032978057861\n",
      "Epoch: 4, Batch: 66, Loss: 4.265652656555176\n",
      "Epoch: 4, Batch: 67, Loss: 1.7552779912948608\n",
      "Epoch: 4, Batch: 68, Loss: 2.4965579509735107\n",
      "Epoch: 4, Batch: 69, Loss: 0.9651682376861572\n",
      "Epoch: 4, Batch: 70, Loss: 3.517976999282837\n",
      "Epoch: 4, Batch: 71, Loss: 3.7751526832580566\n",
      "Epoch: 4, Batch: 72, Loss: 1.2987202405929565\n",
      "Epoch: 4, Batch: 73, Loss: 2.7427358627319336\n",
      "Epoch: 4, Batch: 74, Loss: 1.7278509140014648\n",
      "Epoch: 4, Batch: 75, Loss: 1.405356764793396\n",
      "Epoch: 4, Batch: 76, Loss: 0.6946998834609985\n",
      "Epoch: 4, Batch: 77, Loss: 2.1095035076141357\n",
      "Epoch: 4, Batch: 78, Loss: 0.1748056411743164\n",
      "Epoch: 4, Batch: 79, Loss: 1.4877389669418335\n",
      "Epoch: 4, Batch: 80, Loss: 1.4386717081069946\n",
      "Epoch: 4, Batch: 81, Loss: 1.5355288982391357\n",
      "Epoch: 4, Batch: 82, Loss: 1.8096046447753906\n",
      "Epoch: 4, Batch: 83, Loss: 0.9120813012123108\n",
      "Epoch: 4, Batch: 84, Loss: 0.5851144194602966\n",
      "Epoch: 4, Batch: 85, Loss: 2.674795627593994\n",
      "Epoch: 4, Batch: 86, Loss: 0.749226987361908\n",
      "Epoch: 4, Batch: 87, Loss: 2.229032516479492\n",
      "Epoch: 4, Batch: 88, Loss: 1.1022698879241943\n",
      "Epoch: 4, Batch: 89, Loss: 0.07673853635787964\n",
      "Epoch: 4, Batch: 90, Loss: 0.5878285765647888\n",
      "Epoch: 4, Batch: 91, Loss: 0.8789528608322144\n",
      "Epoch: 4, Batch: 92, Loss: 0.73292475938797\n",
      "Epoch: 4, Batch: 93, Loss: 4.036138534545898\n",
      "Epoch: 4, Batch: 94, Loss: 1.6048617362976074\n",
      "Epoch: 4, Batch: 95, Loss: 1.6193221807479858\n",
      "Epoch: 4, Batch: 96, Loss: 1.134535551071167\n",
      "Epoch: 4, Batch: 97, Loss: 1.4265073537826538\n",
      "Epoch: 4, Batch: 98, Loss: 1.2650452852249146\n",
      "Epoch: 4, Batch: 99, Loss: 0.23501057922840118\n",
      "Epoch: 4, Batch: 100, Loss: 1.057159185409546\n",
      "Epoch: 4, Batch: 101, Loss: 1.954660177230835\n",
      "Epoch: 4, Batch: 102, Loss: 1.5570917129516602\n",
      "Epoch: 4, Batch: 103, Loss: 0.192235067486763\n",
      "Epoch: 4, Batch: 104, Loss: 3.0750482082366943\n",
      "Epoch: 4, Batch: 105, Loss: 1.526689887046814\n",
      "Epoch: 4, Batch: 106, Loss: 2.1366405487060547\n",
      "Epoch: 4, Batch: 107, Loss: 0.9939959049224854\n",
      "Epoch: 4, Batch: 108, Loss: 0.67937171459198\n",
      "Epoch: 4, Batch: 109, Loss: 1.3902432918548584\n",
      "Epoch: 4, Batch: 110, Loss: 1.6811182498931885\n",
      "Epoch: 4, Batch: 111, Loss: 0.32964593172073364\n",
      "Epoch: 4, Batch: 112, Loss: 1.596652865409851\n",
      "Epoch: 4, Batch: 113, Loss: 2.0873496532440186\n",
      "Epoch: 4, Batch: 114, Loss: 0.15334878861904144\n",
      "Epoch: 4, Batch: 115, Loss: 1.255677342414856\n",
      "Epoch: 4, Batch: 116, Loss: 2.1473441123962402\n",
      "Epoch: 4, Batch: 117, Loss: 0.556139349937439\n",
      "Epoch: 4, Batch: 118, Loss: 0.9963913559913635\n",
      "Epoch: 4, Batch: 119, Loss: 1.9242745637893677\n",
      "Epoch: 4, Batch: 120, Loss: 0.7089704871177673\n",
      "Epoch: 4, Batch: 121, Loss: 1.995966911315918\n",
      "Epoch: 4, Batch: 122, Loss: 1.9116075038909912\n",
      "Epoch: 4, Batch: 123, Loss: 2.132455825805664\n",
      "Epoch: 4, Batch: 124, Loss: 0.5146781802177429\n",
      "Epoch: 4, Batch: 125, Loss: 1.8500534296035767\n",
      "Epoch: 4, Batch: 126, Loss: 1.468422293663025\n",
      "Epoch: 4, Batch: 127, Loss: 0.5504980087280273\n",
      "Epoch: 4, Batch: 128, Loss: 1.0170568227767944\n",
      "Epoch: 4, Batch: 129, Loss: 1.8362979888916016\n",
      "Epoch: 4, Batch: 130, Loss: 0.9876663088798523\n",
      "Epoch: 4, Batch: 131, Loss: 1.644822597503662\n",
      "Epoch: 4, Batch: 132, Loss: 1.4900766611099243\n",
      "Epoch: 4, Batch: 133, Loss: 0.11642896384000778\n",
      "Epoch: 4, Batch: 134, Loss: 2.913288116455078\n",
      "Epoch: 4, Batch: 135, Loss: 1.199571132659912\n",
      "Epoch: 4, Batch: 136, Loss: 3.152690887451172\n",
      "Epoch: 4, Batch: 137, Loss: 1.6198301315307617\n",
      "Epoch: 4, Batch: 138, Loss: 0.13818597793579102\n",
      "Epoch: 4, Batch: 139, Loss: 1.2531137466430664\n",
      "Epoch: 4, Batch: 140, Loss: 1.2554984092712402\n",
      "Epoch: 4, Batch: 141, Loss: 1.4686484336853027\n",
      "Epoch: 4, Batch: 142, Loss: 1.8012052774429321\n",
      "Epoch: 4, Batch: 143, Loss: 1.7074811458587646\n",
      "Epoch: 4, Batch: 144, Loss: 0.947117030620575\n",
      "Epoch: 4, Batch: 145, Loss: 0.28401893377304077\n",
      "Epoch: 4, Batch: 146, Loss: 0.9065592288970947\n",
      "Epoch: 4, Batch: 147, Loss: 2.297356605529785\n",
      "Epoch: 4, Batch: 148, Loss: 3.0033726692199707\n",
      "Epoch: 4, Batch: 149, Loss: 0.3292968273162842\n",
      "Epoch: 4, Batch: 150, Loss: 1.0211544036865234\n",
      "Epoch: 4, Batch: 151, Loss: 0.8493432402610779\n",
      "Epoch: 4, Batch: 152, Loss: 1.399656057357788\n",
      "Epoch: 4, Batch: 153, Loss: 1.4184577465057373\n",
      "Epoch: 4, Batch: 154, Loss: 2.6928441524505615\n",
      "Epoch: 4, Batch: 155, Loss: 2.069763660430908\n",
      "Epoch: 4, Batch: 156, Loss: 1.445426344871521\n",
      "Epoch: 4, Batch: 157, Loss: 0.28710711002349854\n",
      "Epoch: 4, Batch: 158, Loss: 1.464709997177124\n",
      "Epoch: 4, Batch: 159, Loss: 2.8665270805358887\n",
      "Epoch: 4, Batch: 160, Loss: 3.2332143783569336\n",
      "Epoch: 4, Batch: 161, Loss: 4.313567161560059\n",
      "Epoch: 4, Batch: 162, Loss: 0.6996712684631348\n",
      "Epoch: 4, Batch: 163, Loss: 0.8707617521286011\n",
      "Epoch: 4, Batch: 164, Loss: 1.2702332735061646\n",
      "Epoch: 4, Batch: 165, Loss: 0.8557689189910889\n",
      "Epoch: 4, Batch: 166, Loss: 0.532030463218689\n",
      "Epoch: 4, Batch: 167, Loss: 1.7789655923843384\n",
      "Epoch: 4, Batch: 168, Loss: 2.5152547359466553\n",
      "Epoch: 4, Batch: 169, Loss: 1.6660900115966797\n",
      "Epoch: 4, Batch: 170, Loss: 1.732611894607544\n",
      "Epoch: 4, Batch: 171, Loss: 0.8852195739746094\n",
      "Epoch: 4, Batch: 172, Loss: 4.586889743804932\n",
      "Epoch: 4, Batch: 173, Loss: 3.2608225345611572\n",
      "Epoch: 4, Batch: 174, Loss: 1.5591050386428833\n",
      "Epoch: 4, Batch: 175, Loss: 1.8171722888946533\n",
      "Epoch: 4, Batch: 176, Loss: 1.131917953491211\n",
      "Epoch: 4, Batch: 177, Loss: 1.067502498626709\n",
      "Epoch: 4, Batch: 178, Loss: 1.4357858896255493\n",
      "Epoch: 4, Batch: 179, Loss: 2.301764726638794\n",
      "Epoch: 4, Batch: 180, Loss: 1.8321683406829834\n",
      "Epoch: 4, Batch: 181, Loss: 0.2754356265068054\n",
      "Epoch: 4, Batch: 182, Loss: 2.111311197280884\n",
      "Epoch: 4, Batch: 183, Loss: 2.6733736991882324\n",
      "Epoch: 4, Batch: 184, Loss: 0.08789698779582977\n",
      "Epoch: 4, Batch: 185, Loss: 0.9291190505027771\n",
      "Epoch: 4, Batch: 186, Loss: 0.17380517721176147\n",
      "Epoch: 4, Batch: 187, Loss: 0.8496944904327393\n",
      "Epoch: 4, Batch: 188, Loss: 0.8781737685203552\n",
      "Epoch: 4, Batch: 189, Loss: 0.6522106528282166\n",
      "Epoch: 4, Batch: 190, Loss: 0.8271324634552002\n",
      "Epoch: 4, Batch: 191, Loss: 4.833905220031738\n",
      "Epoch: 4, Batch: 192, Loss: 2.3076837062835693\n",
      "Epoch: 4, Batch: 193, Loss: 0.869596540927887\n",
      "Epoch: 4, Batch: 194, Loss: 0.9621422290802002\n",
      "Epoch: 4, Batch: 195, Loss: 0.8706422448158264\n",
      "Epoch: 4, Batch: 196, Loss: 1.119723916053772\n",
      "Epoch: 4, Batch: 197, Loss: 1.3550289869308472\n",
      "Epoch: 4, Batch: 198, Loss: 1.5803568363189697\n",
      "Epoch: 4, Batch: 199, Loss: 1.3982346057891846\n",
      "Epoch: 4, Batch: 200, Loss: 0.4983816146850586\n",
      "Epoch: 4, Batch: 201, Loss: 1.2039284706115723\n",
      "Epoch: 4, Batch: 202, Loss: 1.605867862701416\n",
      "Epoch: 4, Batch: 203, Loss: 2.7393898963928223\n",
      "Epoch: 4, Batch: 204, Loss: 2.0562186241149902\n",
      "Epoch: 4, Batch: 205, Loss: 3.9071617126464844\n",
      "Epoch: 4, Batch: 206, Loss: 2.8909549713134766\n",
      "Epoch: 4, Batch: 207, Loss: 1.4403481483459473\n",
      "Epoch: 4, Batch: 208, Loss: 1.96612548828125\n",
      "Epoch: 4, Batch: 209, Loss: 2.36612606048584\n",
      "Epoch: 4, Batch: 210, Loss: 0.6978282332420349\n",
      "Epoch: 4, Batch: 211, Loss: 0.998792290687561\n",
      "Epoch: 4, Batch: 212, Loss: 3.363025188446045\n",
      "Epoch: 4, Batch: 213, Loss: 1.3664617538452148\n",
      "Epoch: 4, Batch: 214, Loss: 5.027133464813232\n",
      "Epoch: 4, Batch: 215, Loss: 2.375373601913452\n",
      "Epoch: 4, Batch: 216, Loss: 1.2661076784133911\n",
      "Epoch: 4, Batch: 217, Loss: 3.5591013431549072\n",
      "Epoch: 4, Batch: 218, Loss: 1.7090232372283936\n",
      "Epoch: 4, Batch: 219, Loss: 1.9414176940917969\n",
      "Epoch: 4, Batch: 220, Loss: 1.6288032531738281\n",
      "Epoch: 4, Batch: 221, Loss: 1.3123254776000977\n",
      "Epoch: 4, Batch: 222, Loss: 0.7022813558578491\n",
      "Epoch: 4, Batch: 223, Loss: 1.73513662815094\n",
      "Epoch: 4, Batch: 224, Loss: 1.3177136182785034\n",
      "Epoch: 4, Batch: 225, Loss: 2.3962836265563965\n",
      "Epoch: 4, Batch: 226, Loss: 2.414384603500366\n",
      "Epoch: 4, Batch: 227, Loss: 1.0046169757843018\n",
      "Epoch: 4, Batch: 228, Loss: 1.217404842376709\n",
      "Epoch: 4, Batch: 229, Loss: 2.5005295276641846\n",
      "Epoch: 4, Batch: 230, Loss: 1.3178470134735107\n",
      "Epoch: 4, Batch: 231, Loss: 0.820875346660614\n",
      "Epoch: 4, Batch: 232, Loss: 1.9036680459976196\n",
      "Epoch: 4, Batch: 233, Loss: 3.1501994132995605\n",
      "Epoch: 4, Batch: 234, Loss: 0.8417102098464966\n",
      "Epoch: 4, Batch: 235, Loss: 0.5382125377655029\n",
      "Epoch: 4, Batch: 236, Loss: 1.8247634172439575\n",
      "Epoch: 4, Batch: 237, Loss: 1.0706347227096558\n",
      "Epoch: 4, Batch: 238, Loss: 1.3068630695343018\n",
      "Epoch: 4, Batch: 239, Loss: 0.8931324481964111\n",
      "Epoch: 4, Batch: 240, Loss: 0.5537176132202148\n",
      "Epoch: 4, Batch: 241, Loss: 0.13739247620105743\n",
      "Epoch: 4, Batch: 242, Loss: 1.5469577312469482\n",
      "Epoch: 4, Batch: 243, Loss: 1.0235238075256348\n",
      "Epoch: 4, Batch: 244, Loss: 2.405113935470581\n",
      "Epoch: 4, Batch: 245, Loss: 1.8536896705627441\n",
      "Epoch: 4, Batch: 246, Loss: 5.724099159240723\n",
      "Epoch: 4, Batch: 247, Loss: 0.677992045879364\n",
      "Epoch: 4, Batch: 248, Loss: 0.4238423705101013\n",
      "Epoch: 4, Batch: 249, Loss: 3.5063059329986572\n",
      "Epoch: 4, Batch: 250, Loss: 1.3277208805084229\n",
      "Epoch: 4, Batch: 251, Loss: 1.0975122451782227\n",
      "Epoch: 4, Batch: 252, Loss: 3.1372570991516113\n",
      "Epoch: 4, Batch: 253, Loss: 1.3724297285079956\n",
      "Epoch: 4, Batch: 254, Loss: 0.814712643623352\n",
      "Epoch: 4, Batch: 255, Loss: 0.39431047439575195\n",
      "Epoch: 4, Batch: 256, Loss: 1.999159812927246\n",
      "Epoch: 4, Batch: 257, Loss: 2.195904016494751\n",
      "Epoch: 4, Batch: 258, Loss: 3.2869486808776855\n",
      "Epoch: 4, Batch: 259, Loss: 0.8865543603897095\n",
      "Epoch: 4, Batch: 260, Loss: 0.7143800258636475\n",
      "Epoch: 4, Batch: 261, Loss: 0.9890214204788208\n",
      "Epoch: 4, Batch: 262, Loss: 3.154723882675171\n",
      "Epoch: 4, Batch: 263, Loss: 2.537663459777832\n",
      "Epoch: 4, Batch: 264, Loss: 2.84161639213562\n",
      "Epoch: 4, Batch: 265, Loss: 2.319836139678955\n",
      "Epoch: 4, Batch: 266, Loss: 2.5165863037109375\n",
      "Epoch: 4, Batch: 267, Loss: 2.237527370452881\n",
      "Epoch: 4, Batch: 268, Loss: 2.476564884185791\n",
      "Epoch: 4, Batch: 269, Loss: 1.7448331117630005\n",
      "Epoch: 4, Batch: 270, Loss: 1.5876407623291016\n",
      "Epoch: 4, Batch: 271, Loss: 1.849012851715088\n",
      "Epoch: 4, Batch: 272, Loss: 1.0625989437103271\n",
      "Epoch: 4, Batch: 273, Loss: 1.0836609601974487\n",
      "Epoch: 4, Batch: 274, Loss: 0.841190755367279\n",
      "Epoch: 4, Batch: 275, Loss: 0.7184150218963623\n",
      "Epoch: 4, Batch: 276, Loss: 5.827950477600098\n",
      "Epoch: 4, Batch: 277, Loss: 3.0960302352905273\n",
      "Epoch: 4, Batch: 278, Loss: 2.2059290409088135\n",
      "Epoch: 4, Batch: 279, Loss: 2.132596969604492\n",
      "Epoch: 4, Batch: 280, Loss: 3.521357297897339\n",
      "Epoch: 4, Batch: 281, Loss: 2.6241252422332764\n",
      "Epoch: 4, Batch: 282, Loss: 1.3716020584106445\n",
      "Epoch: 4, Batch: 283, Loss: 1.3307799100875854\n",
      "Epoch: 4, Batch: 284, Loss: 1.7417652606964111\n",
      "Epoch: 4, Batch: 285, Loss: 0.7482524514198303\n",
      "Epoch: 4, Batch: 286, Loss: 0.6689274907112122\n",
      "Epoch: 4, Batch: 287, Loss: 3.546496629714966\n",
      "Epoch: 4, Batch: 288, Loss: 3.60430908203125\n",
      "Epoch: 4, Batch: 289, Loss: 0.062271639704704285\n",
      "Epoch: 4, Batch: 290, Loss: 2.010946750640869\n",
      "Epoch: 4, Batch: 291, Loss: 0.3791269063949585\n",
      "Epoch: 4, Batch: 292, Loss: 0.8966467380523682\n",
      "Epoch: 4, Batch: 293, Loss: 1.9093220233917236\n",
      "Epoch: 4, Batch: 294, Loss: 2.358367681503296\n",
      "Epoch: 4, Batch: 295, Loss: 1.5515191555023193\n",
      "Epoch: 4, Batch: 296, Loss: 1.4874284267425537\n",
      "Epoch: 4, Batch: 297, Loss: 2.007990598678589\n",
      "Epoch: 4, Batch: 298, Loss: 1.8095605373382568\n",
      "Epoch: 4, Batch: 299, Loss: 2.4939308166503906\n",
      "Epoch: 4, Batch: 300, Loss: 0.8723806142807007\n",
      "Epoch: 4, Batch: 301, Loss: 2.1033835411071777\n",
      "Epoch: 4, Batch: 302, Loss: 2.4153518676757812\n",
      "Epoch: 4, Batch: 303, Loss: 2.313856840133667\n",
      "Epoch: 4, Batch: 304, Loss: 2.8123486042022705\n",
      "Epoch: 4, Batch: 305, Loss: 1.971799612045288\n",
      "Epoch: 4, Batch: 306, Loss: 2.5218594074249268\n",
      "Epoch: 4, Batch: 307, Loss: 1.424893856048584\n",
      "Epoch: 4, Batch: 308, Loss: 1.7531300783157349\n",
      "Epoch: 4, Batch: 309, Loss: 2.0210859775543213\n",
      "Epoch: 4, Batch: 310, Loss: 3.2771856784820557\n",
      "Epoch: 4, Batch: 311, Loss: 1.4737991094589233\n",
      "Epoch: 4, Batch: 312, Loss: 1.4844856262207031\n",
      "Epoch: 4, Batch: 313, Loss: 2.6134326457977295\n",
      "Epoch: 4, Batch: 314, Loss: 2.105879545211792\n",
      "Epoch: 4, Batch: 315, Loss: 0.1267663836479187\n",
      "Epoch: 4, Batch: 316, Loss: 1.2047581672668457\n",
      "Epoch: 4, Batch: 317, Loss: 2.256953716278076\n",
      "Epoch: 4, Batch: 318, Loss: 0.3719354569911957\n",
      "Epoch: 4, Batch: 319, Loss: 1.023662805557251\n",
      "Epoch: 4, Batch: 320, Loss: 0.805009126663208\n",
      "Epoch: 4, Batch: 321, Loss: 1.7889429330825806\n",
      "Epoch: 4, Batch: 322, Loss: 0.44952723383903503\n",
      "Epoch: 4, Batch: 323, Loss: 0.34026044607162476\n",
      "Epoch: 4, Batch: 324, Loss: 1.9638340473175049\n",
      "Epoch: 4, Batch: 325, Loss: 1.940310001373291\n",
      "Epoch: 4, Batch: 326, Loss: 5.624815940856934\n",
      "Epoch: 4, Batch: 327, Loss: 1.1083815097808838\n",
      "Epoch: 4, Batch: 328, Loss: 3.9073097705841064\n",
      "Epoch: 4, Batch: 329, Loss: 0.13405923545360565\n",
      "Epoch: 4, Batch: 330, Loss: 0.8820314407348633\n",
      "Epoch: 4, Batch: 331, Loss: 0.6855829954147339\n",
      "Epoch: 4, Batch: 332, Loss: 2.2127492427825928\n",
      "Epoch: 4, Batch: 333, Loss: 2.3177199363708496\n",
      "Epoch: 4, Batch: 334, Loss: 1.6760566234588623\n",
      "Epoch: 4, Batch: 335, Loss: 3.3736374378204346\n",
      "Epoch: 4, Batch: 336, Loss: 0.9819897413253784\n",
      "Epoch: 4, Batch: 337, Loss: 4.767143249511719\n",
      "Epoch: 4, Batch: 338, Loss: 0.4889644980430603\n",
      "Epoch: 4, Batch: 339, Loss: 1.5179617404937744\n",
      "Epoch: 4, Batch: 340, Loss: 3.016881227493286\n",
      "Epoch: 4, Batch: 341, Loss: 2.6371302604675293\n",
      "Epoch: 4, Batch: 342, Loss: 1.6583784818649292\n",
      "Epoch: 4, Batch: 343, Loss: 2.4047210216522217\n",
      "Epoch: 4, Batch: 344, Loss: 0.7248151302337646\n",
      "Epoch: 4, Batch: 345, Loss: 7.514593124389648\n",
      "Epoch: 4, Batch: 346, Loss: 1.4108366966247559\n",
      "Epoch: 4, Batch: 347, Loss: 2.7875306606292725\n",
      "Epoch: 4, Batch: 348, Loss: 2.3048980236053467\n",
      "Epoch: 4, Batch: 349, Loss: 1.429394245147705\n",
      "Epoch: 4, Batch: 350, Loss: 2.6471304893493652\n",
      "Epoch: 4, Batch: 351, Loss: 3.500692844390869\n",
      "Epoch: 4, Batch: 352, Loss: 1.0599294900894165\n",
      "Epoch: 4, Batch: 353, Loss: 2.359011650085449\n",
      "Epoch: 4, Batch: 354, Loss: 0.9478660821914673\n",
      "Epoch: 4, Batch: 355, Loss: 1.8438224792480469\n",
      "Epoch: 4, Batch: 356, Loss: 0.6534501910209656\n",
      "Epoch: 4, Batch: 357, Loss: 0.7105599641799927\n",
      "Epoch: 4, Batch: 358, Loss: 3.132331609725952\n",
      "Epoch: 4, Batch: 359, Loss: 1.108760952949524\n",
      "Epoch: 4, Batch: 360, Loss: 2.498298168182373\n",
      "Epoch: 4, Batch: 361, Loss: 1.0027581453323364\n",
      "Epoch: 4, Batch: 362, Loss: 3.111621141433716\n",
      "Epoch: 4, Batch: 363, Loss: 0.8140264749526978\n",
      "Epoch: 4, Batch: 364, Loss: 1.7455700635910034\n",
      "Epoch: 4, Batch: 365, Loss: 1.0584743022918701\n",
      "Epoch: 4, Batch: 366, Loss: 0.334770143032074\n",
      "Epoch: 4, Batch: 367, Loss: 0.9553840160369873\n",
      "Epoch: 4, Batch: 368, Loss: 2.725841522216797\n",
      "Epoch: 4, Batch: 369, Loss: 0.9369198083877563\n",
      "Epoch: 4, Batch: 370, Loss: 1.8154042959213257\n",
      "Epoch: 4, Batch: 371, Loss: 2.5502302646636963\n",
      "Epoch: 4, Batch: 372, Loss: 2.377295970916748\n",
      "Epoch: 4, Batch: 373, Loss: 2.1954174041748047\n",
      "Epoch: 4, Batch: 374, Loss: 1.8345677852630615\n",
      "Epoch: 4, Batch: 375, Loss: 1.478420376777649\n",
      "Epoch: 4, Batch: 376, Loss: 0.5268682837486267\n",
      "Epoch: 4, Batch: 377, Loss: 2.919323444366455\n",
      "Epoch: 4, Batch: 378, Loss: 1.9115675687789917\n",
      "Epoch: 4, Batch: 379, Loss: 0.9871273040771484\n",
      "Epoch: 4, Batch: 380, Loss: 1.1531141996383667\n",
      "Epoch: 4, Batch: 381, Loss: 2.504485607147217\n",
      "Epoch: 4, Batch: 382, Loss: 4.495518207550049\n",
      "Epoch: 4, Batch: 383, Loss: 1.7190451622009277\n",
      "Epoch: 4, Batch: 384, Loss: 0.6470885276794434\n",
      "Epoch: 4, Batch: 385, Loss: 4.469653606414795\n",
      "Epoch: 4, Batch: 386, Loss: 0.9494897127151489\n",
      "Epoch: 4, Batch: 387, Loss: 0.7914848327636719\n",
      "Epoch: 4, Batch: 388, Loss: 1.728509783744812\n",
      "Epoch: 4, Batch: 389, Loss: 3.4354195594787598\n",
      "Epoch: 4, Batch: 390, Loss: 1.8241230249404907\n",
      "Epoch: 4, Batch: 391, Loss: 1.7209020853042603\n",
      "Epoch: 4, Batch: 392, Loss: 1.6327383518218994\n",
      "Epoch: 4, Batch: 393, Loss: 1.0942953824996948\n",
      "Epoch: 4, Batch: 394, Loss: 1.602905511856079\n",
      "Epoch: 4, Batch: 395, Loss: 1.5442628860473633\n",
      "Epoch: 4, Batch: 396, Loss: 0.9344856142997742\n",
      "Epoch: 4, Batch: 397, Loss: 1.3157979249954224\n",
      "Epoch: 4, Batch: 398, Loss: 1.2545565366744995\n",
      "Epoch: 4, Batch: 399, Loss: 0.4643165171146393\n",
      "Epoch: 4, Batch: 400, Loss: 1.7720530033111572\n",
      "Epoch: 4, Batch: 401, Loss: 0.4851239323616028\n",
      "Epoch: 4, Batch: 402, Loss: 1.1896382570266724\n",
      "Epoch: 4, Batch: 403, Loss: 1.297878623008728\n",
      "Epoch: 4, Batch: 404, Loss: 0.6708201766014099\n",
      "Epoch: 4, Batch: 405, Loss: 1.2043821811676025\n",
      "Epoch: 4, Batch: 406, Loss: 1.4888155460357666\n",
      "Epoch: 4, Batch: 407, Loss: 2.255481243133545\n",
      "Epoch: 4, Batch: 408, Loss: 2.650144577026367\n",
      "Epoch: 4, Batch: 409, Loss: 0.6640774607658386\n",
      "Epoch: 4, Batch: 410, Loss: 2.7058050632476807\n",
      "Epoch: 4, Batch: 411, Loss: 1.2366691827774048\n",
      "Epoch: 4, Batch: 412, Loss: 1.0859146118164062\n",
      "Epoch: 4, Batch: 413, Loss: 1.0709078311920166\n",
      "Epoch: 4, Batch: 414, Loss: 2.834750175476074\n",
      "Epoch: 4, Batch: 415, Loss: 0.941281795501709\n",
      "Epoch: 4, Batch: 416, Loss: 1.7811819314956665\n",
      "Epoch: 4, Batch: 417, Loss: 1.9622493982315063\n",
      "Epoch: 4, Batch: 418, Loss: 1.026818037033081\n",
      "Epoch: 4, Batch: 419, Loss: 2.414076566696167\n",
      "Epoch: 4, Batch: 420, Loss: 0.8678475618362427\n",
      "Epoch: 4, Batch: 421, Loss: 1.3563950061798096\n",
      "Epoch: 4, Batch: 422, Loss: 0.8536326885223389\n",
      "Epoch: 4, Batch: 423, Loss: 0.6365587711334229\n",
      "Epoch: 4, Batch: 424, Loss: 0.6816849708557129\n",
      "Epoch: 4, Batch: 425, Loss: 0.5083922147750854\n",
      "Epoch: 4, Batch: 426, Loss: 2.4897255897521973\n",
      "Epoch: 4, Batch: 427, Loss: 3.893340826034546\n",
      "Epoch: 4, Batch: 428, Loss: 0.8407483696937561\n",
      "Epoch: 4, Batch: 429, Loss: 1.3402045965194702\n",
      "Epoch: 4, Batch: 430, Loss: 0.637239396572113\n",
      "Epoch: 4, Batch: 431, Loss: 2.2991690635681152\n",
      "Epoch: 4, Batch: 432, Loss: 1.045654535293579\n",
      "Epoch: 4, Batch: 433, Loss: 1.6095267534255981\n",
      "Epoch: 4, Batch: 434, Loss: 2.385241985321045\n",
      "Epoch: 4, Batch: 435, Loss: 1.8546421527862549\n",
      "Epoch: 4, Batch: 436, Loss: 1.864823341369629\n",
      "Epoch: 4, Batch: 437, Loss: 1.4655123949050903\n",
      "Epoch: 4, Batch: 438, Loss: 0.8923863172531128\n",
      "Epoch: 4, Batch: 439, Loss: 2.2765655517578125\n",
      "Epoch: 4, Batch: 440, Loss: 1.9190572500228882\n",
      "Epoch: 4, Batch: 441, Loss: 1.2487906217575073\n",
      "Epoch: 4, Batch: 442, Loss: 0.48776042461395264\n",
      "Epoch: 4, Batch: 443, Loss: 2.6137359142303467\n",
      "Epoch: 4, Batch: 444, Loss: 1.6378364562988281\n",
      "Epoch: 4, Batch: 445, Loss: 1.3675003051757812\n",
      "Epoch: 4, Batch: 446, Loss: 0.8508967161178589\n",
      "Epoch: 4, Batch: 447, Loss: 0.7888090014457703\n",
      "Epoch: 4, Batch: 448, Loss: 0.304641991853714\n",
      "Epoch: 4, Batch: 449, Loss: 3.2510151863098145\n",
      "Epoch: 4, Batch: 450, Loss: 0.22219468653202057\n",
      "Epoch: 4, Batch: 451, Loss: 2.194427967071533\n",
      "Epoch: 4, Batch: 452, Loss: 0.3244352340698242\n",
      "Epoch: 4, Batch: 453, Loss: 2.2200841903686523\n",
      "Epoch: 4, Batch: 454, Loss: 1.7139837741851807\n",
      "Epoch: 4, Batch: 455, Loss: 1.247676134109497\n",
      "Epoch: 4, Batch: 456, Loss: 1.9722352027893066\n",
      "Epoch: 4, Batch: 457, Loss: 1.693803071975708\n",
      "Epoch: 4, Batch: 458, Loss: 1.5601540803909302\n",
      "Epoch: 4, Batch: 459, Loss: 1.053717017173767\n",
      "Epoch: 4, Batch: 460, Loss: 1.4099311828613281\n",
      "Epoch: 4, Batch: 461, Loss: 0.7820240259170532\n",
      "Epoch: 4, Batch: 462, Loss: 2.025128126144409\n",
      "Epoch: 4, Batch: 463, Loss: 2.138618230819702\n",
      "Epoch: 4, Batch: 464, Loss: 0.1939237415790558\n",
      "Epoch: 4, Batch: 465, Loss: 2.592341184616089\n",
      "Epoch: 4, Batch: 466, Loss: 2.1773805618286133\n",
      "Epoch: 4, Batch: 467, Loss: 1.9107000827789307\n",
      "Epoch: 4, Batch: 468, Loss: 1.1487088203430176\n",
      "Epoch: 4, Batch: 469, Loss: 2.569127082824707\n",
      "Epoch: 4, Batch: 470, Loss: 2.15720272064209\n",
      "Epoch: 4, Batch: 471, Loss: 1.009353518486023\n",
      "Epoch: 4, Batch: 472, Loss: 0.5351411700248718\n",
      "Epoch: 4, Batch: 473, Loss: 2.819671154022217\n",
      "Epoch: 4, Batch: 474, Loss: 3.4549241065979004\n",
      "Epoch: 4, Batch: 475, Loss: 1.564380168914795\n",
      "Epoch: 4, Batch: 476, Loss: 1.7717018127441406\n",
      "Epoch: 4, Batch: 477, Loss: 2.0382673740386963\n",
      "Epoch: 4, Batch: 478, Loss: 0.42666560411453247\n",
      "Epoch: 4, Batch: 479, Loss: 1.7265644073486328\n",
      "Epoch: 4, Batch: 480, Loss: 0.041280508041381836\n",
      "Epoch: 4, Batch: 481, Loss: 1.1416449546813965\n",
      "Epoch: 4, Batch: 482, Loss: 1.730602502822876\n",
      "Epoch: 4, Batch: 483, Loss: 2.6656453609466553\n",
      "Epoch: 4, Batch: 484, Loss: 0.9035446643829346\n",
      "Epoch: 4, Batch: 485, Loss: 1.629143476486206\n",
      "Epoch: 4, Batch: 486, Loss: 0.5485156774520874\n",
      "Epoch: 4, Batch: 487, Loss: 0.10330396890640259\n",
      "Epoch: 4, Batch: 488, Loss: 1.6936721801757812\n",
      "Epoch: 4, Batch: 489, Loss: 2.2943122386932373\n",
      "Epoch: 4, Batch: 490, Loss: 0.4528920650482178\n",
      "Epoch: 4, Batch: 491, Loss: 2.409970283508301\n",
      "Epoch: 4, Batch: 492, Loss: 1.7185380458831787\n",
      "Epoch: 4, Batch: 493, Loss: 1.073636770248413\n",
      "Epoch: 4, Batch: 494, Loss: 2.8048958778381348\n",
      "Epoch: 4, Batch: 495, Loss: 2.342097282409668\n",
      "Epoch: 4, Batch: 496, Loss: 0.4678516983985901\n",
      "Epoch: 4, Batch: 497, Loss: 0.5820485949516296\n",
      "Epoch: 4, Batch: 498, Loss: 1.2267158031463623\n",
      "Epoch: 4, Batch: 499, Loss: 0.2823513150215149\n",
      "Epoch: 4, Batch: 500, Loss: 0.5817890763282776\n",
      "Epoch: 4, Batch: 501, Loss: 2.248678207397461\n",
      "Epoch: 4, Batch: 502, Loss: 1.3633555173873901\n",
      "Epoch: 4, Batch: 503, Loss: 2.511253833770752\n",
      "Epoch: 4, Batch: 504, Loss: 0.9433247447013855\n",
      "Epoch: 4, Batch: 505, Loss: 1.5270222425460815\n",
      "Epoch: 4, Batch: 506, Loss: 0.3467167317867279\n",
      "Epoch: 4, Batch: 507, Loss: 0.4724680185317993\n",
      "Epoch: 4, Batch: 508, Loss: 2.7407124042510986\n",
      "Epoch: 4, Batch: 509, Loss: 2.4944818019866943\n",
      "Epoch: 4, Batch: 510, Loss: 2.742036819458008\n",
      "Epoch: 4, Batch: 511, Loss: 1.1650046110153198\n",
      "Epoch: 4, Batch: 512, Loss: 0.6465818881988525\n",
      "Epoch: 4, Batch: 513, Loss: 1.3928191661834717\n",
      "Epoch: 4, Batch: 514, Loss: 2.4712533950805664\n",
      "Epoch: 4, Batch: 515, Loss: 0.46055859327316284\n",
      "Epoch: 4, Batch: 516, Loss: 2.635692596435547\n",
      "Epoch: 4, Batch: 517, Loss: 1.2022181749343872\n",
      "Epoch: 4, Batch: 518, Loss: 0.868636965751648\n",
      "Epoch: 4, Batch: 519, Loss: 0.9406844973564148\n",
      "Epoch: 4, Batch: 520, Loss: 0.9513512253761292\n",
      "Epoch: 4, Batch: 521, Loss: 1.8035105466842651\n",
      "Epoch: 4, Batch: 522, Loss: 1.4456980228424072\n",
      "Epoch: 4, Batch: 523, Loss: 2.359769582748413\n",
      "Epoch: 4, Batch: 524, Loss: 3.5479276180267334\n",
      "Epoch: 4, Batch: 525, Loss: 2.3443193435668945\n",
      "Epoch: 4, Batch: 526, Loss: 1.0710314512252808\n",
      "Epoch: 4, Batch: 527, Loss: 1.1384129524230957\n",
      "Epoch: 4, Batch: 528, Loss: 0.3227652311325073\n",
      "Epoch: 4, Batch: 529, Loss: 3.3014020919799805\n",
      "Epoch: 4, Batch: 530, Loss: 1.7582769393920898\n",
      "Epoch: 4, Batch: 531, Loss: 0.814996600151062\n",
      "Epoch: 4, Batch: 532, Loss: 1.996508002281189\n",
      "Epoch: 4, Batch: 533, Loss: 0.4388159513473511\n",
      "Epoch: 4, Batch: 534, Loss: 2.8937602043151855\n",
      "Epoch: 4, Batch: 535, Loss: 1.7718112468719482\n",
      "Epoch: 4, Batch: 536, Loss: 1.5593682527542114\n",
      "Epoch: 4, Batch: 537, Loss: 1.4908974170684814\n",
      "Epoch: 4, Batch: 538, Loss: 1.6394991874694824\n",
      "Epoch: 4, Batch: 539, Loss: 0.7978392243385315\n",
      "Epoch: 4, Batch: 540, Loss: 5.018609523773193\n",
      "Epoch: 4, Batch: 541, Loss: 0.30280306935310364\n",
      "Epoch: 4, Batch: 542, Loss: 1.5833357572555542\n",
      "Epoch: 4, Batch: 543, Loss: 2.9275400638580322\n",
      "Epoch: 4, Batch: 544, Loss: 2.1487812995910645\n",
      "Epoch: 4, Batch: 545, Loss: 3.6552679538726807\n",
      "Epoch: 4, Batch: 546, Loss: 2.9511771202087402\n",
      "Epoch: 4, Batch: 547, Loss: 0.1899028718471527\n",
      "Epoch: 4, Batch: 548, Loss: 1.9021644592285156\n",
      "Epoch: 4, Batch: 549, Loss: 1.5452402830123901\n",
      "Epoch: 4, Batch: 550, Loss: 2.4233317375183105\n",
      "Epoch: 4, Batch: 551, Loss: 1.540764331817627\n",
      "Epoch: 4, Batch: 552, Loss: 0.5057142972946167\n",
      "Epoch: 4, Batch: 553, Loss: 0.05987708643078804\n",
      "Epoch: 4, Batch: 554, Loss: 1.6868364810943604\n",
      "Epoch: 4, Batch: 555, Loss: 1.9227467775344849\n",
      "Epoch: 4, Batch: 556, Loss: 2.937746524810791\n",
      "Epoch: 4, Batch: 557, Loss: 2.4371278285980225\n",
      "Epoch: 4, Batch: 558, Loss: 2.256945848464966\n",
      "Epoch: 4, Batch: 559, Loss: 2.0108516216278076\n",
      "Epoch: 4, Batch: 560, Loss: 1.8415696620941162\n",
      "Epoch: 4, Batch: 561, Loss: 2.569230318069458\n",
      "Epoch: 4, Batch: 562, Loss: 0.2665683925151825\n",
      "Epoch: 4, Batch: 563, Loss: 2.205420970916748\n",
      "Epoch: 4, Batch: 564, Loss: 1.2512712478637695\n",
      "Epoch: 4, Batch: 565, Loss: 1.1221723556518555\n",
      "Epoch: 4, Batch: 566, Loss: 1.5463614463806152\n",
      "Epoch: 4, Batch: 567, Loss: 0.6967236399650574\n",
      "Epoch: 4, Batch: 568, Loss: 2.0778417587280273\n",
      "Epoch: 4, Batch: 569, Loss: 0.896252453327179\n",
      "Epoch: 4, Batch: 570, Loss: 2.7049806118011475\n",
      "Epoch: 4, Batch: 571, Loss: 2.3772668838500977\n",
      "Epoch: 4, Batch: 572, Loss: 1.594878911972046\n",
      "Epoch: 4, Batch: 573, Loss: 0.03530582785606384\n",
      "Epoch: 4, Batch: 574, Loss: 1.1979717016220093\n",
      "Epoch: 4, Batch: 575, Loss: 2.1784777641296387\n",
      "Epoch: 4, Batch: 576, Loss: 0.8086119890213013\n",
      "Epoch: 4, Batch: 577, Loss: 4.170422077178955\n",
      "Epoch: 4, Batch: 578, Loss: 0.9976590275764465\n",
      "Epoch: 4, Batch: 579, Loss: 3.2387075424194336\n",
      "Epoch: 4, Batch: 580, Loss: 2.4825291633605957\n",
      "Epoch: 4, Batch: 581, Loss: 0.6791795492172241\n",
      "Epoch: 4, Batch: 582, Loss: 2.1861517429351807\n",
      "Epoch: 4, Batch: 583, Loss: 0.8192887306213379\n",
      "Epoch: 4, Batch: 584, Loss: 1.0312151908874512\n",
      "Epoch: 4, Batch: 585, Loss: 0.2581266164779663\n",
      "Epoch: 4, Batch: 586, Loss: 1.9690892696380615\n",
      "Epoch: 4, Batch: 587, Loss: 3.959988832473755\n",
      "Epoch: 4, Batch: 588, Loss: 1.1627426147460938\n",
      "Epoch: 4, Batch: 589, Loss: 0.9550209045410156\n",
      "Epoch: 4, Batch: 590, Loss: 1.1422243118286133\n",
      "Epoch: 4, Batch: 591, Loss: 1.8798943758010864\n",
      "Epoch: 4, Batch: 592, Loss: 2.2153377532958984\n",
      "Epoch: 4, Batch: 593, Loss: 0.9196590781211853\n",
      "Epoch: 4, Batch: 594, Loss: 0.502430260181427\n",
      "Epoch: 4, Batch: 595, Loss: 2.0992753505706787\n",
      "Epoch: 4, Batch: 596, Loss: 2.7037458419799805\n",
      "Epoch: 4, Batch: 597, Loss: 1.629960298538208\n",
      "Epoch: 4, Batch: 598, Loss: 1.4349393844604492\n",
      "Epoch: 4, Batch: 599, Loss: 0.7830544710159302\n",
      "Epoch: 4, Batch: 600, Loss: 1.0696502923965454\n",
      "Epoch: 4, Batch: 601, Loss: 1.120530366897583\n",
      "Epoch: 4, Batch: 602, Loss: 2.748873710632324\n",
      "Epoch: 4, Batch: 603, Loss: 0.49685579538345337\n",
      "Epoch: 4, Batch: 604, Loss: 2.5183770656585693\n",
      "Epoch: 4, Batch: 605, Loss: 1.7068167924880981\n",
      "Epoch: 4, Batch: 606, Loss: 0.28942108154296875\n",
      "Epoch: 4, Batch: 607, Loss: 1.0622721910476685\n",
      "Epoch: 4, Batch: 608, Loss: 2.3470659255981445\n",
      "Epoch: 4, Batch: 609, Loss: 1.8643791675567627\n",
      "Epoch: 4, Batch: 610, Loss: 2.1686949729919434\n",
      "Epoch: 4, Batch: 611, Loss: 1.5092847347259521\n",
      "Epoch: 4, Batch: 612, Loss: 0.610522449016571\n",
      "Epoch: 4, Batch: 613, Loss: 0.5810770988464355\n",
      "Epoch: 4, Batch: 614, Loss: 0.1797858327627182\n",
      "Epoch: 4, Batch: 615, Loss: 2.224374532699585\n",
      "Epoch: 4, Batch: 616, Loss: 0.6821191906929016\n",
      "Epoch: 4, Batch: 617, Loss: 0.5490275621414185\n",
      "Epoch: 4, Batch: 618, Loss: 1.5853005647659302\n",
      "Epoch: 4, Batch: 619, Loss: 0.7751102447509766\n",
      "Epoch: 4, Batch: 620, Loss: 1.5100491046905518\n",
      "Epoch: 4, Batch: 621, Loss: 2.0758771896362305\n",
      "Epoch: 4, Batch: 622, Loss: 0.8182620406150818\n",
      "Epoch: 4, Batch: 623, Loss: 1.6252107620239258\n",
      "Epoch: 4, Batch: 624, Loss: 1.4956494569778442\n",
      "Epoch: 4, Batch: 625, Loss: 2.4235610961914062\n",
      "Epoch: 4, Batch: 626, Loss: 0.7083889245986938\n",
      "Epoch: 4, Batch: 627, Loss: 4.434683799743652\n",
      "Epoch: 4, Batch: 628, Loss: 1.569833755493164\n",
      "Epoch: 4, Batch: 629, Loss: 0.3197258710861206\n",
      "Epoch: 4, Batch: 630, Loss: 0.24785782396793365\n",
      "Epoch: 4, Batch: 631, Loss: 2.3243725299835205\n",
      "Epoch: 4, Batch: 632, Loss: 1.8131766319274902\n",
      "Epoch: 4, Batch: 633, Loss: 1.5241066217422485\n",
      "Epoch: 4, Batch: 634, Loss: 0.7564153075218201\n",
      "Epoch: 4, Batch: 635, Loss: 4.213630199432373\n",
      "Epoch: 4, Batch: 636, Loss: 1.7354429960250854\n",
      "Epoch: 4, Batch: 637, Loss: 2.236180067062378\n",
      "Epoch: 4, Batch: 638, Loss: 2.3404464721679688\n",
      "Epoch: 4, Batch: 639, Loss: 0.2544322609901428\n",
      "Epoch: 4, Batch: 640, Loss: 0.030533134937286377\n",
      "Epoch: 4, Batch: 641, Loss: 1.3329778909683228\n",
      "Epoch: 4, Batch: 642, Loss: 0.7598786354064941\n",
      "Epoch: 4, Batch: 643, Loss: 2.8329503536224365\n",
      "Epoch: 4, Batch: 644, Loss: 1.7117023468017578\n",
      "Epoch: 4, Batch: 645, Loss: 2.517240285873413\n",
      "Epoch: 4, Batch: 646, Loss: 4.634306907653809\n",
      "Epoch: 4, Batch: 647, Loss: 1.9096896648406982\n",
      "Epoch: 4, Batch: 648, Loss: 1.3981412649154663\n",
      "Epoch: 4, Batch: 649, Loss: 1.8730368614196777\n",
      "Epoch: 4, Batch: 650, Loss: 3.1769797801971436\n",
      "Epoch: 4, Batch: 651, Loss: 2.392169237136841\n",
      "Epoch: 4, Batch: 652, Loss: 3.9487476348876953\n",
      "Epoch: 4, Batch: 653, Loss: 1.5355181694030762\n",
      "Epoch: 4, Batch: 654, Loss: 3.3639583587646484\n",
      "Epoch: 4, Batch: 655, Loss: 0.49285805225372314\n",
      "Epoch: 4, Batch: 656, Loss: 2.994692325592041\n",
      "Epoch: 4, Batch: 657, Loss: 0.15246693789958954\n",
      "Epoch: 4, Batch: 658, Loss: 1.573615312576294\n",
      "Epoch: 4, Batch: 659, Loss: 4.568971157073975\n",
      "Epoch: 4, Batch: 660, Loss: 3.1618850231170654\n",
      "Epoch: 4, Batch: 661, Loss: 0.7474323511123657\n",
      "Epoch: 4, Batch: 662, Loss: 0.20529909431934357\n",
      "Epoch: 4, Batch: 663, Loss: 2.3640127182006836\n",
      "Epoch: 4, Batch: 664, Loss: 2.599005699157715\n",
      "Epoch: 4, Batch: 665, Loss: 2.750869035720825\n",
      "Epoch: 4, Batch: 666, Loss: 0.14593413472175598\n",
      "Epoch: 4, Batch: 667, Loss: 2.2900748252868652\n",
      "Epoch: 4, Batch: 668, Loss: 2.736158609390259\n",
      "Epoch: 4, Batch: 669, Loss: 2.271315097808838\n",
      "Epoch: 4, Batch: 670, Loss: 4.837099552154541\n",
      "Epoch: 4, Batch: 671, Loss: 2.171652317047119\n",
      "Epoch: 4, Batch: 672, Loss: 1.4188816547393799\n",
      "Epoch: 4, Batch: 673, Loss: 1.1548056602478027\n",
      "Epoch: 4, Batch: 674, Loss: 1.483167052268982\n",
      "Epoch: 4, Batch: 675, Loss: 0.35879096388816833\n",
      "Epoch: 4, Batch: 676, Loss: 0.9853559136390686\n",
      "Epoch: 4, Batch: 677, Loss: 2.5096659660339355\n",
      "Epoch: 4, Batch: 678, Loss: 1.0085361003875732\n",
      "Epoch: 4, Batch: 679, Loss: 1.5115138292312622\n",
      "Epoch: 4, Batch: 680, Loss: 1.4418057203292847\n",
      "Epoch: 4, Batch: 681, Loss: 1.2191462516784668\n",
      "Epoch: 4, Batch: 682, Loss: 1.9809179306030273\n",
      "Epoch: 4, Batch: 683, Loss: 0.7262132167816162\n",
      "Epoch: 4, Batch: 684, Loss: 0.6521079540252686\n",
      "Epoch: 4, Batch: 685, Loss: 0.8380369544029236\n",
      "Epoch: 4, Batch: 686, Loss: 2.533637762069702\n",
      "Epoch: 4, Batch: 687, Loss: 1.1434104442596436\n",
      "Epoch: 4, Batch: 688, Loss: 1.9859113693237305\n",
      "Epoch: 4, Batch: 689, Loss: 1.3554987907409668\n",
      "Epoch: 4, Batch: 690, Loss: 3.2291650772094727\n",
      "Epoch: 4, Batch: 691, Loss: 0.9718900918960571\n",
      "Epoch: 4, Batch: 692, Loss: 0.04391929507255554\n",
      "Epoch: 4, Batch: 693, Loss: 0.9655582308769226\n",
      "Epoch: 4, Batch: 694, Loss: 0.5229994058609009\n",
      "Epoch: 4, Batch: 695, Loss: 1.0051016807556152\n",
      "Epoch: 4, Batch: 696, Loss: 2.43394136428833\n",
      "Epoch: 4, Batch: 697, Loss: 0.6676687598228455\n",
      "Epoch: 4, Batch: 698, Loss: 1.2954928874969482\n",
      "Epoch: 4, Batch: 699, Loss: 0.20294147729873657\n",
      "Epoch: 4, Batch: 700, Loss: 3.647385835647583\n",
      "Epoch: 4, Batch: 701, Loss: 3.072361469268799\n",
      "Epoch: 4, Batch: 702, Loss: 1.4948656558990479\n",
      "Epoch: 4, Batch: 703, Loss: 0.016014765948057175\n",
      "Epoch: 4, Batch: 704, Loss: 3.7047948837280273\n",
      "Epoch: 4, Batch: 705, Loss: 0.04841913655400276\n",
      "Epoch: 4, Batch: 706, Loss: 1.2223533391952515\n",
      "Epoch: 4, Batch: 707, Loss: 0.9176062941551208\n",
      "Epoch: 4, Batch: 708, Loss: 0.7477625608444214\n",
      "Epoch: 4, Batch: 709, Loss: 5.757885932922363\n",
      "Epoch: 4, Batch: 710, Loss: 0.5695186853408813\n",
      "Epoch: 4, Batch: 711, Loss: 0.932166576385498\n",
      "Epoch: 4, Batch: 712, Loss: 0.20753787457942963\n",
      "Epoch: 4, Batch: 713, Loss: 1.1099196672439575\n",
      "Epoch: 4, Batch: 714, Loss: 1.7437975406646729\n",
      "Epoch: 4, Batch: 715, Loss: 0.6379599571228027\n",
      "Epoch: 4, Batch: 716, Loss: 3.744145393371582\n",
      "Epoch: 4, Batch: 717, Loss: 0.9975718259811401\n",
      "Epoch: 4, Batch: 718, Loss: 2.313135862350464\n",
      "Epoch: 4, Batch: 719, Loss: 1.390383005142212\n",
      "Epoch: 4, Batch: 720, Loss: 1.008474349975586\n",
      "Epoch: 4, Batch: 721, Loss: 1.6462231874465942\n",
      "Epoch: 4, Batch: 722, Loss: 0.7343019843101501\n",
      "Epoch: 4, Batch: 723, Loss: 1.7279891967773438\n",
      "Epoch: 4, Batch: 724, Loss: 1.6241648197174072\n",
      "Epoch: 4, Batch: 725, Loss: 0.5087746381759644\n",
      "Epoch: 4, Batch: 726, Loss: 1.6219885349273682\n",
      "Epoch: 4, Batch: 727, Loss: 2.2357470989227295\n",
      "Epoch: 4, Batch: 728, Loss: 1.2789034843444824\n",
      "Epoch: 4, Batch: 729, Loss: 0.46098464727401733\n",
      "Epoch: 4, Batch: 730, Loss: 0.9892336130142212\n",
      "Epoch: 4, Batch: 731, Loss: 2.927048921585083\n",
      "Epoch: 4, Batch: 732, Loss: 0.535406231880188\n",
      "Epoch: 4, Batch: 733, Loss: 1.5573997497558594\n",
      "Epoch: 4, Batch: 734, Loss: 2.9624037742614746\n",
      "Epoch: 4, Batch: 735, Loss: 0.023270323872566223\n",
      "Epoch: 4, Batch: 736, Loss: 0.9115628600120544\n",
      "Epoch: 4, Batch: 737, Loss: 1.6452312469482422\n",
      "Epoch: 4, Batch: 738, Loss: 0.49243319034576416\n",
      "Epoch: 4, Batch: 739, Loss: 1.138695240020752\n",
      "Epoch: 4, Batch: 740, Loss: 0.291002094745636\n",
      "Epoch: 4, Batch: 741, Loss: 0.7407630681991577\n",
      "Epoch: 4, Batch: 742, Loss: 0.18773046135902405\n",
      "Epoch: 4, Batch: 743, Loss: 1.3508219718933105\n",
      "Epoch: 4, Batch: 744, Loss: 2.1383261680603027\n",
      "Epoch: 4, Batch: 745, Loss: 1.505618929862976\n",
      "Epoch: 4, Batch: 746, Loss: 0.4332813024520874\n",
      "Epoch: 4, Batch: 747, Loss: 2.6277356147766113\n",
      "Epoch: 4, Batch: 748, Loss: 2.252163887023926\n",
      "Epoch: 4, Batch: 749, Loss: 2.101215362548828\n",
      "Epoch: 4, Batch: 750, Loss: 2.119351387023926\n",
      "Epoch: 4, Batch: 751, Loss: 1.0317661762237549\n",
      "Epoch: 4, Batch: 752, Loss: 0.7062830924987793\n",
      "Epoch: 4, Batch: 753, Loss: 0.057419635355472565\n",
      "Epoch: 4, Batch: 754, Loss: 1.4710242748260498\n",
      "Epoch: 4, Batch: 755, Loss: 0.5752912163734436\n",
      "Epoch: 4, Batch: 756, Loss: 3.0667946338653564\n",
      "Epoch: 4, Batch: 757, Loss: 1.4247392416000366\n",
      "Epoch: 4, Batch: 758, Loss: 1.3077784776687622\n",
      "Epoch: 4, Batch: 759, Loss: 3.381173849105835\n",
      "Epoch: 4, Batch: 760, Loss: 2.627696990966797\n",
      "Epoch: 4, Batch: 761, Loss: 0.5057941675186157\n",
      "Epoch: 4, Batch: 762, Loss: 1.0938314199447632\n",
      "Epoch: 4, Batch: 763, Loss: 2.1269404888153076\n",
      "Epoch: 4, Batch: 764, Loss: 2.673046112060547\n",
      "Epoch: 4, Batch: 765, Loss: 2.194840431213379\n",
      "Epoch: 4, Batch: 766, Loss: 1.190177083015442\n",
      "Epoch: 4, Batch: 767, Loss: 0.7996872663497925\n",
      "Epoch: 4, Batch: 768, Loss: 1.0380561351776123\n",
      "Epoch: 4, Batch: 769, Loss: 1.5470696687698364\n",
      "Epoch: 4, Batch: 770, Loss: 0.9305325150489807\n",
      "Epoch: 4, Batch: 771, Loss: 2.3463120460510254\n",
      "Epoch: 4, Batch: 772, Loss: 0.9833487272262573\n",
      "Epoch: 4, Batch: 773, Loss: 1.3229560852050781\n",
      "Epoch: 4, Batch: 774, Loss: 3.0159497261047363\n",
      "Epoch: 4, Batch: 775, Loss: 0.954224169254303\n",
      "Epoch: 4, Batch: 776, Loss: 1.328812837600708\n",
      "Epoch: 4, Batch: 777, Loss: 0.22499720752239227\n",
      "Epoch: 4, Batch: 778, Loss: 1.4442569017410278\n",
      "Epoch: 4, Batch: 779, Loss: 1.190388560295105\n",
      "Epoch: 4, Batch: 780, Loss: 0.811820924282074\n",
      "Epoch: 4, Batch: 781, Loss: 3.989877462387085\n",
      "Epoch: 4, Batch: 782, Loss: 2.646653890609741\n",
      "Epoch: 4, Batch: 783, Loss: 1.1657559871673584\n",
      "Epoch: 4, Batch: 784, Loss: 0.26050394773483276\n",
      "Epoch: 4, Batch: 785, Loss: 0.6248255372047424\n",
      "Epoch: 4, Batch: 786, Loss: 0.19066080451011658\n",
      "Epoch: 4, Batch: 787, Loss: 2.3838491439819336\n",
      "Epoch: 4, Batch: 788, Loss: 2.4636142253875732\n",
      "Epoch: 4, Batch: 789, Loss: 0.906883180141449\n",
      "Epoch: 4, Batch: 790, Loss: 2.0300776958465576\n",
      "Epoch: 4, Batch: 791, Loss: 0.7665907144546509\n",
      "Epoch: 4, Batch: 792, Loss: 0.9852609634399414\n",
      "Epoch: 4, Batch: 793, Loss: 1.9987471103668213\n",
      "Epoch: 4, Batch: 794, Loss: 1.3966838121414185\n",
      "Epoch: 4, Batch: 795, Loss: 1.1797064542770386\n",
      "Epoch: 4, Batch: 796, Loss: 2.907309055328369\n",
      "Epoch: 4, Batch: 797, Loss: 0.8233017325401306\n",
      "Epoch: 4, Batch: 798, Loss: 2.5836801528930664\n",
      "Epoch: 4, Batch: 799, Loss: 1.1727100610733032\n",
      "Epoch: 4, Batch: 800, Loss: 2.9025626182556152\n",
      "Epoch: 4, Batch: 801, Loss: 3.4488322734832764\n",
      "Epoch: 4, Batch: 802, Loss: 1.6101510524749756\n",
      "Epoch: 4, Batch: 803, Loss: 1.526941180229187\n",
      "Epoch: 4, Batch: 804, Loss: 1.0750207901000977\n",
      "Epoch: 4, Batch: 805, Loss: 1.7879081964492798\n",
      "Epoch: 4, Batch: 806, Loss: 0.6510847210884094\n",
      "Epoch: 4, Batch: 807, Loss: 1.2361167669296265\n",
      "Epoch: 4, Batch: 808, Loss: 2.9458301067352295\n",
      "Epoch: 4, Batch: 809, Loss: 2.99605655670166\n",
      "Epoch: 4, Batch: 810, Loss: 1.4675984382629395\n",
      "Epoch: 4, Batch: 811, Loss: 0.9542481303215027\n",
      "Epoch: 4, Batch: 812, Loss: 0.5575481653213501\n",
      "Epoch: 4, Batch: 813, Loss: 0.9559205770492554\n",
      "Epoch: 4, Batch: 814, Loss: 0.5951218605041504\n",
      "Epoch: 4, Batch: 815, Loss: 3.276179552078247\n",
      "Epoch: 4, Batch: 816, Loss: 1.7126847505569458\n",
      "Epoch: 4, Batch: 817, Loss: 0.3032107353210449\n",
      "Epoch: 4, Batch: 818, Loss: 1.027877926826477\n",
      "Epoch: 4, Batch: 819, Loss: 6.379192352294922\n",
      "Epoch: 4, Batch: 820, Loss: 1.947761058807373\n",
      "Epoch: 4, Batch: 821, Loss: 2.0066511631011963\n",
      "Epoch: 4, Batch: 822, Loss: 0.8024888038635254\n",
      "Epoch: 4, Batch: 823, Loss: 2.8264589309692383\n",
      "Epoch: 4, Batch: 824, Loss: 0.8213909864425659\n",
      "Epoch: 4, Batch: 825, Loss: 0.3657718896865845\n",
      "Epoch: 4, Batch: 826, Loss: 3.391244649887085\n",
      "Epoch: 4, Batch: 827, Loss: 1.035412311553955\n",
      "Epoch: 4, Batch: 828, Loss: 1.0930942296981812\n",
      "Epoch: 4, Batch: 829, Loss: 2.118544101715088\n",
      "Epoch: 4, Batch: 830, Loss: 1.7841670513153076\n",
      "Epoch: 4, Batch: 831, Loss: 2.371792793273926\n",
      "Epoch: 4, Batch: 832, Loss: 1.9374113082885742\n",
      "Epoch: 4, Batch: 833, Loss: 2.7343125343322754\n",
      "Epoch: 4, Batch: 834, Loss: 0.6213313937187195\n",
      "Epoch: 4, Batch: 835, Loss: 2.9142215251922607\n",
      "Epoch: 4, Batch: 836, Loss: 0.33815011382102966\n",
      "Epoch: 4, Batch: 837, Loss: 0.1228385865688324\n",
      "Epoch: 4, Batch: 838, Loss: 0.7061631679534912\n",
      "Epoch: 4, Batch: 839, Loss: 1.3190150260925293\n",
      "Epoch: 4, Batch: 840, Loss: 1.953853964805603\n",
      "Epoch: 4, Batch: 841, Loss: 1.902726173400879\n",
      "Epoch: 4, Batch: 842, Loss: 1.8395684957504272\n",
      "Epoch: 4, Batch: 843, Loss: 1.6248046159744263\n",
      "Epoch: 4, Batch: 844, Loss: 1.2080544233322144\n",
      "Epoch: 4, Batch: 845, Loss: 2.1301605701446533\n",
      "Epoch: 4, Batch: 846, Loss: 1.5008234977722168\n",
      "Epoch: 4, Batch: 847, Loss: 1.5840413570404053\n",
      "Epoch: 4, Batch: 848, Loss: 0.6774940490722656\n",
      "Epoch: 4, Batch: 849, Loss: 0.08612272143363953\n",
      "Epoch: 4, Batch: 850, Loss: 1.103498101234436\n",
      "Epoch: 4, Batch: 851, Loss: 1.0889338254928589\n",
      "Epoch: 4, Batch: 852, Loss: 2.8320021629333496\n",
      "Epoch: 4, Batch: 853, Loss: 1.0198792219161987\n",
      "Epoch: 4, Batch: 854, Loss: 1.4491853713989258\n",
      "Epoch: 4, Batch: 855, Loss: 0.8601875305175781\n",
      "Epoch: 4, Batch: 856, Loss: 1.2583765983581543\n",
      "Epoch: 4, Batch: 857, Loss: 2.0589566230773926\n",
      "Epoch: 4, Batch: 858, Loss: 2.4652419090270996\n",
      "Epoch: 4, Batch: 859, Loss: 1.1959407329559326\n",
      "Epoch: 4, Batch: 860, Loss: 2.1022582054138184\n",
      "Epoch: 4, Batch: 861, Loss: 1.7664709091186523\n",
      "Epoch: 4, Batch: 862, Loss: 1.5360256433486938\n",
      "Epoch: 4, Batch: 863, Loss: 0.4250546991825104\n",
      "Epoch: 4, Batch: 864, Loss: 1.458021640777588\n",
      "Epoch: 4, Batch: 865, Loss: 0.17825867235660553\n",
      "Epoch: 4, Batch: 866, Loss: 1.4792159795761108\n",
      "Epoch: 4, Batch: 867, Loss: 2.2081546783447266\n",
      "Epoch: 4, Batch: 868, Loss: 0.6865675449371338\n",
      "Epoch: 4, Batch: 869, Loss: 0.6588072776794434\n",
      "Epoch: 4, Batch: 870, Loss: 2.7059688568115234\n",
      "Epoch: 4, Batch: 871, Loss: 1.3500655889511108\n",
      "Epoch: 4, Batch: 872, Loss: 1.63187575340271\n",
      "Epoch: 4, Batch: 873, Loss: 0.824234664440155\n",
      "Epoch: 4, Batch: 874, Loss: 1.49101984500885\n",
      "Epoch: 4, Batch: 875, Loss: 2.6315858364105225\n",
      "Epoch: 4, Batch: 876, Loss: 0.7051830291748047\n",
      "Epoch: 4, Batch: 877, Loss: 1.3816320896148682\n",
      "Epoch: 4, Batch: 878, Loss: 1.3813003301620483\n",
      "Epoch: 4, Batch: 879, Loss: 3.688969612121582\n",
      "Epoch: 4, Batch: 880, Loss: 0.3460991084575653\n",
      "Epoch: 4, Batch: 881, Loss: 1.6361066102981567\n",
      "Epoch: 4, Batch: 882, Loss: 2.6414742469787598\n",
      "Epoch: 4, Batch: 883, Loss: 1.7071712017059326\n",
      "Epoch: 4, Batch: 884, Loss: 1.1351276636123657\n",
      "Epoch: 4, Batch: 885, Loss: 2.833461284637451\n",
      "Epoch: 4, Batch: 886, Loss: 3.0837624073028564\n",
      "Epoch: 4, Batch: 887, Loss: 2.7466800212860107\n",
      "Epoch: 4, Batch: 888, Loss: 0.5775122046470642\n",
      "Epoch: 4, Batch: 889, Loss: 2.0566272735595703\n",
      "Epoch: 4, Batch: 890, Loss: 1.2316778898239136\n",
      "Epoch: 4, Batch: 891, Loss: 1.6334949731826782\n",
      "Epoch: 4, Batch: 892, Loss: 1.6893587112426758\n",
      "Epoch: 4, Batch: 893, Loss: 0.18156589567661285\n",
      "Epoch: 4, Batch: 894, Loss: 0.8115035891532898\n",
      "Epoch: 4, Batch: 895, Loss: 0.8260225653648376\n",
      "Epoch: 4, Batch: 896, Loss: 1.4675469398498535\n",
      "Epoch: 4, Batch: 897, Loss: 3.011593818664551\n",
      "Epoch: 4, Batch: 898, Loss: 1.0548810958862305\n",
      "Epoch: 4, Batch: 899, Loss: 1.4055943489074707\n",
      "Epoch: 4, Batch: 900, Loss: 0.7939398884773254\n",
      "Epoch: 4, Batch: 901, Loss: 2.6465327739715576\n",
      "Epoch: 4, Batch: 902, Loss: 0.4484466314315796\n",
      "Epoch: 4, Batch: 903, Loss: 2.6600096225738525\n",
      "Epoch: 4, Batch: 904, Loss: 2.619168281555176\n",
      "Epoch: 4, Batch: 905, Loss: 1.1714284420013428\n",
      "Epoch: 4, Batch: 906, Loss: 2.5166969299316406\n",
      "Epoch: 4, Batch: 907, Loss: 1.708100438117981\n",
      "Epoch: 4, Batch: 908, Loss: 0.9648339748382568\n",
      "Epoch: 4, Batch: 909, Loss: 2.7380270957946777\n",
      "Epoch: 4, Batch: 910, Loss: 1.8246006965637207\n",
      "Epoch: 4, Batch: 911, Loss: 1.7669317722320557\n",
      "Epoch: 4, Batch: 912, Loss: 2.6408448219299316\n",
      "Epoch: 4, Batch: 913, Loss: 2.6809487342834473\n",
      "Epoch: 4, Batch: 914, Loss: 1.1435201168060303\n",
      "Epoch: 4, Batch: 915, Loss: 1.374982476234436\n",
      "Epoch: 4, Batch: 916, Loss: 1.1846071481704712\n",
      "Epoch: 4, Batch: 917, Loss: 4.585263252258301\n",
      "Epoch: 4, Batch: 918, Loss: 0.5292001962661743\n",
      "Epoch: 4, Batch: 919, Loss: 1.966500997543335\n",
      "Epoch: 4, Batch: 920, Loss: 0.699956476688385\n",
      "Epoch: 4, Batch: 921, Loss: 1.6449933052062988\n",
      "Epoch: 4, Batch: 922, Loss: 1.5167737007141113\n",
      "Epoch: 4, Batch: 923, Loss: 1.283623456954956\n",
      "Epoch: 4, Batch: 924, Loss: 1.114351749420166\n",
      "Epoch: 4, Batch: 925, Loss: 1.4444334506988525\n",
      "Epoch: 4, Batch: 926, Loss: 0.9468948245048523\n",
      "Epoch: 4, Batch: 927, Loss: 1.7432317733764648\n",
      "Epoch: 4, Batch: 928, Loss: 3.4420833587646484\n",
      "Epoch: 4, Batch: 929, Loss: 1.7330152988433838\n",
      "Epoch: 4, Batch: 930, Loss: 2.2341487407684326\n",
      "Epoch: 4, Batch: 931, Loss: 0.7207551598548889\n",
      "Epoch: 4, Batch: 932, Loss: 2.0083298683166504\n",
      "Epoch: 4, Batch: 933, Loss: 0.41802820563316345\n",
      "Epoch: 4, Batch: 934, Loss: 0.04438314214348793\n",
      "Epoch: 4, Batch: 935, Loss: 3.0180540084838867\n",
      "Epoch: 4, Batch: 936, Loss: 1.5513107776641846\n",
      "Epoch: 4, Batch: 937, Loss: 1.1686580181121826\n",
      "Epoch: 4, Batch: 938, Loss: 0.05219002068042755\n",
      "Epoch: 4, Batch: 939, Loss: 1.52173912525177\n",
      "Epoch: 4, Batch: 940, Loss: 1.343027114868164\n",
      "Epoch: 4, Batch: 941, Loss: 0.44591814279556274\n",
      "Epoch: 4, Batch: 942, Loss: 1.7535502910614014\n",
      "Epoch: 4, Batch: 943, Loss: 1.6197513341903687\n",
      "Epoch: 4, Batch: 944, Loss: 2.060525894165039\n",
      "Epoch: 4, Batch: 945, Loss: 0.6657856702804565\n",
      "Epoch: 4, Batch: 946, Loss: 2.099116325378418\n",
      "Epoch: 4, Batch: 947, Loss: 0.0493939071893692\n",
      "Epoch: 4, Batch: 948, Loss: 1.2216295003890991\n",
      "Epoch: 4, Batch: 949, Loss: 1.1217650175094604\n",
      "Epoch: 4, Batch: 950, Loss: 1.3853651285171509\n",
      "Epoch: 4, Batch: 951, Loss: 0.2827918231487274\n",
      "Epoch: 4, Batch: 952, Loss: 1.9082221984863281\n",
      "Epoch: 4, Batch: 953, Loss: 2.2182750701904297\n",
      "Epoch: 4, Batch: 954, Loss: 1.2137123346328735\n",
      "Epoch: 4, Batch: 955, Loss: 1.1225348711013794\n",
      "Epoch: 4, Batch: 956, Loss: 0.5075778365135193\n",
      "Epoch: 4, Batch: 957, Loss: 0.8406338095664978\n",
      "Epoch: 4, Batch: 958, Loss: 1.4864476919174194\n",
      "Epoch: 4, Batch: 959, Loss: 3.279236316680908\n",
      "Epoch: 4, Batch: 960, Loss: 0.8417110443115234\n",
      "Epoch: 4, Batch: 961, Loss: 0.564048171043396\n",
      "Epoch: 4, Batch: 962, Loss: 1.2922956943511963\n",
      "Epoch: 4, Batch: 963, Loss: 2.607937812805176\n",
      "Epoch: 4, Batch: 964, Loss: 1.4640922546386719\n",
      "Epoch: 4, Batch: 965, Loss: 2.240619421005249\n",
      "Epoch: 4, Batch: 966, Loss: 2.078701972961426\n",
      "Epoch: 4, Batch: 967, Loss: 1.0701037645339966\n",
      "Epoch: 4, Batch: 968, Loss: 1.953171730041504\n",
      "Epoch: 4, Batch: 969, Loss: 0.5091614723205566\n",
      "Epoch: 4, Batch: 970, Loss: 0.7164430618286133\n",
      "Epoch: 4, Batch: 971, Loss: 0.11916965991258621\n",
      "Epoch: 4, Batch: 972, Loss: 4.2796783447265625\n",
      "Epoch: 4, Batch: 973, Loss: 2.2887542247772217\n",
      "Epoch: 4, Batch: 974, Loss: 0.1502920389175415\n",
      "Epoch: 4, Batch: 975, Loss: 1.5980968475341797\n",
      "Epoch: 4, Batch: 976, Loss: 1.8787113428115845\n",
      "Epoch: 4, Batch: 977, Loss: 0.7909097671508789\n",
      "Epoch: 4, Batch: 978, Loss: 1.5013139247894287\n",
      "Epoch: 4, Batch: 979, Loss: 1.546630859375\n",
      "Epoch: 4, Batch: 980, Loss: 1.8694541454315186\n",
      "Epoch: 4, Batch: 981, Loss: 1.5588217973709106\n",
      "Epoch: 4, Batch: 982, Loss: 1.2662700414657593\n",
      "Epoch: 4, Batch: 983, Loss: 1.1894903182983398\n",
      "Epoch: 4, Batch: 984, Loss: 0.7469619512557983\n",
      "Epoch: 4, Batch: 985, Loss: 1.494138240814209\n",
      "Epoch: 4, Batch: 986, Loss: 0.12234222888946533\n",
      "Epoch: 4, Batch: 987, Loss: 1.2573421001434326\n",
      "Epoch: 4, Batch: 988, Loss: 1.7486774921417236\n",
      "Epoch: 4, Batch: 989, Loss: 2.3009676933288574\n",
      "Epoch: 4, Batch: 990, Loss: 2.849189519882202\n",
      "Epoch: 4, Batch: 991, Loss: 4.574223041534424\n",
      "Epoch: 4, Batch: 992, Loss: 0.7809115052223206\n",
      "Epoch: 4, Batch: 993, Loss: 0.7484623789787292\n",
      "Epoch: 4, Batch: 994, Loss: 1.064824104309082\n",
      "Epoch: 4, Batch: 995, Loss: 1.9640421867370605\n",
      "Epoch: 4, Batch: 996, Loss: 1.9286190271377563\n",
      "Epoch: 4, Batch: 997, Loss: 0.9263015389442444\n",
      "Epoch: 4, Batch: 998, Loss: 0.8298439979553223\n",
      "Epoch: 4, Batch: 999, Loss: 2.2920310497283936\n",
      "Accuracy: 0.0885\n"
     ]
    }
   ],
   "source": [
    "class ParamsDownloader:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.ln1b = np.load(f'{self.data_path}/ln1b.npy')\n",
    "        self.ln1w = np.load(f'{self.data_path}/ln1w.npy')\n",
    "        self.ln2b = np.load(f'{self.data_path}/ln2b.npy')\n",
    "        self.ln2w = np.load(f'{self.data_path}/ln2w.npy')\n",
    "        \n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ln1w, ln1b, ln2w, ln2b):\n",
    "        super(Model, self).__init__()\n",
    "        N, H1 = ln1w.shape\n",
    "        H2, _ = ln2w.shape\n",
    "        \n",
    "        self.l1 = nn.Linear(N, H1)\n",
    "        self.l1.weight.data = torch.from_numpy(ln1w).float()\n",
    "        self.l1.bias.data = torch.from_numpy(ln1b).float()\n",
    "\n",
    "        self.l2 = nn.Linear(H1, H2)\n",
    "        self.l2.weight.data = torch.from_numpy(ln2w).float()\n",
    "        self.l2.bias.data = torch.from_numpy(ln2b).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.l1(x)\n",
    "        y1_relu = F.relu(y1)\n",
    "        y2 = self.l2(y1_relu)\n",
    "        return y1, y1_relu, y2\n",
    "    \n",
    "    \n",
    "X_train = np.load('../dataset/x_train.npy')\n",
    "y_train = np.load('../dataset/y_train.npy')\n",
    "print(X_train [0,0:5])\n",
    "# X_test = np.load('../dataset/x_test.npy')\n",
    "# y_test = np.load('../dataset/y_test.npy')\n",
    "\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long()), batch_size=BATCH_SIZE, shuffle=False)\n",
    "data_loader = ParamsDownloader('../with-torch-tests/trained-model')\n",
    "model = Model(data_loader.ln1w, data_loader.ln1b, data_loader.ln2w, data_loader.ln2b)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y1, y1_relu, y2 = model(X)\n",
    "        loss = criterion(y2, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "x_test = np.load('../dataset/x_test.npy')\n",
    "y_test = np.load('../dataset/y_test.npy')\n",
    "y1, y1_relu, y2 = model(torch.from_numpy(x_test).float())\n",
    "y_pred = y2.argmax(dim=1).numpy()\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022875\n",
      "Accuracy: 0.64325\n"
     ]
    }
   ],
   "source": [
    "class ParamsDownloader:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.ln1b = np.load(f'{self.data_path}/ln1b.npy')\n",
    "        self.ln1w = np.load(f'{self.data_path}/ln1w.npy')\n",
    "        self.ln2b = np.load(f'{self.data_path}/ln2b.npy')\n",
    "        self.ln2w = np.load(f'{self.data_path}/ln2w.npy')\n",
    "        \n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        N = 130\n",
    "        H1, H2, H3 = 1024, 1024, 16\n",
    "        self.l1 = nn.Linear(N, H1)\n",
    "        self.l2 = nn.Linear(H1, H2)\n",
    "        self.l3 = nn.Linear(H2, H3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.l1(x)\n",
    "        y1_relu = F.relu(y1)\n",
    "        y2 = self.l2(y1_relu)\n",
    "        y2_relu = F.relu(y2)\n",
    "        y3 = self.l3(y2_relu)\n",
    "        return y3\n",
    "    \n",
    "    \n",
    "X_train = np.load('../dataset/x_test.npy')\n",
    "y_train = np.load('../dataset/y_test.npy')\n",
    "\n",
    "# X_test = np.load('../dataset/x_test.npy')\n",
    "# y_test = np.load('../dataset/y_test.npy')\n",
    "\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long()), batch_size=BATCH_SIZE, shuffle=False)\n",
    "model = Model()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "# data_loader = ParamsDownloader('../with-torch-tests/trained-model')\n",
    "\n",
    "x_test = np.load('../dataset/x_test.npy')\n",
    "y_test = np.load('../dataset/y_test.npy')\n",
    "y3 = model(torch.from_numpy(x_test).float())\n",
    "y_pred = y3.argmax(dim=1).numpy()\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(accuracy)\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y3 = model(X)\n",
    "        loss = criterion(y3, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "        \n",
    "\n",
    "\n",
    "x_test = np.load('../dataset/x_test.npy')\n",
    "y_test = np.load('../dataset/y_test.npy')\n",
    "y3 = model(torch.from_numpy(x_test).float())\n",
    "y_pred = y3.argmax(dim=1).numpy()\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.4500256  -4.164225    2.0214434   0.48262623  0.05314786]\n",
      "tensor([-2.4500, -4.1642,  2.0214,  0.4826,  0.0531], grad_fn=<SliceBackward0>)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# read arrays from .npy files and func Linear to compare\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "X = np.load('../with-torch-tests/linear-layer/X_C.npy')\n",
    "W = np.load('../with-torch-tests/linear-layer/W_C.npy')\n",
    "bias = np.load('../with-torch-tests/linear-layer/bias_C.npy')\n",
    "Y = np.load('../with-torch-tests/linear-layer/out_C.npy')\n",
    "B,N = X.shape\n",
    "_,M = Y.shape\n",
    "l = nn.Linear(M,N)\n",
    "l.weight.data = torch.from_numpy(W).to(torch.float32)\n",
    "l.bias.data = torch.from_numpy(bias).to(torch.float32)\n",
    "X_torch = torch.from_numpy(X).to(torch.float32)\n",
    "Y_torch = l(X_torch)\n",
    "\n",
    "print(Y[0,0:5])\n",
    "print(Y_torch[0,0:5])\n",
    "print( np.allclose(Y, Y_torch.detach().numpy(), atol=1e-4, rtol=1e-4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100) (100, 100) (100, 100) (100, 100)\n",
      "Forward pass comparison:\n",
      "Y (numpy): [0.09152496 0.         0.3774835  0.         0.59312725]\n",
      "Y_torch: [0.09152496 0.         0.3774835  0.         0.59312725]\n",
      "Match: True\n",
      "\n",
      "Backward pass comparison:\n",
      "dX (numpy): [-0.9976806   0.          0.29630423  0.         -0.45951718]\n",
      "dX_torch: [-0.9976806   0.          0.29630423  0.         -0.45951718]\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Relu forward and backward tests\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load data\n",
    "X = np.load(r'../with-torch-tests/relu-layer/X_relu.npy')\n",
    "Y = np.load(r'../with-torch-tests/relu-layer/out_relu.npy')\n",
    "dY = np.load(r'../with-torch-tests/relu-layer/up_grad_relu.npy')\n",
    "dX = np.load(r'../with-torch-tests/relu-layer/down_grad_relu.npy')\n",
    "print(X.shape, Y.shape, dY.shape, dX.shape)\n",
    "# Convert to PyTorch tensors\n",
    "# make sure to set requires_grad=True for the input tensor so that the Autograd engine can compute the gradients\n",
    "X_torch = torch.from_numpy(X).to(torch.float32).requires_grad_(True)\n",
    "dY_torch = torch.from_numpy(dY).to(torch.float32)\n",
    "\n",
    "# Forward pass with ReLU\n",
    "relu = nn.ReLU()\n",
    "Y_torch = relu(X_torch)\n",
    "\n",
    "# Compare the forward pass results\n",
    "print(\"Forward pass comparison:\")\n",
    "print(\"Y (numpy):\", Y[0, 0:5])\n",
    "print(\"Y_torch:\", Y_torch.detach().numpy()[0, 0:5])\n",
    "print(\"Match:\", np.allclose(Y, Y_torch.detach().numpy(), atol=1e-4, rtol=1e-4))\n",
    "\n",
    "\n",
    "# Validate the backward pass\n",
    "Y_torch.backward(dY_torch)\n",
    "\n",
    "# Get the gradients from X_torch\n",
    "dX_torch = X_torch.grad\n",
    "\n",
    "# Compare the backward pass results\n",
    "print(\"\\nBackward pass comparison:\")\n",
    "print(\"dX (numpy):\", dX[0, 0:5])\n",
    "print(\"dX_torch:\", dX_torch.numpy()[0, 0:5])\n",
    "print(\"Match:\", np.allclose(dX, dX_torch.numpy(), atol=1e-4, rtol=1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C = 3 x 5\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.tensor([1, 0, 4])\n",
    "print(target.dtype)\n",
    "output = loss(m(input), target)\n",
    "output.backward()\n",
    "# 2D loss example (used, for example, with image inputs)\n",
    "N, C = 5, 4\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C x height x width\n",
    "data = torch.randn(N, 16, 10, 10)\n",
    "conv = nn.Conv2d(16, C, (3, 3))\n",
    "m = nn.LogSoftmax(dim=1)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\n",
    "output = loss(m(conv(data)), target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 128) (1024, 128) (1024, 128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1024 is different from 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42400\\3849160127.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'../with-torch-tests/matmul/C.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mC_py\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC_py\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1024 is different from 128)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.load(r'../with-torch-tests/matmul/A.npy')\n",
    "B = np.load(r'../with-torch-tests/matmul/B.npy')\n",
    "C = np.load(r'../with-torch-tests/matmul/C.npy')\n",
    "print(A.shape, B.shape, C.shape)\n",
    "C_py = A @ B\n",
    "print(C[:5,:5])\n",
    "print(C_py[:5,:5])\n",
    "print(np.allclose(C, C_py, atol=1e-4, rtol=1e-4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../with-torch-tests/linear-backward/X_c.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the input data\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../with-torch-tests/linear-backward/X_c.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m W \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../with-torch-tests/linear-backward/W_c.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m bias \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../with-torch-tests/linear-backward/bias_c.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../with-torch-tests/linear-backward/X_c.npy'"
     ]
    }
   ],
   "source": [
    "# Test backward pass of the Linear layer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the input data\n",
    "X = np.load('../with-torch-tests/linear-backward/X_c.npy')\n",
    "W = np.load('../with-torch-tests/linear-backward/W_c.npy')\n",
    "bias = np.load('../with-torch-tests/linear-backward/bias_c.npy')\n",
    "upgrad = np.load('../with-torch-tests/linear-backward/up_grad.npy')\n",
    "\n",
    "\n",
    "# out to comoare to\n",
    "dLdb = np.load('../with-torch-tests/linear-backward/dLdb.npy')\n",
    "dLdW = np.load('../with-torch-tests/linear-backward/dLdW.npy')\n",
    "dLdX = np.load('../with-torch-tests/linear-backward/dLdX.npy')\n",
    "\n",
    "# get sizes\n",
    "B,N = X.shape\n",
    "M,_ = W.shape\n",
    "\n",
    "print(X.shape, W.shape, bias.shape, upgrad.shape)\n",
    "\n",
    "lin = nn.Linear(N,M)\n",
    "lin.weight.data = torch.from_numpy(W).to(torch.float32)\n",
    "lin.bias.data = torch.from_numpy(bias).to(torch.float32)\n",
    "# X must be a tensor with requires_grad=True\n",
    "X_torch = torch.from_numpy(X).to(torch.float32).requires_grad_(True)\n",
    "upgrad_torch = torch.from_numpy(upgrad).to(torch.float32)\n",
    "\n",
    "# Forward pass\n",
    "Y = lin(X_torch)\n",
    "\n",
    "# Backward pass\n",
    "Y.backward(upgrad_torch)\n",
    "\n",
    "# Get the gradients\n",
    "dLdW_torch = lin.weight.grad\n",
    "dLdb_torch = lin.bias.grad\n",
    "dLdX_torch = X_torch.grad\n",
    "\n",
    "# Compare the gradients\n",
    "# print(\"dLdW (numpy):\", dLdW[0, 0:5])\n",
    "# print(\"dLdW_torch:\", dLdW_torch.numpy()[0, 0:5])\n",
    "print(\"Match:\", np.allclose(dLdW, dLdW_torch.numpy(), atol=1e-4, rtol=1e-4))\n",
    "\n",
    "# print(\"dLdb (numpy):\", dLdb[0:10].reshape(-1, 1))\n",
    "# print(\"dLdb_torch:\", dLdb_torch.numpy()[0:10].reshape(-1, 1))\n",
    "print(\"Match:\", np.allclose(dLdb.reshape(-1, 1), dLdb_torch.numpy().reshape(-1, 1), atol=1e-2, rtol=1e-2))\n",
    "\n",
    "# print(\"dLdX (numpy):\", dLdX[0, 0:5])\n",
    "# print(\"dLdX_torch:\", dLdX_torch.numpy()[0, 0:5])\n",
    "print(\"Match:\", np.allclose(dLdX, dLdX_torch.numpy(), atol=1e-4, rtol=1e-4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
