{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      "tensor([[-0.9474, -1.1502, -1.2185],\n",
      "        [-0.7117, -1.3378, -1.3993],\n",
      "        [-0.9267, -1.1669, -1.2283],\n",
      "        [-0.8556, -1.2144, -1.2798]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Loss: 1.0035268068313599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a custom neural network class\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        \n",
    "        # Define the network layers\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) # First linear layer\n",
    "        self.activation1 = nn.ReLU() # Activation function after the first layer\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size) # Second linear layer\n",
    "        self.softmax = nn.Softmax(dim=1) # Softmax layer for the output\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) # LogSoftmax layer for the output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        x = self.logsoftmax(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "input_size = 10\n",
    "hidden_size = 5\n",
    "output_size = 3\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Create a loss function\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Create an optimizer\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define a batch of inputs and targets\n",
    "batch_size = 4\n",
    "input_data = torch.randn(batch_size, input_size) # Random input tensor with batch size\n",
    "targets = torch.randint(0, output_size, (batch_size,)) # Random target tensor for each input in the batch\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(input_data)\n",
    "\n",
    "# Compute loss\n",
    "loss = criterion(outputs, targets)\n",
    "\n",
    "# Backward pass\n",
    "# loss.backward()\n",
    "\n",
    "# Update weights\n",
    "# optimizer.step()\n",
    "\n",
    "# Optionally, print output and loss\n",
    "print(f\"Outputs:\\n{outputs}\")\n",
    "print(f\"Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random array and save it to a file .npy\n",
    "# import numpy as np\n",
    "\n",
    "# B = 1000\n",
    "# N = 100\n",
    "# M = 30\n",
    "# X = np.random.rand(B, N).astype(np.float32)\n",
    "# W = np.random.rand(M,N).astype(np.float32)\n",
    "# bias = np.random.rand(M).astype(np.float32)\n",
    "# np.save('../with-torch-tests/linear-layer/X.npy', X)\n",
    "# np.save('../with-torch-tests/linear-layer/W.npy', W)\n",
    "# np.save('../with-torch-tests/linear-layer/bias.npy', bias)\n",
    "\n",
    "# l = nn.Linear(N,M)\n",
    "# l.weight.data = torch.from_numpy(W)\n",
    "# l.bias.data = torch.from_numpy(bias)\n",
    "# X_torch = torch.from_numpy(X)\n",
    "# Y = l(X_torch)\n",
    "# np.save('../with-torch-tests/linear-layer/Y.npy', Y.detach().numpy())\n",
    "# print(Y[0,0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(176.5740, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the input data\n",
    "ln1b = np.load('../with-torch-tests/all-model-cpu/ln1b.npy')\n",
    "ln1w = np.load('../with-torch-tests/all-model-cpu/ln1w.npy')\n",
    "ln2b = np.load('../with-torch-tests/all-model-cpu/ln2b.npy')\n",
    "ln2w = np.load('../with-torch-tests/all-model-cpu/ln2w.npy')\n",
    "target = np.load('../with-torch-tests/all-model-cpu/target.npy')\n",
    "X_c = np.load('../with-torch-tests/all-model-cpu/X_c.npy')\n",
    "\n",
    "# get sizes\n",
    "B,N = X_c.shape\n",
    "H1,N = ln1w.shape\n",
    "l1 = nn.Linear(N,H1)\n",
    "l1.weight.data = torch.from_numpy(ln1w).to(torch.float32)\n",
    "l1.bias.data = torch.from_numpy(ln1b).to(torch.float32)\n",
    "\n",
    "\n",
    "H2,_ = ln2w.shape\n",
    "l2 = nn.Linear(H1,H2)\n",
    "l2.weight.data = torch.from_numpy(ln2w).to(torch.float32)\n",
    "l2.bias.data = torch.from_numpy(ln2b).to(torch.float32)\n",
    "\n",
    "X = torch.from_numpy(X_c).to(torch.float32)\n",
    "Y1 = l1(X)\n",
    "y1_relu = F.relu(Y1)\n",
    "Y2 = l2(y1_relu)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "loss = criterion(Y2, torch.from_numpy(target).long())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  354.73419189453125\n",
      "Forward\n",
      "True\n",
      "True\n",
      "True\n",
      "Back\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Updated weights\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "def pp(a1,a2):\n",
    "            print(a1[0,0:5])\n",
    "            print(a2[0,0:5])\n",
    "class DataLoaderModule:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.a1 = np.load(f'{self.data_path}/a1.npy')\n",
    "        self.da1 = np.load(f'{self.data_path}/da1.npy')\n",
    "        self.dln1 = np.load(f'{self.data_path}/dln1.npy')\n",
    "        self.dln2 = np.load(f'{self.data_path}/dln2.npy')\n",
    "        self.dsm = np.load(f'{self.data_path}/dsm.npy')\n",
    "        self.ln1 = np.load(f'{self.data_path}/ln1.npy')\n",
    "        self.ln1b_grad = np.load(f'{self.data_path}/ln1b_grad.npy')\n",
    "        self.ln1b = np.load(f'{self.data_path}/ln1b.npy')\n",
    "        self.ln1w_grad = np.load(f'{self.data_path}/ln1w_grad.npy')\n",
    "        self.ln1w = np.load(f'{self.data_path}/ln1w.npy')\n",
    "        self.ln2 = np.load(f'{self.data_path}/ln2.npy')\n",
    "        self.ln2b_grad = np.load(f'{self.data_path}/ln2b_grad.npy')\n",
    "        self.ln2b = np.load(f'{self.data_path}/ln2b.npy')\n",
    "        self.ln2w_grad = np.load(f'{self.data_path}/ln2w_grad.npy')\n",
    "        self.ln2w = np.load(f'{self.data_path}/ln2w.npy')\n",
    "        \n",
    "        # pp(self.ln1w, self.ln1w)\n",
    "        \n",
    "        self.target = np.load(f'{self.data_path}/target.npy')\n",
    "        self.X_c = np.load(f'{self.data_path}/X_c.npy')\n",
    "        self.updated_ln1b = np.load(f'{self.data_path}/updated_ln1b.npy')\n",
    "        self.updated_ln1w = np.load(f'{self.data_path}/updated_ln1w.npy')\n",
    "        self.updated_ln2b = np.load(f'{self.data_path}/updated_ln2b.npy')\n",
    "        self.updated_ln2w = np.load(f'{self.data_path}/updated_ln2w.npy')\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ln1w, ln1b, ln2w, ln2b):\n",
    "        super(Model, self).__init__()\n",
    "        N, H1 = ln1w.shape\n",
    "        H2, _ = ln2w.shape\n",
    "        \n",
    "        self.l1 = nn.Linear(N, H1)\n",
    "        self.l1.weight.data = torch.from_numpy(ln1w).float()\n",
    "        self.l1.bias.data = torch.from_numpy(ln1b).float()\n",
    "\n",
    "        self.l2 = nn.Linear(H1, H2)\n",
    "        self.l2.weight.data = torch.from_numpy(ln2w).float()\n",
    "        self.l2.bias.data = torch.from_numpy(ln2b).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.l1(x)\n",
    "        y1_relu = F.relu(y1)\n",
    "        y2 = self.l2(y1_relu)\n",
    "        return y1, y1_relu, y2\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, data_loader, criterion, optimizer):\n",
    "        self.model = model\n",
    "        self.data_loader = data_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def train(self):\n",
    "        X = torch.from_numpy(self.data_loader.X_c).float().requires_grad_(True)\n",
    "        target = torch.from_numpy(self.data_loader.target).long()\n",
    "        \n",
    "        y1, y1_relu, y2 = self.model(X)\n",
    "\n",
    "        # Retain gradients\n",
    "        y1.retain_grad()\n",
    "        y1_relu.retain_grad()\n",
    "        y2.retain_grad()\n",
    "\n",
    "        loss = self.criterion(y2, target)\n",
    "        print(\"loss \", loss.item())\n",
    "\n",
    "        # Forward pass comparison\n",
    "        print(\"Forward\")\n",
    "        print(np.allclose(y1.detach().numpy(), self.data_loader.ln1, atol=1e-6))\n",
    "        print(np.allclose(y1_relu.detach().numpy(), self.data_loader.a1, atol=1e-6))\n",
    "        print(np.allclose(y2.detach().numpy(), self.data_loader.ln2, atol=1e-4))\n",
    "\n",
    "        # Backward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Compare the gradients\n",
    "        print(\"Back\")\n",
    "        print(np.allclose(y2.grad.numpy(), self.data_loader.dsm, atol=1e-4))\n",
    "        print(np.allclose(y1_relu.grad.numpy(), self.data_loader.dln2, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.weight.grad.numpy(), self.data_loader.ln2w_grad, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.bias.grad.numpy(), self.data_loader.ln2b_grad, atol=1e-4))\n",
    "        print(np.allclose(y1.grad.numpy(), self.data_loader.da1, atol=1e-4))\n",
    "        print(np.allclose(self.model.l1.weight.grad.numpy(), self.data_loader.ln1w_grad, atol=1e-4))\n",
    "        print(np.allclose(self.model.l1.bias.grad.numpy(), self.data_loader.ln1b_grad, atol=1e-4))\n",
    "        \n",
    "        \n",
    "        # optimzer \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # print the updated weights\n",
    "        print(\"Updated weights\")\n",
    "        print(np.allclose(self.model.l1.weight.detach().numpy(), self.data_loader.updated_ln1w, atol=1e-2))\n",
    "        # print first elements in both \n",
    "        \n",
    "        # pp(self.model.l1.weight.detach().numpy(), self.data_loader.updated_ln1w)\n",
    "        \n",
    "        print(np.allclose(self.model.l1.bias.detach().numpy(), self.data_loader.updated_ln1b, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.weight.detach().numpy(), self.data_loader.updated_ln2w, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.bias.detach().numpy(), self.data_loader.updated_ln2b, atol=1e-4))\n",
    "def main():\n",
    "    data_loader = DataLoaderModule('../with-torch-tests/all-model')\n",
    "    \n",
    "    model = Model(data_loader.ln1w, data_loader.ln1b, data_loader.ln2w, data_loader.ln2b)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    trainer = Trainer(model, data_loader, criterion, optimizer)\n",
    "    trainer.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 2985.98583984375\n",
      "Epoch: 0, Batch: 1, Loss: 3153.0185546875\n",
      "Epoch: 0, Batch: 2, Loss: 2635.7021484375\n",
      "Epoch: 0, Batch: 3, Loss: 3138.022705078125\n",
      "Epoch: 0, Batch: 4, Loss: 2677.77099609375\n",
      "Epoch: 0, Batch: 5, Loss: 2726.751953125\n",
      "Epoch: 0, Batch: 6, Loss: 2633.2138671875\n",
      "Epoch: 0, Batch: 7, Loss: 2215.740966796875\n",
      "Epoch: 0, Batch: 8, Loss: 2722.53369140625\n",
      "Epoch: 0, Batch: 9, Loss: 2501.446533203125\n",
      "Epoch: 0, Batch: 10, Loss: 2353.607666015625\n",
      "Epoch: 0, Batch: 11, Loss: 2788.94384765625\n",
      "Epoch: 0, Batch: 12, Loss: 2299.307861328125\n",
      "Epoch: 0, Batch: 13, Loss: 2060.51025390625\n",
      "Epoch: 0, Batch: 14, Loss: 2600.10595703125\n",
      "Epoch: 0, Batch: 15, Loss: 2263.06689453125\n",
      "Epoch: 0, Batch: 16, Loss: 2533.971435546875\n",
      "Epoch: 0, Batch: 17, Loss: 3104.484375\n",
      "Epoch: 0, Batch: 18, Loss: 2148.990234375\n",
      "Epoch: 0, Batch: 19, Loss: 2849.841796875\n",
      "Epoch: 0, Batch: 20, Loss: 2540.383544921875\n",
      "Epoch: 0, Batch: 21, Loss: 3262.6015625\n",
      "Epoch: 0, Batch: 22, Loss: 2153.51953125\n",
      "Epoch: 0, Batch: 23, Loss: 2343.58447265625\n",
      "Epoch: 0, Batch: 24, Loss: 3089.1025390625\n",
      "Epoch: 0, Batch: 25, Loss: 2788.96044921875\n",
      "Epoch: 0, Batch: 26, Loss: 2545.463623046875\n",
      "Epoch: 0, Batch: 27, Loss: 2402.03076171875\n",
      "Epoch: 0, Batch: 28, Loss: 2817.551513671875\n",
      "Epoch: 0, Batch: 29, Loss: 2751.3037109375\n",
      "Epoch: 0, Batch: 30, Loss: 2656.836181640625\n",
      "Epoch: 0, Batch: 31, Loss: 1774.7095947265625\n",
      "Epoch: 0, Batch: 32, Loss: 2609.88037109375\n",
      "Epoch: 0, Batch: 33, Loss: 3227.611083984375\n",
      "Epoch: 0, Batch: 34, Loss: 2695.786865234375\n",
      "Epoch: 0, Batch: 35, Loss: 2413.733154296875\n",
      "Epoch: 0, Batch: 36, Loss: 2651.77783203125\n",
      "Epoch: 0, Batch: 37, Loss: 2242.424560546875\n",
      "Epoch: 0, Batch: 38, Loss: 2864.486328125\n",
      "Epoch: 0, Batch: 39, Loss: 2517.673095703125\n",
      "Epoch: 0, Batch: 40, Loss: 2520.90478515625\n",
      "Epoch: 0, Batch: 41, Loss: 2661.1826171875\n",
      "Epoch: 0, Batch: 42, Loss: 2855.5205078125\n",
      "Epoch: 0, Batch: 43, Loss: 3210.128173828125\n",
      "Epoch: 0, Batch: 44, Loss: 2173.12353515625\n",
      "Epoch: 0, Batch: 45, Loss: 2362.407470703125\n",
      "Epoch: 0, Batch: 46, Loss: 2492.531494140625\n",
      "Epoch: 0, Batch: 47, Loss: 2948.123291015625\n",
      "Epoch: 0, Batch: 48, Loss: 2655.017333984375\n",
      "Epoch: 0, Batch: 49, Loss: 2879.685546875\n",
      "Epoch: 0, Batch: 50, Loss: 2860.089599609375\n",
      "Epoch: 0, Batch: 51, Loss: 2735.600830078125\n",
      "Epoch: 0, Batch: 52, Loss: 2375.834228515625\n",
      "Epoch: 0, Batch: 53, Loss: 2864.471435546875\n",
      "Epoch: 0, Batch: 54, Loss: 3027.56982421875\n",
      "Epoch: 0, Batch: 55, Loss: 3184.584716796875\n",
      "Epoch: 0, Batch: 56, Loss: 2657.995849609375\n",
      "Epoch: 0, Batch: 57, Loss: 2750.069580078125\n",
      "Epoch: 0, Batch: 58, Loss: 2218.611083984375\n",
      "Epoch: 0, Batch: 59, Loss: 2625.458984375\n",
      "Epoch: 0, Batch: 60, Loss: 2891.47314453125\n",
      "Epoch: 0, Batch: 61, Loss: 2364.871337890625\n",
      "Epoch: 0, Batch: 62, Loss: 2982.513427734375\n",
      "Epoch: 0, Batch: 63, Loss: 2435.918212890625\n",
      "Epoch: 0, Batch: 64, Loss: 3040.685302734375\n",
      "Epoch: 0, Batch: 65, Loss: 3179.88671875\n",
      "Epoch: 0, Batch: 66, Loss: 2225.115234375\n",
      "Epoch: 0, Batch: 67, Loss: 2682.634765625\n",
      "Epoch: 0, Batch: 68, Loss: 2494.09375\n",
      "Epoch: 0, Batch: 69, Loss: 2681.86181640625\n",
      "Epoch: 0, Batch: 70, Loss: 2968.037353515625\n",
      "Epoch: 0, Batch: 71, Loss: 2499.95556640625\n",
      "Epoch: 0, Batch: 72, Loss: 2739.669921875\n",
      "Epoch: 0, Batch: 73, Loss: 3103.86962890625\n",
      "Epoch: 0, Batch: 74, Loss: 2508.58251953125\n",
      "Epoch: 0, Batch: 75, Loss: 2774.369140625\n",
      "Epoch: 0, Batch: 76, Loss: 2532.33984375\n",
      "Epoch: 0, Batch: 77, Loss: 2832.199951171875\n",
      "Epoch: 0, Batch: 78, Loss: 2474.895263671875\n",
      "Epoch: 0, Batch: 79, Loss: 2542.835693359375\n",
      "Epoch: 0, Batch: 80, Loss: 2685.96435546875\n",
      "Epoch: 0, Batch: 81, Loss: 2460.9599609375\n",
      "Epoch: 0, Batch: 82, Loss: 2642.1728515625\n",
      "Epoch: 0, Batch: 83, Loss: 2753.26416015625\n",
      "Epoch: 0, Batch: 84, Loss: 2386.75390625\n",
      "Epoch: 0, Batch: 85, Loss: 2504.2763671875\n",
      "Epoch: 0, Batch: 86, Loss: 2722.662109375\n",
      "Epoch: 0, Batch: 87, Loss: 2542.07470703125\n",
      "Epoch: 0, Batch: 88, Loss: 3051.17578125\n",
      "Epoch: 0, Batch: 89, Loss: 2557.545166015625\n",
      "Epoch: 0, Batch: 90, Loss: 2689.76123046875\n",
      "Epoch: 0, Batch: 91, Loss: 2884.066162109375\n",
      "Epoch: 0, Batch: 92, Loss: 2293.11181640625\n",
      "Epoch: 0, Batch: 93, Loss: 2064.7802734375\n",
      "Epoch: 0, Batch: 94, Loss: 3127.042236328125\n",
      "Epoch: 0, Batch: 95, Loss: 2891.7333984375\n",
      "Epoch: 0, Batch: 96, Loss: 3040.64794921875\n",
      "Epoch: 0, Batch: 97, Loss: 2468.122802734375\n",
      "Epoch: 0, Batch: 98, Loss: 2600.2578125\n",
      "Epoch: 0, Batch: 99, Loss: 2518.13916015625\n",
      "Epoch: 0, Batch: 100, Loss: 2719.42333984375\n",
      "Epoch: 0, Batch: 101, Loss: 2683.785888671875\n",
      "Epoch: 0, Batch: 102, Loss: 2988.7333984375\n",
      "Epoch: 0, Batch: 103, Loss: 2344.6044921875\n",
      "Epoch: 0, Batch: 104, Loss: 2169.4501953125\n",
      "Epoch: 0, Batch: 105, Loss: 1938.30859375\n",
      "Epoch: 0, Batch: 106, Loss: 2396.671875\n",
      "Epoch: 0, Batch: 107, Loss: 2440.706787109375\n",
      "Epoch: 0, Batch: 108, Loss: 2525.737548828125\n",
      "Epoch: 0, Batch: 109, Loss: 2559.0712890625\n",
      "Epoch: 0, Batch: 110, Loss: 1856.087646484375\n",
      "Epoch: 0, Batch: 111, Loss: 2779.1796875\n",
      "Epoch: 0, Batch: 112, Loss: 2664.72802734375\n",
      "Epoch: 0, Batch: 113, Loss: 2758.74609375\n",
      "Epoch: 0, Batch: 114, Loss: 2336.62109375\n",
      "Epoch: 0, Batch: 115, Loss: 2564.4296875\n",
      "Epoch: 0, Batch: 116, Loss: 2577.01806640625\n",
      "Epoch: 0, Batch: 117, Loss: 3020.9873046875\n",
      "Epoch: 0, Batch: 118, Loss: 2776.89501953125\n",
      "Epoch: 0, Batch: 119, Loss: 2371.199462890625\n",
      "Epoch: 0, Batch: 120, Loss: 3414.95654296875\n",
      "Epoch: 0, Batch: 121, Loss: 2431.05859375\n",
      "Epoch: 0, Batch: 122, Loss: 3065.35986328125\n",
      "Epoch: 0, Batch: 123, Loss: 2235.482421875\n",
      "Epoch: 0, Batch: 124, Loss: 3249.8193359375\n",
      "Epoch: 0, Batch: 125, Loss: 3218.28564453125\n",
      "Epoch: 0, Batch: 126, Loss: 3219.096923828125\n",
      "Epoch: 0, Batch: 127, Loss: 2265.056640625\n",
      "Epoch: 0, Batch: 128, Loss: 2435.89453125\n",
      "Epoch: 0, Batch: 129, Loss: 2564.289794921875\n",
      "Epoch: 0, Batch: 130, Loss: 2375.66455078125\n",
      "Epoch: 0, Batch: 131, Loss: 2184.602294921875\n",
      "Epoch: 0, Batch: 132, Loss: 2839.47119140625\n",
      "Epoch: 0, Batch: 133, Loss: 2483.548583984375\n",
      "Epoch: 0, Batch: 134, Loss: 2173.58544921875\n",
      "Epoch: 0, Batch: 135, Loss: 2737.174072265625\n",
      "Epoch: 0, Batch: 136, Loss: 2481.82470703125\n",
      "Epoch: 0, Batch: 137, Loss: 2931.45849609375\n",
      "Epoch: 0, Batch: 138, Loss: 2229.140625\n",
      "Epoch: 0, Batch: 139, Loss: 2744.350830078125\n",
      "Epoch: 0, Batch: 140, Loss: 2292.630126953125\n",
      "Epoch: 0, Batch: 141, Loss: 2690.3134765625\n",
      "Epoch: 0, Batch: 142, Loss: 2148.893310546875\n",
      "Epoch: 0, Batch: 143, Loss: 3095.236328125\n",
      "Epoch: 0, Batch: 144, Loss: 1772.25\n",
      "Epoch: 0, Batch: 145, Loss: 2392.10546875\n",
      "Epoch: 0, Batch: 146, Loss: 2492.946044921875\n",
      "Epoch: 0, Batch: 147, Loss: 2938.040771484375\n",
      "Epoch: 0, Batch: 148, Loss: 3186.14599609375\n",
      "Epoch: 0, Batch: 149, Loss: 2263.382568359375\n",
      "Epoch: 0, Batch: 150, Loss: 2498.392333984375\n",
      "Epoch: 0, Batch: 151, Loss: 2850.05419921875\n",
      "Epoch: 0, Batch: 152, Loss: 2825.734619140625\n",
      "Epoch: 0, Batch: 153, Loss: 2042.78173828125\n",
      "Epoch: 0, Batch: 154, Loss: 2095.80712890625\n",
      "Epoch: 0, Batch: 155, Loss: 2538.99609375\n",
      "Epoch: 0, Batch: 156, Loss: 2082.86328125\n",
      "Epoch: 0, Batch: 157, Loss: 2735.254638671875\n",
      "Epoch: 0, Batch: 158, Loss: 2571.287109375\n",
      "Epoch: 0, Batch: 159, Loss: 2971.46875\n",
      "Epoch: 0, Batch: 160, Loss: 2695.3154296875\n",
      "Epoch: 0, Batch: 161, Loss: 2721.87353515625\n",
      "Epoch: 0, Batch: 162, Loss: 2793.906005859375\n",
      "Epoch: 0, Batch: 163, Loss: 2719.95556640625\n",
      "Epoch: 0, Batch: 164, Loss: 2669.46728515625\n",
      "Epoch: 0, Batch: 165, Loss: 2763.079833984375\n",
      "Epoch: 0, Batch: 166, Loss: 2687.782958984375\n",
      "Epoch: 0, Batch: 167, Loss: 2775.1611328125\n",
      "Epoch: 0, Batch: 168, Loss: 2811.6767578125\n",
      "Epoch: 0, Batch: 169, Loss: 2339.4404296875\n",
      "Epoch: 0, Batch: 170, Loss: 2358.3369140625\n",
      "Epoch: 0, Batch: 171, Loss: 2378.17236328125\n",
      "Epoch: 0, Batch: 172, Loss: 2537.263427734375\n",
      "Epoch: 0, Batch: 173, Loss: 2556.000732421875\n",
      "Epoch: 0, Batch: 174, Loss: 2850.582763671875\n",
      "Epoch: 0, Batch: 175, Loss: 2748.635986328125\n",
      "Epoch: 0, Batch: 176, Loss: 2707.857666015625\n",
      "Epoch: 0, Batch: 177, Loss: 2424.264892578125\n",
      "Epoch: 0, Batch: 178, Loss: 2677.650146484375\n",
      "Epoch: 0, Batch: 179, Loss: 2880.552734375\n",
      "Epoch: 0, Batch: 180, Loss: 2645.673095703125\n",
      "Epoch: 0, Batch: 181, Loss: 3427.012939453125\n",
      "Epoch: 0, Batch: 182, Loss: 2464.703857421875\n",
      "Epoch: 0, Batch: 183, Loss: 2252.2099609375\n",
      "Epoch: 0, Batch: 184, Loss: 2297.56005859375\n",
      "Epoch: 0, Batch: 185, Loss: 2835.283935546875\n",
      "Epoch: 0, Batch: 186, Loss: 2282.881591796875\n",
      "Epoch: 0, Batch: 187, Loss: 2886.446533203125\n",
      "Epoch: 0, Batch: 188, Loss: 3276.34423828125\n",
      "Epoch: 0, Batch: 189, Loss: 2785.177490234375\n",
      "Epoch: 0, Batch: 190, Loss: 2283.177490234375\n",
      "Epoch: 0, Batch: 191, Loss: 2410.01171875\n",
      "Epoch: 0, Batch: 192, Loss: 2243.513916015625\n",
      "Epoch: 0, Batch: 193, Loss: 2851.740478515625\n",
      "Epoch: 0, Batch: 194, Loss: 2512.725341796875\n",
      "Epoch: 0, Batch: 195, Loss: 2280.943603515625\n",
      "Epoch: 0, Batch: 196, Loss: 2158.686767578125\n",
      "Epoch: 0, Batch: 197, Loss: 2390.02392578125\n",
      "Epoch: 0, Batch: 198, Loss: 2937.166259765625\n",
      "Epoch: 0, Batch: 199, Loss: 2564.066650390625\n",
      "Epoch: 0, Batch: 200, Loss: 2591.772216796875\n",
      "Epoch: 0, Batch: 201, Loss: 2984.12744140625\n",
      "Epoch: 0, Batch: 202, Loss: 2663.46923828125\n",
      "Epoch: 0, Batch: 203, Loss: 2022.6402587890625\n",
      "Epoch: 0, Batch: 204, Loss: 2090.81884765625\n",
      "Epoch: 0, Batch: 205, Loss: 2528.98974609375\n",
      "Epoch: 0, Batch: 206, Loss: 2719.157958984375\n",
      "Epoch: 0, Batch: 207, Loss: 2645.40087890625\n",
      "Epoch: 0, Batch: 208, Loss: 2530.133056640625\n",
      "Epoch: 0, Batch: 209, Loss: 2606.72314453125\n",
      "Epoch: 0, Batch: 210, Loss: 2498.126953125\n",
      "Epoch: 0, Batch: 211, Loss: 3109.745361328125\n",
      "Epoch: 0, Batch: 212, Loss: 2659.76806640625\n",
      "Epoch: 0, Batch: 213, Loss: 3096.935546875\n",
      "Epoch: 0, Batch: 214, Loss: 2165.644287109375\n",
      "Epoch: 0, Batch: 215, Loss: 2903.150390625\n",
      "Epoch: 0, Batch: 216, Loss: 2932.587890625\n",
      "Epoch: 0, Batch: 217, Loss: 2815.05029296875\n",
      "Epoch: 0, Batch: 218, Loss: 2760.333251953125\n",
      "Epoch: 0, Batch: 219, Loss: 2277.8583984375\n",
      "Epoch: 0, Batch: 220, Loss: 2403.3203125\n",
      "Epoch: 0, Batch: 221, Loss: 2754.41845703125\n",
      "Epoch: 0, Batch: 222, Loss: 2360.745849609375\n",
      "Epoch: 0, Batch: 223, Loss: 3040.385498046875\n",
      "Epoch: 0, Batch: 224, Loss: 2799.391845703125\n",
      "Epoch: 0, Batch: 225, Loss: 2398.386474609375\n",
      "Epoch: 0, Batch: 226, Loss: 2798.27099609375\n",
      "Epoch: 0, Batch: 227, Loss: 2682.19140625\n",
      "Epoch: 0, Batch: 228, Loss: 2833.002685546875\n",
      "Epoch: 0, Batch: 229, Loss: 2490.85009765625\n",
      "Epoch: 0, Batch: 230, Loss: 2963.93212890625\n",
      "Epoch: 0, Batch: 231, Loss: 2894.22412109375\n",
      "Epoch: 0, Batch: 232, Loss: 2637.433349609375\n",
      "Epoch: 0, Batch: 233, Loss: 2776.735595703125\n",
      "Epoch: 0, Batch: 234, Loss: 2701.083984375\n",
      "Epoch: 0, Batch: 235, Loss: 2362.113037109375\n",
      "Epoch: 0, Batch: 236, Loss: 2273.681640625\n",
      "Epoch: 0, Batch: 237, Loss: 2067.546875\n",
      "Epoch: 0, Batch: 238, Loss: 2477.049560546875\n",
      "Epoch: 0, Batch: 239, Loss: 2652.35791015625\n",
      "Epoch: 0, Batch: 240, Loss: 2789.30810546875\n",
      "Epoch: 0, Batch: 241, Loss: 2541.590087890625\n",
      "Epoch: 0, Batch: 242, Loss: 2661.085693359375\n",
      "Epoch: 0, Batch: 243, Loss: 2995.808349609375\n",
      "Epoch: 0, Batch: 244, Loss: 2215.18896484375\n",
      "Epoch: 0, Batch: 245, Loss: 2584.63427734375\n",
      "Epoch: 0, Batch: 246, Loss: 2781.0576171875\n",
      "Epoch: 0, Batch: 247, Loss: 3052.463623046875\n",
      "Epoch: 0, Batch: 248, Loss: 2381.539794921875\n",
      "Epoch: 0, Batch: 249, Loss: 2811.958984375\n",
      "Epoch: 0, Batch: 250, Loss: 2538.19970703125\n",
      "Epoch: 0, Batch: 251, Loss: 2366.491455078125\n",
      "Epoch: 0, Batch: 252, Loss: 2888.5615234375\n",
      "Epoch: 0, Batch: 253, Loss: 2868.7861328125\n",
      "Epoch: 0, Batch: 254, Loss: 1963.4007568359375\n",
      "Epoch: 0, Batch: 255, Loss: 2566.578125\n",
      "Epoch: 0, Batch: 256, Loss: 2429.2978515625\n",
      "Epoch: 0, Batch: 257, Loss: 2531.060546875\n",
      "Epoch: 0, Batch: 258, Loss: 2672.7783203125\n",
      "Epoch: 0, Batch: 259, Loss: 2205.05615234375\n",
      "Epoch: 0, Batch: 260, Loss: 2881.83544921875\n",
      "Epoch: 0, Batch: 261, Loss: 2892.673095703125\n",
      "Epoch: 0, Batch: 262, Loss: 2808.6455078125\n",
      "Epoch: 0, Batch: 263, Loss: 2714.650146484375\n",
      "Epoch: 0, Batch: 264, Loss: 2739.76611328125\n",
      "Epoch: 0, Batch: 265, Loss: 2386.24609375\n",
      "Epoch: 0, Batch: 266, Loss: 2706.91552734375\n",
      "Epoch: 0, Batch: 267, Loss: 2725.60498046875\n",
      "Epoch: 0, Batch: 268, Loss: 2268.31591796875\n",
      "Epoch: 0, Batch: 269, Loss: 2401.821533203125\n",
      "Epoch: 0, Batch: 270, Loss: 2427.907470703125\n",
      "Epoch: 0, Batch: 271, Loss: 2434.1708984375\n",
      "Epoch: 0, Batch: 272, Loss: 2665.42138671875\n",
      "Epoch: 0, Batch: 273, Loss: 2839.682861328125\n",
      "Epoch: 0, Batch: 274, Loss: 3124.83349609375\n",
      "Epoch: 0, Batch: 275, Loss: 2451.31494140625\n",
      "Epoch: 0, Batch: 276, Loss: 3254.502685546875\n",
      "Epoch: 0, Batch: 277, Loss: 2849.4609375\n",
      "Epoch: 0, Batch: 278, Loss: 2602.14404296875\n",
      "Epoch: 0, Batch: 279, Loss: 2076.19775390625\n",
      "Epoch: 0, Batch: 280, Loss: 2994.8603515625\n",
      "Epoch: 0, Batch: 281, Loss: 3179.137451171875\n",
      "Epoch: 0, Batch: 282, Loss: 2828.185791015625\n",
      "Epoch: 0, Batch: 283, Loss: 2971.943115234375\n",
      "Epoch: 0, Batch: 284, Loss: 2781.80517578125\n",
      "Epoch: 0, Batch: 285, Loss: 2661.476318359375\n",
      "Epoch: 0, Batch: 286, Loss: 2747.091552734375\n",
      "Epoch: 0, Batch: 287, Loss: 2897.319091796875\n",
      "Epoch: 0, Batch: 288, Loss: 2464.92236328125\n",
      "Epoch: 0, Batch: 289, Loss: 3076.58251953125\n",
      "Epoch: 0, Batch: 290, Loss: 1948.2928466796875\n",
      "Epoch: 0, Batch: 291, Loss: 2316.1650390625\n",
      "Epoch: 0, Batch: 292, Loss: 2954.9560546875\n",
      "Epoch: 0, Batch: 293, Loss: 2459.38916015625\n",
      "Epoch: 0, Batch: 294, Loss: 2283.768310546875\n",
      "Epoch: 0, Batch: 295, Loss: 2638.73876953125\n",
      "Epoch: 0, Batch: 296, Loss: 3077.964111328125\n",
      "Epoch: 0, Batch: 297, Loss: 2669.91455078125\n",
      "Epoch: 0, Batch: 298, Loss: 2875.705078125\n",
      "Epoch: 0, Batch: 299, Loss: 3325.809814453125\n",
      "Epoch: 0, Batch: 300, Loss: 2809.95068359375\n",
      "Epoch: 0, Batch: 301, Loss: 2761.41259765625\n",
      "Epoch: 0, Batch: 302, Loss: 2135.437255859375\n",
      "Epoch: 0, Batch: 303, Loss: 2331.30126953125\n",
      "Epoch: 0, Batch: 304, Loss: 2829.015869140625\n",
      "Epoch: 0, Batch: 305, Loss: 2410.01220703125\n",
      "Epoch: 0, Batch: 306, Loss: 2862.2216796875\n",
      "Epoch: 0, Batch: 307, Loss: 2191.25830078125\n",
      "Epoch: 0, Batch: 308, Loss: 2752.52880859375\n",
      "Epoch: 0, Batch: 309, Loss: 2530.854736328125\n",
      "Epoch: 0, Batch: 310, Loss: 3288.916259765625\n",
      "Epoch: 0, Batch: 311, Loss: 2742.994384765625\n",
      "Epoch: 0, Batch: 312, Loss: 2871.544921875\n",
      "Epoch: 0, Batch: 313, Loss: 2359.52587890625\n",
      "Epoch: 0, Batch: 314, Loss: 2223.372802734375\n",
      "Epoch: 0, Batch: 315, Loss: 2662.017822265625\n",
      "Epoch: 0, Batch: 316, Loss: 2870.433349609375\n",
      "Epoch: 0, Batch: 317, Loss: 2684.59814453125\n",
      "Epoch: 0, Batch: 318, Loss: 2726.1865234375\n",
      "Epoch: 0, Batch: 319, Loss: 2464.906982421875\n",
      "Epoch: 0, Batch: 320, Loss: 2610.66162109375\n",
      "Epoch: 0, Batch: 321, Loss: 2604.319091796875\n",
      "Epoch: 0, Batch: 322, Loss: 2303.447021484375\n",
      "Epoch: 0, Batch: 323, Loss: 2968.67529296875\n",
      "Epoch: 0, Batch: 324, Loss: 2365.945556640625\n",
      "Epoch: 0, Batch: 325, Loss: 2196.67236328125\n",
      "Epoch: 0, Batch: 326, Loss: 2128.399658203125\n",
      "Epoch: 0, Batch: 327, Loss: 2215.368408203125\n",
      "Epoch: 0, Batch: 328, Loss: 3105.26318359375\n",
      "Epoch: 0, Batch: 329, Loss: 2484.7138671875\n",
      "Epoch: 0, Batch: 330, Loss: 2646.67578125\n",
      "Epoch: 0, Batch: 331, Loss: 3099.849609375\n",
      "Epoch: 0, Batch: 332, Loss: 2595.425537109375\n",
      "Epoch: 0, Batch: 333, Loss: 2350.011474609375\n",
      "Epoch: 0, Batch: 334, Loss: 2149.011474609375\n",
      "Epoch: 0, Batch: 335, Loss: 2825.5087890625\n",
      "Epoch: 0, Batch: 336, Loss: 2962.6220703125\n",
      "Epoch: 0, Batch: 337, Loss: 2951.69189453125\n",
      "Epoch: 0, Batch: 338, Loss: 3217.14599609375\n",
      "Epoch: 0, Batch: 339, Loss: 2588.942626953125\n",
      "Epoch: 0, Batch: 340, Loss: 2191.805419921875\n",
      "Epoch: 0, Batch: 341, Loss: 2877.712158203125\n",
      "Epoch: 0, Batch: 342, Loss: 2578.392578125\n",
      "Epoch: 0, Batch: 343, Loss: 2986.41015625\n",
      "Epoch: 0, Batch: 344, Loss: 2403.220947265625\n",
      "Epoch: 0, Batch: 345, Loss: 2539.56103515625\n",
      "Epoch: 0, Batch: 346, Loss: 2384.50732421875\n",
      "Epoch: 0, Batch: 347, Loss: 1917.070556640625\n",
      "Epoch: 0, Batch: 348, Loss: 2417.693115234375\n",
      "Epoch: 0, Batch: 349, Loss: 3156.824462890625\n",
      "Epoch: 0, Batch: 350, Loss: 3230.098876953125\n",
      "Epoch: 0, Batch: 351, Loss: 2812.9990234375\n",
      "Epoch: 0, Batch: 352, Loss: 2517.910400390625\n",
      "Epoch: 0, Batch: 353, Loss: 2773.9130859375\n",
      "Epoch: 0, Batch: 354, Loss: 2433.72607421875\n",
      "Epoch: 0, Batch: 355, Loss: 2685.692138671875\n",
      "Epoch: 0, Batch: 356, Loss: 2675.60791015625\n",
      "Epoch: 0, Batch: 357, Loss: 2848.419677734375\n",
      "Epoch: 0, Batch: 358, Loss: 2203.02294921875\n",
      "Epoch: 0, Batch: 359, Loss: 2847.685302734375\n",
      "Epoch: 0, Batch: 360, Loss: 2672.05224609375\n",
      "Epoch: 0, Batch: 361, Loss: 2609.806884765625\n",
      "Epoch: 0, Batch: 362, Loss: 2531.99072265625\n",
      "Epoch: 0, Batch: 363, Loss: 2208.23046875\n",
      "Epoch: 0, Batch: 364, Loss: 2888.975830078125\n",
      "Epoch: 0, Batch: 365, Loss: 2336.53515625\n",
      "Epoch: 0, Batch: 366, Loss: 1826.61669921875\n",
      "Epoch: 0, Batch: 367, Loss: 2943.806396484375\n",
      "Epoch: 0, Batch: 368, Loss: 2943.267578125\n",
      "Epoch: 0, Batch: 369, Loss: 2784.28369140625\n",
      "Epoch: 0, Batch: 370, Loss: 2574.3720703125\n",
      "Epoch: 0, Batch: 371, Loss: 2229.13818359375\n",
      "Epoch: 0, Batch: 372, Loss: 2549.49609375\n",
      "Epoch: 0, Batch: 373, Loss: 1811.4033203125\n",
      "Epoch: 0, Batch: 374, Loss: 2350.628173828125\n",
      "Epoch: 0, Batch: 375, Loss: 2459.155029296875\n",
      "Epoch: 0, Batch: 376, Loss: 2787.509521484375\n",
      "Epoch: 0, Batch: 377, Loss: 2743.72705078125\n",
      "Epoch: 0, Batch: 378, Loss: 2313.506591796875\n",
      "Epoch: 0, Batch: 379, Loss: 3275.180908203125\n",
      "Epoch: 0, Batch: 380, Loss: 3127.248291015625\n",
      "Epoch: 0, Batch: 381, Loss: 2073.610595703125\n",
      "Epoch: 0, Batch: 382, Loss: 2320.272216796875\n",
      "Epoch: 0, Batch: 383, Loss: 2316.09423828125\n",
      "Epoch: 0, Batch: 384, Loss: 2987.271728515625\n",
      "Epoch: 0, Batch: 385, Loss: 2701.26318359375\n",
      "Epoch: 0, Batch: 386, Loss: 2866.979736328125\n",
      "Epoch: 0, Batch: 387, Loss: 2636.95947265625\n",
      "Epoch: 0, Batch: 388, Loss: 2398.6328125\n",
      "Epoch: 0, Batch: 389, Loss: 2746.552001953125\n",
      "Epoch: 0, Batch: 390, Loss: 2349.7275390625\n",
      "Epoch: 0, Batch: 391, Loss: 2305.09228515625\n",
      "Epoch: 0, Batch: 392, Loss: 2842.524169921875\n",
      "Epoch: 0, Batch: 393, Loss: 2280.85400390625\n",
      "Epoch: 0, Batch: 394, Loss: 2667.731201171875\n",
      "Epoch: 0, Batch: 395, Loss: 2660.83544921875\n",
      "Epoch: 0, Batch: 396, Loss: 2479.223388671875\n",
      "Epoch: 0, Batch: 397, Loss: 2450.4921875\n",
      "Epoch: 0, Batch: 398, Loss: 3154.9248046875\n",
      "Epoch: 0, Batch: 399, Loss: 2819.041259765625\n",
      "Epoch: 0, Batch: 400, Loss: 2542.847412109375\n",
      "Epoch: 0, Batch: 401, Loss: 2542.706298828125\n",
      "Epoch: 0, Batch: 402, Loss: 2727.848388671875\n",
      "Epoch: 0, Batch: 403, Loss: 3004.518798828125\n",
      "Epoch: 0, Batch: 404, Loss: 3474.347900390625\n",
      "Epoch: 0, Batch: 405, Loss: 2304.39697265625\n",
      "Epoch: 0, Batch: 406, Loss: 2292.051025390625\n",
      "Epoch: 0, Batch: 407, Loss: 2705.6767578125\n",
      "Epoch: 0, Batch: 408, Loss: 3450.962158203125\n",
      "Epoch: 0, Batch: 409, Loss: 2938.492431640625\n",
      "Epoch: 0, Batch: 410, Loss: 2555.72314453125\n",
      "Epoch: 0, Batch: 411, Loss: 2542.218017578125\n",
      "Epoch: 0, Batch: 412, Loss: 2378.994873046875\n",
      "Epoch: 0, Batch: 413, Loss: 2412.384521484375\n",
      "Epoch: 0, Batch: 414, Loss: 2525.023681640625\n",
      "Epoch: 0, Batch: 415, Loss: 2716.79541015625\n",
      "Epoch: 0, Batch: 416, Loss: 1957.5343017578125\n",
      "Epoch: 0, Batch: 417, Loss: 2432.60107421875\n",
      "Epoch: 0, Batch: 418, Loss: 2591.365478515625\n",
      "Epoch: 0, Batch: 419, Loss: 2172.966796875\n",
      "Epoch: 0, Batch: 420, Loss: 2375.255615234375\n",
      "Epoch: 0, Batch: 421, Loss: 2192.921142578125\n",
      "Epoch: 0, Batch: 422, Loss: 2702.6123046875\n",
      "Epoch: 0, Batch: 423, Loss: 3462.871826171875\n",
      "Epoch: 0, Batch: 424, Loss: 2812.473388671875\n",
      "Epoch: 0, Batch: 425, Loss: 2982.57080078125\n",
      "Epoch: 0, Batch: 426, Loss: 2599.917236328125\n",
      "Epoch: 0, Batch: 427, Loss: 2892.009521484375\n",
      "Epoch: 0, Batch: 428, Loss: 3390.808837890625\n",
      "Epoch: 0, Batch: 429, Loss: 2313.615234375\n",
      "Epoch: 0, Batch: 430, Loss: 2775.2431640625\n",
      "Epoch: 0, Batch: 431, Loss: 3072.095947265625\n",
      "Epoch: 0, Batch: 432, Loss: 2554.366943359375\n",
      "Epoch: 0, Batch: 433, Loss: 2311.387939453125\n",
      "Epoch: 0, Batch: 434, Loss: 2101.00537109375\n",
      "Epoch: 0, Batch: 435, Loss: 2234.71240234375\n",
      "Epoch: 0, Batch: 436, Loss: 2524.090087890625\n",
      "Epoch: 0, Batch: 437, Loss: 3187.801025390625\n",
      "Epoch: 0, Batch: 438, Loss: 2372.350341796875\n",
      "Epoch: 0, Batch: 439, Loss: 2303.234130859375\n",
      "Epoch: 0, Batch: 440, Loss: 3469.17041015625\n",
      "Epoch: 0, Batch: 441, Loss: 2738.22265625\n",
      "Epoch: 0, Batch: 442, Loss: 2467.625244140625\n",
      "Epoch: 0, Batch: 443, Loss: 2566.492919921875\n",
      "Epoch: 0, Batch: 444, Loss: 2925.694580078125\n",
      "Epoch: 0, Batch: 445, Loss: 2733.79833984375\n",
      "Epoch: 0, Batch: 446, Loss: 2386.85888671875\n",
      "Epoch: 0, Batch: 447, Loss: 2960.704345703125\n",
      "Epoch: 0, Batch: 448, Loss: 2246.33154296875\n",
      "Epoch: 0, Batch: 449, Loss: 3776.17919921875\n",
      "Epoch: 0, Batch: 450, Loss: 2709.82568359375\n",
      "Epoch: 0, Batch: 451, Loss: 2955.094482421875\n",
      "Epoch: 0, Batch: 452, Loss: 3038.454345703125\n",
      "Epoch: 0, Batch: 453, Loss: 2490.474853515625\n",
      "Epoch: 0, Batch: 454, Loss: 3018.972900390625\n",
      "Epoch: 0, Batch: 455, Loss: 2736.10107421875\n",
      "Epoch: 0, Batch: 456, Loss: 2410.12109375\n",
      "Epoch: 0, Batch: 457, Loss: 2451.606689453125\n",
      "Epoch: 0, Batch: 458, Loss: 2440.17529296875\n",
      "Epoch: 0, Batch: 459, Loss: 3184.29833984375\n",
      "Epoch: 0, Batch: 460, Loss: 3536.955810546875\n",
      "Epoch: 0, Batch: 461, Loss: 2629.17041015625\n",
      "Epoch: 0, Batch: 462, Loss: 2742.928955078125\n",
      "Epoch: 0, Batch: 463, Loss: 2416.238037109375\n",
      "Epoch: 0, Batch: 464, Loss: 2519.464599609375\n",
      "Epoch: 0, Batch: 465, Loss: 2337.81298828125\n",
      "Epoch: 0, Batch: 466, Loss: 2624.452392578125\n",
      "Epoch: 0, Batch: 467, Loss: 2412.224853515625\n",
      "Epoch: 0, Batch: 468, Loss: 2639.23486328125\n",
      "Epoch: 0, Batch: 469, Loss: 2837.164794921875\n",
      "Epoch: 0, Batch: 470, Loss: 2370.0166015625\n",
      "Epoch: 0, Batch: 471, Loss: 2851.16357421875\n",
      "Epoch: 0, Batch: 472, Loss: 2657.011474609375\n",
      "Epoch: 0, Batch: 473, Loss: 2333.676025390625\n",
      "Epoch: 0, Batch: 474, Loss: 2797.850830078125\n",
      "Epoch: 0, Batch: 475, Loss: 2967.935791015625\n",
      "Epoch: 0, Batch: 476, Loss: 2767.302001953125\n",
      "Epoch: 0, Batch: 477, Loss: 2370.254638671875\n",
      "Epoch: 0, Batch: 478, Loss: 2556.928466796875\n",
      "Epoch: 0, Batch: 479, Loss: 2650.5966796875\n",
      "Epoch: 0, Batch: 480, Loss: 2345.20556640625\n",
      "Epoch: 0, Batch: 481, Loss: 2795.606689453125\n",
      "Epoch: 0, Batch: 482, Loss: 2013.5511474609375\n",
      "Epoch: 0, Batch: 483, Loss: 2346.168701171875\n",
      "Epoch: 0, Batch: 484, Loss: 2969.26904296875\n",
      "Epoch: 0, Batch: 485, Loss: 2436.038818359375\n",
      "Epoch: 0, Batch: 486, Loss: 2489.840576171875\n",
      "Epoch: 0, Batch: 487, Loss: 2593.328369140625\n",
      "Epoch: 0, Batch: 488, Loss: 2973.38037109375\n",
      "Epoch: 0, Batch: 489, Loss: 2694.07470703125\n",
      "Epoch: 0, Batch: 490, Loss: 2073.52099609375\n",
      "Epoch: 0, Batch: 491, Loss: 2926.637939453125\n",
      "Epoch: 0, Batch: 492, Loss: 2539.494873046875\n",
      "Epoch: 0, Batch: 493, Loss: 2126.715576171875\n",
      "Epoch: 0, Batch: 494, Loss: 2556.862060546875\n",
      "Epoch: 0, Batch: 495, Loss: 2407.15234375\n",
      "Epoch: 0, Batch: 496, Loss: 2735.54150390625\n",
      "Epoch: 0, Batch: 497, Loss: 2516.55859375\n",
      "Epoch: 0, Batch: 498, Loss: 1851.6624755859375\n",
      "Epoch: 0, Batch: 499, Loss: 2661.739501953125\n",
      "Epoch: 0, Batch: 500, Loss: 2773.4951171875\n",
      "Epoch: 0, Batch: 501, Loss: 3076.4638671875\n",
      "Epoch: 0, Batch: 502, Loss: 2611.842041015625\n",
      "Epoch: 0, Batch: 503, Loss: 2122.584228515625\n",
      "Epoch: 0, Batch: 504, Loss: 2167.103515625\n",
      "Epoch: 0, Batch: 505, Loss: 2352.07568359375\n",
      "Epoch: 0, Batch: 506, Loss: 2805.78271484375\n",
      "Epoch: 0, Batch: 507, Loss: 2910.73095703125\n",
      "Epoch: 0, Batch: 508, Loss: 2563.645751953125\n",
      "Epoch: 0, Batch: 509, Loss: 3022.611328125\n",
      "Epoch: 0, Batch: 510, Loss: 2211.787109375\n",
      "Epoch: 0, Batch: 511, Loss: 2284.1201171875\n",
      "Epoch: 0, Batch: 512, Loss: 2697.715576171875\n",
      "Epoch: 0, Batch: 513, Loss: 2142.93310546875\n",
      "Epoch: 0, Batch: 514, Loss: 2938.5224609375\n",
      "Epoch: 0, Batch: 515, Loss: 2858.015380859375\n",
      "Epoch: 0, Batch: 516, Loss: 2534.53173828125\n",
      "Epoch: 0, Batch: 517, Loss: 2629.749755859375\n",
      "Epoch: 0, Batch: 518, Loss: 2649.395263671875\n",
      "Epoch: 0, Batch: 519, Loss: 2892.787841796875\n",
      "Epoch: 0, Batch: 520, Loss: 3110.879638671875\n",
      "Epoch: 0, Batch: 521, Loss: 2217.973388671875\n",
      "Epoch: 0, Batch: 522, Loss: 2930.08984375\n",
      "Epoch: 0, Batch: 523, Loss: 2819.72607421875\n",
      "Epoch: 0, Batch: 524, Loss: 2381.541259765625\n",
      "Epoch: 0, Batch: 525, Loss: 2577.537109375\n",
      "Epoch: 0, Batch: 526, Loss: 2212.84521484375\n",
      "Epoch: 0, Batch: 527, Loss: 2768.74462890625\n",
      "Epoch: 0, Batch: 528, Loss: 3186.990478515625\n",
      "Epoch: 0, Batch: 529, Loss: 2565.626708984375\n",
      "Epoch: 0, Batch: 530, Loss: 2631.993896484375\n",
      "Epoch: 0, Batch: 531, Loss: 2558.12353515625\n",
      "Epoch: 0, Batch: 532, Loss: 2924.109375\n",
      "Epoch: 0, Batch: 533, Loss: 2420.810791015625\n",
      "Epoch: 0, Batch: 534, Loss: 2504.144287109375\n",
      "Epoch: 0, Batch: 535, Loss: 2399.915771484375\n",
      "Epoch: 0, Batch: 536, Loss: 2790.869140625\n",
      "Epoch: 0, Batch: 537, Loss: 2568.939697265625\n",
      "Epoch: 0, Batch: 538, Loss: 2791.435791015625\n",
      "Epoch: 0, Batch: 539, Loss: 3074.026611328125\n",
      "Epoch: 0, Batch: 540, Loss: 2396.510986328125\n",
      "Epoch: 0, Batch: 541, Loss: 2529.00830078125\n",
      "Epoch: 0, Batch: 542, Loss: 3041.965576171875\n",
      "Epoch: 0, Batch: 543, Loss: 2486.962890625\n",
      "Epoch: 0, Batch: 544, Loss: 3010.12744140625\n",
      "Epoch: 0, Batch: 545, Loss: 2358.039794921875\n",
      "Epoch: 0, Batch: 546, Loss: 2662.2275390625\n",
      "Epoch: 0, Batch: 547, Loss: 2357.148193359375\n",
      "Epoch: 0, Batch: 548, Loss: 2652.510009765625\n",
      "Epoch: 0, Batch: 549, Loss: 2830.1083984375\n",
      "Epoch: 0, Batch: 550, Loss: 2344.970947265625\n",
      "Epoch: 0, Batch: 551, Loss: 2526.703857421875\n",
      "Epoch: 0, Batch: 552, Loss: 3313.728271484375\n",
      "Epoch: 0, Batch: 553, Loss: 2202.11181640625\n",
      "Epoch: 0, Batch: 554, Loss: 3076.068359375\n",
      "Epoch: 0, Batch: 555, Loss: 3137.335693359375\n",
      "Epoch: 0, Batch: 556, Loss: 2820.373779296875\n",
      "Epoch: 0, Batch: 557, Loss: 2712.056396484375\n",
      "Epoch: 0, Batch: 558, Loss: 2647.152099609375\n",
      "Epoch: 0, Batch: 559, Loss: 2621.2021484375\n",
      "Epoch: 0, Batch: 560, Loss: 2233.55712890625\n",
      "Epoch: 0, Batch: 561, Loss: 2806.7314453125\n",
      "Epoch: 0, Batch: 562, Loss: 2556.14990234375\n",
      "Epoch: 0, Batch: 563, Loss: 2484.74072265625\n",
      "Epoch: 0, Batch: 564, Loss: 2468.62353515625\n",
      "Epoch: 0, Batch: 565, Loss: 3003.218994140625\n",
      "Epoch: 0, Batch: 566, Loss: 2379.76416015625\n",
      "Epoch: 0, Batch: 567, Loss: 2482.5830078125\n",
      "Epoch: 0, Batch: 568, Loss: 2444.726318359375\n",
      "Epoch: 0, Batch: 569, Loss: 2952.52001953125\n",
      "Epoch: 0, Batch: 570, Loss: 2480.238037109375\n",
      "Epoch: 0, Batch: 571, Loss: 2526.614990234375\n",
      "Epoch: 0, Batch: 572, Loss: 3022.4306640625\n",
      "Epoch: 0, Batch: 573, Loss: 2735.31298828125\n",
      "Epoch: 0, Batch: 574, Loss: 3110.5654296875\n",
      "Epoch: 0, Batch: 575, Loss: 3205.145263671875\n",
      "Epoch: 0, Batch: 576, Loss: 2661.630615234375\n",
      "Epoch: 0, Batch: 577, Loss: 3284.384033203125\n",
      "Epoch: 0, Batch: 578, Loss: 2030.1009521484375\n",
      "Epoch: 0, Batch: 579, Loss: 2797.890625\n",
      "Epoch: 0, Batch: 580, Loss: 3158.1142578125\n",
      "Epoch: 0, Batch: 581, Loss: 2805.95947265625\n",
      "Epoch: 0, Batch: 582, Loss: 2695.683349609375\n",
      "Epoch: 0, Batch: 583, Loss: 2900.2431640625\n",
      "Epoch: 0, Batch: 584, Loss: 2573.62744140625\n",
      "Epoch: 0, Batch: 585, Loss: 2815.94287109375\n",
      "Epoch: 0, Batch: 586, Loss: 2698.7333984375\n",
      "Epoch: 0, Batch: 587, Loss: 2408.361328125\n",
      "Epoch: 0, Batch: 588, Loss: 2541.5693359375\n",
      "Epoch: 0, Batch: 589, Loss: 2772.559814453125\n",
      "Epoch: 0, Batch: 590, Loss: 2593.08251953125\n",
      "Epoch: 0, Batch: 591, Loss: 2655.302001953125\n",
      "Epoch: 0, Batch: 592, Loss: 2636.334716796875\n",
      "Epoch: 0, Batch: 593, Loss: 2316.53759765625\n",
      "Epoch: 0, Batch: 594, Loss: 2184.733154296875\n",
      "Epoch: 0, Batch: 595, Loss: 2178.052978515625\n",
      "Epoch: 0, Batch: 596, Loss: 2670.390869140625\n",
      "Epoch: 0, Batch: 597, Loss: 2562.776123046875\n",
      "Epoch: 0, Batch: 598, Loss: 2047.084716796875\n",
      "Epoch: 0, Batch: 599, Loss: 3004.80419921875\n",
      "Epoch: 0, Batch: 600, Loss: 2873.039794921875\n",
      "Epoch: 0, Batch: 601, Loss: 2550.83740234375\n",
      "Epoch: 0, Batch: 602, Loss: 2565.602294921875\n",
      "Epoch: 0, Batch: 603, Loss: 2841.46142578125\n",
      "Epoch: 0, Batch: 604, Loss: 2342.072998046875\n",
      "Epoch: 0, Batch: 605, Loss: 3145.154052734375\n",
      "Epoch: 0, Batch: 606, Loss: 2494.370849609375\n",
      "Epoch: 0, Batch: 607, Loss: 2877.96142578125\n",
      "Epoch: 0, Batch: 608, Loss: 2460.744140625\n",
      "Epoch: 0, Batch: 609, Loss: 2610.9111328125\n",
      "Epoch: 0, Batch: 610, Loss: 2321.015625\n",
      "Epoch: 0, Batch: 611, Loss: 3080.099609375\n",
      "Epoch: 0, Batch: 612, Loss: 2678.36865234375\n",
      "Epoch: 0, Batch: 613, Loss: 2261.91845703125\n",
      "Epoch: 0, Batch: 614, Loss: 2284.871826171875\n",
      "Epoch: 0, Batch: 615, Loss: 2438.2412109375\n",
      "Epoch: 0, Batch: 616, Loss: 2862.61865234375\n",
      "Epoch: 0, Batch: 617, Loss: 2759.551025390625\n",
      "Epoch: 0, Batch: 618, Loss: 2394.895263671875\n",
      "Epoch: 0, Batch: 619, Loss: 2501.234619140625\n",
      "Epoch: 0, Batch: 620, Loss: 2404.510498046875\n",
      "Epoch: 0, Batch: 621, Loss: 2458.4375\n",
      "Epoch: 0, Batch: 622, Loss: 2592.115478515625\n",
      "Epoch: 0, Batch: 623, Loss: 3079.894775390625\n",
      "Epoch: 0, Batch: 624, Loss: 2776.896728515625\n",
      "Epoch: 0, Batch: 625, Loss: 2614.006103515625\n",
      "Epoch: 0, Batch: 626, Loss: 2523.50830078125\n",
      "Epoch: 0, Batch: 627, Loss: 3221.440185546875\n",
      "Epoch: 0, Batch: 628, Loss: 2935.994140625\n",
      "Epoch: 0, Batch: 629, Loss: 2866.54541015625\n",
      "Epoch: 0, Batch: 630, Loss: 2820.1015625\n",
      "Epoch: 0, Batch: 631, Loss: 2053.80224609375\n",
      "Epoch: 0, Batch: 632, Loss: 2833.53564453125\n",
      "Epoch: 0, Batch: 633, Loss: 2651.529296875\n",
      "Epoch: 0, Batch: 634, Loss: 3134.175537109375\n",
      "Epoch: 0, Batch: 635, Loss: 2438.731201171875\n",
      "Epoch: 0, Batch: 636, Loss: 2937.95361328125\n",
      "Epoch: 0, Batch: 637, Loss: 2906.36962890625\n",
      "Epoch: 0, Batch: 638, Loss: 2499.6796875\n",
      "Epoch: 0, Batch: 639, Loss: 2574.5546875\n",
      "Epoch: 0, Batch: 640, Loss: 2559.12646484375\n",
      "Epoch: 0, Batch: 641, Loss: 2630.0205078125\n",
      "Epoch: 0, Batch: 642, Loss: 2663.79248046875\n",
      "Epoch: 0, Batch: 643, Loss: 2950.632080078125\n",
      "Epoch: 0, Batch: 644, Loss: 3021.35791015625\n",
      "Epoch: 0, Batch: 645, Loss: 3157.110107421875\n",
      "Epoch: 0, Batch: 646, Loss: 2157.932861328125\n",
      "Epoch: 0, Batch: 647, Loss: 2340.51318359375\n",
      "Epoch: 0, Batch: 648, Loss: 3062.54833984375\n",
      "Epoch: 0, Batch: 649, Loss: 2703.1005859375\n",
      "Epoch: 0, Batch: 650, Loss: 2640.27490234375\n",
      "Epoch: 0, Batch: 651, Loss: 2846.953125\n",
      "Epoch: 0, Batch: 652, Loss: 2846.243896484375\n",
      "Epoch: 0, Batch: 653, Loss: 2554.006591796875\n",
      "Epoch: 0, Batch: 654, Loss: 2735.92431640625\n",
      "Epoch: 0, Batch: 655, Loss: 2821.23779296875\n",
      "Epoch: 0, Batch: 656, Loss: 2566.572998046875\n",
      "Epoch: 0, Batch: 657, Loss: 3466.0703125\n",
      "Epoch: 0, Batch: 658, Loss: 3070.51416015625\n",
      "Epoch: 0, Batch: 659, Loss: 2591.292236328125\n",
      "Epoch: 0, Batch: 660, Loss: 2872.50341796875\n",
      "Epoch: 0, Batch: 661, Loss: 2639.3974609375\n",
      "Epoch: 0, Batch: 662, Loss: 2079.589111328125\n",
      "Epoch: 0, Batch: 663, Loss: 2721.603515625\n",
      "Epoch: 0, Batch: 664, Loss: 2579.877197265625\n",
      "Epoch: 0, Batch: 665, Loss: 2824.583740234375\n",
      "Epoch: 0, Batch: 666, Loss: 2645.579345703125\n",
      "Epoch: 0, Batch: 667, Loss: 2396.975341796875\n",
      "Epoch: 0, Batch: 668, Loss: 2145.063720703125\n",
      "Epoch: 0, Batch: 669, Loss: 2317.68505859375\n",
      "Epoch: 0, Batch: 670, Loss: 2590.08251953125\n",
      "Epoch: 0, Batch: 671, Loss: 2816.514892578125\n",
      "Epoch: 0, Batch: 672, Loss: 2464.290283203125\n",
      "Epoch: 0, Batch: 673, Loss: 3001.332275390625\n",
      "Epoch: 0, Batch: 674, Loss: 3002.7763671875\n",
      "Epoch: 0, Batch: 675, Loss: 2955.28857421875\n",
      "Epoch: 0, Batch: 676, Loss: 3045.2451171875\n",
      "Epoch: 0, Batch: 677, Loss: 2706.25830078125\n",
      "Epoch: 0, Batch: 678, Loss: 2792.52978515625\n",
      "Epoch: 0, Batch: 679, Loss: 2473.9853515625\n",
      "Epoch: 0, Batch: 680, Loss: 2861.042724609375\n",
      "Epoch: 0, Batch: 681, Loss: 3181.374755859375\n",
      "Epoch: 0, Batch: 682, Loss: 2592.197509765625\n",
      "Epoch: 0, Batch: 683, Loss: 2321.8408203125\n",
      "Epoch: 0, Batch: 684, Loss: 2609.77294921875\n",
      "Epoch: 0, Batch: 685, Loss: 2671.5595703125\n",
      "Epoch: 0, Batch: 686, Loss: 2258.814208984375\n",
      "Epoch: 0, Batch: 687, Loss: 2601.289306640625\n",
      "Epoch: 0, Batch: 688, Loss: 2872.5244140625\n",
      "Epoch: 0, Batch: 689, Loss: 2975.9931640625\n",
      "Epoch: 0, Batch: 690, Loss: 2756.95361328125\n",
      "Epoch: 0, Batch: 691, Loss: 2708.4716796875\n",
      "Epoch: 0, Batch: 692, Loss: 2766.16845703125\n",
      "Epoch: 0, Batch: 693, Loss: 2858.66845703125\n",
      "Epoch: 0, Batch: 694, Loss: 2713.819091796875\n",
      "Epoch: 0, Batch: 695, Loss: 2280.00634765625\n",
      "Epoch: 0, Batch: 696, Loss: 3062.185302734375\n",
      "Epoch: 0, Batch: 697, Loss: 2432.3701171875\n",
      "Epoch: 0, Batch: 698, Loss: 2804.8720703125\n",
      "Epoch: 0, Batch: 699, Loss: 2177.249267578125\n",
      "Epoch: 0, Batch: 700, Loss: 2462.961181640625\n",
      "Epoch: 0, Batch: 701, Loss: 2213.09033203125\n",
      "Epoch: 0, Batch: 702, Loss: 3188.978759765625\n",
      "Epoch: 0, Batch: 703, Loss: 2035.47216796875\n",
      "Epoch: 0, Batch: 704, Loss: 2542.79931640625\n",
      "Epoch: 0, Batch: 705, Loss: 1644.504150390625\n",
      "Epoch: 0, Batch: 706, Loss: 2305.672119140625\n",
      "Epoch: 0, Batch: 707, Loss: 2497.102294921875\n",
      "Epoch: 0, Batch: 708, Loss: 2715.6328125\n",
      "Epoch: 0, Batch: 709, Loss: 2671.771240234375\n",
      "Epoch: 0, Batch: 710, Loss: 2685.94091796875\n",
      "Epoch: 0, Batch: 711, Loss: 2827.554443359375\n",
      "Epoch: 0, Batch: 712, Loss: 2661.486572265625\n",
      "Epoch: 0, Batch: 713, Loss: 3077.2734375\n",
      "Epoch: 0, Batch: 714, Loss: 2734.17041015625\n",
      "Epoch: 0, Batch: 715, Loss: 2857.420166015625\n",
      "Epoch: 0, Batch: 716, Loss: 2910.3271484375\n",
      "Epoch: 0, Batch: 717, Loss: 2826.902587890625\n",
      "Epoch: 0, Batch: 718, Loss: 2685.931884765625\n",
      "Epoch: 0, Batch: 719, Loss: 2634.260009765625\n",
      "Epoch: 0, Batch: 720, Loss: 2566.48095703125\n",
      "Epoch: 0, Batch: 721, Loss: 2686.328125\n",
      "Epoch: 0, Batch: 722, Loss: 2860.5\n",
      "Epoch: 0, Batch: 723, Loss: 2543.337158203125\n",
      "Epoch: 0, Batch: 724, Loss: 2390.164794921875\n",
      "Epoch: 0, Batch: 725, Loss: 2789.552978515625\n",
      "Epoch: 0, Batch: 726, Loss: 2609.552978515625\n",
      "Epoch: 0, Batch: 727, Loss: 2730.887939453125\n",
      "Epoch: 0, Batch: 728, Loss: 2541.615478515625\n",
      "Epoch: 0, Batch: 729, Loss: 2560.953369140625\n",
      "Epoch: 0, Batch: 730, Loss: 2672.057861328125\n",
      "Epoch: 0, Batch: 731, Loss: 2628.70751953125\n",
      "Epoch: 0, Batch: 732, Loss: 2332.74462890625\n",
      "Epoch: 0, Batch: 733, Loss: 3387.01708984375\n",
      "Epoch: 0, Batch: 734, Loss: 3163.168212890625\n",
      "Epoch: 0, Batch: 735, Loss: 2880.189453125\n",
      "Epoch: 0, Batch: 736, Loss: 2870.58251953125\n",
      "Epoch: 0, Batch: 737, Loss: 2519.0390625\n",
      "Epoch: 0, Batch: 738, Loss: 2627.302734375\n",
      "Epoch: 0, Batch: 739, Loss: 3004.188232421875\n",
      "Epoch: 0, Batch: 740, Loss: 2623.859619140625\n",
      "Epoch: 0, Batch: 741, Loss: 2733.34375\n",
      "Epoch: 0, Batch: 742, Loss: 2753.49853515625\n",
      "Epoch: 0, Batch: 743, Loss: 2974.94970703125\n",
      "Epoch: 0, Batch: 744, Loss: 2444.22265625\n",
      "Epoch: 0, Batch: 745, Loss: 2346.339599609375\n",
      "Epoch: 0, Batch: 746, Loss: 2393.081787109375\n",
      "Epoch: 0, Batch: 747, Loss: 2406.655029296875\n",
      "Epoch: 0, Batch: 748, Loss: 2964.7705078125\n",
      "Epoch: 0, Batch: 749, Loss: 2406.30322265625\n",
      "Epoch: 0, Batch: 750, Loss: 3011.023681640625\n",
      "Epoch: 0, Batch: 751, Loss: 2344.26025390625\n",
      "Epoch: 0, Batch: 752, Loss: 2345.370361328125\n",
      "Epoch: 0, Batch: 753, Loss: 2199.734130859375\n",
      "Epoch: 0, Batch: 754, Loss: 2578.838134765625\n",
      "Epoch: 0, Batch: 755, Loss: 2908.3427734375\n",
      "Epoch: 0, Batch: 756, Loss: 2418.0859375\n",
      "Epoch: 0, Batch: 757, Loss: 2440.10693359375\n",
      "Epoch: 0, Batch: 758, Loss: 2295.51611328125\n",
      "Epoch: 0, Batch: 759, Loss: 2843.76220703125\n",
      "Epoch: 0, Batch: 760, Loss: 2780.2529296875\n",
      "Epoch: 0, Batch: 761, Loss: 2272.7529296875\n",
      "Epoch: 0, Batch: 762, Loss: 2486.331298828125\n",
      "Epoch: 0, Batch: 763, Loss: 2636.14794921875\n",
      "Epoch: 0, Batch: 764, Loss: 2666.243408203125\n",
      "Epoch: 0, Batch: 765, Loss: 2932.4130859375\n",
      "Epoch: 0, Batch: 766, Loss: 2732.80224609375\n",
      "Epoch: 0, Batch: 767, Loss: 2662.649169921875\n",
      "Epoch: 0, Batch: 768, Loss: 2388.556884765625\n",
      "Epoch: 0, Batch: 769, Loss: 2421.010009765625\n",
      "Epoch: 0, Batch: 770, Loss: 2615.0634765625\n",
      "Epoch: 0, Batch: 771, Loss: 2710.906494140625\n",
      "Epoch: 0, Batch: 772, Loss: 3480.86376953125\n",
      "Epoch: 0, Batch: 773, Loss: 2595.892822265625\n",
      "Epoch: 0, Batch: 774, Loss: 2882.76123046875\n",
      "Epoch: 0, Batch: 775, Loss: 2679.916015625\n",
      "Epoch: 0, Batch: 776, Loss: 2700.0185546875\n",
      "Epoch: 0, Batch: 777, Loss: 2518.33544921875\n",
      "Epoch: 0, Batch: 778, Loss: 2689.733154296875\n",
      "Epoch: 0, Batch: 779, Loss: 2888.22021484375\n",
      "Epoch: 0, Batch: 780, Loss: 1947.1551513671875\n",
      "Epoch: 0, Batch: 781, Loss: 3075.377197265625\n",
      "Epoch: 0, Batch: 782, Loss: 2178.165771484375\n",
      "Epoch: 0, Batch: 783, Loss: 3104.264404296875\n",
      "Epoch: 0, Batch: 784, Loss: 2790.54443359375\n",
      "Epoch: 0, Batch: 785, Loss: 2324.361572265625\n",
      "Epoch: 0, Batch: 786, Loss: 2478.05419921875\n",
      "Epoch: 0, Batch: 787, Loss: 2795.909912109375\n",
      "Epoch: 0, Batch: 788, Loss: 2815.571044921875\n",
      "Epoch: 0, Batch: 789, Loss: 2082.67724609375\n",
      "Epoch: 0, Batch: 790, Loss: 2534.961181640625\n",
      "Epoch: 0, Batch: 791, Loss: 2733.64892578125\n",
      "Epoch: 0, Batch: 792, Loss: 2839.493896484375\n",
      "Epoch: 0, Batch: 793, Loss: 2971.884033203125\n",
      "Epoch: 0, Batch: 794, Loss: 2380.012451171875\n",
      "Epoch: 0, Batch: 795, Loss: 2512.588134765625\n",
      "Epoch: 0, Batch: 796, Loss: 2559.001220703125\n",
      "Epoch: 0, Batch: 797, Loss: 2452.359130859375\n",
      "Epoch: 0, Batch: 798, Loss: 2320.964111328125\n",
      "Epoch: 0, Batch: 799, Loss: 2418.179931640625\n",
      "Epoch: 0, Batch: 800, Loss: 3054.09130859375\n",
      "Epoch: 0, Batch: 801, Loss: 2441.701171875\n",
      "Epoch: 0, Batch: 802, Loss: 3073.905517578125\n",
      "Epoch: 0, Batch: 803, Loss: 2938.197998046875\n",
      "Epoch: 0, Batch: 804, Loss: 2930.2158203125\n",
      "Epoch: 0, Batch: 805, Loss: 2964.89111328125\n",
      "Epoch: 0, Batch: 806, Loss: 3020.6630859375\n",
      "Epoch: 0, Batch: 807, Loss: 3066.1533203125\n",
      "Epoch: 0, Batch: 808, Loss: 2252.541015625\n",
      "Epoch: 0, Batch: 809, Loss: 3031.15673828125\n",
      "Epoch: 0, Batch: 810, Loss: 2939.875732421875\n",
      "Epoch: 0, Batch: 811, Loss: 2724.6689453125\n",
      "Epoch: 0, Batch: 812, Loss: 2560.8623046875\n",
      "Epoch: 0, Batch: 813, Loss: 2996.844482421875\n",
      "Epoch: 0, Batch: 814, Loss: 2283.167236328125\n",
      "Epoch: 0, Batch: 815, Loss: 2987.21142578125\n",
      "Epoch: 0, Batch: 816, Loss: 2380.55029296875\n",
      "Epoch: 0, Batch: 817, Loss: 2505.843994140625\n",
      "Epoch: 0, Batch: 818, Loss: 2285.62548828125\n",
      "Epoch: 0, Batch: 819, Loss: 3141.5703125\n",
      "Epoch: 0, Batch: 820, Loss: 2562.404296875\n",
      "Epoch: 0, Batch: 821, Loss: 2241.40478515625\n",
      "Epoch: 0, Batch: 822, Loss: 2824.70703125\n",
      "Epoch: 0, Batch: 823, Loss: 3004.007080078125\n",
      "Epoch: 0, Batch: 824, Loss: 2792.84619140625\n",
      "Epoch: 0, Batch: 825, Loss: 2735.470458984375\n",
      "Epoch: 0, Batch: 826, Loss: 2231.22021484375\n",
      "Epoch: 0, Batch: 827, Loss: 3271.73046875\n",
      "Epoch: 0, Batch: 828, Loss: 2735.849609375\n",
      "Epoch: 0, Batch: 829, Loss: 2909.959228515625\n",
      "Epoch: 0, Batch: 830, Loss: 2740.375\n",
      "Epoch: 0, Batch: 831, Loss: 2333.397705078125\n",
      "Epoch: 0, Batch: 832, Loss: 2630.93408203125\n",
      "Epoch: 0, Batch: 833, Loss: 2358.18896484375\n",
      "Epoch: 0, Batch: 834, Loss: 2117.576416015625\n",
      "Epoch: 0, Batch: 835, Loss: 2053.286376953125\n",
      "Epoch: 0, Batch: 836, Loss: 2820.759765625\n",
      "Epoch: 0, Batch: 837, Loss: 3099.162109375\n",
      "Epoch: 0, Batch: 838, Loss: 2770.514404296875\n",
      "Epoch: 0, Batch: 839, Loss: 2686.995849609375\n",
      "Epoch: 0, Batch: 840, Loss: 2507.155517578125\n",
      "Epoch: 0, Batch: 841, Loss: 2087.5234375\n",
      "Epoch: 0, Batch: 842, Loss: 2587.673583984375\n",
      "Epoch: 0, Batch: 843, Loss: 2395.1318359375\n",
      "Epoch: 0, Batch: 844, Loss: 3191.560302734375\n",
      "Epoch: 0, Batch: 845, Loss: 2430.672119140625\n",
      "Epoch: 0, Batch: 846, Loss: 2951.447998046875\n",
      "Epoch: 0, Batch: 847, Loss: 2674.37353515625\n",
      "Epoch: 0, Batch: 848, Loss: 3091.5615234375\n",
      "Epoch: 0, Batch: 849, Loss: 2845.1650390625\n",
      "Epoch: 0, Batch: 850, Loss: 2440.93408203125\n",
      "Epoch: 0, Batch: 851, Loss: 2489.374755859375\n",
      "Epoch: 0, Batch: 852, Loss: 2402.57177734375\n",
      "Epoch: 0, Batch: 853, Loss: 2977.15625\n",
      "Epoch: 0, Batch: 854, Loss: 2930.6494140625\n",
      "Epoch: 0, Batch: 855, Loss: 3050.485595703125\n",
      "Epoch: 0, Batch: 856, Loss: 2352.56494140625\n",
      "Epoch: 0, Batch: 857, Loss: 2840.44189453125\n",
      "Epoch: 0, Batch: 858, Loss: 3035.1728515625\n",
      "Epoch: 0, Batch: 859, Loss: 2716.37548828125\n",
      "Epoch: 0, Batch: 860, Loss: 2582.749267578125\n",
      "Epoch: 0, Batch: 861, Loss: 2200.269775390625\n",
      "Epoch: 0, Batch: 862, Loss: 2629.00146484375\n",
      "Epoch: 0, Batch: 863, Loss: 2553.264404296875\n",
      "Epoch: 0, Batch: 864, Loss: 2616.21337890625\n",
      "Epoch: 0, Batch: 865, Loss: 3048.6640625\n",
      "Epoch: 0, Batch: 866, Loss: 2296.08056640625\n",
      "Epoch: 0, Batch: 867, Loss: 2616.292724609375\n",
      "Epoch: 0, Batch: 868, Loss: 2993.66162109375\n",
      "Epoch: 0, Batch: 869, Loss: 2717.3359375\n",
      "Epoch: 0, Batch: 870, Loss: 2420.3193359375\n",
      "Epoch: 0, Batch: 871, Loss: 2960.146240234375\n",
      "Epoch: 0, Batch: 872, Loss: 3792.26318359375\n",
      "Epoch: 0, Batch: 873, Loss: 2676.18359375\n",
      "Epoch: 0, Batch: 874, Loss: 2854.693603515625\n",
      "Epoch: 0, Batch: 875, Loss: 2539.78857421875\n",
      "Epoch: 0, Batch: 876, Loss: 3046.58349609375\n",
      "Epoch: 0, Batch: 877, Loss: 2994.681396484375\n",
      "Epoch: 0, Batch: 878, Loss: 3106.343017578125\n",
      "Epoch: 0, Batch: 879, Loss: 2552.736572265625\n",
      "Epoch: 0, Batch: 880, Loss: 2355.790771484375\n",
      "Epoch: 0, Batch: 881, Loss: 2506.082763671875\n",
      "Epoch: 0, Batch: 882, Loss: 2656.50390625\n",
      "Epoch: 0, Batch: 883, Loss: 2942.890380859375\n",
      "Epoch: 0, Batch: 884, Loss: 2781.506591796875\n",
      "Epoch: 0, Batch: 885, Loss: 2765.18359375\n",
      "Epoch: 0, Batch: 886, Loss: 2166.9638671875\n",
      "Epoch: 0, Batch: 887, Loss: 2553.298095703125\n",
      "Epoch: 0, Batch: 888, Loss: 2913.0361328125\n",
      "Epoch: 0, Batch: 889, Loss: 2738.93408203125\n",
      "Epoch: 0, Batch: 890, Loss: 2255.742919921875\n",
      "Epoch: 0, Batch: 891, Loss: 2629.662841796875\n",
      "Epoch: 0, Batch: 892, Loss: 2587.11376953125\n",
      "Epoch: 0, Batch: 893, Loss: 2095.4384765625\n",
      "Epoch: 0, Batch: 894, Loss: 2883.9970703125\n",
      "Epoch: 0, Batch: 895, Loss: 2555.716796875\n",
      "Epoch: 0, Batch: 896, Loss: 2082.643798828125\n",
      "Epoch: 0, Batch: 897, Loss: 2303.535400390625\n",
      "Epoch: 0, Batch: 898, Loss: 2426.1318359375\n",
      "Epoch: 0, Batch: 899, Loss: 2462.892333984375\n",
      "Epoch: 0, Batch: 900, Loss: 2633.2177734375\n",
      "Epoch: 0, Batch: 901, Loss: 2322.750244140625\n",
      "Epoch: 0, Batch: 902, Loss: 2833.8291015625\n",
      "Epoch: 0, Batch: 903, Loss: 3048.864990234375\n",
      "Epoch: 0, Batch: 904, Loss: 2430.9814453125\n",
      "Epoch: 0, Batch: 905, Loss: 2501.615478515625\n",
      "Epoch: 0, Batch: 906, Loss: 2222.19677734375\n",
      "Epoch: 0, Batch: 907, Loss: 3205.976806640625\n",
      "Epoch: 0, Batch: 908, Loss: 2776.421630859375\n",
      "Epoch: 0, Batch: 909, Loss: 2451.904052734375\n",
      "Epoch: 0, Batch: 910, Loss: 2163.10009765625\n",
      "Epoch: 0, Batch: 911, Loss: 2871.33056640625\n",
      "Epoch: 0, Batch: 912, Loss: 3146.18701171875\n",
      "Epoch: 0, Batch: 913, Loss: 2785.132568359375\n",
      "Epoch: 0, Batch: 914, Loss: 3123.71435546875\n",
      "Epoch: 0, Batch: 915, Loss: 2430.219970703125\n",
      "Epoch: 0, Batch: 916, Loss: 3155.63818359375\n",
      "Epoch: 0, Batch: 917, Loss: 1996.21728515625\n",
      "Epoch: 0, Batch: 918, Loss: 2693.92529296875\n",
      "Epoch: 0, Batch: 919, Loss: 2851.18896484375\n",
      "Epoch: 0, Batch: 920, Loss: 2649.86767578125\n",
      "Epoch: 0, Batch: 921, Loss: 2604.15625\n",
      "Epoch: 0, Batch: 922, Loss: 1937.04345703125\n",
      "Epoch: 0, Batch: 923, Loss: 2655.25537109375\n",
      "Epoch: 0, Batch: 924, Loss: 2550.311279296875\n",
      "Epoch: 0, Batch: 925, Loss: 2625.37353515625\n",
      "Epoch: 0, Batch: 926, Loss: 2862.75732421875\n",
      "Epoch: 0, Batch: 927, Loss: 2267.8095703125\n",
      "Epoch: 0, Batch: 928, Loss: 2604.19580078125\n",
      "Epoch: 0, Batch: 929, Loss: 2750.40478515625\n",
      "Epoch: 0, Batch: 930, Loss: 2634.98974609375\n",
      "Epoch: 0, Batch: 931, Loss: 2331.45849609375\n",
      "Epoch: 0, Batch: 932, Loss: 2535.314453125\n",
      "Epoch: 0, Batch: 933, Loss: 2623.958251953125\n",
      "Epoch: 0, Batch: 934, Loss: 2444.690185546875\n",
      "Epoch: 0, Batch: 935, Loss: 3141.68212890625\n",
      "Epoch: 0, Batch: 936, Loss: 2716.920654296875\n",
      "Epoch: 0, Batch: 937, Loss: 2540.02197265625\n",
      "Epoch: 0, Batch: 938, Loss: 2825.93896484375\n",
      "Epoch: 0, Batch: 939, Loss: 2079.552734375\n",
      "Epoch: 0, Batch: 940, Loss: 2114.46240234375\n",
      "Epoch: 0, Batch: 941, Loss: 2564.64306640625\n",
      "Epoch: 0, Batch: 942, Loss: 2247.438232421875\n",
      "Epoch: 0, Batch: 943, Loss: 2812.3955078125\n",
      "Epoch: 0, Batch: 944, Loss: 2332.7353515625\n",
      "Epoch: 0, Batch: 945, Loss: 2857.900634765625\n",
      "Epoch: 0, Batch: 946, Loss: 2213.9677734375\n",
      "Epoch: 0, Batch: 947, Loss: 2936.590576171875\n",
      "Epoch: 0, Batch: 948, Loss: 2985.9716796875\n",
      "Epoch: 0, Batch: 949, Loss: 2849.40673828125\n",
      "Epoch: 0, Batch: 950, Loss: 2695.675537109375\n",
      "Epoch: 0, Batch: 951, Loss: 2290.5244140625\n",
      "Epoch: 0, Batch: 952, Loss: 2712.494384765625\n",
      "Epoch: 0, Batch: 953, Loss: 2436.117431640625\n",
      "Epoch: 0, Batch: 954, Loss: 2519.182373046875\n",
      "Epoch: 0, Batch: 955, Loss: 2909.8818359375\n",
      "Epoch: 0, Batch: 956, Loss: 2654.112060546875\n",
      "Epoch: 0, Batch: 957, Loss: 2395.925537109375\n",
      "Epoch: 0, Batch: 958, Loss: 2800.060791015625\n",
      "Epoch: 0, Batch: 959, Loss: 2337.89892578125\n",
      "Epoch: 0, Batch: 960, Loss: 2541.533447265625\n",
      "Epoch: 0, Batch: 961, Loss: 2862.846923828125\n",
      "Epoch: 0, Batch: 962, Loss: 2251.283203125\n",
      "Epoch: 0, Batch: 963, Loss: 2275.96923828125\n",
      "Epoch: 0, Batch: 964, Loss: 2058.197998046875\n",
      "Epoch: 0, Batch: 965, Loss: 2651.14990234375\n",
      "Epoch: 0, Batch: 966, Loss: 2316.755126953125\n",
      "Epoch: 0, Batch: 967, Loss: 2465.280029296875\n",
      "Epoch: 0, Batch: 968, Loss: 2473.797119140625\n",
      "Epoch: 0, Batch: 969, Loss: 2645.298095703125\n",
      "Epoch: 0, Batch: 970, Loss: 3318.93017578125\n",
      "Epoch: 0, Batch: 971, Loss: 2554.496337890625\n",
      "Epoch: 0, Batch: 972, Loss: 2173.142333984375\n",
      "Epoch: 0, Batch: 973, Loss: 2765.970947265625\n",
      "Epoch: 0, Batch: 974, Loss: 2616.26220703125\n",
      "Epoch: 0, Batch: 975, Loss: 3000.95654296875\n",
      "Epoch: 0, Batch: 976, Loss: 1956.09423828125\n",
      "Epoch: 0, Batch: 977, Loss: 3080.207275390625\n",
      "Epoch: 0, Batch: 978, Loss: 2918.706298828125\n",
      "Epoch: 0, Batch: 979, Loss: 3135.5390625\n",
      "Epoch: 0, Batch: 980, Loss: 2700.805419921875\n",
      "Epoch: 0, Batch: 981, Loss: 2618.76708984375\n",
      "Epoch: 0, Batch: 982, Loss: 3356.610595703125\n",
      "Epoch: 0, Batch: 983, Loss: 2607.689697265625\n",
      "Epoch: 0, Batch: 984, Loss: 2611.3046875\n",
      "Epoch: 0, Batch: 985, Loss: 2634.34765625\n",
      "Epoch: 0, Batch: 986, Loss: 2406.0703125\n",
      "Epoch: 0, Batch: 987, Loss: 2142.119140625\n",
      "Epoch: 0, Batch: 988, Loss: 2646.177490234375\n",
      "Epoch: 0, Batch: 989, Loss: 2643.5205078125\n",
      "Epoch: 0, Batch: 990, Loss: 2501.730712890625\n",
      "Epoch: 0, Batch: 991, Loss: 2852.640380859375\n",
      "Epoch: 0, Batch: 992, Loss: 2323.76513671875\n",
      "Epoch: 0, Batch: 993, Loss: 2659.96630859375\n",
      "Epoch: 0, Batch: 994, Loss: 2211.675048828125\n",
      "Epoch: 0, Batch: 995, Loss: 2177.16552734375\n",
      "Epoch: 0, Batch: 996, Loss: 2462.370361328125\n",
      "Epoch: 0, Batch: 997, Loss: 1501.802490234375\n",
      "Epoch: 0, Batch: 998, Loss: 2861.83056640625\n",
      "Epoch: 0, Batch: 999, Loss: 2385.682861328125\n",
      "Epoch: 1, Batch: 0, Loss: 2985.98583984375\n",
      "Epoch: 1, Batch: 1, Loss: 3153.0185546875\n",
      "Epoch: 1, Batch: 2, Loss: 2635.7021484375\n",
      "Epoch: 1, Batch: 3, Loss: 3138.022705078125\n",
      "Epoch: 1, Batch: 4, Loss: 2677.77099609375\n",
      "Epoch: 1, Batch: 5, Loss: 2726.751953125\n",
      "Epoch: 1, Batch: 6, Loss: 2633.2138671875\n",
      "Epoch: 1, Batch: 7, Loss: 2215.740966796875\n",
      "Epoch: 1, Batch: 8, Loss: 2722.53369140625\n",
      "Epoch: 1, Batch: 9, Loss: 2501.446533203125\n",
      "Epoch: 1, Batch: 10, Loss: 2353.607666015625\n",
      "Epoch: 1, Batch: 11, Loss: 2788.94384765625\n",
      "Epoch: 1, Batch: 12, Loss: 2299.307861328125\n",
      "Epoch: 1, Batch: 13, Loss: 2060.51025390625\n",
      "Epoch: 1, Batch: 14, Loss: 2600.10595703125\n",
      "Epoch: 1, Batch: 15, Loss: 2263.06689453125\n",
      "Epoch: 1, Batch: 16, Loss: 2533.971435546875\n",
      "Epoch: 1, Batch: 17, Loss: 3104.484375\n",
      "Epoch: 1, Batch: 18, Loss: 2148.990234375\n",
      "Epoch: 1, Batch: 19, Loss: 2849.841796875\n",
      "Epoch: 1, Batch: 20, Loss: 2540.383544921875\n",
      "Epoch: 1, Batch: 21, Loss: 3262.6015625\n",
      "Epoch: 1, Batch: 22, Loss: 2153.51953125\n",
      "Epoch: 1, Batch: 23, Loss: 2343.58447265625\n",
      "Epoch: 1, Batch: 24, Loss: 3089.1025390625\n",
      "Epoch: 1, Batch: 25, Loss: 2788.96044921875\n",
      "Epoch: 1, Batch: 26, Loss: 2545.463623046875\n",
      "Epoch: 1, Batch: 27, Loss: 2402.03076171875\n",
      "Epoch: 1, Batch: 28, Loss: 2817.551513671875\n",
      "Epoch: 1, Batch: 29, Loss: 2751.3037109375\n",
      "Epoch: 1, Batch: 30, Loss: 2656.836181640625\n",
      "Epoch: 1, Batch: 31, Loss: 1774.7095947265625\n",
      "Epoch: 1, Batch: 32, Loss: 2609.88037109375\n",
      "Epoch: 1, Batch: 33, Loss: 3227.611083984375\n",
      "Epoch: 1, Batch: 34, Loss: 2695.786865234375\n",
      "Epoch: 1, Batch: 35, Loss: 2413.733154296875\n",
      "Epoch: 1, Batch: 36, Loss: 2651.77783203125\n",
      "Epoch: 1, Batch: 37, Loss: 2242.424560546875\n",
      "Epoch: 1, Batch: 38, Loss: 2864.486328125\n",
      "Epoch: 1, Batch: 39, Loss: 2517.673095703125\n",
      "Epoch: 1, Batch: 40, Loss: 2520.90478515625\n",
      "Epoch: 1, Batch: 41, Loss: 2661.1826171875\n",
      "Epoch: 1, Batch: 42, Loss: 2855.5205078125\n",
      "Epoch: 1, Batch: 43, Loss: 3210.128173828125\n",
      "Epoch: 1, Batch: 44, Loss: 2173.12353515625\n",
      "Epoch: 1, Batch: 45, Loss: 2362.407470703125\n",
      "Epoch: 1, Batch: 46, Loss: 2492.531494140625\n",
      "Epoch: 1, Batch: 47, Loss: 2948.123291015625\n",
      "Epoch: 1, Batch: 48, Loss: 2655.017333984375\n",
      "Epoch: 1, Batch: 49, Loss: 2879.685546875\n",
      "Epoch: 1, Batch: 50, Loss: 2860.089599609375\n",
      "Epoch: 1, Batch: 51, Loss: 2735.600830078125\n",
      "Epoch: 1, Batch: 52, Loss: 2375.834228515625\n",
      "Epoch: 1, Batch: 53, Loss: 2864.471435546875\n",
      "Epoch: 1, Batch: 54, Loss: 3027.56982421875\n",
      "Epoch: 1, Batch: 55, Loss: 3184.584716796875\n",
      "Epoch: 1, Batch: 56, Loss: 2657.995849609375\n",
      "Epoch: 1, Batch: 57, Loss: 2750.069580078125\n",
      "Epoch: 1, Batch: 58, Loss: 2218.611083984375\n",
      "Epoch: 1, Batch: 59, Loss: 2625.458984375\n",
      "Epoch: 1, Batch: 60, Loss: 2891.47314453125\n",
      "Epoch: 1, Batch: 61, Loss: 2364.871337890625\n",
      "Epoch: 1, Batch: 62, Loss: 2982.513427734375\n",
      "Epoch: 1, Batch: 63, Loss: 2435.918212890625\n",
      "Epoch: 1, Batch: 64, Loss: 3040.685302734375\n",
      "Epoch: 1, Batch: 65, Loss: 3179.88671875\n",
      "Epoch: 1, Batch: 66, Loss: 2225.115234375\n",
      "Epoch: 1, Batch: 67, Loss: 2682.634765625\n",
      "Epoch: 1, Batch: 68, Loss: 2494.09375\n",
      "Epoch: 1, Batch: 69, Loss: 2681.86181640625\n",
      "Epoch: 1, Batch: 70, Loss: 2968.037353515625\n",
      "Epoch: 1, Batch: 71, Loss: 2499.95556640625\n",
      "Epoch: 1, Batch: 72, Loss: 2739.669921875\n",
      "Epoch: 1, Batch: 73, Loss: 3103.86962890625\n",
      "Epoch: 1, Batch: 74, Loss: 2508.58251953125\n",
      "Epoch: 1, Batch: 75, Loss: 2774.369140625\n",
      "Epoch: 1, Batch: 76, Loss: 2532.33984375\n",
      "Epoch: 1, Batch: 77, Loss: 2832.199951171875\n",
      "Epoch: 1, Batch: 78, Loss: 2474.895263671875\n",
      "Epoch: 1, Batch: 79, Loss: 2542.835693359375\n",
      "Epoch: 1, Batch: 80, Loss: 2685.96435546875\n",
      "Epoch: 1, Batch: 81, Loss: 2460.9599609375\n",
      "Epoch: 1, Batch: 82, Loss: 2642.1728515625\n",
      "Epoch: 1, Batch: 83, Loss: 2753.26416015625\n",
      "Epoch: 1, Batch: 84, Loss: 2386.75390625\n",
      "Epoch: 1, Batch: 85, Loss: 2504.2763671875\n",
      "Epoch: 1, Batch: 86, Loss: 2722.662109375\n",
      "Epoch: 1, Batch: 87, Loss: 2542.07470703125\n",
      "Epoch: 1, Batch: 88, Loss: 3051.17578125\n",
      "Epoch: 1, Batch: 89, Loss: 2557.545166015625\n",
      "Epoch: 1, Batch: 90, Loss: 2689.76123046875\n",
      "Epoch: 1, Batch: 91, Loss: 2884.066162109375\n",
      "Epoch: 1, Batch: 92, Loss: 2293.11181640625\n",
      "Epoch: 1, Batch: 93, Loss: 2064.7802734375\n",
      "Epoch: 1, Batch: 94, Loss: 3127.042236328125\n",
      "Epoch: 1, Batch: 95, Loss: 2891.7333984375\n",
      "Epoch: 1, Batch: 96, Loss: 3040.64794921875\n",
      "Epoch: 1, Batch: 97, Loss: 2468.122802734375\n",
      "Epoch: 1, Batch: 98, Loss: 2600.2578125\n",
      "Epoch: 1, Batch: 99, Loss: 2518.13916015625\n",
      "Epoch: 1, Batch: 100, Loss: 2719.42333984375\n",
      "Epoch: 1, Batch: 101, Loss: 2683.785888671875\n",
      "Epoch: 1, Batch: 102, Loss: 2988.7333984375\n",
      "Epoch: 1, Batch: 103, Loss: 2344.6044921875\n",
      "Epoch: 1, Batch: 104, Loss: 2169.4501953125\n",
      "Epoch: 1, Batch: 105, Loss: 1938.30859375\n",
      "Epoch: 1, Batch: 106, Loss: 2396.671875\n",
      "Epoch: 1, Batch: 107, Loss: 2440.706787109375\n",
      "Epoch: 1, Batch: 108, Loss: 2525.737548828125\n",
      "Epoch: 1, Batch: 109, Loss: 2559.0712890625\n",
      "Epoch: 1, Batch: 110, Loss: 1856.087646484375\n",
      "Epoch: 1, Batch: 111, Loss: 2779.1796875\n",
      "Epoch: 1, Batch: 112, Loss: 2664.72802734375\n",
      "Epoch: 1, Batch: 113, Loss: 2758.74609375\n",
      "Epoch: 1, Batch: 114, Loss: 2336.62109375\n",
      "Epoch: 1, Batch: 115, Loss: 2564.4296875\n",
      "Epoch: 1, Batch: 116, Loss: 2577.01806640625\n",
      "Epoch: 1, Batch: 117, Loss: 3020.9873046875\n",
      "Epoch: 1, Batch: 118, Loss: 2776.89501953125\n",
      "Epoch: 1, Batch: 119, Loss: 2371.199462890625\n",
      "Epoch: 1, Batch: 120, Loss: 3414.95654296875\n",
      "Epoch: 1, Batch: 121, Loss: 2431.05859375\n",
      "Epoch: 1, Batch: 122, Loss: 3065.35986328125\n",
      "Epoch: 1, Batch: 123, Loss: 2235.482421875\n",
      "Epoch: 1, Batch: 124, Loss: 3249.8193359375\n",
      "Epoch: 1, Batch: 125, Loss: 3218.28564453125\n",
      "Epoch: 1, Batch: 126, Loss: 3219.096923828125\n",
      "Epoch: 1, Batch: 127, Loss: 2265.056640625\n",
      "Epoch: 1, Batch: 128, Loss: 2435.89453125\n",
      "Epoch: 1, Batch: 129, Loss: 2564.289794921875\n",
      "Epoch: 1, Batch: 130, Loss: 2375.66455078125\n",
      "Epoch: 1, Batch: 131, Loss: 2184.602294921875\n",
      "Epoch: 1, Batch: 132, Loss: 2839.47119140625\n",
      "Epoch: 1, Batch: 133, Loss: 2483.548583984375\n",
      "Epoch: 1, Batch: 134, Loss: 2173.58544921875\n",
      "Epoch: 1, Batch: 135, Loss: 2737.174072265625\n",
      "Epoch: 1, Batch: 136, Loss: 2481.82470703125\n",
      "Epoch: 1, Batch: 137, Loss: 2931.45849609375\n",
      "Epoch: 1, Batch: 138, Loss: 2229.140625\n",
      "Epoch: 1, Batch: 139, Loss: 2744.350830078125\n",
      "Epoch: 1, Batch: 140, Loss: 2292.630126953125\n",
      "Epoch: 1, Batch: 141, Loss: 2690.3134765625\n",
      "Epoch: 1, Batch: 142, Loss: 2148.893310546875\n",
      "Epoch: 1, Batch: 143, Loss: 3095.236328125\n",
      "Epoch: 1, Batch: 144, Loss: 1772.25\n",
      "Epoch: 1, Batch: 145, Loss: 2392.10546875\n",
      "Epoch: 1, Batch: 146, Loss: 2492.946044921875\n",
      "Epoch: 1, Batch: 147, Loss: 2938.040771484375\n",
      "Epoch: 1, Batch: 148, Loss: 3186.14599609375\n",
      "Epoch: 1, Batch: 149, Loss: 2263.382568359375\n",
      "Epoch: 1, Batch: 150, Loss: 2498.392333984375\n",
      "Epoch: 1, Batch: 151, Loss: 2850.05419921875\n",
      "Epoch: 1, Batch: 152, Loss: 2825.734619140625\n",
      "Epoch: 1, Batch: 153, Loss: 2042.78173828125\n",
      "Epoch: 1, Batch: 154, Loss: 2095.80712890625\n",
      "Epoch: 1, Batch: 155, Loss: 2538.99609375\n",
      "Epoch: 1, Batch: 156, Loss: 2082.86328125\n",
      "Epoch: 1, Batch: 157, Loss: 2735.254638671875\n",
      "Epoch: 1, Batch: 158, Loss: 2571.287109375\n",
      "Epoch: 1, Batch: 159, Loss: 2971.46875\n",
      "Epoch: 1, Batch: 160, Loss: 2695.3154296875\n",
      "Epoch: 1, Batch: 161, Loss: 2721.87353515625\n",
      "Epoch: 1, Batch: 162, Loss: 2793.906005859375\n",
      "Epoch: 1, Batch: 163, Loss: 2719.95556640625\n",
      "Epoch: 1, Batch: 164, Loss: 2669.46728515625\n",
      "Epoch: 1, Batch: 165, Loss: 2763.079833984375\n",
      "Epoch: 1, Batch: 166, Loss: 2687.782958984375\n",
      "Epoch: 1, Batch: 167, Loss: 2775.1611328125\n",
      "Epoch: 1, Batch: 168, Loss: 2811.6767578125\n",
      "Epoch: 1, Batch: 169, Loss: 2339.4404296875\n",
      "Epoch: 1, Batch: 170, Loss: 2358.3369140625\n",
      "Epoch: 1, Batch: 171, Loss: 2378.17236328125\n",
      "Epoch: 1, Batch: 172, Loss: 2537.263427734375\n",
      "Epoch: 1, Batch: 173, Loss: 2556.000732421875\n",
      "Epoch: 1, Batch: 174, Loss: 2850.582763671875\n",
      "Epoch: 1, Batch: 175, Loss: 2748.635986328125\n",
      "Epoch: 1, Batch: 176, Loss: 2707.857666015625\n",
      "Epoch: 1, Batch: 177, Loss: 2424.264892578125\n",
      "Epoch: 1, Batch: 178, Loss: 2677.650146484375\n",
      "Epoch: 1, Batch: 179, Loss: 2880.552734375\n",
      "Epoch: 1, Batch: 180, Loss: 2645.673095703125\n",
      "Epoch: 1, Batch: 181, Loss: 3427.012939453125\n",
      "Epoch: 1, Batch: 182, Loss: 2464.703857421875\n",
      "Epoch: 1, Batch: 183, Loss: 2252.2099609375\n",
      "Epoch: 1, Batch: 184, Loss: 2297.56005859375\n",
      "Epoch: 1, Batch: 185, Loss: 2835.283935546875\n",
      "Epoch: 1, Batch: 186, Loss: 2282.881591796875\n",
      "Epoch: 1, Batch: 187, Loss: 2886.446533203125\n",
      "Epoch: 1, Batch: 188, Loss: 3276.34423828125\n",
      "Epoch: 1, Batch: 189, Loss: 2785.177490234375\n",
      "Epoch: 1, Batch: 190, Loss: 2283.177490234375\n",
      "Epoch: 1, Batch: 191, Loss: 2410.01171875\n",
      "Epoch: 1, Batch: 192, Loss: 2243.513916015625\n",
      "Epoch: 1, Batch: 193, Loss: 2851.740478515625\n",
      "Epoch: 1, Batch: 194, Loss: 2512.725341796875\n",
      "Epoch: 1, Batch: 195, Loss: 2280.943603515625\n",
      "Epoch: 1, Batch: 196, Loss: 2158.686767578125\n",
      "Epoch: 1, Batch: 197, Loss: 2390.02392578125\n",
      "Epoch: 1, Batch: 198, Loss: 2937.166259765625\n",
      "Epoch: 1, Batch: 199, Loss: 2564.066650390625\n",
      "Epoch: 1, Batch: 200, Loss: 2591.772216796875\n",
      "Epoch: 1, Batch: 201, Loss: 2984.12744140625\n",
      "Epoch: 1, Batch: 202, Loss: 2663.46923828125\n",
      "Epoch: 1, Batch: 203, Loss: 2022.6402587890625\n",
      "Epoch: 1, Batch: 204, Loss: 2090.81884765625\n",
      "Epoch: 1, Batch: 205, Loss: 2528.98974609375\n",
      "Epoch: 1, Batch: 206, Loss: 2719.157958984375\n",
      "Epoch: 1, Batch: 207, Loss: 2645.40087890625\n",
      "Epoch: 1, Batch: 208, Loss: 2530.133056640625\n",
      "Epoch: 1, Batch: 209, Loss: 2606.72314453125\n",
      "Epoch: 1, Batch: 210, Loss: 2498.126953125\n",
      "Epoch: 1, Batch: 211, Loss: 3109.745361328125\n",
      "Epoch: 1, Batch: 212, Loss: 2659.76806640625\n",
      "Epoch: 1, Batch: 213, Loss: 3096.935546875\n",
      "Epoch: 1, Batch: 214, Loss: 2165.644287109375\n",
      "Epoch: 1, Batch: 215, Loss: 2903.150390625\n",
      "Epoch: 1, Batch: 216, Loss: 2932.587890625\n",
      "Epoch: 1, Batch: 217, Loss: 2815.05029296875\n",
      "Epoch: 1, Batch: 218, Loss: 2760.333251953125\n",
      "Epoch: 1, Batch: 219, Loss: 2277.8583984375\n",
      "Epoch: 1, Batch: 220, Loss: 2403.3203125\n",
      "Epoch: 1, Batch: 221, Loss: 2754.41845703125\n",
      "Epoch: 1, Batch: 222, Loss: 2360.745849609375\n",
      "Epoch: 1, Batch: 223, Loss: 3040.385498046875\n",
      "Epoch: 1, Batch: 224, Loss: 2799.391845703125\n",
      "Epoch: 1, Batch: 225, Loss: 2398.386474609375\n",
      "Epoch: 1, Batch: 226, Loss: 2798.27099609375\n",
      "Epoch: 1, Batch: 227, Loss: 2682.19140625\n",
      "Epoch: 1, Batch: 228, Loss: 2833.002685546875\n",
      "Epoch: 1, Batch: 229, Loss: 2490.85009765625\n",
      "Epoch: 1, Batch: 230, Loss: 2963.93212890625\n",
      "Epoch: 1, Batch: 231, Loss: 2894.22412109375\n",
      "Epoch: 1, Batch: 232, Loss: 2637.433349609375\n",
      "Epoch: 1, Batch: 233, Loss: 2776.735595703125\n",
      "Epoch: 1, Batch: 234, Loss: 2701.083984375\n",
      "Epoch: 1, Batch: 235, Loss: 2362.113037109375\n",
      "Epoch: 1, Batch: 236, Loss: 2273.681640625\n",
      "Epoch: 1, Batch: 237, Loss: 2067.546875\n",
      "Epoch: 1, Batch: 238, Loss: 2477.049560546875\n",
      "Epoch: 1, Batch: 239, Loss: 2652.35791015625\n",
      "Epoch: 1, Batch: 240, Loss: 2789.30810546875\n",
      "Epoch: 1, Batch: 241, Loss: 2541.590087890625\n",
      "Epoch: 1, Batch: 242, Loss: 2661.085693359375\n",
      "Epoch: 1, Batch: 243, Loss: 2995.808349609375\n",
      "Epoch: 1, Batch: 244, Loss: 2215.18896484375\n",
      "Epoch: 1, Batch: 245, Loss: 2584.63427734375\n",
      "Epoch: 1, Batch: 246, Loss: 2781.0576171875\n",
      "Epoch: 1, Batch: 247, Loss: 3052.463623046875\n",
      "Epoch: 1, Batch: 248, Loss: 2381.539794921875\n",
      "Epoch: 1, Batch: 249, Loss: 2811.958984375\n",
      "Epoch: 1, Batch: 250, Loss: 2538.19970703125\n",
      "Epoch: 1, Batch: 251, Loss: 2366.491455078125\n",
      "Epoch: 1, Batch: 252, Loss: 2888.5615234375\n",
      "Epoch: 1, Batch: 253, Loss: 2868.7861328125\n",
      "Epoch: 1, Batch: 254, Loss: 1963.4007568359375\n",
      "Epoch: 1, Batch: 255, Loss: 2566.578125\n",
      "Epoch: 1, Batch: 256, Loss: 2429.2978515625\n",
      "Epoch: 1, Batch: 257, Loss: 2531.060546875\n",
      "Epoch: 1, Batch: 258, Loss: 2672.7783203125\n",
      "Epoch: 1, Batch: 259, Loss: 2205.05615234375\n",
      "Epoch: 1, Batch: 260, Loss: 2881.83544921875\n",
      "Epoch: 1, Batch: 261, Loss: 2892.673095703125\n",
      "Epoch: 1, Batch: 262, Loss: 2808.6455078125\n",
      "Epoch: 1, Batch: 263, Loss: 2714.650146484375\n",
      "Epoch: 1, Batch: 264, Loss: 2739.76611328125\n",
      "Epoch: 1, Batch: 265, Loss: 2386.24609375\n",
      "Epoch: 1, Batch: 266, Loss: 2706.91552734375\n",
      "Epoch: 1, Batch: 267, Loss: 2725.60498046875\n",
      "Epoch: 1, Batch: 268, Loss: 2268.31591796875\n",
      "Epoch: 1, Batch: 269, Loss: 2401.821533203125\n",
      "Epoch: 1, Batch: 270, Loss: 2427.907470703125\n",
      "Epoch: 1, Batch: 271, Loss: 2434.1708984375\n",
      "Epoch: 1, Batch: 272, Loss: 2665.42138671875\n",
      "Epoch: 1, Batch: 273, Loss: 2839.682861328125\n",
      "Epoch: 1, Batch: 274, Loss: 3124.83349609375\n",
      "Epoch: 1, Batch: 275, Loss: 2451.31494140625\n",
      "Epoch: 1, Batch: 276, Loss: 3254.502685546875\n",
      "Epoch: 1, Batch: 277, Loss: 2849.4609375\n",
      "Epoch: 1, Batch: 278, Loss: 2602.14404296875\n",
      "Epoch: 1, Batch: 279, Loss: 2076.19775390625\n",
      "Epoch: 1, Batch: 280, Loss: 2994.8603515625\n",
      "Epoch: 1, Batch: 281, Loss: 3179.137451171875\n",
      "Epoch: 1, Batch: 282, Loss: 2828.185791015625\n",
      "Epoch: 1, Batch: 283, Loss: 2971.943115234375\n",
      "Epoch: 1, Batch: 284, Loss: 2781.80517578125\n",
      "Epoch: 1, Batch: 285, Loss: 2661.476318359375\n",
      "Epoch: 1, Batch: 286, Loss: 2747.091552734375\n",
      "Epoch: 1, Batch: 287, Loss: 2897.319091796875\n",
      "Epoch: 1, Batch: 288, Loss: 2464.92236328125\n",
      "Epoch: 1, Batch: 289, Loss: 3076.58251953125\n",
      "Epoch: 1, Batch: 290, Loss: 1948.2928466796875\n",
      "Epoch: 1, Batch: 291, Loss: 2316.1650390625\n",
      "Epoch: 1, Batch: 292, Loss: 2954.9560546875\n",
      "Epoch: 1, Batch: 293, Loss: 2459.38916015625\n",
      "Epoch: 1, Batch: 294, Loss: 2283.768310546875\n",
      "Epoch: 1, Batch: 295, Loss: 2638.73876953125\n",
      "Epoch: 1, Batch: 296, Loss: 3077.964111328125\n",
      "Epoch: 1, Batch: 297, Loss: 2669.91455078125\n",
      "Epoch: 1, Batch: 298, Loss: 2875.705078125\n",
      "Epoch: 1, Batch: 299, Loss: 3325.809814453125\n",
      "Epoch: 1, Batch: 300, Loss: 2809.95068359375\n",
      "Epoch: 1, Batch: 301, Loss: 2761.41259765625\n",
      "Epoch: 1, Batch: 302, Loss: 2135.437255859375\n",
      "Epoch: 1, Batch: 303, Loss: 2331.30126953125\n",
      "Epoch: 1, Batch: 304, Loss: 2829.015869140625\n",
      "Epoch: 1, Batch: 305, Loss: 2410.01220703125\n",
      "Epoch: 1, Batch: 306, Loss: 2862.2216796875\n",
      "Epoch: 1, Batch: 307, Loss: 2191.25830078125\n",
      "Epoch: 1, Batch: 308, Loss: 2752.52880859375\n",
      "Epoch: 1, Batch: 309, Loss: 2530.854736328125\n",
      "Epoch: 1, Batch: 310, Loss: 3288.916259765625\n",
      "Epoch: 1, Batch: 311, Loss: 2742.994384765625\n",
      "Epoch: 1, Batch: 312, Loss: 2871.544921875\n",
      "Epoch: 1, Batch: 313, Loss: 2359.52587890625\n",
      "Epoch: 1, Batch: 314, Loss: 2223.372802734375\n",
      "Epoch: 1, Batch: 315, Loss: 2662.017822265625\n",
      "Epoch: 1, Batch: 316, Loss: 2870.433349609375\n",
      "Epoch: 1, Batch: 317, Loss: 2684.59814453125\n",
      "Epoch: 1, Batch: 318, Loss: 2726.1865234375\n",
      "Epoch: 1, Batch: 319, Loss: 2464.906982421875\n",
      "Epoch: 1, Batch: 320, Loss: 2610.66162109375\n",
      "Epoch: 1, Batch: 321, Loss: 2604.319091796875\n",
      "Epoch: 1, Batch: 322, Loss: 2303.447021484375\n",
      "Epoch: 1, Batch: 323, Loss: 2968.67529296875\n",
      "Epoch: 1, Batch: 324, Loss: 2365.945556640625\n",
      "Epoch: 1, Batch: 325, Loss: 2196.67236328125\n",
      "Epoch: 1, Batch: 326, Loss: 2128.399658203125\n",
      "Epoch: 1, Batch: 327, Loss: 2215.368408203125\n",
      "Epoch: 1, Batch: 328, Loss: 3105.26318359375\n",
      "Epoch: 1, Batch: 329, Loss: 2484.7138671875\n",
      "Epoch: 1, Batch: 330, Loss: 2646.67578125\n",
      "Epoch: 1, Batch: 331, Loss: 3099.849609375\n",
      "Epoch: 1, Batch: 332, Loss: 2595.425537109375\n",
      "Epoch: 1, Batch: 333, Loss: 2350.011474609375\n",
      "Epoch: 1, Batch: 334, Loss: 2149.011474609375\n",
      "Epoch: 1, Batch: 335, Loss: 2825.5087890625\n",
      "Epoch: 1, Batch: 336, Loss: 2962.6220703125\n",
      "Epoch: 1, Batch: 337, Loss: 2951.69189453125\n",
      "Epoch: 1, Batch: 338, Loss: 3217.14599609375\n",
      "Epoch: 1, Batch: 339, Loss: 2588.942626953125\n",
      "Epoch: 1, Batch: 340, Loss: 2191.805419921875\n",
      "Epoch: 1, Batch: 341, Loss: 2877.712158203125\n",
      "Epoch: 1, Batch: 342, Loss: 2578.392578125\n",
      "Epoch: 1, Batch: 343, Loss: 2986.41015625\n",
      "Epoch: 1, Batch: 344, Loss: 2403.220947265625\n",
      "Epoch: 1, Batch: 345, Loss: 2539.56103515625\n",
      "Epoch: 1, Batch: 346, Loss: 2384.50732421875\n",
      "Epoch: 1, Batch: 347, Loss: 1917.070556640625\n",
      "Epoch: 1, Batch: 348, Loss: 2417.693115234375\n",
      "Epoch: 1, Batch: 349, Loss: 3156.824462890625\n",
      "Epoch: 1, Batch: 350, Loss: 3230.098876953125\n",
      "Epoch: 1, Batch: 351, Loss: 2812.9990234375\n",
      "Epoch: 1, Batch: 352, Loss: 2517.910400390625\n",
      "Epoch: 1, Batch: 353, Loss: 2773.9130859375\n",
      "Epoch: 1, Batch: 354, Loss: 2433.72607421875\n",
      "Epoch: 1, Batch: 355, Loss: 2685.692138671875\n",
      "Epoch: 1, Batch: 356, Loss: 2675.60791015625\n",
      "Epoch: 1, Batch: 357, Loss: 2848.419677734375\n",
      "Epoch: 1, Batch: 358, Loss: 2203.02294921875\n",
      "Epoch: 1, Batch: 359, Loss: 2847.685302734375\n",
      "Epoch: 1, Batch: 360, Loss: 2672.05224609375\n",
      "Epoch: 1, Batch: 361, Loss: 2609.806884765625\n",
      "Epoch: 1, Batch: 362, Loss: 2531.99072265625\n",
      "Epoch: 1, Batch: 363, Loss: 2208.23046875\n",
      "Epoch: 1, Batch: 364, Loss: 2888.975830078125\n",
      "Epoch: 1, Batch: 365, Loss: 2336.53515625\n",
      "Epoch: 1, Batch: 366, Loss: 1826.61669921875\n",
      "Epoch: 1, Batch: 367, Loss: 2943.806396484375\n",
      "Epoch: 1, Batch: 368, Loss: 2943.267578125\n",
      "Epoch: 1, Batch: 369, Loss: 2784.28369140625\n",
      "Epoch: 1, Batch: 370, Loss: 2574.3720703125\n",
      "Epoch: 1, Batch: 371, Loss: 2229.13818359375\n",
      "Epoch: 1, Batch: 372, Loss: 2549.49609375\n",
      "Epoch: 1, Batch: 373, Loss: 1811.4033203125\n",
      "Epoch: 1, Batch: 374, Loss: 2350.628173828125\n",
      "Epoch: 1, Batch: 375, Loss: 2459.155029296875\n",
      "Epoch: 1, Batch: 376, Loss: 2787.509521484375\n",
      "Epoch: 1, Batch: 377, Loss: 2743.72705078125\n",
      "Epoch: 1, Batch: 378, Loss: 2313.506591796875\n",
      "Epoch: 1, Batch: 379, Loss: 3275.180908203125\n",
      "Epoch: 1, Batch: 380, Loss: 3127.248291015625\n",
      "Epoch: 1, Batch: 381, Loss: 2073.610595703125\n",
      "Epoch: 1, Batch: 382, Loss: 2320.272216796875\n",
      "Epoch: 1, Batch: 383, Loss: 2316.09423828125\n",
      "Epoch: 1, Batch: 384, Loss: 2987.271728515625\n",
      "Epoch: 1, Batch: 385, Loss: 2701.26318359375\n",
      "Epoch: 1, Batch: 386, Loss: 2866.979736328125\n",
      "Epoch: 1, Batch: 387, Loss: 2636.95947265625\n",
      "Epoch: 1, Batch: 388, Loss: 2398.6328125\n",
      "Epoch: 1, Batch: 389, Loss: 2746.552001953125\n",
      "Epoch: 1, Batch: 390, Loss: 2349.7275390625\n",
      "Epoch: 1, Batch: 391, Loss: 2305.09228515625\n",
      "Epoch: 1, Batch: 392, Loss: 2842.524169921875\n",
      "Epoch: 1, Batch: 393, Loss: 2280.85400390625\n",
      "Epoch: 1, Batch: 394, Loss: 2667.731201171875\n",
      "Epoch: 1, Batch: 395, Loss: 2660.83544921875\n",
      "Epoch: 1, Batch: 396, Loss: 2479.223388671875\n",
      "Epoch: 1, Batch: 397, Loss: 2450.4921875\n",
      "Epoch: 1, Batch: 398, Loss: 3154.9248046875\n",
      "Epoch: 1, Batch: 399, Loss: 2819.041259765625\n",
      "Epoch: 1, Batch: 400, Loss: 2542.847412109375\n",
      "Epoch: 1, Batch: 401, Loss: 2542.706298828125\n",
      "Epoch: 1, Batch: 402, Loss: 2727.848388671875\n",
      "Epoch: 1, Batch: 403, Loss: 3004.518798828125\n",
      "Epoch: 1, Batch: 404, Loss: 3474.347900390625\n",
      "Epoch: 1, Batch: 405, Loss: 2304.39697265625\n",
      "Epoch: 1, Batch: 406, Loss: 2292.051025390625\n",
      "Epoch: 1, Batch: 407, Loss: 2705.6767578125\n",
      "Epoch: 1, Batch: 408, Loss: 3450.962158203125\n",
      "Epoch: 1, Batch: 409, Loss: 2938.492431640625\n",
      "Epoch: 1, Batch: 410, Loss: 2555.72314453125\n",
      "Epoch: 1, Batch: 411, Loss: 2542.218017578125\n",
      "Epoch: 1, Batch: 412, Loss: 2378.994873046875\n",
      "Epoch: 1, Batch: 413, Loss: 2412.384521484375\n",
      "Epoch: 1, Batch: 414, Loss: 2525.023681640625\n",
      "Epoch: 1, Batch: 415, Loss: 2716.79541015625\n",
      "Epoch: 1, Batch: 416, Loss: 1957.5343017578125\n",
      "Epoch: 1, Batch: 417, Loss: 2432.60107421875\n",
      "Epoch: 1, Batch: 418, Loss: 2591.365478515625\n",
      "Epoch: 1, Batch: 419, Loss: 2172.966796875\n",
      "Epoch: 1, Batch: 420, Loss: 2375.255615234375\n",
      "Epoch: 1, Batch: 421, Loss: 2192.921142578125\n",
      "Epoch: 1, Batch: 422, Loss: 2702.6123046875\n",
      "Epoch: 1, Batch: 423, Loss: 3462.871826171875\n",
      "Epoch: 1, Batch: 424, Loss: 2812.473388671875\n",
      "Epoch: 1, Batch: 425, Loss: 2982.57080078125\n",
      "Epoch: 1, Batch: 426, Loss: 2599.917236328125\n",
      "Epoch: 1, Batch: 427, Loss: 2892.009521484375\n",
      "Epoch: 1, Batch: 428, Loss: 3390.808837890625\n",
      "Epoch: 1, Batch: 429, Loss: 2313.615234375\n",
      "Epoch: 1, Batch: 430, Loss: 2775.2431640625\n",
      "Epoch: 1, Batch: 431, Loss: 3072.095947265625\n",
      "Epoch: 1, Batch: 432, Loss: 2554.366943359375\n",
      "Epoch: 1, Batch: 433, Loss: 2311.387939453125\n",
      "Epoch: 1, Batch: 434, Loss: 2101.00537109375\n",
      "Epoch: 1, Batch: 435, Loss: 2234.71240234375\n",
      "Epoch: 1, Batch: 436, Loss: 2524.090087890625\n",
      "Epoch: 1, Batch: 437, Loss: 3187.801025390625\n",
      "Epoch: 1, Batch: 438, Loss: 2372.350341796875\n",
      "Epoch: 1, Batch: 439, Loss: 2303.234130859375\n",
      "Epoch: 1, Batch: 440, Loss: 3469.17041015625\n",
      "Epoch: 1, Batch: 441, Loss: 2738.22265625\n",
      "Epoch: 1, Batch: 442, Loss: 2467.625244140625\n",
      "Epoch: 1, Batch: 443, Loss: 2566.492919921875\n",
      "Epoch: 1, Batch: 444, Loss: 2925.694580078125\n",
      "Epoch: 1, Batch: 445, Loss: 2733.79833984375\n",
      "Epoch: 1, Batch: 446, Loss: 2386.85888671875\n",
      "Epoch: 1, Batch: 447, Loss: 2960.704345703125\n",
      "Epoch: 1, Batch: 448, Loss: 2246.33154296875\n",
      "Epoch: 1, Batch: 449, Loss: 3776.17919921875\n",
      "Epoch: 1, Batch: 450, Loss: 2709.82568359375\n",
      "Epoch: 1, Batch: 451, Loss: 2955.094482421875\n",
      "Epoch: 1, Batch: 452, Loss: 3038.454345703125\n",
      "Epoch: 1, Batch: 453, Loss: 2490.474853515625\n",
      "Epoch: 1, Batch: 454, Loss: 3018.972900390625\n",
      "Epoch: 1, Batch: 455, Loss: 2736.10107421875\n",
      "Epoch: 1, Batch: 456, Loss: 2410.12109375\n",
      "Epoch: 1, Batch: 457, Loss: 2451.606689453125\n",
      "Epoch: 1, Batch: 458, Loss: 2440.17529296875\n",
      "Epoch: 1, Batch: 459, Loss: 3184.29833984375\n",
      "Epoch: 1, Batch: 460, Loss: 3536.955810546875\n",
      "Epoch: 1, Batch: 461, Loss: 2629.17041015625\n",
      "Epoch: 1, Batch: 462, Loss: 2742.928955078125\n",
      "Epoch: 1, Batch: 463, Loss: 2416.238037109375\n",
      "Epoch: 1, Batch: 464, Loss: 2519.464599609375\n",
      "Epoch: 1, Batch: 465, Loss: 2337.81298828125\n",
      "Epoch: 1, Batch: 466, Loss: 2624.452392578125\n",
      "Epoch: 1, Batch: 467, Loss: 2412.224853515625\n",
      "Epoch: 1, Batch: 468, Loss: 2639.23486328125\n",
      "Epoch: 1, Batch: 469, Loss: 2837.164794921875\n",
      "Epoch: 1, Batch: 470, Loss: 2370.0166015625\n",
      "Epoch: 1, Batch: 471, Loss: 2851.16357421875\n",
      "Epoch: 1, Batch: 472, Loss: 2657.011474609375\n",
      "Epoch: 1, Batch: 473, Loss: 2333.676025390625\n",
      "Epoch: 1, Batch: 474, Loss: 2797.850830078125\n",
      "Epoch: 1, Batch: 475, Loss: 2967.935791015625\n",
      "Epoch: 1, Batch: 476, Loss: 2767.302001953125\n",
      "Epoch: 1, Batch: 477, Loss: 2370.254638671875\n",
      "Epoch: 1, Batch: 478, Loss: 2556.928466796875\n",
      "Epoch: 1, Batch: 479, Loss: 2650.5966796875\n",
      "Epoch: 1, Batch: 480, Loss: 2345.20556640625\n",
      "Epoch: 1, Batch: 481, Loss: 2795.606689453125\n",
      "Epoch: 1, Batch: 482, Loss: 2013.5511474609375\n",
      "Epoch: 1, Batch: 483, Loss: 2346.168701171875\n",
      "Epoch: 1, Batch: 484, Loss: 2969.26904296875\n",
      "Epoch: 1, Batch: 485, Loss: 2436.038818359375\n",
      "Epoch: 1, Batch: 486, Loss: 2489.840576171875\n",
      "Epoch: 1, Batch: 487, Loss: 2593.328369140625\n",
      "Epoch: 1, Batch: 488, Loss: 2973.38037109375\n",
      "Epoch: 1, Batch: 489, Loss: 2694.07470703125\n",
      "Epoch: 1, Batch: 490, Loss: 2073.52099609375\n",
      "Epoch: 1, Batch: 491, Loss: 2926.637939453125\n",
      "Epoch: 1, Batch: 492, Loss: 2539.494873046875\n",
      "Epoch: 1, Batch: 493, Loss: 2126.715576171875\n",
      "Epoch: 1, Batch: 494, Loss: 2556.862060546875\n",
      "Epoch: 1, Batch: 495, Loss: 2407.15234375\n",
      "Epoch: 1, Batch: 496, Loss: 2735.54150390625\n",
      "Epoch: 1, Batch: 497, Loss: 2516.55859375\n",
      "Epoch: 1, Batch: 498, Loss: 1851.6624755859375\n",
      "Epoch: 1, Batch: 499, Loss: 2661.739501953125\n",
      "Epoch: 1, Batch: 500, Loss: 2773.4951171875\n",
      "Epoch: 1, Batch: 501, Loss: 3076.4638671875\n",
      "Epoch: 1, Batch: 502, Loss: 2611.842041015625\n",
      "Epoch: 1, Batch: 503, Loss: 2122.584228515625\n",
      "Epoch: 1, Batch: 504, Loss: 2167.103515625\n",
      "Epoch: 1, Batch: 505, Loss: 2352.07568359375\n",
      "Epoch: 1, Batch: 506, Loss: 2805.78271484375\n",
      "Epoch: 1, Batch: 507, Loss: 2910.73095703125\n",
      "Epoch: 1, Batch: 508, Loss: 2563.645751953125\n",
      "Epoch: 1, Batch: 509, Loss: 3022.611328125\n",
      "Epoch: 1, Batch: 510, Loss: 2211.787109375\n",
      "Epoch: 1, Batch: 511, Loss: 2284.1201171875\n",
      "Epoch: 1, Batch: 512, Loss: 2697.715576171875\n",
      "Epoch: 1, Batch: 513, Loss: 2142.93310546875\n",
      "Epoch: 1, Batch: 514, Loss: 2938.5224609375\n",
      "Epoch: 1, Batch: 515, Loss: 2858.015380859375\n",
      "Epoch: 1, Batch: 516, Loss: 2534.53173828125\n",
      "Epoch: 1, Batch: 517, Loss: 2629.749755859375\n",
      "Epoch: 1, Batch: 518, Loss: 2649.395263671875\n",
      "Epoch: 1, Batch: 519, Loss: 2892.787841796875\n",
      "Epoch: 1, Batch: 520, Loss: 3110.879638671875\n",
      "Epoch: 1, Batch: 521, Loss: 2217.973388671875\n",
      "Epoch: 1, Batch: 522, Loss: 2930.08984375\n",
      "Epoch: 1, Batch: 523, Loss: 2819.72607421875\n",
      "Epoch: 1, Batch: 524, Loss: 2381.541259765625\n",
      "Epoch: 1, Batch: 525, Loss: 2577.537109375\n",
      "Epoch: 1, Batch: 526, Loss: 2212.84521484375\n",
      "Epoch: 1, Batch: 527, Loss: 2768.74462890625\n",
      "Epoch: 1, Batch: 528, Loss: 3186.990478515625\n",
      "Epoch: 1, Batch: 529, Loss: 2565.626708984375\n",
      "Epoch: 1, Batch: 530, Loss: 2631.993896484375\n",
      "Epoch: 1, Batch: 531, Loss: 2558.12353515625\n",
      "Epoch: 1, Batch: 532, Loss: 2924.109375\n",
      "Epoch: 1, Batch: 533, Loss: 2420.810791015625\n",
      "Epoch: 1, Batch: 534, Loss: 2504.144287109375\n",
      "Epoch: 1, Batch: 535, Loss: 2399.915771484375\n",
      "Epoch: 1, Batch: 536, Loss: 2790.869140625\n",
      "Epoch: 1, Batch: 537, Loss: 2568.939697265625\n",
      "Epoch: 1, Batch: 538, Loss: 2791.435791015625\n",
      "Epoch: 1, Batch: 539, Loss: 3074.026611328125\n",
      "Epoch: 1, Batch: 540, Loss: 2396.510986328125\n",
      "Epoch: 1, Batch: 541, Loss: 2529.00830078125\n",
      "Epoch: 1, Batch: 542, Loss: 3041.965576171875\n",
      "Epoch: 1, Batch: 543, Loss: 2486.962890625\n",
      "Epoch: 1, Batch: 544, Loss: 3010.12744140625\n",
      "Epoch: 1, Batch: 545, Loss: 2358.039794921875\n",
      "Epoch: 1, Batch: 546, Loss: 2662.2275390625\n",
      "Epoch: 1, Batch: 547, Loss: 2357.148193359375\n",
      "Epoch: 1, Batch: 548, Loss: 2652.510009765625\n",
      "Epoch: 1, Batch: 549, Loss: 2830.1083984375\n",
      "Epoch: 1, Batch: 550, Loss: 2344.970947265625\n",
      "Epoch: 1, Batch: 551, Loss: 2526.703857421875\n",
      "Epoch: 1, Batch: 552, Loss: 3313.728271484375\n",
      "Epoch: 1, Batch: 553, Loss: 2202.11181640625\n",
      "Epoch: 1, Batch: 554, Loss: 3076.068359375\n",
      "Epoch: 1, Batch: 555, Loss: 3137.335693359375\n",
      "Epoch: 1, Batch: 556, Loss: 2820.373779296875\n",
      "Epoch: 1, Batch: 557, Loss: 2712.056396484375\n",
      "Epoch: 1, Batch: 558, Loss: 2647.152099609375\n",
      "Epoch: 1, Batch: 559, Loss: 2621.2021484375\n",
      "Epoch: 1, Batch: 560, Loss: 2233.55712890625\n",
      "Epoch: 1, Batch: 561, Loss: 2806.7314453125\n",
      "Epoch: 1, Batch: 562, Loss: 2556.14990234375\n",
      "Epoch: 1, Batch: 563, Loss: 2484.74072265625\n",
      "Epoch: 1, Batch: 564, Loss: 2468.62353515625\n",
      "Epoch: 1, Batch: 565, Loss: 3003.218994140625\n",
      "Epoch: 1, Batch: 566, Loss: 2379.76416015625\n",
      "Epoch: 1, Batch: 567, Loss: 2482.5830078125\n",
      "Epoch: 1, Batch: 568, Loss: 2444.726318359375\n",
      "Epoch: 1, Batch: 569, Loss: 2952.52001953125\n",
      "Epoch: 1, Batch: 570, Loss: 2480.238037109375\n",
      "Epoch: 1, Batch: 571, Loss: 2526.614990234375\n",
      "Epoch: 1, Batch: 572, Loss: 3022.4306640625\n",
      "Epoch: 1, Batch: 573, Loss: 2735.31298828125\n",
      "Epoch: 1, Batch: 574, Loss: 3110.5654296875\n",
      "Epoch: 1, Batch: 575, Loss: 3205.145263671875\n",
      "Epoch: 1, Batch: 576, Loss: 2661.630615234375\n",
      "Epoch: 1, Batch: 577, Loss: 3284.384033203125\n",
      "Epoch: 1, Batch: 578, Loss: 2030.1009521484375\n",
      "Epoch: 1, Batch: 579, Loss: 2797.890625\n",
      "Epoch: 1, Batch: 580, Loss: 3158.1142578125\n",
      "Epoch: 1, Batch: 581, Loss: 2805.95947265625\n",
      "Epoch: 1, Batch: 582, Loss: 2695.683349609375\n",
      "Epoch: 1, Batch: 583, Loss: 2900.2431640625\n",
      "Epoch: 1, Batch: 584, Loss: 2573.62744140625\n",
      "Epoch: 1, Batch: 585, Loss: 2815.94287109375\n",
      "Epoch: 1, Batch: 586, Loss: 2698.7333984375\n",
      "Epoch: 1, Batch: 587, Loss: 2408.361328125\n",
      "Epoch: 1, Batch: 588, Loss: 2541.5693359375\n",
      "Epoch: 1, Batch: 589, Loss: 2772.559814453125\n",
      "Epoch: 1, Batch: 590, Loss: 2593.08251953125\n",
      "Epoch: 1, Batch: 591, Loss: 2655.302001953125\n",
      "Epoch: 1, Batch: 592, Loss: 2636.334716796875\n",
      "Epoch: 1, Batch: 593, Loss: 2316.53759765625\n",
      "Epoch: 1, Batch: 594, Loss: 2184.733154296875\n",
      "Epoch: 1, Batch: 595, Loss: 2178.052978515625\n",
      "Epoch: 1, Batch: 596, Loss: 2670.390869140625\n",
      "Epoch: 1, Batch: 597, Loss: 2562.776123046875\n",
      "Epoch: 1, Batch: 598, Loss: 2047.084716796875\n",
      "Epoch: 1, Batch: 599, Loss: 3004.80419921875\n",
      "Epoch: 1, Batch: 600, Loss: 2873.039794921875\n",
      "Epoch: 1, Batch: 601, Loss: 2550.83740234375\n",
      "Epoch: 1, Batch: 602, Loss: 2565.602294921875\n",
      "Epoch: 1, Batch: 603, Loss: 2841.46142578125\n",
      "Epoch: 1, Batch: 604, Loss: 2342.072998046875\n",
      "Epoch: 1, Batch: 605, Loss: 3145.154052734375\n",
      "Epoch: 1, Batch: 606, Loss: 2494.370849609375\n",
      "Epoch: 1, Batch: 607, Loss: 2877.96142578125\n",
      "Epoch: 1, Batch: 608, Loss: 2460.744140625\n",
      "Epoch: 1, Batch: 609, Loss: 2610.9111328125\n",
      "Epoch: 1, Batch: 610, Loss: 2321.015625\n",
      "Epoch: 1, Batch: 611, Loss: 3080.099609375\n",
      "Epoch: 1, Batch: 612, Loss: 2678.36865234375\n",
      "Epoch: 1, Batch: 613, Loss: 2261.91845703125\n",
      "Epoch: 1, Batch: 614, Loss: 2284.871826171875\n",
      "Epoch: 1, Batch: 615, Loss: 2438.2412109375\n",
      "Epoch: 1, Batch: 616, Loss: 2862.61865234375\n",
      "Epoch: 1, Batch: 617, Loss: 2759.551025390625\n",
      "Epoch: 1, Batch: 618, Loss: 2394.895263671875\n",
      "Epoch: 1, Batch: 619, Loss: 2501.234619140625\n",
      "Epoch: 1, Batch: 620, Loss: 2404.510498046875\n",
      "Epoch: 1, Batch: 621, Loss: 2458.4375\n",
      "Epoch: 1, Batch: 622, Loss: 2592.115478515625\n",
      "Epoch: 1, Batch: 623, Loss: 3079.894775390625\n",
      "Epoch: 1, Batch: 624, Loss: 2776.896728515625\n",
      "Epoch: 1, Batch: 625, Loss: 2614.006103515625\n",
      "Epoch: 1, Batch: 626, Loss: 2523.50830078125\n",
      "Epoch: 1, Batch: 627, Loss: 3221.440185546875\n",
      "Epoch: 1, Batch: 628, Loss: 2935.994140625\n",
      "Epoch: 1, Batch: 629, Loss: 2866.54541015625\n",
      "Epoch: 1, Batch: 630, Loss: 2820.1015625\n",
      "Epoch: 1, Batch: 631, Loss: 2053.80224609375\n",
      "Epoch: 1, Batch: 632, Loss: 2833.53564453125\n",
      "Epoch: 1, Batch: 633, Loss: 2651.529296875\n",
      "Epoch: 1, Batch: 634, Loss: 3134.175537109375\n",
      "Epoch: 1, Batch: 635, Loss: 2438.731201171875\n",
      "Epoch: 1, Batch: 636, Loss: 2937.95361328125\n",
      "Epoch: 1, Batch: 637, Loss: 2906.36962890625\n",
      "Epoch: 1, Batch: 638, Loss: 2499.6796875\n",
      "Epoch: 1, Batch: 639, Loss: 2574.5546875\n",
      "Epoch: 1, Batch: 640, Loss: 2559.12646484375\n",
      "Epoch: 1, Batch: 641, Loss: 2630.0205078125\n",
      "Epoch: 1, Batch: 642, Loss: 2663.79248046875\n",
      "Epoch: 1, Batch: 643, Loss: 2950.632080078125\n",
      "Epoch: 1, Batch: 644, Loss: 3021.35791015625\n",
      "Epoch: 1, Batch: 645, Loss: 3157.110107421875\n",
      "Epoch: 1, Batch: 646, Loss: 2157.932861328125\n",
      "Epoch: 1, Batch: 647, Loss: 2340.51318359375\n",
      "Epoch: 1, Batch: 648, Loss: 3062.54833984375\n",
      "Epoch: 1, Batch: 649, Loss: 2703.1005859375\n",
      "Epoch: 1, Batch: 650, Loss: 2640.27490234375\n",
      "Epoch: 1, Batch: 651, Loss: 2846.953125\n",
      "Epoch: 1, Batch: 652, Loss: 2846.243896484375\n",
      "Epoch: 1, Batch: 653, Loss: 2554.006591796875\n",
      "Epoch: 1, Batch: 654, Loss: 2735.92431640625\n",
      "Epoch: 1, Batch: 655, Loss: 2821.23779296875\n",
      "Epoch: 1, Batch: 656, Loss: 2566.572998046875\n",
      "Epoch: 1, Batch: 657, Loss: 3466.0703125\n",
      "Epoch: 1, Batch: 658, Loss: 3070.51416015625\n",
      "Epoch: 1, Batch: 659, Loss: 2591.292236328125\n",
      "Epoch: 1, Batch: 660, Loss: 2872.50341796875\n",
      "Epoch: 1, Batch: 661, Loss: 2639.3974609375\n",
      "Epoch: 1, Batch: 662, Loss: 2079.589111328125\n",
      "Epoch: 1, Batch: 663, Loss: 2721.603515625\n",
      "Epoch: 1, Batch: 664, Loss: 2579.877197265625\n",
      "Epoch: 1, Batch: 665, Loss: 2824.583740234375\n",
      "Epoch: 1, Batch: 666, Loss: 2645.579345703125\n",
      "Epoch: 1, Batch: 667, Loss: 2396.975341796875\n",
      "Epoch: 1, Batch: 668, Loss: 2145.063720703125\n",
      "Epoch: 1, Batch: 669, Loss: 2317.68505859375\n",
      "Epoch: 1, Batch: 670, Loss: 2590.08251953125\n",
      "Epoch: 1, Batch: 671, Loss: 2816.514892578125\n",
      "Epoch: 1, Batch: 672, Loss: 2464.290283203125\n",
      "Epoch: 1, Batch: 673, Loss: 3001.332275390625\n",
      "Epoch: 1, Batch: 674, Loss: 3002.7763671875\n",
      "Epoch: 1, Batch: 675, Loss: 2955.28857421875\n",
      "Epoch: 1, Batch: 676, Loss: 3045.2451171875\n",
      "Epoch: 1, Batch: 677, Loss: 2706.25830078125\n",
      "Epoch: 1, Batch: 678, Loss: 2792.52978515625\n",
      "Epoch: 1, Batch: 679, Loss: 2473.9853515625\n",
      "Epoch: 1, Batch: 680, Loss: 2861.042724609375\n",
      "Epoch: 1, Batch: 681, Loss: 3181.374755859375\n",
      "Epoch: 1, Batch: 682, Loss: 2592.197509765625\n",
      "Epoch: 1, Batch: 683, Loss: 2321.8408203125\n",
      "Epoch: 1, Batch: 684, Loss: 2609.77294921875\n",
      "Epoch: 1, Batch: 685, Loss: 2671.5595703125\n",
      "Epoch: 1, Batch: 686, Loss: 2258.814208984375\n",
      "Epoch: 1, Batch: 687, Loss: 2601.289306640625\n",
      "Epoch: 1, Batch: 688, Loss: 2872.5244140625\n",
      "Epoch: 1, Batch: 689, Loss: 2975.9931640625\n",
      "Epoch: 1, Batch: 690, Loss: 2756.95361328125\n",
      "Epoch: 1, Batch: 691, Loss: 2708.4716796875\n",
      "Epoch: 1, Batch: 692, Loss: 2766.16845703125\n",
      "Epoch: 1, Batch: 693, Loss: 2858.66845703125\n",
      "Epoch: 1, Batch: 694, Loss: 2713.819091796875\n",
      "Epoch: 1, Batch: 695, Loss: 2280.00634765625\n",
      "Epoch: 1, Batch: 696, Loss: 3062.185302734375\n",
      "Epoch: 1, Batch: 697, Loss: 2432.3701171875\n",
      "Epoch: 1, Batch: 698, Loss: 2804.8720703125\n",
      "Epoch: 1, Batch: 699, Loss: 2177.249267578125\n",
      "Epoch: 1, Batch: 700, Loss: 2462.961181640625\n",
      "Epoch: 1, Batch: 701, Loss: 2213.09033203125\n",
      "Epoch: 1, Batch: 702, Loss: 3188.978759765625\n",
      "Epoch: 1, Batch: 703, Loss: 2035.47216796875\n",
      "Epoch: 1, Batch: 704, Loss: 2542.79931640625\n",
      "Epoch: 1, Batch: 705, Loss: 1644.504150390625\n",
      "Epoch: 1, Batch: 706, Loss: 2305.672119140625\n",
      "Epoch: 1, Batch: 707, Loss: 2497.102294921875\n",
      "Epoch: 1, Batch: 708, Loss: 2715.6328125\n",
      "Epoch: 1, Batch: 709, Loss: 2671.771240234375\n",
      "Epoch: 1, Batch: 710, Loss: 2685.94091796875\n",
      "Epoch: 1, Batch: 711, Loss: 2827.554443359375\n",
      "Epoch: 1, Batch: 712, Loss: 2661.486572265625\n",
      "Epoch: 1, Batch: 713, Loss: 3077.2734375\n",
      "Epoch: 1, Batch: 714, Loss: 2734.17041015625\n",
      "Epoch: 1, Batch: 715, Loss: 2857.420166015625\n",
      "Epoch: 1, Batch: 716, Loss: 2910.3271484375\n",
      "Epoch: 1, Batch: 717, Loss: 2826.902587890625\n",
      "Epoch: 1, Batch: 718, Loss: 2685.931884765625\n",
      "Epoch: 1, Batch: 719, Loss: 2634.260009765625\n",
      "Epoch: 1, Batch: 720, Loss: 2566.48095703125\n",
      "Epoch: 1, Batch: 721, Loss: 2686.328125\n",
      "Epoch: 1, Batch: 722, Loss: 2860.5\n",
      "Epoch: 1, Batch: 723, Loss: 2543.337158203125\n",
      "Epoch: 1, Batch: 724, Loss: 2390.164794921875\n",
      "Epoch: 1, Batch: 725, Loss: 2789.552978515625\n",
      "Epoch: 1, Batch: 726, Loss: 2609.552978515625\n",
      "Epoch: 1, Batch: 727, Loss: 2730.887939453125\n",
      "Epoch: 1, Batch: 728, Loss: 2541.615478515625\n",
      "Epoch: 1, Batch: 729, Loss: 2560.953369140625\n",
      "Epoch: 1, Batch: 730, Loss: 2672.057861328125\n",
      "Epoch: 1, Batch: 731, Loss: 2628.70751953125\n",
      "Epoch: 1, Batch: 732, Loss: 2332.74462890625\n",
      "Epoch: 1, Batch: 733, Loss: 3387.01708984375\n",
      "Epoch: 1, Batch: 734, Loss: 3163.168212890625\n",
      "Epoch: 1, Batch: 735, Loss: 2880.189453125\n",
      "Epoch: 1, Batch: 736, Loss: 2870.58251953125\n",
      "Epoch: 1, Batch: 737, Loss: 2519.0390625\n",
      "Epoch: 1, Batch: 738, Loss: 2627.302734375\n",
      "Epoch: 1, Batch: 739, Loss: 3004.188232421875\n",
      "Epoch: 1, Batch: 740, Loss: 2623.859619140625\n",
      "Epoch: 1, Batch: 741, Loss: 2733.34375\n",
      "Epoch: 1, Batch: 742, Loss: 2753.49853515625\n",
      "Epoch: 1, Batch: 743, Loss: 2974.94970703125\n",
      "Epoch: 1, Batch: 744, Loss: 2444.22265625\n",
      "Epoch: 1, Batch: 745, Loss: 2346.339599609375\n",
      "Epoch: 1, Batch: 746, Loss: 2393.081787109375\n",
      "Epoch: 1, Batch: 747, Loss: 2406.655029296875\n",
      "Epoch: 1, Batch: 748, Loss: 2964.7705078125\n",
      "Epoch: 1, Batch: 749, Loss: 2406.30322265625\n",
      "Epoch: 1, Batch: 750, Loss: 3011.023681640625\n",
      "Epoch: 1, Batch: 751, Loss: 2344.26025390625\n",
      "Epoch: 1, Batch: 752, Loss: 2345.370361328125\n",
      "Epoch: 1, Batch: 753, Loss: 2199.734130859375\n",
      "Epoch: 1, Batch: 754, Loss: 2578.838134765625\n",
      "Epoch: 1, Batch: 755, Loss: 2908.3427734375\n",
      "Epoch: 1, Batch: 756, Loss: 2418.0859375\n",
      "Epoch: 1, Batch: 757, Loss: 2440.10693359375\n",
      "Epoch: 1, Batch: 758, Loss: 2295.51611328125\n",
      "Epoch: 1, Batch: 759, Loss: 2843.76220703125\n",
      "Epoch: 1, Batch: 760, Loss: 2780.2529296875\n",
      "Epoch: 1, Batch: 761, Loss: 2272.7529296875\n",
      "Epoch: 1, Batch: 762, Loss: 2486.331298828125\n",
      "Epoch: 1, Batch: 763, Loss: 2636.14794921875\n",
      "Epoch: 1, Batch: 764, Loss: 2666.243408203125\n",
      "Epoch: 1, Batch: 765, Loss: 2932.4130859375\n",
      "Epoch: 1, Batch: 766, Loss: 2732.80224609375\n",
      "Epoch: 1, Batch: 767, Loss: 2662.649169921875\n",
      "Epoch: 1, Batch: 768, Loss: 2388.556884765625\n",
      "Epoch: 1, Batch: 769, Loss: 2421.010009765625\n",
      "Epoch: 1, Batch: 770, Loss: 2615.0634765625\n",
      "Epoch: 1, Batch: 771, Loss: 2710.906494140625\n",
      "Epoch: 1, Batch: 772, Loss: 3480.86376953125\n",
      "Epoch: 1, Batch: 773, Loss: 2595.892822265625\n",
      "Epoch: 1, Batch: 774, Loss: 2882.76123046875\n",
      "Epoch: 1, Batch: 775, Loss: 2679.916015625\n",
      "Epoch: 1, Batch: 776, Loss: 2700.0185546875\n",
      "Epoch: 1, Batch: 777, Loss: 2518.33544921875\n",
      "Epoch: 1, Batch: 778, Loss: 2689.733154296875\n",
      "Epoch: 1, Batch: 779, Loss: 2888.22021484375\n",
      "Epoch: 1, Batch: 780, Loss: 1947.1551513671875\n",
      "Epoch: 1, Batch: 781, Loss: 3075.377197265625\n",
      "Epoch: 1, Batch: 782, Loss: 2178.165771484375\n",
      "Epoch: 1, Batch: 783, Loss: 3104.264404296875\n",
      "Epoch: 1, Batch: 784, Loss: 2790.54443359375\n",
      "Epoch: 1, Batch: 785, Loss: 2324.361572265625\n",
      "Epoch: 1, Batch: 786, Loss: 2478.05419921875\n",
      "Epoch: 1, Batch: 787, Loss: 2795.909912109375\n",
      "Epoch: 1, Batch: 788, Loss: 2815.571044921875\n",
      "Epoch: 1, Batch: 789, Loss: 2082.67724609375\n",
      "Epoch: 1, Batch: 790, Loss: 2534.961181640625\n",
      "Epoch: 1, Batch: 791, Loss: 2733.64892578125\n",
      "Epoch: 1, Batch: 792, Loss: 2839.493896484375\n",
      "Epoch: 1, Batch: 793, Loss: 2971.884033203125\n",
      "Epoch: 1, Batch: 794, Loss: 2380.012451171875\n",
      "Epoch: 1, Batch: 795, Loss: 2512.588134765625\n",
      "Epoch: 1, Batch: 796, Loss: 2559.001220703125\n",
      "Epoch: 1, Batch: 797, Loss: 2452.359130859375\n",
      "Epoch: 1, Batch: 798, Loss: 2320.964111328125\n",
      "Epoch: 1, Batch: 799, Loss: 2418.179931640625\n",
      "Epoch: 1, Batch: 800, Loss: 3054.09130859375\n",
      "Epoch: 1, Batch: 801, Loss: 2441.701171875\n",
      "Epoch: 1, Batch: 802, Loss: 3073.905517578125\n",
      "Epoch: 1, Batch: 803, Loss: 2938.197998046875\n",
      "Epoch: 1, Batch: 804, Loss: 2930.2158203125\n",
      "Epoch: 1, Batch: 805, Loss: 2964.89111328125\n",
      "Epoch: 1, Batch: 806, Loss: 3020.6630859375\n",
      "Epoch: 1, Batch: 807, Loss: 3066.1533203125\n",
      "Epoch: 1, Batch: 808, Loss: 2252.541015625\n",
      "Epoch: 1, Batch: 809, Loss: 3031.15673828125\n",
      "Epoch: 1, Batch: 810, Loss: 2939.875732421875\n",
      "Epoch: 1, Batch: 811, Loss: 2724.6689453125\n",
      "Epoch: 1, Batch: 812, Loss: 2560.8623046875\n",
      "Epoch: 1, Batch: 813, Loss: 2996.844482421875\n",
      "Epoch: 1, Batch: 814, Loss: 2283.167236328125\n",
      "Epoch: 1, Batch: 815, Loss: 2987.21142578125\n",
      "Epoch: 1, Batch: 816, Loss: 2380.55029296875\n",
      "Epoch: 1, Batch: 817, Loss: 2505.843994140625\n",
      "Epoch: 1, Batch: 818, Loss: 2285.62548828125\n",
      "Epoch: 1, Batch: 819, Loss: 3141.5703125\n",
      "Epoch: 1, Batch: 820, Loss: 2562.404296875\n",
      "Epoch: 1, Batch: 821, Loss: 2241.40478515625\n",
      "Epoch: 1, Batch: 822, Loss: 2824.70703125\n",
      "Epoch: 1, Batch: 823, Loss: 3004.007080078125\n",
      "Epoch: 1, Batch: 824, Loss: 2792.84619140625\n",
      "Epoch: 1, Batch: 825, Loss: 2735.470458984375\n",
      "Epoch: 1, Batch: 826, Loss: 2231.22021484375\n",
      "Epoch: 1, Batch: 827, Loss: 3271.73046875\n",
      "Epoch: 1, Batch: 828, Loss: 2735.849609375\n",
      "Epoch: 1, Batch: 829, Loss: 2909.959228515625\n",
      "Epoch: 1, Batch: 830, Loss: 2740.375\n",
      "Epoch: 1, Batch: 831, Loss: 2333.397705078125\n",
      "Epoch: 1, Batch: 832, Loss: 2630.93408203125\n",
      "Epoch: 1, Batch: 833, Loss: 2358.18896484375\n",
      "Epoch: 1, Batch: 834, Loss: 2117.576416015625\n",
      "Epoch: 1, Batch: 835, Loss: 2053.286376953125\n",
      "Epoch: 1, Batch: 836, Loss: 2820.759765625\n",
      "Epoch: 1, Batch: 837, Loss: 3099.162109375\n",
      "Epoch: 1, Batch: 838, Loss: 2770.514404296875\n",
      "Epoch: 1, Batch: 839, Loss: 2686.995849609375\n",
      "Epoch: 1, Batch: 840, Loss: 2507.155517578125\n",
      "Epoch: 1, Batch: 841, Loss: 2087.5234375\n",
      "Epoch: 1, Batch: 842, Loss: 2587.673583984375\n",
      "Epoch: 1, Batch: 843, Loss: 2395.1318359375\n",
      "Epoch: 1, Batch: 844, Loss: 3191.560302734375\n",
      "Epoch: 1, Batch: 845, Loss: 2430.672119140625\n",
      "Epoch: 1, Batch: 846, Loss: 2951.447998046875\n",
      "Epoch: 1, Batch: 847, Loss: 2674.37353515625\n",
      "Epoch: 1, Batch: 848, Loss: 3091.5615234375\n",
      "Epoch: 1, Batch: 849, Loss: 2845.1650390625\n",
      "Epoch: 1, Batch: 850, Loss: 2440.93408203125\n",
      "Epoch: 1, Batch: 851, Loss: 2489.374755859375\n",
      "Epoch: 1, Batch: 852, Loss: 2402.57177734375\n",
      "Epoch: 1, Batch: 853, Loss: 2977.15625\n",
      "Epoch: 1, Batch: 854, Loss: 2930.6494140625\n",
      "Epoch: 1, Batch: 855, Loss: 3050.485595703125\n",
      "Epoch: 1, Batch: 856, Loss: 2352.56494140625\n",
      "Epoch: 1, Batch: 857, Loss: 2840.44189453125\n",
      "Epoch: 1, Batch: 858, Loss: 3035.1728515625\n",
      "Epoch: 1, Batch: 859, Loss: 2716.37548828125\n",
      "Epoch: 1, Batch: 860, Loss: 2582.749267578125\n",
      "Epoch: 1, Batch: 861, Loss: 2200.269775390625\n",
      "Epoch: 1, Batch: 862, Loss: 2629.00146484375\n",
      "Epoch: 1, Batch: 863, Loss: 2553.264404296875\n",
      "Epoch: 1, Batch: 864, Loss: 2616.21337890625\n",
      "Epoch: 1, Batch: 865, Loss: 3048.6640625\n",
      "Epoch: 1, Batch: 866, Loss: 2296.08056640625\n",
      "Epoch: 1, Batch: 867, Loss: 2616.292724609375\n",
      "Epoch: 1, Batch: 868, Loss: 2993.66162109375\n",
      "Epoch: 1, Batch: 869, Loss: 2717.3359375\n",
      "Epoch: 1, Batch: 870, Loss: 2420.3193359375\n",
      "Epoch: 1, Batch: 871, Loss: 2960.146240234375\n",
      "Epoch: 1, Batch: 872, Loss: 3792.26318359375\n",
      "Epoch: 1, Batch: 873, Loss: 2676.18359375\n",
      "Epoch: 1, Batch: 874, Loss: 2854.693603515625\n",
      "Epoch: 1, Batch: 875, Loss: 2539.78857421875\n",
      "Epoch: 1, Batch: 876, Loss: 3046.58349609375\n",
      "Epoch: 1, Batch: 877, Loss: 2994.681396484375\n",
      "Epoch: 1, Batch: 878, Loss: 3106.343017578125\n",
      "Epoch: 1, Batch: 879, Loss: 2552.736572265625\n",
      "Epoch: 1, Batch: 880, Loss: 2355.790771484375\n",
      "Epoch: 1, Batch: 881, Loss: 2506.082763671875\n",
      "Epoch: 1, Batch: 882, Loss: 2656.50390625\n",
      "Epoch: 1, Batch: 883, Loss: 2942.890380859375\n",
      "Epoch: 1, Batch: 884, Loss: 2781.506591796875\n",
      "Epoch: 1, Batch: 885, Loss: 2765.18359375\n",
      "Epoch: 1, Batch: 886, Loss: 2166.9638671875\n",
      "Epoch: 1, Batch: 887, Loss: 2553.298095703125\n",
      "Epoch: 1, Batch: 888, Loss: 2913.0361328125\n",
      "Epoch: 1, Batch: 889, Loss: 2738.93408203125\n",
      "Epoch: 1, Batch: 890, Loss: 2255.742919921875\n",
      "Epoch: 1, Batch: 891, Loss: 2629.662841796875\n",
      "Epoch: 1, Batch: 892, Loss: 2587.11376953125\n",
      "Epoch: 1, Batch: 893, Loss: 2095.4384765625\n",
      "Epoch: 1, Batch: 894, Loss: 2883.9970703125\n",
      "Epoch: 1, Batch: 895, Loss: 2555.716796875\n",
      "Epoch: 1, Batch: 896, Loss: 2082.643798828125\n",
      "Epoch: 1, Batch: 897, Loss: 2303.535400390625\n",
      "Epoch: 1, Batch: 898, Loss: 2426.1318359375\n",
      "Epoch: 1, Batch: 899, Loss: 2462.892333984375\n",
      "Epoch: 1, Batch: 900, Loss: 2633.2177734375\n",
      "Epoch: 1, Batch: 901, Loss: 2322.750244140625\n",
      "Epoch: 1, Batch: 902, Loss: 2833.8291015625\n",
      "Epoch: 1, Batch: 903, Loss: 3048.864990234375\n",
      "Epoch: 1, Batch: 904, Loss: 2430.9814453125\n",
      "Epoch: 1, Batch: 905, Loss: 2501.615478515625\n",
      "Epoch: 1, Batch: 906, Loss: 2222.19677734375\n",
      "Epoch: 1, Batch: 907, Loss: 3205.976806640625\n",
      "Epoch: 1, Batch: 908, Loss: 2776.421630859375\n",
      "Epoch: 1, Batch: 909, Loss: 2451.904052734375\n",
      "Epoch: 1, Batch: 910, Loss: 2163.10009765625\n",
      "Epoch: 1, Batch: 911, Loss: 2871.33056640625\n",
      "Epoch: 1, Batch: 912, Loss: 3146.18701171875\n",
      "Epoch: 1, Batch: 913, Loss: 2785.132568359375\n",
      "Epoch: 1, Batch: 914, Loss: 3123.71435546875\n",
      "Epoch: 1, Batch: 915, Loss: 2430.219970703125\n",
      "Epoch: 1, Batch: 916, Loss: 3155.63818359375\n",
      "Epoch: 1, Batch: 917, Loss: 1996.21728515625\n",
      "Epoch: 1, Batch: 918, Loss: 2693.92529296875\n",
      "Epoch: 1, Batch: 919, Loss: 2851.18896484375\n",
      "Epoch: 1, Batch: 920, Loss: 2649.86767578125\n",
      "Epoch: 1, Batch: 921, Loss: 2604.15625\n",
      "Epoch: 1, Batch: 922, Loss: 1937.04345703125\n",
      "Epoch: 1, Batch: 923, Loss: 2655.25537109375\n",
      "Epoch: 1, Batch: 924, Loss: 2550.311279296875\n",
      "Epoch: 1, Batch: 925, Loss: 2625.37353515625\n",
      "Epoch: 1, Batch: 926, Loss: 2862.75732421875\n",
      "Epoch: 1, Batch: 927, Loss: 2267.8095703125\n",
      "Epoch: 1, Batch: 928, Loss: 2604.19580078125\n",
      "Epoch: 1, Batch: 929, Loss: 2750.40478515625\n",
      "Epoch: 1, Batch: 930, Loss: 2634.98974609375\n",
      "Epoch: 1, Batch: 931, Loss: 2331.45849609375\n",
      "Epoch: 1, Batch: 932, Loss: 2535.314453125\n",
      "Epoch: 1, Batch: 933, Loss: 2623.958251953125\n",
      "Epoch: 1, Batch: 934, Loss: 2444.690185546875\n",
      "Epoch: 1, Batch: 935, Loss: 3141.68212890625\n",
      "Epoch: 1, Batch: 936, Loss: 2716.920654296875\n",
      "Epoch: 1, Batch: 937, Loss: 2540.02197265625\n",
      "Epoch: 1, Batch: 938, Loss: 2825.93896484375\n",
      "Epoch: 1, Batch: 939, Loss: 2079.552734375\n",
      "Epoch: 1, Batch: 940, Loss: 2114.46240234375\n",
      "Epoch: 1, Batch: 941, Loss: 2564.64306640625\n",
      "Epoch: 1, Batch: 942, Loss: 2247.438232421875\n",
      "Epoch: 1, Batch: 943, Loss: 2812.3955078125\n",
      "Epoch: 1, Batch: 944, Loss: 2332.7353515625\n",
      "Epoch: 1, Batch: 945, Loss: 2857.900634765625\n",
      "Epoch: 1, Batch: 946, Loss: 2213.9677734375\n",
      "Epoch: 1, Batch: 947, Loss: 2936.590576171875\n",
      "Epoch: 1, Batch: 948, Loss: 2985.9716796875\n",
      "Epoch: 1, Batch: 949, Loss: 2849.40673828125\n",
      "Epoch: 1, Batch: 950, Loss: 2695.675537109375\n",
      "Epoch: 1, Batch: 951, Loss: 2290.5244140625\n",
      "Epoch: 1, Batch: 952, Loss: 2712.494384765625\n",
      "Epoch: 1, Batch: 953, Loss: 2436.117431640625\n",
      "Epoch: 1, Batch: 954, Loss: 2519.182373046875\n",
      "Epoch: 1, Batch: 955, Loss: 2909.8818359375\n",
      "Epoch: 1, Batch: 956, Loss: 2654.112060546875\n",
      "Epoch: 1, Batch: 957, Loss: 2395.925537109375\n",
      "Epoch: 1, Batch: 958, Loss: 2800.060791015625\n",
      "Epoch: 1, Batch: 959, Loss: 2337.89892578125\n",
      "Epoch: 1, Batch: 960, Loss: 2541.533447265625\n",
      "Epoch: 1, Batch: 961, Loss: 2862.846923828125\n",
      "Epoch: 1, Batch: 962, Loss: 2251.283203125\n",
      "Epoch: 1, Batch: 963, Loss: 2275.96923828125\n",
      "Epoch: 1, Batch: 964, Loss: 2058.197998046875\n",
      "Epoch: 1, Batch: 965, Loss: 2651.14990234375\n",
      "Epoch: 1, Batch: 966, Loss: 2316.755126953125\n",
      "Epoch: 1, Batch: 967, Loss: 2465.280029296875\n",
      "Epoch: 1, Batch: 968, Loss: 2473.797119140625\n",
      "Epoch: 1, Batch: 969, Loss: 2645.298095703125\n",
      "Epoch: 1, Batch: 970, Loss: 3318.93017578125\n",
      "Epoch: 1, Batch: 971, Loss: 2554.496337890625\n",
      "Epoch: 1, Batch: 972, Loss: 2173.142333984375\n",
      "Epoch: 1, Batch: 973, Loss: 2765.970947265625\n",
      "Epoch: 1, Batch: 974, Loss: 2616.26220703125\n",
      "Epoch: 1, Batch: 975, Loss: 3000.95654296875\n",
      "Epoch: 1, Batch: 976, Loss: 1956.09423828125\n",
      "Epoch: 1, Batch: 977, Loss: 3080.207275390625\n",
      "Epoch: 1, Batch: 978, Loss: 2918.706298828125\n",
      "Epoch: 1, Batch: 979, Loss: 3135.5390625\n",
      "Epoch: 1, Batch: 980, Loss: 2700.805419921875\n",
      "Epoch: 1, Batch: 981, Loss: 2618.76708984375\n",
      "Epoch: 1, Batch: 982, Loss: 3356.610595703125\n",
      "Epoch: 1, Batch: 983, Loss: 2607.689697265625\n",
      "Epoch: 1, Batch: 984, Loss: 2611.3046875\n",
      "Epoch: 1, Batch: 985, Loss: 2634.34765625\n",
      "Epoch: 1, Batch: 986, Loss: 2406.0703125\n",
      "Epoch: 1, Batch: 987, Loss: 2142.119140625\n",
      "Epoch: 1, Batch: 988, Loss: 2646.177490234375\n",
      "Epoch: 1, Batch: 989, Loss: 2643.5205078125\n",
      "Epoch: 1, Batch: 990, Loss: 2501.730712890625\n",
      "Epoch: 1, Batch: 991, Loss: 2852.640380859375\n",
      "Epoch: 1, Batch: 992, Loss: 2323.76513671875\n",
      "Epoch: 1, Batch: 993, Loss: 2659.96630859375\n",
      "Epoch: 1, Batch: 994, Loss: 2211.675048828125\n",
      "Epoch: 1, Batch: 995, Loss: 2177.16552734375\n",
      "Epoch: 1, Batch: 996, Loss: 2462.370361328125\n",
      "Epoch: 1, Batch: 997, Loss: 1501.802490234375\n",
      "Epoch: 1, Batch: 998, Loss: 2861.83056640625\n",
      "Epoch: 1, Batch: 999, Loss: 2385.682861328125\n",
      "Epoch: 2, Batch: 0, Loss: 2985.98583984375\n",
      "Epoch: 2, Batch: 1, Loss: 3153.0185546875\n",
      "Epoch: 2, Batch: 2, Loss: 2635.7021484375\n",
      "Epoch: 2, Batch: 3, Loss: 3138.022705078125\n",
      "Epoch: 2, Batch: 4, Loss: 2677.77099609375\n",
      "Epoch: 2, Batch: 5, Loss: 2726.751953125\n",
      "Epoch: 2, Batch: 6, Loss: 2633.2138671875\n",
      "Epoch: 2, Batch: 7, Loss: 2215.740966796875\n",
      "Epoch: 2, Batch: 8, Loss: 2722.53369140625\n",
      "Epoch: 2, Batch: 9, Loss: 2501.446533203125\n",
      "Epoch: 2, Batch: 10, Loss: 2353.607666015625\n",
      "Epoch: 2, Batch: 11, Loss: 2788.94384765625\n",
      "Epoch: 2, Batch: 12, Loss: 2299.307861328125\n",
      "Epoch: 2, Batch: 13, Loss: 2060.51025390625\n",
      "Epoch: 2, Batch: 14, Loss: 2600.10595703125\n",
      "Epoch: 2, Batch: 15, Loss: 2263.06689453125\n",
      "Epoch: 2, Batch: 16, Loss: 2533.971435546875\n",
      "Epoch: 2, Batch: 17, Loss: 3104.484375\n",
      "Epoch: 2, Batch: 18, Loss: 2148.990234375\n",
      "Epoch: 2, Batch: 19, Loss: 2849.841796875\n",
      "Epoch: 2, Batch: 20, Loss: 2540.383544921875\n",
      "Epoch: 2, Batch: 21, Loss: 3262.6015625\n",
      "Epoch: 2, Batch: 22, Loss: 2153.51953125\n",
      "Epoch: 2, Batch: 23, Loss: 2343.58447265625\n",
      "Epoch: 2, Batch: 24, Loss: 3089.1025390625\n",
      "Epoch: 2, Batch: 25, Loss: 2788.96044921875\n",
      "Epoch: 2, Batch: 26, Loss: 2545.463623046875\n",
      "Epoch: 2, Batch: 27, Loss: 2402.03076171875\n",
      "Epoch: 2, Batch: 28, Loss: 2817.551513671875\n",
      "Epoch: 2, Batch: 29, Loss: 2751.3037109375\n",
      "Epoch: 2, Batch: 30, Loss: 2656.836181640625\n",
      "Epoch: 2, Batch: 31, Loss: 1774.7095947265625\n",
      "Epoch: 2, Batch: 32, Loss: 2609.88037109375\n",
      "Epoch: 2, Batch: 33, Loss: 3227.611083984375\n",
      "Epoch: 2, Batch: 34, Loss: 2695.786865234375\n",
      "Epoch: 2, Batch: 35, Loss: 2413.733154296875\n",
      "Epoch: 2, Batch: 36, Loss: 2651.77783203125\n",
      "Epoch: 2, Batch: 37, Loss: 2242.424560546875\n",
      "Epoch: 2, Batch: 38, Loss: 2864.486328125\n",
      "Epoch: 2, Batch: 39, Loss: 2517.673095703125\n",
      "Epoch: 2, Batch: 40, Loss: 2520.90478515625\n",
      "Epoch: 2, Batch: 41, Loss: 2661.1826171875\n",
      "Epoch: 2, Batch: 42, Loss: 2855.5205078125\n",
      "Epoch: 2, Batch: 43, Loss: 3210.128173828125\n",
      "Epoch: 2, Batch: 44, Loss: 2173.12353515625\n",
      "Epoch: 2, Batch: 45, Loss: 2362.407470703125\n",
      "Epoch: 2, Batch: 46, Loss: 2492.531494140625\n",
      "Epoch: 2, Batch: 47, Loss: 2948.123291015625\n",
      "Epoch: 2, Batch: 48, Loss: 2655.017333984375\n",
      "Epoch: 2, Batch: 49, Loss: 2879.685546875\n",
      "Epoch: 2, Batch: 50, Loss: 2860.089599609375\n",
      "Epoch: 2, Batch: 51, Loss: 2735.600830078125\n",
      "Epoch: 2, Batch: 52, Loss: 2375.834228515625\n",
      "Epoch: 2, Batch: 53, Loss: 2864.471435546875\n",
      "Epoch: 2, Batch: 54, Loss: 3027.56982421875\n",
      "Epoch: 2, Batch: 55, Loss: 3184.584716796875\n",
      "Epoch: 2, Batch: 56, Loss: 2657.995849609375\n",
      "Epoch: 2, Batch: 57, Loss: 2750.069580078125\n",
      "Epoch: 2, Batch: 58, Loss: 2218.611083984375\n",
      "Epoch: 2, Batch: 59, Loss: 2625.458984375\n",
      "Epoch: 2, Batch: 60, Loss: 2891.47314453125\n",
      "Epoch: 2, Batch: 61, Loss: 2364.871337890625\n",
      "Epoch: 2, Batch: 62, Loss: 2982.513427734375\n",
      "Epoch: 2, Batch: 63, Loss: 2435.918212890625\n",
      "Epoch: 2, Batch: 64, Loss: 3040.685302734375\n",
      "Epoch: 2, Batch: 65, Loss: 3179.88671875\n",
      "Epoch: 2, Batch: 66, Loss: 2225.115234375\n",
      "Epoch: 2, Batch: 67, Loss: 2682.634765625\n",
      "Epoch: 2, Batch: 68, Loss: 2494.09375\n",
      "Epoch: 2, Batch: 69, Loss: 2681.86181640625\n",
      "Epoch: 2, Batch: 70, Loss: 2968.037353515625\n",
      "Epoch: 2, Batch: 71, Loss: 2499.95556640625\n",
      "Epoch: 2, Batch: 72, Loss: 2739.669921875\n",
      "Epoch: 2, Batch: 73, Loss: 3103.86962890625\n",
      "Epoch: 2, Batch: 74, Loss: 2508.58251953125\n",
      "Epoch: 2, Batch: 75, Loss: 2774.369140625\n",
      "Epoch: 2, Batch: 76, Loss: 2532.33984375\n",
      "Epoch: 2, Batch: 77, Loss: 2832.199951171875\n",
      "Epoch: 2, Batch: 78, Loss: 2474.895263671875\n",
      "Epoch: 2, Batch: 79, Loss: 2542.835693359375\n",
      "Epoch: 2, Batch: 80, Loss: 2685.96435546875\n",
      "Epoch: 2, Batch: 81, Loss: 2460.9599609375\n",
      "Epoch: 2, Batch: 82, Loss: 2642.1728515625\n",
      "Epoch: 2, Batch: 83, Loss: 2753.26416015625\n",
      "Epoch: 2, Batch: 84, Loss: 2386.75390625\n",
      "Epoch: 2, Batch: 85, Loss: 2504.2763671875\n",
      "Epoch: 2, Batch: 86, Loss: 2722.662109375\n",
      "Epoch: 2, Batch: 87, Loss: 2542.07470703125\n",
      "Epoch: 2, Batch: 88, Loss: 3051.17578125\n",
      "Epoch: 2, Batch: 89, Loss: 2557.545166015625\n",
      "Epoch: 2, Batch: 90, Loss: 2689.76123046875\n",
      "Epoch: 2, Batch: 91, Loss: 2884.066162109375\n",
      "Epoch: 2, Batch: 92, Loss: 2293.11181640625\n",
      "Epoch: 2, Batch: 93, Loss: 2064.7802734375\n",
      "Epoch: 2, Batch: 94, Loss: 3127.042236328125\n",
      "Epoch: 2, Batch: 95, Loss: 2891.7333984375\n",
      "Epoch: 2, Batch: 96, Loss: 3040.64794921875\n",
      "Epoch: 2, Batch: 97, Loss: 2468.122802734375\n",
      "Epoch: 2, Batch: 98, Loss: 2600.2578125\n",
      "Epoch: 2, Batch: 99, Loss: 2518.13916015625\n",
      "Epoch: 2, Batch: 100, Loss: 2719.42333984375\n",
      "Epoch: 2, Batch: 101, Loss: 2683.785888671875\n",
      "Epoch: 2, Batch: 102, Loss: 2988.7333984375\n",
      "Epoch: 2, Batch: 103, Loss: 2344.6044921875\n",
      "Epoch: 2, Batch: 104, Loss: 2169.4501953125\n",
      "Epoch: 2, Batch: 105, Loss: 1938.30859375\n",
      "Epoch: 2, Batch: 106, Loss: 2396.671875\n",
      "Epoch: 2, Batch: 107, Loss: 2440.706787109375\n",
      "Epoch: 2, Batch: 108, Loss: 2525.737548828125\n",
      "Epoch: 2, Batch: 109, Loss: 2559.0712890625\n",
      "Epoch: 2, Batch: 110, Loss: 1856.087646484375\n",
      "Epoch: 2, Batch: 111, Loss: 2779.1796875\n",
      "Epoch: 2, Batch: 112, Loss: 2664.72802734375\n",
      "Epoch: 2, Batch: 113, Loss: 2758.74609375\n",
      "Epoch: 2, Batch: 114, Loss: 2336.62109375\n",
      "Epoch: 2, Batch: 115, Loss: 2564.4296875\n",
      "Epoch: 2, Batch: 116, Loss: 2577.01806640625\n",
      "Epoch: 2, Batch: 117, Loss: 3020.9873046875\n",
      "Epoch: 2, Batch: 118, Loss: 2776.89501953125\n",
      "Epoch: 2, Batch: 119, Loss: 2371.199462890625\n",
      "Epoch: 2, Batch: 120, Loss: 3414.95654296875\n",
      "Epoch: 2, Batch: 121, Loss: 2431.05859375\n",
      "Epoch: 2, Batch: 122, Loss: 3065.35986328125\n",
      "Epoch: 2, Batch: 123, Loss: 2235.482421875\n",
      "Epoch: 2, Batch: 124, Loss: 3249.8193359375\n",
      "Epoch: 2, Batch: 125, Loss: 3218.28564453125\n",
      "Epoch: 2, Batch: 126, Loss: 3219.096923828125\n",
      "Epoch: 2, Batch: 127, Loss: 2265.056640625\n",
      "Epoch: 2, Batch: 128, Loss: 2435.89453125\n",
      "Epoch: 2, Batch: 129, Loss: 2564.289794921875\n",
      "Epoch: 2, Batch: 130, Loss: 2375.66455078125\n",
      "Epoch: 2, Batch: 131, Loss: 2184.602294921875\n",
      "Epoch: 2, Batch: 132, Loss: 2839.47119140625\n",
      "Epoch: 2, Batch: 133, Loss: 2483.548583984375\n",
      "Epoch: 2, Batch: 134, Loss: 2173.58544921875\n",
      "Epoch: 2, Batch: 135, Loss: 2737.174072265625\n",
      "Epoch: 2, Batch: 136, Loss: 2481.82470703125\n",
      "Epoch: 2, Batch: 137, Loss: 2931.45849609375\n",
      "Epoch: 2, Batch: 138, Loss: 2229.140625\n",
      "Epoch: 2, Batch: 139, Loss: 2744.350830078125\n",
      "Epoch: 2, Batch: 140, Loss: 2292.630126953125\n",
      "Epoch: 2, Batch: 141, Loss: 2690.3134765625\n",
      "Epoch: 2, Batch: 142, Loss: 2148.893310546875\n",
      "Epoch: 2, Batch: 143, Loss: 3095.236328125\n",
      "Epoch: 2, Batch: 144, Loss: 1772.25\n",
      "Epoch: 2, Batch: 145, Loss: 2392.10546875\n",
      "Epoch: 2, Batch: 146, Loss: 2492.946044921875\n",
      "Epoch: 2, Batch: 147, Loss: 2938.040771484375\n",
      "Epoch: 2, Batch: 148, Loss: 3186.14599609375\n",
      "Epoch: 2, Batch: 149, Loss: 2263.382568359375\n",
      "Epoch: 2, Batch: 150, Loss: 2498.392333984375\n",
      "Epoch: 2, Batch: 151, Loss: 2850.05419921875\n",
      "Epoch: 2, Batch: 152, Loss: 2825.734619140625\n",
      "Epoch: 2, Batch: 153, Loss: 2042.78173828125\n",
      "Epoch: 2, Batch: 154, Loss: 2095.80712890625\n",
      "Epoch: 2, Batch: 155, Loss: 2538.99609375\n",
      "Epoch: 2, Batch: 156, Loss: 2082.86328125\n",
      "Epoch: 2, Batch: 157, Loss: 2735.254638671875\n",
      "Epoch: 2, Batch: 158, Loss: 2571.287109375\n",
      "Epoch: 2, Batch: 159, Loss: 2971.46875\n",
      "Epoch: 2, Batch: 160, Loss: 2695.3154296875\n",
      "Epoch: 2, Batch: 161, Loss: 2721.87353515625\n",
      "Epoch: 2, Batch: 162, Loss: 2793.906005859375\n",
      "Epoch: 2, Batch: 163, Loss: 2719.95556640625\n",
      "Epoch: 2, Batch: 164, Loss: 2669.46728515625\n",
      "Epoch: 2, Batch: 165, Loss: 2763.079833984375\n",
      "Epoch: 2, Batch: 166, Loss: 2687.782958984375\n",
      "Epoch: 2, Batch: 167, Loss: 2775.1611328125\n",
      "Epoch: 2, Batch: 168, Loss: 2811.6767578125\n",
      "Epoch: 2, Batch: 169, Loss: 2339.4404296875\n",
      "Epoch: 2, Batch: 170, Loss: 2358.3369140625\n",
      "Epoch: 2, Batch: 171, Loss: 2378.17236328125\n",
      "Epoch: 2, Batch: 172, Loss: 2537.263427734375\n",
      "Epoch: 2, Batch: 173, Loss: 2556.000732421875\n",
      "Epoch: 2, Batch: 174, Loss: 2850.582763671875\n",
      "Epoch: 2, Batch: 175, Loss: 2748.635986328125\n",
      "Epoch: 2, Batch: 176, Loss: 2707.857666015625\n",
      "Epoch: 2, Batch: 177, Loss: 2424.264892578125\n",
      "Epoch: 2, Batch: 178, Loss: 2677.650146484375\n",
      "Epoch: 2, Batch: 179, Loss: 2880.552734375\n",
      "Epoch: 2, Batch: 180, Loss: 2645.673095703125\n",
      "Epoch: 2, Batch: 181, Loss: 3427.012939453125\n",
      "Epoch: 2, Batch: 182, Loss: 2464.703857421875\n",
      "Epoch: 2, Batch: 183, Loss: 2252.2099609375\n",
      "Epoch: 2, Batch: 184, Loss: 2297.56005859375\n",
      "Epoch: 2, Batch: 185, Loss: 2835.283935546875\n",
      "Epoch: 2, Batch: 186, Loss: 2282.881591796875\n",
      "Epoch: 2, Batch: 187, Loss: 2886.446533203125\n",
      "Epoch: 2, Batch: 188, Loss: 3276.34423828125\n",
      "Epoch: 2, Batch: 189, Loss: 2785.177490234375\n",
      "Epoch: 2, Batch: 190, Loss: 2283.177490234375\n",
      "Epoch: 2, Batch: 191, Loss: 2410.01171875\n",
      "Epoch: 2, Batch: 192, Loss: 2243.513916015625\n",
      "Epoch: 2, Batch: 193, Loss: 2851.740478515625\n",
      "Epoch: 2, Batch: 194, Loss: 2512.725341796875\n",
      "Epoch: 2, Batch: 195, Loss: 2280.943603515625\n",
      "Epoch: 2, Batch: 196, Loss: 2158.686767578125\n",
      "Epoch: 2, Batch: 197, Loss: 2390.02392578125\n",
      "Epoch: 2, Batch: 198, Loss: 2937.166259765625\n",
      "Epoch: 2, Batch: 199, Loss: 2564.066650390625\n",
      "Epoch: 2, Batch: 200, Loss: 2591.772216796875\n",
      "Epoch: 2, Batch: 201, Loss: 2984.12744140625\n",
      "Epoch: 2, Batch: 202, Loss: 2663.46923828125\n",
      "Epoch: 2, Batch: 203, Loss: 2022.6402587890625\n",
      "Epoch: 2, Batch: 204, Loss: 2090.81884765625\n",
      "Epoch: 2, Batch: 205, Loss: 2528.98974609375\n",
      "Epoch: 2, Batch: 206, Loss: 2719.157958984375\n",
      "Epoch: 2, Batch: 207, Loss: 2645.40087890625\n",
      "Epoch: 2, Batch: 208, Loss: 2530.133056640625\n",
      "Epoch: 2, Batch: 209, Loss: 2606.72314453125\n",
      "Epoch: 2, Batch: 210, Loss: 2498.126953125\n",
      "Epoch: 2, Batch: 211, Loss: 3109.745361328125\n",
      "Epoch: 2, Batch: 212, Loss: 2659.76806640625\n",
      "Epoch: 2, Batch: 213, Loss: 3096.935546875\n",
      "Epoch: 2, Batch: 214, Loss: 2165.644287109375\n",
      "Epoch: 2, Batch: 215, Loss: 2903.150390625\n",
      "Epoch: 2, Batch: 216, Loss: 2932.587890625\n",
      "Epoch: 2, Batch: 217, Loss: 2815.05029296875\n",
      "Epoch: 2, Batch: 218, Loss: 2760.333251953125\n",
      "Epoch: 2, Batch: 219, Loss: 2277.8583984375\n",
      "Epoch: 2, Batch: 220, Loss: 2403.3203125\n",
      "Epoch: 2, Batch: 221, Loss: 2754.41845703125\n",
      "Epoch: 2, Batch: 222, Loss: 2360.745849609375\n",
      "Epoch: 2, Batch: 223, Loss: 3040.385498046875\n",
      "Epoch: 2, Batch: 224, Loss: 2799.391845703125\n",
      "Epoch: 2, Batch: 225, Loss: 2398.386474609375\n",
      "Epoch: 2, Batch: 226, Loss: 2798.27099609375\n",
      "Epoch: 2, Batch: 227, Loss: 2682.19140625\n",
      "Epoch: 2, Batch: 228, Loss: 2833.002685546875\n",
      "Epoch: 2, Batch: 229, Loss: 2490.85009765625\n",
      "Epoch: 2, Batch: 230, Loss: 2963.93212890625\n",
      "Epoch: 2, Batch: 231, Loss: 2894.22412109375\n",
      "Epoch: 2, Batch: 232, Loss: 2637.433349609375\n",
      "Epoch: 2, Batch: 233, Loss: 2776.735595703125\n",
      "Epoch: 2, Batch: 234, Loss: 2701.083984375\n",
      "Epoch: 2, Batch: 235, Loss: 2362.113037109375\n",
      "Epoch: 2, Batch: 236, Loss: 2273.681640625\n",
      "Epoch: 2, Batch: 237, Loss: 2067.546875\n",
      "Epoch: 2, Batch: 238, Loss: 2477.049560546875\n",
      "Epoch: 2, Batch: 239, Loss: 2652.35791015625\n",
      "Epoch: 2, Batch: 240, Loss: 2789.30810546875\n",
      "Epoch: 2, Batch: 241, Loss: 2541.590087890625\n",
      "Epoch: 2, Batch: 242, Loss: 2661.085693359375\n",
      "Epoch: 2, Batch: 243, Loss: 2995.808349609375\n",
      "Epoch: 2, Batch: 244, Loss: 2215.18896484375\n",
      "Epoch: 2, Batch: 245, Loss: 2584.63427734375\n",
      "Epoch: 2, Batch: 246, Loss: 2781.0576171875\n",
      "Epoch: 2, Batch: 247, Loss: 3052.463623046875\n",
      "Epoch: 2, Batch: 248, Loss: 2381.539794921875\n",
      "Epoch: 2, Batch: 249, Loss: 2811.958984375\n",
      "Epoch: 2, Batch: 250, Loss: 2538.19970703125\n",
      "Epoch: 2, Batch: 251, Loss: 2366.491455078125\n",
      "Epoch: 2, Batch: 252, Loss: 2888.5615234375\n",
      "Epoch: 2, Batch: 253, Loss: 2868.7861328125\n",
      "Epoch: 2, Batch: 254, Loss: 1963.4007568359375\n",
      "Epoch: 2, Batch: 255, Loss: 2566.578125\n",
      "Epoch: 2, Batch: 256, Loss: 2429.2978515625\n",
      "Epoch: 2, Batch: 257, Loss: 2531.060546875\n",
      "Epoch: 2, Batch: 258, Loss: 2672.7783203125\n",
      "Epoch: 2, Batch: 259, Loss: 2205.05615234375\n",
      "Epoch: 2, Batch: 260, Loss: 2881.83544921875\n",
      "Epoch: 2, Batch: 261, Loss: 2892.673095703125\n",
      "Epoch: 2, Batch: 262, Loss: 2808.6455078125\n",
      "Epoch: 2, Batch: 263, Loss: 2714.650146484375\n",
      "Epoch: 2, Batch: 264, Loss: 2739.76611328125\n",
      "Epoch: 2, Batch: 265, Loss: 2386.24609375\n",
      "Epoch: 2, Batch: 266, Loss: 2706.91552734375\n",
      "Epoch: 2, Batch: 267, Loss: 2725.60498046875\n",
      "Epoch: 2, Batch: 268, Loss: 2268.31591796875\n",
      "Epoch: 2, Batch: 269, Loss: 2401.821533203125\n",
      "Epoch: 2, Batch: 270, Loss: 2427.907470703125\n",
      "Epoch: 2, Batch: 271, Loss: 2434.1708984375\n",
      "Epoch: 2, Batch: 272, Loss: 2665.42138671875\n",
      "Epoch: 2, Batch: 273, Loss: 2839.682861328125\n",
      "Epoch: 2, Batch: 274, Loss: 3124.83349609375\n",
      "Epoch: 2, Batch: 275, Loss: 2451.31494140625\n",
      "Epoch: 2, Batch: 276, Loss: 3254.502685546875\n",
      "Epoch: 2, Batch: 277, Loss: 2849.4609375\n",
      "Epoch: 2, Batch: 278, Loss: 2602.14404296875\n",
      "Epoch: 2, Batch: 279, Loss: 2076.19775390625\n",
      "Epoch: 2, Batch: 280, Loss: 2994.8603515625\n",
      "Epoch: 2, Batch: 281, Loss: 3179.137451171875\n",
      "Epoch: 2, Batch: 282, Loss: 2828.185791015625\n",
      "Epoch: 2, Batch: 283, Loss: 2971.943115234375\n",
      "Epoch: 2, Batch: 284, Loss: 2781.80517578125\n",
      "Epoch: 2, Batch: 285, Loss: 2661.476318359375\n",
      "Epoch: 2, Batch: 286, Loss: 2747.091552734375\n",
      "Epoch: 2, Batch: 287, Loss: 2897.319091796875\n",
      "Epoch: 2, Batch: 288, Loss: 2464.92236328125\n",
      "Epoch: 2, Batch: 289, Loss: 3076.58251953125\n",
      "Epoch: 2, Batch: 290, Loss: 1948.2928466796875\n",
      "Epoch: 2, Batch: 291, Loss: 2316.1650390625\n",
      "Epoch: 2, Batch: 292, Loss: 2954.9560546875\n",
      "Epoch: 2, Batch: 293, Loss: 2459.38916015625\n",
      "Epoch: 2, Batch: 294, Loss: 2283.768310546875\n",
      "Epoch: 2, Batch: 295, Loss: 2638.73876953125\n",
      "Epoch: 2, Batch: 296, Loss: 3077.964111328125\n",
      "Epoch: 2, Batch: 297, Loss: 2669.91455078125\n",
      "Epoch: 2, Batch: 298, Loss: 2875.705078125\n",
      "Epoch: 2, Batch: 299, Loss: 3325.809814453125\n",
      "Epoch: 2, Batch: 300, Loss: 2809.95068359375\n",
      "Epoch: 2, Batch: 301, Loss: 2761.41259765625\n",
      "Epoch: 2, Batch: 302, Loss: 2135.437255859375\n",
      "Epoch: 2, Batch: 303, Loss: 2331.30126953125\n",
      "Epoch: 2, Batch: 304, Loss: 2829.015869140625\n",
      "Epoch: 2, Batch: 305, Loss: 2410.01220703125\n",
      "Epoch: 2, Batch: 306, Loss: 2862.2216796875\n",
      "Epoch: 2, Batch: 307, Loss: 2191.25830078125\n",
      "Epoch: 2, Batch: 308, Loss: 2752.52880859375\n",
      "Epoch: 2, Batch: 309, Loss: 2530.854736328125\n",
      "Epoch: 2, Batch: 310, Loss: 3288.916259765625\n",
      "Epoch: 2, Batch: 311, Loss: 2742.994384765625\n",
      "Epoch: 2, Batch: 312, Loss: 2871.544921875\n",
      "Epoch: 2, Batch: 313, Loss: 2359.52587890625\n",
      "Epoch: 2, Batch: 314, Loss: 2223.372802734375\n",
      "Epoch: 2, Batch: 315, Loss: 2662.017822265625\n",
      "Epoch: 2, Batch: 316, Loss: 2870.433349609375\n",
      "Epoch: 2, Batch: 317, Loss: 2684.59814453125\n",
      "Epoch: 2, Batch: 318, Loss: 2726.1865234375\n",
      "Epoch: 2, Batch: 319, Loss: 2464.906982421875\n",
      "Epoch: 2, Batch: 320, Loss: 2610.66162109375\n",
      "Epoch: 2, Batch: 321, Loss: 2604.319091796875\n",
      "Epoch: 2, Batch: 322, Loss: 2303.447021484375\n",
      "Epoch: 2, Batch: 323, Loss: 2968.67529296875\n",
      "Epoch: 2, Batch: 324, Loss: 2365.945556640625\n",
      "Epoch: 2, Batch: 325, Loss: 2196.67236328125\n",
      "Epoch: 2, Batch: 326, Loss: 2128.399658203125\n",
      "Epoch: 2, Batch: 327, Loss: 2215.368408203125\n",
      "Epoch: 2, Batch: 328, Loss: 3105.26318359375\n",
      "Epoch: 2, Batch: 329, Loss: 2484.7138671875\n",
      "Epoch: 2, Batch: 330, Loss: 2646.67578125\n",
      "Epoch: 2, Batch: 331, Loss: 3099.849609375\n",
      "Epoch: 2, Batch: 332, Loss: 2595.425537109375\n",
      "Epoch: 2, Batch: 333, Loss: 2350.011474609375\n",
      "Epoch: 2, Batch: 334, Loss: 2149.011474609375\n",
      "Epoch: 2, Batch: 335, Loss: 2825.5087890625\n",
      "Epoch: 2, Batch: 336, Loss: 2962.6220703125\n",
      "Epoch: 2, Batch: 337, Loss: 2951.69189453125\n",
      "Epoch: 2, Batch: 338, Loss: 3217.14599609375\n",
      "Epoch: 2, Batch: 339, Loss: 2588.942626953125\n",
      "Epoch: 2, Batch: 340, Loss: 2191.805419921875\n",
      "Epoch: 2, Batch: 341, Loss: 2877.712158203125\n",
      "Epoch: 2, Batch: 342, Loss: 2578.392578125\n",
      "Epoch: 2, Batch: 343, Loss: 2986.41015625\n",
      "Epoch: 2, Batch: 344, Loss: 2403.220947265625\n",
      "Epoch: 2, Batch: 345, Loss: 2539.56103515625\n",
      "Epoch: 2, Batch: 346, Loss: 2384.50732421875\n",
      "Epoch: 2, Batch: 347, Loss: 1917.070556640625\n",
      "Epoch: 2, Batch: 348, Loss: 2417.693115234375\n",
      "Epoch: 2, Batch: 349, Loss: 3156.824462890625\n",
      "Epoch: 2, Batch: 350, Loss: 3230.098876953125\n",
      "Epoch: 2, Batch: 351, Loss: 2812.9990234375\n",
      "Epoch: 2, Batch: 352, Loss: 2517.910400390625\n",
      "Epoch: 2, Batch: 353, Loss: 2773.9130859375\n",
      "Epoch: 2, Batch: 354, Loss: 2433.72607421875\n",
      "Epoch: 2, Batch: 355, Loss: 2685.692138671875\n",
      "Epoch: 2, Batch: 356, Loss: 2675.60791015625\n",
      "Epoch: 2, Batch: 357, Loss: 2848.419677734375\n",
      "Epoch: 2, Batch: 358, Loss: 2203.02294921875\n",
      "Epoch: 2, Batch: 359, Loss: 2847.685302734375\n",
      "Epoch: 2, Batch: 360, Loss: 2672.05224609375\n",
      "Epoch: 2, Batch: 361, Loss: 2609.806884765625\n",
      "Epoch: 2, Batch: 362, Loss: 2531.99072265625\n",
      "Epoch: 2, Batch: 363, Loss: 2208.23046875\n",
      "Epoch: 2, Batch: 364, Loss: 2888.975830078125\n",
      "Epoch: 2, Batch: 365, Loss: 2336.53515625\n",
      "Epoch: 2, Batch: 366, Loss: 1826.61669921875\n",
      "Epoch: 2, Batch: 367, Loss: 2943.806396484375\n",
      "Epoch: 2, Batch: 368, Loss: 2943.267578125\n",
      "Epoch: 2, Batch: 369, Loss: 2784.28369140625\n",
      "Epoch: 2, Batch: 370, Loss: 2574.3720703125\n",
      "Epoch: 2, Batch: 371, Loss: 2229.13818359375\n",
      "Epoch: 2, Batch: 372, Loss: 2549.49609375\n",
      "Epoch: 2, Batch: 373, Loss: 1811.4033203125\n",
      "Epoch: 2, Batch: 374, Loss: 2350.628173828125\n",
      "Epoch: 2, Batch: 375, Loss: 2459.155029296875\n",
      "Epoch: 2, Batch: 376, Loss: 2787.509521484375\n",
      "Epoch: 2, Batch: 377, Loss: 2743.72705078125\n",
      "Epoch: 2, Batch: 378, Loss: 2313.506591796875\n",
      "Epoch: 2, Batch: 379, Loss: 3275.180908203125\n",
      "Epoch: 2, Batch: 380, Loss: 3127.248291015625\n",
      "Epoch: 2, Batch: 381, Loss: 2073.610595703125\n",
      "Epoch: 2, Batch: 382, Loss: 2320.272216796875\n",
      "Epoch: 2, Batch: 383, Loss: 2316.09423828125\n",
      "Epoch: 2, Batch: 384, Loss: 2987.271728515625\n",
      "Epoch: 2, Batch: 385, Loss: 2701.26318359375\n",
      "Epoch: 2, Batch: 386, Loss: 2866.979736328125\n",
      "Epoch: 2, Batch: 387, Loss: 2636.95947265625\n",
      "Epoch: 2, Batch: 388, Loss: 2398.6328125\n",
      "Epoch: 2, Batch: 389, Loss: 2746.552001953125\n",
      "Epoch: 2, Batch: 390, Loss: 2349.7275390625\n",
      "Epoch: 2, Batch: 391, Loss: 2305.09228515625\n",
      "Epoch: 2, Batch: 392, Loss: 2842.524169921875\n",
      "Epoch: 2, Batch: 393, Loss: 2280.85400390625\n",
      "Epoch: 2, Batch: 394, Loss: 2667.731201171875\n",
      "Epoch: 2, Batch: 395, Loss: 2660.83544921875\n",
      "Epoch: 2, Batch: 396, Loss: 2479.223388671875\n",
      "Epoch: 2, Batch: 397, Loss: 2450.4921875\n",
      "Epoch: 2, Batch: 398, Loss: 3154.9248046875\n",
      "Epoch: 2, Batch: 399, Loss: 2819.041259765625\n",
      "Epoch: 2, Batch: 400, Loss: 2542.847412109375\n",
      "Epoch: 2, Batch: 401, Loss: 2542.706298828125\n",
      "Epoch: 2, Batch: 402, Loss: 2727.848388671875\n",
      "Epoch: 2, Batch: 403, Loss: 3004.518798828125\n",
      "Epoch: 2, Batch: 404, Loss: 3474.347900390625\n",
      "Epoch: 2, Batch: 405, Loss: 2304.39697265625\n",
      "Epoch: 2, Batch: 406, Loss: 2292.051025390625\n",
      "Epoch: 2, Batch: 407, Loss: 2705.6767578125\n",
      "Epoch: 2, Batch: 408, Loss: 3450.962158203125\n",
      "Epoch: 2, Batch: 409, Loss: 2938.492431640625\n",
      "Epoch: 2, Batch: 410, Loss: 2555.72314453125\n",
      "Epoch: 2, Batch: 411, Loss: 2542.218017578125\n",
      "Epoch: 2, Batch: 412, Loss: 2378.994873046875\n",
      "Epoch: 2, Batch: 413, Loss: 2412.384521484375\n",
      "Epoch: 2, Batch: 414, Loss: 2525.023681640625\n",
      "Epoch: 2, Batch: 415, Loss: 2716.79541015625\n",
      "Epoch: 2, Batch: 416, Loss: 1957.5343017578125\n",
      "Epoch: 2, Batch: 417, Loss: 2432.60107421875\n",
      "Epoch: 2, Batch: 418, Loss: 2591.365478515625\n",
      "Epoch: 2, Batch: 419, Loss: 2172.966796875\n",
      "Epoch: 2, Batch: 420, Loss: 2375.255615234375\n",
      "Epoch: 2, Batch: 421, Loss: 2192.921142578125\n",
      "Epoch: 2, Batch: 422, Loss: 2702.6123046875\n",
      "Epoch: 2, Batch: 423, Loss: 3462.871826171875\n",
      "Epoch: 2, Batch: 424, Loss: 2812.473388671875\n",
      "Epoch: 2, Batch: 425, Loss: 2982.57080078125\n",
      "Epoch: 2, Batch: 426, Loss: 2599.917236328125\n",
      "Epoch: 2, Batch: 427, Loss: 2892.009521484375\n",
      "Epoch: 2, Batch: 428, Loss: 3390.808837890625\n",
      "Epoch: 2, Batch: 429, Loss: 2313.615234375\n",
      "Epoch: 2, Batch: 430, Loss: 2775.2431640625\n",
      "Epoch: 2, Batch: 431, Loss: 3072.095947265625\n",
      "Epoch: 2, Batch: 432, Loss: 2554.366943359375\n",
      "Epoch: 2, Batch: 433, Loss: 2311.387939453125\n",
      "Epoch: 2, Batch: 434, Loss: 2101.00537109375\n",
      "Epoch: 2, Batch: 435, Loss: 2234.71240234375\n",
      "Epoch: 2, Batch: 436, Loss: 2524.090087890625\n",
      "Epoch: 2, Batch: 437, Loss: 3187.801025390625\n",
      "Epoch: 2, Batch: 438, Loss: 2372.350341796875\n",
      "Epoch: 2, Batch: 439, Loss: 2303.234130859375\n",
      "Epoch: 2, Batch: 440, Loss: 3469.17041015625\n",
      "Epoch: 2, Batch: 441, Loss: 2738.22265625\n",
      "Epoch: 2, Batch: 442, Loss: 2467.625244140625\n",
      "Epoch: 2, Batch: 443, Loss: 2566.492919921875\n",
      "Epoch: 2, Batch: 444, Loss: 2925.694580078125\n",
      "Epoch: 2, Batch: 445, Loss: 2733.79833984375\n",
      "Epoch: 2, Batch: 446, Loss: 2386.85888671875\n",
      "Epoch: 2, Batch: 447, Loss: 2960.704345703125\n",
      "Epoch: 2, Batch: 448, Loss: 2246.33154296875\n",
      "Epoch: 2, Batch: 449, Loss: 3776.17919921875\n",
      "Epoch: 2, Batch: 450, Loss: 2709.82568359375\n",
      "Epoch: 2, Batch: 451, Loss: 2955.094482421875\n",
      "Epoch: 2, Batch: 452, Loss: 3038.454345703125\n",
      "Epoch: 2, Batch: 453, Loss: 2490.474853515625\n",
      "Epoch: 2, Batch: 454, Loss: 3018.972900390625\n",
      "Epoch: 2, Batch: 455, Loss: 2736.10107421875\n",
      "Epoch: 2, Batch: 456, Loss: 2410.12109375\n",
      "Epoch: 2, Batch: 457, Loss: 2451.606689453125\n",
      "Epoch: 2, Batch: 458, Loss: 2440.17529296875\n",
      "Epoch: 2, Batch: 459, Loss: 3184.29833984375\n",
      "Epoch: 2, Batch: 460, Loss: 3536.955810546875\n",
      "Epoch: 2, Batch: 461, Loss: 2629.17041015625\n",
      "Epoch: 2, Batch: 462, Loss: 2742.928955078125\n",
      "Epoch: 2, Batch: 463, Loss: 2416.238037109375\n",
      "Epoch: 2, Batch: 464, Loss: 2519.464599609375\n",
      "Epoch: 2, Batch: 465, Loss: 2337.81298828125\n",
      "Epoch: 2, Batch: 466, Loss: 2624.452392578125\n",
      "Epoch: 2, Batch: 467, Loss: 2412.224853515625\n",
      "Epoch: 2, Batch: 468, Loss: 2639.23486328125\n",
      "Epoch: 2, Batch: 469, Loss: 2837.164794921875\n",
      "Epoch: 2, Batch: 470, Loss: 2370.0166015625\n",
      "Epoch: 2, Batch: 471, Loss: 2851.16357421875\n",
      "Epoch: 2, Batch: 472, Loss: 2657.011474609375\n",
      "Epoch: 2, Batch: 473, Loss: 2333.676025390625\n",
      "Epoch: 2, Batch: 474, Loss: 2797.850830078125\n",
      "Epoch: 2, Batch: 475, Loss: 2967.935791015625\n",
      "Epoch: 2, Batch: 476, Loss: 2767.302001953125\n",
      "Epoch: 2, Batch: 477, Loss: 2370.254638671875\n",
      "Epoch: 2, Batch: 478, Loss: 2556.928466796875\n",
      "Epoch: 2, Batch: 479, Loss: 2650.5966796875\n",
      "Epoch: 2, Batch: 480, Loss: 2345.20556640625\n",
      "Epoch: 2, Batch: 481, Loss: 2795.606689453125\n",
      "Epoch: 2, Batch: 482, Loss: 2013.5511474609375\n",
      "Epoch: 2, Batch: 483, Loss: 2346.168701171875\n",
      "Epoch: 2, Batch: 484, Loss: 2969.26904296875\n",
      "Epoch: 2, Batch: 485, Loss: 2436.038818359375\n",
      "Epoch: 2, Batch: 486, Loss: 2489.840576171875\n",
      "Epoch: 2, Batch: 487, Loss: 2593.328369140625\n",
      "Epoch: 2, Batch: 488, Loss: 2973.38037109375\n",
      "Epoch: 2, Batch: 489, Loss: 2694.07470703125\n",
      "Epoch: 2, Batch: 490, Loss: 2073.52099609375\n",
      "Epoch: 2, Batch: 491, Loss: 2926.637939453125\n",
      "Epoch: 2, Batch: 492, Loss: 2539.494873046875\n",
      "Epoch: 2, Batch: 493, Loss: 2126.715576171875\n",
      "Epoch: 2, Batch: 494, Loss: 2556.862060546875\n",
      "Epoch: 2, Batch: 495, Loss: 2407.15234375\n",
      "Epoch: 2, Batch: 496, Loss: 2735.54150390625\n",
      "Epoch: 2, Batch: 497, Loss: 2516.55859375\n",
      "Epoch: 2, Batch: 498, Loss: 1851.6624755859375\n",
      "Epoch: 2, Batch: 499, Loss: 2661.739501953125\n",
      "Epoch: 2, Batch: 500, Loss: 2773.4951171875\n",
      "Epoch: 2, Batch: 501, Loss: 3076.4638671875\n",
      "Epoch: 2, Batch: 502, Loss: 2611.842041015625\n",
      "Epoch: 2, Batch: 503, Loss: 2122.584228515625\n",
      "Epoch: 2, Batch: 504, Loss: 2167.103515625\n",
      "Epoch: 2, Batch: 505, Loss: 2352.07568359375\n",
      "Epoch: 2, Batch: 506, Loss: 2805.78271484375\n",
      "Epoch: 2, Batch: 507, Loss: 2910.73095703125\n",
      "Epoch: 2, Batch: 508, Loss: 2563.645751953125\n",
      "Epoch: 2, Batch: 509, Loss: 3022.611328125\n",
      "Epoch: 2, Batch: 510, Loss: 2211.787109375\n",
      "Epoch: 2, Batch: 511, Loss: 2284.1201171875\n",
      "Epoch: 2, Batch: 512, Loss: 2697.715576171875\n",
      "Epoch: 2, Batch: 513, Loss: 2142.93310546875\n",
      "Epoch: 2, Batch: 514, Loss: 2938.5224609375\n",
      "Epoch: 2, Batch: 515, Loss: 2858.015380859375\n",
      "Epoch: 2, Batch: 516, Loss: 2534.53173828125\n",
      "Epoch: 2, Batch: 517, Loss: 2629.749755859375\n",
      "Epoch: 2, Batch: 518, Loss: 2649.395263671875\n",
      "Epoch: 2, Batch: 519, Loss: 2892.787841796875\n",
      "Epoch: 2, Batch: 520, Loss: 3110.879638671875\n",
      "Epoch: 2, Batch: 521, Loss: 2217.973388671875\n",
      "Epoch: 2, Batch: 522, Loss: 2930.08984375\n",
      "Epoch: 2, Batch: 523, Loss: 2819.72607421875\n",
      "Epoch: 2, Batch: 524, Loss: 2381.541259765625\n",
      "Epoch: 2, Batch: 525, Loss: 2577.537109375\n",
      "Epoch: 2, Batch: 526, Loss: 2212.84521484375\n",
      "Epoch: 2, Batch: 527, Loss: 2768.74462890625\n",
      "Epoch: 2, Batch: 528, Loss: 3186.990478515625\n",
      "Epoch: 2, Batch: 529, Loss: 2565.626708984375\n",
      "Epoch: 2, Batch: 530, Loss: 2631.993896484375\n",
      "Epoch: 2, Batch: 531, Loss: 2558.12353515625\n",
      "Epoch: 2, Batch: 532, Loss: 2924.109375\n",
      "Epoch: 2, Batch: 533, Loss: 2420.810791015625\n",
      "Epoch: 2, Batch: 534, Loss: 2504.144287109375\n",
      "Epoch: 2, Batch: 535, Loss: 2399.915771484375\n",
      "Epoch: 2, Batch: 536, Loss: 2790.869140625\n",
      "Epoch: 2, Batch: 537, Loss: 2568.939697265625\n",
      "Epoch: 2, Batch: 538, Loss: 2791.435791015625\n",
      "Epoch: 2, Batch: 539, Loss: 3074.026611328125\n",
      "Epoch: 2, Batch: 540, Loss: 2396.510986328125\n",
      "Epoch: 2, Batch: 541, Loss: 2529.00830078125\n",
      "Epoch: 2, Batch: 542, Loss: 3041.965576171875\n",
      "Epoch: 2, Batch: 543, Loss: 2486.962890625\n",
      "Epoch: 2, Batch: 544, Loss: 3010.12744140625\n",
      "Epoch: 2, Batch: 545, Loss: 2358.039794921875\n",
      "Epoch: 2, Batch: 546, Loss: 2662.2275390625\n",
      "Epoch: 2, Batch: 547, Loss: 2357.148193359375\n",
      "Epoch: 2, Batch: 548, Loss: 2652.510009765625\n",
      "Epoch: 2, Batch: 549, Loss: 2830.1083984375\n",
      "Epoch: 2, Batch: 550, Loss: 2344.970947265625\n",
      "Epoch: 2, Batch: 551, Loss: 2526.703857421875\n",
      "Epoch: 2, Batch: 552, Loss: 3313.728271484375\n",
      "Epoch: 2, Batch: 553, Loss: 2202.11181640625\n",
      "Epoch: 2, Batch: 554, Loss: 3076.068359375\n",
      "Epoch: 2, Batch: 555, Loss: 3137.335693359375\n",
      "Epoch: 2, Batch: 556, Loss: 2820.373779296875\n",
      "Epoch: 2, Batch: 557, Loss: 2712.056396484375\n",
      "Epoch: 2, Batch: 558, Loss: 2647.152099609375\n",
      "Epoch: 2, Batch: 559, Loss: 2621.2021484375\n",
      "Epoch: 2, Batch: 560, Loss: 2233.55712890625\n",
      "Epoch: 2, Batch: 561, Loss: 2806.7314453125\n",
      "Epoch: 2, Batch: 562, Loss: 2556.14990234375\n",
      "Epoch: 2, Batch: 563, Loss: 2484.74072265625\n",
      "Epoch: 2, Batch: 564, Loss: 2468.62353515625\n",
      "Epoch: 2, Batch: 565, Loss: 3003.218994140625\n",
      "Epoch: 2, Batch: 566, Loss: 2379.76416015625\n",
      "Epoch: 2, Batch: 567, Loss: 2482.5830078125\n",
      "Epoch: 2, Batch: 568, Loss: 2444.726318359375\n",
      "Epoch: 2, Batch: 569, Loss: 2952.52001953125\n",
      "Epoch: 2, Batch: 570, Loss: 2480.238037109375\n",
      "Epoch: 2, Batch: 571, Loss: 2526.614990234375\n",
      "Epoch: 2, Batch: 572, Loss: 3022.4306640625\n",
      "Epoch: 2, Batch: 573, Loss: 2735.31298828125\n",
      "Epoch: 2, Batch: 574, Loss: 3110.5654296875\n",
      "Epoch: 2, Batch: 575, Loss: 3205.145263671875\n",
      "Epoch: 2, Batch: 576, Loss: 2661.630615234375\n",
      "Epoch: 2, Batch: 577, Loss: 3284.384033203125\n",
      "Epoch: 2, Batch: 578, Loss: 2030.1009521484375\n",
      "Epoch: 2, Batch: 579, Loss: 2797.890625\n",
      "Epoch: 2, Batch: 580, Loss: 3158.1142578125\n",
      "Epoch: 2, Batch: 581, Loss: 2805.95947265625\n",
      "Epoch: 2, Batch: 582, Loss: 2695.683349609375\n",
      "Epoch: 2, Batch: 583, Loss: 2900.2431640625\n",
      "Epoch: 2, Batch: 584, Loss: 2573.62744140625\n",
      "Epoch: 2, Batch: 585, Loss: 2815.94287109375\n",
      "Epoch: 2, Batch: 586, Loss: 2698.7333984375\n",
      "Epoch: 2, Batch: 587, Loss: 2408.361328125\n",
      "Epoch: 2, Batch: 588, Loss: 2541.5693359375\n",
      "Epoch: 2, Batch: 589, Loss: 2772.559814453125\n",
      "Epoch: 2, Batch: 590, Loss: 2593.08251953125\n",
      "Epoch: 2, Batch: 591, Loss: 2655.302001953125\n",
      "Epoch: 2, Batch: 592, Loss: 2636.334716796875\n",
      "Epoch: 2, Batch: 593, Loss: 2316.53759765625\n",
      "Epoch: 2, Batch: 594, Loss: 2184.733154296875\n",
      "Epoch: 2, Batch: 595, Loss: 2178.052978515625\n",
      "Epoch: 2, Batch: 596, Loss: 2670.390869140625\n",
      "Epoch: 2, Batch: 597, Loss: 2562.776123046875\n",
      "Epoch: 2, Batch: 598, Loss: 2047.084716796875\n",
      "Epoch: 2, Batch: 599, Loss: 3004.80419921875\n",
      "Epoch: 2, Batch: 600, Loss: 2873.039794921875\n",
      "Epoch: 2, Batch: 601, Loss: 2550.83740234375\n",
      "Epoch: 2, Batch: 602, Loss: 2565.602294921875\n",
      "Epoch: 2, Batch: 603, Loss: 2841.46142578125\n",
      "Epoch: 2, Batch: 604, Loss: 2342.072998046875\n",
      "Epoch: 2, Batch: 605, Loss: 3145.154052734375\n",
      "Epoch: 2, Batch: 606, Loss: 2494.370849609375\n",
      "Epoch: 2, Batch: 607, Loss: 2877.96142578125\n",
      "Epoch: 2, Batch: 608, Loss: 2460.744140625\n",
      "Epoch: 2, Batch: 609, Loss: 2610.9111328125\n",
      "Epoch: 2, Batch: 610, Loss: 2321.015625\n",
      "Epoch: 2, Batch: 611, Loss: 3080.099609375\n",
      "Epoch: 2, Batch: 612, Loss: 2678.36865234375\n",
      "Epoch: 2, Batch: 613, Loss: 2261.91845703125\n",
      "Epoch: 2, Batch: 614, Loss: 2284.871826171875\n",
      "Epoch: 2, Batch: 615, Loss: 2438.2412109375\n",
      "Epoch: 2, Batch: 616, Loss: 2862.61865234375\n",
      "Epoch: 2, Batch: 617, Loss: 2759.551025390625\n",
      "Epoch: 2, Batch: 618, Loss: 2394.895263671875\n",
      "Epoch: 2, Batch: 619, Loss: 2501.234619140625\n",
      "Epoch: 2, Batch: 620, Loss: 2404.510498046875\n",
      "Epoch: 2, Batch: 621, Loss: 2458.4375\n",
      "Epoch: 2, Batch: 622, Loss: 2592.115478515625\n",
      "Epoch: 2, Batch: 623, Loss: 3079.894775390625\n",
      "Epoch: 2, Batch: 624, Loss: 2776.896728515625\n",
      "Epoch: 2, Batch: 625, Loss: 2614.006103515625\n",
      "Epoch: 2, Batch: 626, Loss: 2523.50830078125\n",
      "Epoch: 2, Batch: 627, Loss: 3221.440185546875\n",
      "Epoch: 2, Batch: 628, Loss: 2935.994140625\n",
      "Epoch: 2, Batch: 629, Loss: 2866.54541015625\n",
      "Epoch: 2, Batch: 630, Loss: 2820.1015625\n",
      "Epoch: 2, Batch: 631, Loss: 2053.80224609375\n",
      "Epoch: 2, Batch: 632, Loss: 2833.53564453125\n",
      "Epoch: 2, Batch: 633, Loss: 2651.529296875\n",
      "Epoch: 2, Batch: 634, Loss: 3134.175537109375\n",
      "Epoch: 2, Batch: 635, Loss: 2438.731201171875\n",
      "Epoch: 2, Batch: 636, Loss: 2937.95361328125\n",
      "Epoch: 2, Batch: 637, Loss: 2906.36962890625\n",
      "Epoch: 2, Batch: 638, Loss: 2499.6796875\n",
      "Epoch: 2, Batch: 639, Loss: 2574.5546875\n",
      "Epoch: 2, Batch: 640, Loss: 2559.12646484375\n",
      "Epoch: 2, Batch: 641, Loss: 2630.0205078125\n",
      "Epoch: 2, Batch: 642, Loss: 2663.79248046875\n",
      "Epoch: 2, Batch: 643, Loss: 2950.632080078125\n",
      "Epoch: 2, Batch: 644, Loss: 3021.35791015625\n",
      "Epoch: 2, Batch: 645, Loss: 3157.110107421875\n",
      "Epoch: 2, Batch: 646, Loss: 2157.932861328125\n",
      "Epoch: 2, Batch: 647, Loss: 2340.51318359375\n",
      "Epoch: 2, Batch: 648, Loss: 3062.54833984375\n",
      "Epoch: 2, Batch: 649, Loss: 2703.1005859375\n",
      "Epoch: 2, Batch: 650, Loss: 2640.27490234375\n",
      "Epoch: 2, Batch: 651, Loss: 2846.953125\n",
      "Epoch: 2, Batch: 652, Loss: 2846.243896484375\n",
      "Epoch: 2, Batch: 653, Loss: 2554.006591796875\n",
      "Epoch: 2, Batch: 654, Loss: 2735.92431640625\n",
      "Epoch: 2, Batch: 655, Loss: 2821.23779296875\n",
      "Epoch: 2, Batch: 656, Loss: 2566.572998046875\n",
      "Epoch: 2, Batch: 657, Loss: 3466.0703125\n",
      "Epoch: 2, Batch: 658, Loss: 3070.51416015625\n",
      "Epoch: 2, Batch: 659, Loss: 2591.292236328125\n",
      "Epoch: 2, Batch: 660, Loss: 2872.50341796875\n",
      "Epoch: 2, Batch: 661, Loss: 2639.3974609375\n",
      "Epoch: 2, Batch: 662, Loss: 2079.589111328125\n",
      "Epoch: 2, Batch: 663, Loss: 2721.603515625\n",
      "Epoch: 2, Batch: 664, Loss: 2579.877197265625\n",
      "Epoch: 2, Batch: 665, Loss: 2824.583740234375\n",
      "Epoch: 2, Batch: 666, Loss: 2645.579345703125\n",
      "Epoch: 2, Batch: 667, Loss: 2396.975341796875\n",
      "Epoch: 2, Batch: 668, Loss: 2145.063720703125\n",
      "Epoch: 2, Batch: 669, Loss: 2317.68505859375\n",
      "Epoch: 2, Batch: 670, Loss: 2590.08251953125\n",
      "Epoch: 2, Batch: 671, Loss: 2816.514892578125\n",
      "Epoch: 2, Batch: 672, Loss: 2464.290283203125\n",
      "Epoch: 2, Batch: 673, Loss: 3001.332275390625\n",
      "Epoch: 2, Batch: 674, Loss: 3002.7763671875\n",
      "Epoch: 2, Batch: 675, Loss: 2955.28857421875\n",
      "Epoch: 2, Batch: 676, Loss: 3045.2451171875\n",
      "Epoch: 2, Batch: 677, Loss: 2706.25830078125\n",
      "Epoch: 2, Batch: 678, Loss: 2792.52978515625\n",
      "Epoch: 2, Batch: 679, Loss: 2473.9853515625\n",
      "Epoch: 2, Batch: 680, Loss: 2861.042724609375\n",
      "Epoch: 2, Batch: 681, Loss: 3181.374755859375\n",
      "Epoch: 2, Batch: 682, Loss: 2592.197509765625\n",
      "Epoch: 2, Batch: 683, Loss: 2321.8408203125\n",
      "Epoch: 2, Batch: 684, Loss: 2609.77294921875\n",
      "Epoch: 2, Batch: 685, Loss: 2671.5595703125\n",
      "Epoch: 2, Batch: 686, Loss: 2258.814208984375\n",
      "Epoch: 2, Batch: 687, Loss: 2601.289306640625\n",
      "Epoch: 2, Batch: 688, Loss: 2872.5244140625\n",
      "Epoch: 2, Batch: 689, Loss: 2975.9931640625\n",
      "Epoch: 2, Batch: 690, Loss: 2756.95361328125\n",
      "Epoch: 2, Batch: 691, Loss: 2708.4716796875\n",
      "Epoch: 2, Batch: 692, Loss: 2766.16845703125\n",
      "Epoch: 2, Batch: 693, Loss: 2858.66845703125\n",
      "Epoch: 2, Batch: 694, Loss: 2713.819091796875\n",
      "Epoch: 2, Batch: 695, Loss: 2280.00634765625\n",
      "Epoch: 2, Batch: 696, Loss: 3062.185302734375\n",
      "Epoch: 2, Batch: 697, Loss: 2432.3701171875\n",
      "Epoch: 2, Batch: 698, Loss: 2804.8720703125\n",
      "Epoch: 2, Batch: 699, Loss: 2177.249267578125\n",
      "Epoch: 2, Batch: 700, Loss: 2462.961181640625\n",
      "Epoch: 2, Batch: 701, Loss: 2213.09033203125\n",
      "Epoch: 2, Batch: 702, Loss: 3188.978759765625\n",
      "Epoch: 2, Batch: 703, Loss: 2035.47216796875\n",
      "Epoch: 2, Batch: 704, Loss: 2542.79931640625\n",
      "Epoch: 2, Batch: 705, Loss: 1644.504150390625\n",
      "Epoch: 2, Batch: 706, Loss: 2305.672119140625\n",
      "Epoch: 2, Batch: 707, Loss: 2497.102294921875\n",
      "Epoch: 2, Batch: 708, Loss: 2715.6328125\n",
      "Epoch: 2, Batch: 709, Loss: 2671.771240234375\n",
      "Epoch: 2, Batch: 710, Loss: 2685.94091796875\n",
      "Epoch: 2, Batch: 711, Loss: 2827.554443359375\n",
      "Epoch: 2, Batch: 712, Loss: 2661.486572265625\n",
      "Epoch: 2, Batch: 713, Loss: 3077.2734375\n",
      "Epoch: 2, Batch: 714, Loss: 2734.17041015625\n",
      "Epoch: 2, Batch: 715, Loss: 2857.420166015625\n",
      "Epoch: 2, Batch: 716, Loss: 2910.3271484375\n",
      "Epoch: 2, Batch: 717, Loss: 2826.902587890625\n",
      "Epoch: 2, Batch: 718, Loss: 2685.931884765625\n",
      "Epoch: 2, Batch: 719, Loss: 2634.260009765625\n",
      "Epoch: 2, Batch: 720, Loss: 2566.48095703125\n",
      "Epoch: 2, Batch: 721, Loss: 2686.328125\n",
      "Epoch: 2, Batch: 722, Loss: 2860.5\n",
      "Epoch: 2, Batch: 723, Loss: 2543.337158203125\n",
      "Epoch: 2, Batch: 724, Loss: 2390.164794921875\n",
      "Epoch: 2, Batch: 725, Loss: 2789.552978515625\n",
      "Epoch: 2, Batch: 726, Loss: 2609.552978515625\n",
      "Epoch: 2, Batch: 727, Loss: 2730.887939453125\n",
      "Epoch: 2, Batch: 728, Loss: 2541.615478515625\n",
      "Epoch: 2, Batch: 729, Loss: 2560.953369140625\n",
      "Epoch: 2, Batch: 730, Loss: 2672.057861328125\n",
      "Epoch: 2, Batch: 731, Loss: 2628.70751953125\n",
      "Epoch: 2, Batch: 732, Loss: 2332.74462890625\n",
      "Epoch: 2, Batch: 733, Loss: 3387.01708984375\n",
      "Epoch: 2, Batch: 734, Loss: 3163.168212890625\n",
      "Epoch: 2, Batch: 735, Loss: 2880.189453125\n",
      "Epoch: 2, Batch: 736, Loss: 2870.58251953125\n",
      "Epoch: 2, Batch: 737, Loss: 2519.0390625\n",
      "Epoch: 2, Batch: 738, Loss: 2627.302734375\n",
      "Epoch: 2, Batch: 739, Loss: 3004.188232421875\n",
      "Epoch: 2, Batch: 740, Loss: 2623.859619140625\n",
      "Epoch: 2, Batch: 741, Loss: 2733.34375\n",
      "Epoch: 2, Batch: 742, Loss: 2753.49853515625\n",
      "Epoch: 2, Batch: 743, Loss: 2974.94970703125\n",
      "Epoch: 2, Batch: 744, Loss: 2444.22265625\n",
      "Epoch: 2, Batch: 745, Loss: 2346.339599609375\n",
      "Epoch: 2, Batch: 746, Loss: 2393.081787109375\n",
      "Epoch: 2, Batch: 747, Loss: 2406.655029296875\n",
      "Epoch: 2, Batch: 748, Loss: 2964.7705078125\n",
      "Epoch: 2, Batch: 749, Loss: 2406.30322265625\n",
      "Epoch: 2, Batch: 750, Loss: 3011.023681640625\n",
      "Epoch: 2, Batch: 751, Loss: 2344.26025390625\n",
      "Epoch: 2, Batch: 752, Loss: 2345.370361328125\n",
      "Epoch: 2, Batch: 753, Loss: 2199.734130859375\n",
      "Epoch: 2, Batch: 754, Loss: 2578.838134765625\n",
      "Epoch: 2, Batch: 755, Loss: 2908.3427734375\n",
      "Epoch: 2, Batch: 756, Loss: 2418.0859375\n",
      "Epoch: 2, Batch: 757, Loss: 2440.10693359375\n",
      "Epoch: 2, Batch: 758, Loss: 2295.51611328125\n",
      "Epoch: 2, Batch: 759, Loss: 2843.76220703125\n",
      "Epoch: 2, Batch: 760, Loss: 2780.2529296875\n",
      "Epoch: 2, Batch: 761, Loss: 2272.7529296875\n",
      "Epoch: 2, Batch: 762, Loss: 2486.331298828125\n",
      "Epoch: 2, Batch: 763, Loss: 2636.14794921875\n",
      "Epoch: 2, Batch: 764, Loss: 2666.243408203125\n",
      "Epoch: 2, Batch: 765, Loss: 2932.4130859375\n",
      "Epoch: 2, Batch: 766, Loss: 2732.80224609375\n",
      "Epoch: 2, Batch: 767, Loss: 2662.649169921875\n",
      "Epoch: 2, Batch: 768, Loss: 2388.556884765625\n",
      "Epoch: 2, Batch: 769, Loss: 2421.010009765625\n",
      "Epoch: 2, Batch: 770, Loss: 2615.0634765625\n",
      "Epoch: 2, Batch: 771, Loss: 2710.906494140625\n",
      "Epoch: 2, Batch: 772, Loss: 3480.86376953125\n",
      "Epoch: 2, Batch: 773, Loss: 2595.892822265625\n",
      "Epoch: 2, Batch: 774, Loss: 2882.76123046875\n",
      "Epoch: 2, Batch: 775, Loss: 2679.916015625\n",
      "Epoch: 2, Batch: 776, Loss: 2700.0185546875\n",
      "Epoch: 2, Batch: 777, Loss: 2518.33544921875\n",
      "Epoch: 2, Batch: 778, Loss: 2689.733154296875\n",
      "Epoch: 2, Batch: 779, Loss: 2888.22021484375\n",
      "Epoch: 2, Batch: 780, Loss: 1947.1551513671875\n",
      "Epoch: 2, Batch: 781, Loss: 3075.377197265625\n",
      "Epoch: 2, Batch: 782, Loss: 2178.165771484375\n",
      "Epoch: 2, Batch: 783, Loss: 3104.264404296875\n",
      "Epoch: 2, Batch: 784, Loss: 2790.54443359375\n",
      "Epoch: 2, Batch: 785, Loss: 2324.361572265625\n",
      "Epoch: 2, Batch: 786, Loss: 2478.05419921875\n",
      "Epoch: 2, Batch: 787, Loss: 2795.909912109375\n",
      "Epoch: 2, Batch: 788, Loss: 2815.571044921875\n",
      "Epoch: 2, Batch: 789, Loss: 2082.67724609375\n",
      "Epoch: 2, Batch: 790, Loss: 2534.961181640625\n",
      "Epoch: 2, Batch: 791, Loss: 2733.64892578125\n",
      "Epoch: 2, Batch: 792, Loss: 2839.493896484375\n",
      "Epoch: 2, Batch: 793, Loss: 2971.884033203125\n",
      "Epoch: 2, Batch: 794, Loss: 2380.012451171875\n",
      "Epoch: 2, Batch: 795, Loss: 2512.588134765625\n",
      "Epoch: 2, Batch: 796, Loss: 2559.001220703125\n",
      "Epoch: 2, Batch: 797, Loss: 2452.359130859375\n",
      "Epoch: 2, Batch: 798, Loss: 2320.964111328125\n",
      "Epoch: 2, Batch: 799, Loss: 2418.179931640625\n",
      "Epoch: 2, Batch: 800, Loss: 3054.09130859375\n",
      "Epoch: 2, Batch: 801, Loss: 2441.701171875\n",
      "Epoch: 2, Batch: 802, Loss: 3073.905517578125\n",
      "Epoch: 2, Batch: 803, Loss: 2938.197998046875\n",
      "Epoch: 2, Batch: 804, Loss: 2930.2158203125\n",
      "Epoch: 2, Batch: 805, Loss: 2964.89111328125\n",
      "Epoch: 2, Batch: 806, Loss: 3020.6630859375\n",
      "Epoch: 2, Batch: 807, Loss: 3066.1533203125\n",
      "Epoch: 2, Batch: 808, Loss: 2252.541015625\n",
      "Epoch: 2, Batch: 809, Loss: 3031.15673828125\n",
      "Epoch: 2, Batch: 810, Loss: 2939.875732421875\n",
      "Epoch: 2, Batch: 811, Loss: 2724.6689453125\n",
      "Epoch: 2, Batch: 812, Loss: 2560.8623046875\n",
      "Epoch: 2, Batch: 813, Loss: 2996.844482421875\n",
      "Epoch: 2, Batch: 814, Loss: 2283.167236328125\n",
      "Epoch: 2, Batch: 815, Loss: 2987.21142578125\n",
      "Epoch: 2, Batch: 816, Loss: 2380.55029296875\n",
      "Epoch: 2, Batch: 817, Loss: 2505.843994140625\n",
      "Epoch: 2, Batch: 818, Loss: 2285.62548828125\n",
      "Epoch: 2, Batch: 819, Loss: 3141.5703125\n",
      "Epoch: 2, Batch: 820, Loss: 2562.404296875\n",
      "Epoch: 2, Batch: 821, Loss: 2241.40478515625\n",
      "Epoch: 2, Batch: 822, Loss: 2824.70703125\n",
      "Epoch: 2, Batch: 823, Loss: 3004.007080078125\n",
      "Epoch: 2, Batch: 824, Loss: 2792.84619140625\n",
      "Epoch: 2, Batch: 825, Loss: 2735.470458984375\n",
      "Epoch: 2, Batch: 826, Loss: 2231.22021484375\n",
      "Epoch: 2, Batch: 827, Loss: 3271.73046875\n",
      "Epoch: 2, Batch: 828, Loss: 2735.849609375\n",
      "Epoch: 2, Batch: 829, Loss: 2909.959228515625\n",
      "Epoch: 2, Batch: 830, Loss: 2740.375\n",
      "Epoch: 2, Batch: 831, Loss: 2333.397705078125\n",
      "Epoch: 2, Batch: 832, Loss: 2630.93408203125\n",
      "Epoch: 2, Batch: 833, Loss: 2358.18896484375\n",
      "Epoch: 2, Batch: 834, Loss: 2117.576416015625\n",
      "Epoch: 2, Batch: 835, Loss: 2053.286376953125\n",
      "Epoch: 2, Batch: 836, Loss: 2820.759765625\n",
      "Epoch: 2, Batch: 837, Loss: 3099.162109375\n",
      "Epoch: 2, Batch: 838, Loss: 2770.514404296875\n",
      "Epoch: 2, Batch: 839, Loss: 2686.995849609375\n",
      "Epoch: 2, Batch: 840, Loss: 2507.155517578125\n",
      "Epoch: 2, Batch: 841, Loss: 2087.5234375\n",
      "Epoch: 2, Batch: 842, Loss: 2587.673583984375\n",
      "Epoch: 2, Batch: 843, Loss: 2395.1318359375\n",
      "Epoch: 2, Batch: 844, Loss: 3191.560302734375\n",
      "Epoch: 2, Batch: 845, Loss: 2430.672119140625\n",
      "Epoch: 2, Batch: 846, Loss: 2951.447998046875\n",
      "Epoch: 2, Batch: 847, Loss: 2674.37353515625\n",
      "Epoch: 2, Batch: 848, Loss: 3091.5615234375\n",
      "Epoch: 2, Batch: 849, Loss: 2845.1650390625\n",
      "Epoch: 2, Batch: 850, Loss: 2440.93408203125\n",
      "Epoch: 2, Batch: 851, Loss: 2489.374755859375\n",
      "Epoch: 2, Batch: 852, Loss: 2402.57177734375\n",
      "Epoch: 2, Batch: 853, Loss: 2977.15625\n",
      "Epoch: 2, Batch: 854, Loss: 2930.6494140625\n",
      "Epoch: 2, Batch: 855, Loss: 3050.485595703125\n",
      "Epoch: 2, Batch: 856, Loss: 2352.56494140625\n",
      "Epoch: 2, Batch: 857, Loss: 2840.44189453125\n",
      "Epoch: 2, Batch: 858, Loss: 3035.1728515625\n",
      "Epoch: 2, Batch: 859, Loss: 2716.37548828125\n",
      "Epoch: 2, Batch: 860, Loss: 2582.749267578125\n",
      "Epoch: 2, Batch: 861, Loss: 2200.269775390625\n",
      "Epoch: 2, Batch: 862, Loss: 2629.00146484375\n",
      "Epoch: 2, Batch: 863, Loss: 2553.264404296875\n",
      "Epoch: 2, Batch: 864, Loss: 2616.21337890625\n",
      "Epoch: 2, Batch: 865, Loss: 3048.6640625\n",
      "Epoch: 2, Batch: 866, Loss: 2296.08056640625\n",
      "Epoch: 2, Batch: 867, Loss: 2616.292724609375\n",
      "Epoch: 2, Batch: 868, Loss: 2993.66162109375\n",
      "Epoch: 2, Batch: 869, Loss: 2717.3359375\n",
      "Epoch: 2, Batch: 870, Loss: 2420.3193359375\n",
      "Epoch: 2, Batch: 871, Loss: 2960.146240234375\n",
      "Epoch: 2, Batch: 872, Loss: 3792.26318359375\n",
      "Epoch: 2, Batch: 873, Loss: 2676.18359375\n",
      "Epoch: 2, Batch: 874, Loss: 2854.693603515625\n",
      "Epoch: 2, Batch: 875, Loss: 2539.78857421875\n",
      "Epoch: 2, Batch: 876, Loss: 3046.58349609375\n",
      "Epoch: 2, Batch: 877, Loss: 2994.681396484375\n",
      "Epoch: 2, Batch: 878, Loss: 3106.343017578125\n",
      "Epoch: 2, Batch: 879, Loss: 2552.736572265625\n",
      "Epoch: 2, Batch: 880, Loss: 2355.790771484375\n",
      "Epoch: 2, Batch: 881, Loss: 2506.082763671875\n",
      "Epoch: 2, Batch: 882, Loss: 2656.50390625\n",
      "Epoch: 2, Batch: 883, Loss: 2942.890380859375\n",
      "Epoch: 2, Batch: 884, Loss: 2781.506591796875\n",
      "Epoch: 2, Batch: 885, Loss: 2765.18359375\n",
      "Epoch: 2, Batch: 886, Loss: 2166.9638671875\n",
      "Epoch: 2, Batch: 887, Loss: 2553.298095703125\n",
      "Epoch: 2, Batch: 888, Loss: 2913.0361328125\n",
      "Epoch: 2, Batch: 889, Loss: 2738.93408203125\n",
      "Epoch: 2, Batch: 890, Loss: 2255.742919921875\n",
      "Epoch: 2, Batch: 891, Loss: 2629.662841796875\n",
      "Epoch: 2, Batch: 892, Loss: 2587.11376953125\n",
      "Epoch: 2, Batch: 893, Loss: 2095.4384765625\n",
      "Epoch: 2, Batch: 894, Loss: 2883.9970703125\n",
      "Epoch: 2, Batch: 895, Loss: 2555.716796875\n",
      "Epoch: 2, Batch: 896, Loss: 2082.643798828125\n",
      "Epoch: 2, Batch: 897, Loss: 2303.535400390625\n",
      "Epoch: 2, Batch: 898, Loss: 2426.1318359375\n",
      "Epoch: 2, Batch: 899, Loss: 2462.892333984375\n",
      "Epoch: 2, Batch: 900, Loss: 2633.2177734375\n",
      "Epoch: 2, Batch: 901, Loss: 2322.750244140625\n",
      "Epoch: 2, Batch: 902, Loss: 2833.8291015625\n",
      "Epoch: 2, Batch: 903, Loss: 3048.864990234375\n",
      "Epoch: 2, Batch: 904, Loss: 2430.9814453125\n",
      "Epoch: 2, Batch: 905, Loss: 2501.615478515625\n",
      "Epoch: 2, Batch: 906, Loss: 2222.19677734375\n",
      "Epoch: 2, Batch: 907, Loss: 3205.976806640625\n",
      "Epoch: 2, Batch: 908, Loss: 2776.421630859375\n",
      "Epoch: 2, Batch: 909, Loss: 2451.904052734375\n",
      "Epoch: 2, Batch: 910, Loss: 2163.10009765625\n",
      "Epoch: 2, Batch: 911, Loss: 2871.33056640625\n",
      "Epoch: 2, Batch: 912, Loss: 3146.18701171875\n",
      "Epoch: 2, Batch: 913, Loss: 2785.132568359375\n",
      "Epoch: 2, Batch: 914, Loss: 3123.71435546875\n",
      "Epoch: 2, Batch: 915, Loss: 2430.219970703125\n",
      "Epoch: 2, Batch: 916, Loss: 3155.63818359375\n",
      "Epoch: 2, Batch: 917, Loss: 1996.21728515625\n",
      "Epoch: 2, Batch: 918, Loss: 2693.92529296875\n",
      "Epoch: 2, Batch: 919, Loss: 2851.18896484375\n",
      "Epoch: 2, Batch: 920, Loss: 2649.86767578125\n",
      "Epoch: 2, Batch: 921, Loss: 2604.15625\n",
      "Epoch: 2, Batch: 922, Loss: 1937.04345703125\n",
      "Epoch: 2, Batch: 923, Loss: 2655.25537109375\n",
      "Epoch: 2, Batch: 924, Loss: 2550.311279296875\n",
      "Epoch: 2, Batch: 925, Loss: 2625.37353515625\n",
      "Epoch: 2, Batch: 926, Loss: 2862.75732421875\n",
      "Epoch: 2, Batch: 927, Loss: 2267.8095703125\n",
      "Epoch: 2, Batch: 928, Loss: 2604.19580078125\n",
      "Epoch: 2, Batch: 929, Loss: 2750.40478515625\n",
      "Epoch: 2, Batch: 930, Loss: 2634.98974609375\n",
      "Epoch: 2, Batch: 931, Loss: 2331.45849609375\n",
      "Epoch: 2, Batch: 932, Loss: 2535.314453125\n",
      "Epoch: 2, Batch: 933, Loss: 2623.958251953125\n",
      "Epoch: 2, Batch: 934, Loss: 2444.690185546875\n",
      "Epoch: 2, Batch: 935, Loss: 3141.68212890625\n",
      "Epoch: 2, Batch: 936, Loss: 2716.920654296875\n",
      "Epoch: 2, Batch: 937, Loss: 2540.02197265625\n",
      "Epoch: 2, Batch: 938, Loss: 2825.93896484375\n",
      "Epoch: 2, Batch: 939, Loss: 2079.552734375\n",
      "Epoch: 2, Batch: 940, Loss: 2114.46240234375\n",
      "Epoch: 2, Batch: 941, Loss: 2564.64306640625\n",
      "Epoch: 2, Batch: 942, Loss: 2247.438232421875\n",
      "Epoch: 2, Batch: 943, Loss: 2812.3955078125\n",
      "Epoch: 2, Batch: 944, Loss: 2332.7353515625\n",
      "Epoch: 2, Batch: 945, Loss: 2857.900634765625\n",
      "Epoch: 2, Batch: 946, Loss: 2213.9677734375\n",
      "Epoch: 2, Batch: 947, Loss: 2936.590576171875\n",
      "Epoch: 2, Batch: 948, Loss: 2985.9716796875\n",
      "Epoch: 2, Batch: 949, Loss: 2849.40673828125\n",
      "Epoch: 2, Batch: 950, Loss: 2695.675537109375\n",
      "Epoch: 2, Batch: 951, Loss: 2290.5244140625\n",
      "Epoch: 2, Batch: 952, Loss: 2712.494384765625\n",
      "Epoch: 2, Batch: 953, Loss: 2436.117431640625\n",
      "Epoch: 2, Batch: 954, Loss: 2519.182373046875\n",
      "Epoch: 2, Batch: 955, Loss: 2909.8818359375\n",
      "Epoch: 2, Batch: 956, Loss: 2654.112060546875\n",
      "Epoch: 2, Batch: 957, Loss: 2395.925537109375\n",
      "Epoch: 2, Batch: 958, Loss: 2800.060791015625\n",
      "Epoch: 2, Batch: 959, Loss: 2337.89892578125\n",
      "Epoch: 2, Batch: 960, Loss: 2541.533447265625\n",
      "Epoch: 2, Batch: 961, Loss: 2862.846923828125\n",
      "Epoch: 2, Batch: 962, Loss: 2251.283203125\n",
      "Epoch: 2, Batch: 963, Loss: 2275.96923828125\n",
      "Epoch: 2, Batch: 964, Loss: 2058.197998046875\n",
      "Epoch: 2, Batch: 965, Loss: 2651.14990234375\n",
      "Epoch: 2, Batch: 966, Loss: 2316.755126953125\n",
      "Epoch: 2, Batch: 967, Loss: 2465.280029296875\n",
      "Epoch: 2, Batch: 968, Loss: 2473.797119140625\n",
      "Epoch: 2, Batch: 969, Loss: 2645.298095703125\n",
      "Epoch: 2, Batch: 970, Loss: 3318.93017578125\n",
      "Epoch: 2, Batch: 971, Loss: 2554.496337890625\n",
      "Epoch: 2, Batch: 972, Loss: 2173.142333984375\n",
      "Epoch: 2, Batch: 973, Loss: 2765.970947265625\n",
      "Epoch: 2, Batch: 974, Loss: 2616.26220703125\n",
      "Epoch: 2, Batch: 975, Loss: 3000.95654296875\n",
      "Epoch: 2, Batch: 976, Loss: 1956.09423828125\n",
      "Epoch: 2, Batch: 977, Loss: 3080.207275390625\n",
      "Epoch: 2, Batch: 978, Loss: 2918.706298828125\n",
      "Epoch: 2, Batch: 979, Loss: 3135.5390625\n",
      "Epoch: 2, Batch: 980, Loss: 2700.805419921875\n",
      "Epoch: 2, Batch: 981, Loss: 2618.76708984375\n",
      "Epoch: 2, Batch: 982, Loss: 3356.610595703125\n",
      "Epoch: 2, Batch: 983, Loss: 2607.689697265625\n",
      "Epoch: 2, Batch: 984, Loss: 2611.3046875\n",
      "Epoch: 2, Batch: 985, Loss: 2634.34765625\n",
      "Epoch: 2, Batch: 986, Loss: 2406.0703125\n",
      "Epoch: 2, Batch: 987, Loss: 2142.119140625\n",
      "Epoch: 2, Batch: 988, Loss: 2646.177490234375\n",
      "Epoch: 2, Batch: 989, Loss: 2643.5205078125\n",
      "Epoch: 2, Batch: 990, Loss: 2501.730712890625\n",
      "Epoch: 2, Batch: 991, Loss: 2852.640380859375\n",
      "Epoch: 2, Batch: 992, Loss: 2323.76513671875\n",
      "Epoch: 2, Batch: 993, Loss: 2659.96630859375\n",
      "Epoch: 2, Batch: 994, Loss: 2211.675048828125\n",
      "Epoch: 2, Batch: 995, Loss: 2177.16552734375\n",
      "Epoch: 2, Batch: 996, Loss: 2462.370361328125\n",
      "Epoch: 2, Batch: 997, Loss: 1501.802490234375\n",
      "Epoch: 2, Batch: 998, Loss: 2861.83056640625\n",
      "Epoch: 2, Batch: 999, Loss: 2385.682861328125\n",
      "Epoch: 3, Batch: 0, Loss: 2985.98583984375\n",
      "Epoch: 3, Batch: 1, Loss: 3153.0185546875\n",
      "Epoch: 3, Batch: 2, Loss: 2635.7021484375\n",
      "Epoch: 3, Batch: 3, Loss: 3138.022705078125\n",
      "Epoch: 3, Batch: 4, Loss: 2677.77099609375\n",
      "Epoch: 3, Batch: 5, Loss: 2726.751953125\n",
      "Epoch: 3, Batch: 6, Loss: 2633.2138671875\n",
      "Epoch: 3, Batch: 7, Loss: 2215.740966796875\n",
      "Epoch: 3, Batch: 8, Loss: 2722.53369140625\n",
      "Epoch: 3, Batch: 9, Loss: 2501.446533203125\n",
      "Epoch: 3, Batch: 10, Loss: 2353.607666015625\n",
      "Epoch: 3, Batch: 11, Loss: 2788.94384765625\n",
      "Epoch: 3, Batch: 12, Loss: 2299.307861328125\n",
      "Epoch: 3, Batch: 13, Loss: 2060.51025390625\n",
      "Epoch: 3, Batch: 14, Loss: 2600.10595703125\n",
      "Epoch: 3, Batch: 15, Loss: 2263.06689453125\n",
      "Epoch: 3, Batch: 16, Loss: 2533.971435546875\n",
      "Epoch: 3, Batch: 17, Loss: 3104.484375\n",
      "Epoch: 3, Batch: 18, Loss: 2148.990234375\n",
      "Epoch: 3, Batch: 19, Loss: 2849.841796875\n",
      "Epoch: 3, Batch: 20, Loss: 2540.383544921875\n",
      "Epoch: 3, Batch: 21, Loss: 3262.6015625\n",
      "Epoch: 3, Batch: 22, Loss: 2153.51953125\n",
      "Epoch: 3, Batch: 23, Loss: 2343.58447265625\n",
      "Epoch: 3, Batch: 24, Loss: 3089.1025390625\n",
      "Epoch: 3, Batch: 25, Loss: 2788.96044921875\n",
      "Epoch: 3, Batch: 26, Loss: 2545.463623046875\n",
      "Epoch: 3, Batch: 27, Loss: 2402.03076171875\n",
      "Epoch: 3, Batch: 28, Loss: 2817.551513671875\n",
      "Epoch: 3, Batch: 29, Loss: 2751.3037109375\n",
      "Epoch: 3, Batch: 30, Loss: 2656.836181640625\n",
      "Epoch: 3, Batch: 31, Loss: 1774.7095947265625\n",
      "Epoch: 3, Batch: 32, Loss: 2609.88037109375\n",
      "Epoch: 3, Batch: 33, Loss: 3227.611083984375\n",
      "Epoch: 3, Batch: 34, Loss: 2695.786865234375\n",
      "Epoch: 3, Batch: 35, Loss: 2413.733154296875\n",
      "Epoch: 3, Batch: 36, Loss: 2651.77783203125\n",
      "Epoch: 3, Batch: 37, Loss: 2242.424560546875\n",
      "Epoch: 3, Batch: 38, Loss: 2864.486328125\n",
      "Epoch: 3, Batch: 39, Loss: 2517.673095703125\n",
      "Epoch: 3, Batch: 40, Loss: 2520.90478515625\n",
      "Epoch: 3, Batch: 41, Loss: 2661.1826171875\n",
      "Epoch: 3, Batch: 42, Loss: 2855.5205078125\n",
      "Epoch: 3, Batch: 43, Loss: 3210.128173828125\n",
      "Epoch: 3, Batch: 44, Loss: 2173.12353515625\n",
      "Epoch: 3, Batch: 45, Loss: 2362.407470703125\n",
      "Epoch: 3, Batch: 46, Loss: 2492.531494140625\n",
      "Epoch: 3, Batch: 47, Loss: 2948.123291015625\n",
      "Epoch: 3, Batch: 48, Loss: 2655.017333984375\n",
      "Epoch: 3, Batch: 49, Loss: 2879.685546875\n",
      "Epoch: 3, Batch: 50, Loss: 2860.089599609375\n",
      "Epoch: 3, Batch: 51, Loss: 2735.600830078125\n",
      "Epoch: 3, Batch: 52, Loss: 2375.834228515625\n",
      "Epoch: 3, Batch: 53, Loss: 2864.471435546875\n",
      "Epoch: 3, Batch: 54, Loss: 3027.56982421875\n",
      "Epoch: 3, Batch: 55, Loss: 3184.584716796875\n",
      "Epoch: 3, Batch: 56, Loss: 2657.995849609375\n",
      "Epoch: 3, Batch: 57, Loss: 2750.069580078125\n",
      "Epoch: 3, Batch: 58, Loss: 2218.611083984375\n",
      "Epoch: 3, Batch: 59, Loss: 2625.458984375\n",
      "Epoch: 3, Batch: 60, Loss: 2891.47314453125\n",
      "Epoch: 3, Batch: 61, Loss: 2364.871337890625\n",
      "Epoch: 3, Batch: 62, Loss: 2982.513427734375\n",
      "Epoch: 3, Batch: 63, Loss: 2435.918212890625\n",
      "Epoch: 3, Batch: 64, Loss: 3040.685302734375\n",
      "Epoch: 3, Batch: 65, Loss: 3179.88671875\n",
      "Epoch: 3, Batch: 66, Loss: 2225.115234375\n",
      "Epoch: 3, Batch: 67, Loss: 2682.634765625\n",
      "Epoch: 3, Batch: 68, Loss: 2494.09375\n",
      "Epoch: 3, Batch: 69, Loss: 2681.86181640625\n",
      "Epoch: 3, Batch: 70, Loss: 2968.037353515625\n",
      "Epoch: 3, Batch: 71, Loss: 2499.95556640625\n",
      "Epoch: 3, Batch: 72, Loss: 2739.669921875\n",
      "Epoch: 3, Batch: 73, Loss: 3103.86962890625\n",
      "Epoch: 3, Batch: 74, Loss: 2508.58251953125\n",
      "Epoch: 3, Batch: 75, Loss: 2774.369140625\n",
      "Epoch: 3, Batch: 76, Loss: 2532.33984375\n",
      "Epoch: 3, Batch: 77, Loss: 2832.199951171875\n",
      "Epoch: 3, Batch: 78, Loss: 2474.895263671875\n",
      "Epoch: 3, Batch: 79, Loss: 2542.835693359375\n",
      "Epoch: 3, Batch: 80, Loss: 2685.96435546875\n",
      "Epoch: 3, Batch: 81, Loss: 2460.9599609375\n",
      "Epoch: 3, Batch: 82, Loss: 2642.1728515625\n",
      "Epoch: 3, Batch: 83, Loss: 2753.26416015625\n",
      "Epoch: 3, Batch: 84, Loss: 2386.75390625\n",
      "Epoch: 3, Batch: 85, Loss: 2504.2763671875\n",
      "Epoch: 3, Batch: 86, Loss: 2722.662109375\n",
      "Epoch: 3, Batch: 87, Loss: 2542.07470703125\n",
      "Epoch: 3, Batch: 88, Loss: 3051.17578125\n",
      "Epoch: 3, Batch: 89, Loss: 2557.545166015625\n",
      "Epoch: 3, Batch: 90, Loss: 2689.76123046875\n",
      "Epoch: 3, Batch: 91, Loss: 2884.066162109375\n",
      "Epoch: 3, Batch: 92, Loss: 2293.11181640625\n",
      "Epoch: 3, Batch: 93, Loss: 2064.7802734375\n",
      "Epoch: 3, Batch: 94, Loss: 3127.042236328125\n",
      "Epoch: 3, Batch: 95, Loss: 2891.7333984375\n",
      "Epoch: 3, Batch: 96, Loss: 3040.64794921875\n",
      "Epoch: 3, Batch: 97, Loss: 2468.122802734375\n",
      "Epoch: 3, Batch: 98, Loss: 2600.2578125\n",
      "Epoch: 3, Batch: 99, Loss: 2518.13916015625\n",
      "Epoch: 3, Batch: 100, Loss: 2719.42333984375\n",
      "Epoch: 3, Batch: 101, Loss: 2683.785888671875\n",
      "Epoch: 3, Batch: 102, Loss: 2988.7333984375\n",
      "Epoch: 3, Batch: 103, Loss: 2344.6044921875\n",
      "Epoch: 3, Batch: 104, Loss: 2169.4501953125\n",
      "Epoch: 3, Batch: 105, Loss: 1938.30859375\n",
      "Epoch: 3, Batch: 106, Loss: 2396.671875\n",
      "Epoch: 3, Batch: 107, Loss: 2440.706787109375\n",
      "Epoch: 3, Batch: 108, Loss: 2525.737548828125\n",
      "Epoch: 3, Batch: 109, Loss: 2559.0712890625\n",
      "Epoch: 3, Batch: 110, Loss: 1856.087646484375\n",
      "Epoch: 3, Batch: 111, Loss: 2779.1796875\n",
      "Epoch: 3, Batch: 112, Loss: 2664.72802734375\n",
      "Epoch: 3, Batch: 113, Loss: 2758.74609375\n",
      "Epoch: 3, Batch: 114, Loss: 2336.62109375\n",
      "Epoch: 3, Batch: 115, Loss: 2564.4296875\n",
      "Epoch: 3, Batch: 116, Loss: 2577.01806640625\n",
      "Epoch: 3, Batch: 117, Loss: 3020.9873046875\n",
      "Epoch: 3, Batch: 118, Loss: 2776.89501953125\n",
      "Epoch: 3, Batch: 119, Loss: 2371.199462890625\n",
      "Epoch: 3, Batch: 120, Loss: 3414.95654296875\n",
      "Epoch: 3, Batch: 121, Loss: 2431.05859375\n",
      "Epoch: 3, Batch: 122, Loss: 3065.35986328125\n",
      "Epoch: 3, Batch: 123, Loss: 2235.482421875\n",
      "Epoch: 3, Batch: 124, Loss: 3249.8193359375\n",
      "Epoch: 3, Batch: 125, Loss: 3218.28564453125\n",
      "Epoch: 3, Batch: 126, Loss: 3219.096923828125\n",
      "Epoch: 3, Batch: 127, Loss: 2265.056640625\n",
      "Epoch: 3, Batch: 128, Loss: 2435.89453125\n",
      "Epoch: 3, Batch: 129, Loss: 2564.289794921875\n",
      "Epoch: 3, Batch: 130, Loss: 2375.66455078125\n",
      "Epoch: 3, Batch: 131, Loss: 2184.602294921875\n",
      "Epoch: 3, Batch: 132, Loss: 2839.47119140625\n",
      "Epoch: 3, Batch: 133, Loss: 2483.548583984375\n",
      "Epoch: 3, Batch: 134, Loss: 2173.58544921875\n",
      "Epoch: 3, Batch: 135, Loss: 2737.174072265625\n",
      "Epoch: 3, Batch: 136, Loss: 2481.82470703125\n",
      "Epoch: 3, Batch: 137, Loss: 2931.45849609375\n",
      "Epoch: 3, Batch: 138, Loss: 2229.140625\n",
      "Epoch: 3, Batch: 139, Loss: 2744.350830078125\n",
      "Epoch: 3, Batch: 140, Loss: 2292.630126953125\n",
      "Epoch: 3, Batch: 141, Loss: 2690.3134765625\n",
      "Epoch: 3, Batch: 142, Loss: 2148.893310546875\n",
      "Epoch: 3, Batch: 143, Loss: 3095.236328125\n",
      "Epoch: 3, Batch: 144, Loss: 1772.25\n",
      "Epoch: 3, Batch: 145, Loss: 2392.10546875\n",
      "Epoch: 3, Batch: 146, Loss: 2492.946044921875\n",
      "Epoch: 3, Batch: 147, Loss: 2938.040771484375\n",
      "Epoch: 3, Batch: 148, Loss: 3186.14599609375\n",
      "Epoch: 3, Batch: 149, Loss: 2263.382568359375\n",
      "Epoch: 3, Batch: 150, Loss: 2498.392333984375\n",
      "Epoch: 3, Batch: 151, Loss: 2850.05419921875\n",
      "Epoch: 3, Batch: 152, Loss: 2825.734619140625\n",
      "Epoch: 3, Batch: 153, Loss: 2042.78173828125\n",
      "Epoch: 3, Batch: 154, Loss: 2095.80712890625\n",
      "Epoch: 3, Batch: 155, Loss: 2538.99609375\n",
      "Epoch: 3, Batch: 156, Loss: 2082.86328125\n",
      "Epoch: 3, Batch: 157, Loss: 2735.254638671875\n",
      "Epoch: 3, Batch: 158, Loss: 2571.287109375\n",
      "Epoch: 3, Batch: 159, Loss: 2971.46875\n",
      "Epoch: 3, Batch: 160, Loss: 2695.3154296875\n",
      "Epoch: 3, Batch: 161, Loss: 2721.87353515625\n",
      "Epoch: 3, Batch: 162, Loss: 2793.906005859375\n",
      "Epoch: 3, Batch: 163, Loss: 2719.95556640625\n",
      "Epoch: 3, Batch: 164, Loss: 2669.46728515625\n",
      "Epoch: 3, Batch: 165, Loss: 2763.079833984375\n",
      "Epoch: 3, Batch: 166, Loss: 2687.782958984375\n",
      "Epoch: 3, Batch: 167, Loss: 2775.1611328125\n",
      "Epoch: 3, Batch: 168, Loss: 2811.6767578125\n",
      "Epoch: 3, Batch: 169, Loss: 2339.4404296875\n",
      "Epoch: 3, Batch: 170, Loss: 2358.3369140625\n",
      "Epoch: 3, Batch: 171, Loss: 2378.17236328125\n",
      "Epoch: 3, Batch: 172, Loss: 2537.263427734375\n",
      "Epoch: 3, Batch: 173, Loss: 2556.000732421875\n",
      "Epoch: 3, Batch: 174, Loss: 2850.582763671875\n",
      "Epoch: 3, Batch: 175, Loss: 2748.635986328125\n",
      "Epoch: 3, Batch: 176, Loss: 2707.857666015625\n",
      "Epoch: 3, Batch: 177, Loss: 2424.264892578125\n",
      "Epoch: 3, Batch: 178, Loss: 2677.650146484375\n",
      "Epoch: 3, Batch: 179, Loss: 2880.552734375\n",
      "Epoch: 3, Batch: 180, Loss: 2645.673095703125\n",
      "Epoch: 3, Batch: 181, Loss: 3427.012939453125\n",
      "Epoch: 3, Batch: 182, Loss: 2464.703857421875\n",
      "Epoch: 3, Batch: 183, Loss: 2252.2099609375\n",
      "Epoch: 3, Batch: 184, Loss: 2297.56005859375\n",
      "Epoch: 3, Batch: 185, Loss: 2835.283935546875\n",
      "Epoch: 3, Batch: 186, Loss: 2282.881591796875\n",
      "Epoch: 3, Batch: 187, Loss: 2886.446533203125\n",
      "Epoch: 3, Batch: 188, Loss: 3276.34423828125\n",
      "Epoch: 3, Batch: 189, Loss: 2785.177490234375\n",
      "Epoch: 3, Batch: 190, Loss: 2283.177490234375\n",
      "Epoch: 3, Batch: 191, Loss: 2410.01171875\n",
      "Epoch: 3, Batch: 192, Loss: 2243.513916015625\n",
      "Epoch: 3, Batch: 193, Loss: 2851.740478515625\n",
      "Epoch: 3, Batch: 194, Loss: 2512.725341796875\n",
      "Epoch: 3, Batch: 195, Loss: 2280.943603515625\n",
      "Epoch: 3, Batch: 196, Loss: 2158.686767578125\n",
      "Epoch: 3, Batch: 197, Loss: 2390.02392578125\n",
      "Epoch: 3, Batch: 198, Loss: 2937.166259765625\n",
      "Epoch: 3, Batch: 199, Loss: 2564.066650390625\n",
      "Epoch: 3, Batch: 200, Loss: 2591.772216796875\n",
      "Epoch: 3, Batch: 201, Loss: 2984.12744140625\n",
      "Epoch: 3, Batch: 202, Loss: 2663.46923828125\n",
      "Epoch: 3, Batch: 203, Loss: 2022.6402587890625\n",
      "Epoch: 3, Batch: 204, Loss: 2090.81884765625\n",
      "Epoch: 3, Batch: 205, Loss: 2528.98974609375\n",
      "Epoch: 3, Batch: 206, Loss: 2719.157958984375\n",
      "Epoch: 3, Batch: 207, Loss: 2645.40087890625\n",
      "Epoch: 3, Batch: 208, Loss: 2530.133056640625\n",
      "Epoch: 3, Batch: 209, Loss: 2606.72314453125\n",
      "Epoch: 3, Batch: 210, Loss: 2498.126953125\n",
      "Epoch: 3, Batch: 211, Loss: 3109.745361328125\n",
      "Epoch: 3, Batch: 212, Loss: 2659.76806640625\n",
      "Epoch: 3, Batch: 213, Loss: 3096.935546875\n",
      "Epoch: 3, Batch: 214, Loss: 2165.644287109375\n",
      "Epoch: 3, Batch: 215, Loss: 2903.150390625\n",
      "Epoch: 3, Batch: 216, Loss: 2932.587890625\n",
      "Epoch: 3, Batch: 217, Loss: 2815.05029296875\n",
      "Epoch: 3, Batch: 218, Loss: 2760.333251953125\n",
      "Epoch: 3, Batch: 219, Loss: 2277.8583984375\n",
      "Epoch: 3, Batch: 220, Loss: 2403.3203125\n",
      "Epoch: 3, Batch: 221, Loss: 2754.41845703125\n",
      "Epoch: 3, Batch: 222, Loss: 2360.745849609375\n",
      "Epoch: 3, Batch: 223, Loss: 3040.385498046875\n",
      "Epoch: 3, Batch: 224, Loss: 2799.391845703125\n",
      "Epoch: 3, Batch: 225, Loss: 2398.386474609375\n",
      "Epoch: 3, Batch: 226, Loss: 2798.27099609375\n",
      "Epoch: 3, Batch: 227, Loss: 2682.19140625\n",
      "Epoch: 3, Batch: 228, Loss: 2833.002685546875\n",
      "Epoch: 3, Batch: 229, Loss: 2490.85009765625\n",
      "Epoch: 3, Batch: 230, Loss: 2963.93212890625\n",
      "Epoch: 3, Batch: 231, Loss: 2894.22412109375\n",
      "Epoch: 3, Batch: 232, Loss: 2637.433349609375\n",
      "Epoch: 3, Batch: 233, Loss: 2776.735595703125\n",
      "Epoch: 3, Batch: 234, Loss: 2701.083984375\n",
      "Epoch: 3, Batch: 235, Loss: 2362.113037109375\n",
      "Epoch: 3, Batch: 236, Loss: 2273.681640625\n",
      "Epoch: 3, Batch: 237, Loss: 2067.546875\n",
      "Epoch: 3, Batch: 238, Loss: 2477.049560546875\n",
      "Epoch: 3, Batch: 239, Loss: 2652.35791015625\n",
      "Epoch: 3, Batch: 240, Loss: 2789.30810546875\n",
      "Epoch: 3, Batch: 241, Loss: 2541.590087890625\n",
      "Epoch: 3, Batch: 242, Loss: 2661.085693359375\n",
      "Epoch: 3, Batch: 243, Loss: 2995.808349609375\n",
      "Epoch: 3, Batch: 244, Loss: 2215.18896484375\n",
      "Epoch: 3, Batch: 245, Loss: 2584.63427734375\n",
      "Epoch: 3, Batch: 246, Loss: 2781.0576171875\n",
      "Epoch: 3, Batch: 247, Loss: 3052.463623046875\n",
      "Epoch: 3, Batch: 248, Loss: 2381.539794921875\n",
      "Epoch: 3, Batch: 249, Loss: 2811.958984375\n",
      "Epoch: 3, Batch: 250, Loss: 2538.19970703125\n",
      "Epoch: 3, Batch: 251, Loss: 2366.491455078125\n",
      "Epoch: 3, Batch: 252, Loss: 2888.5615234375\n",
      "Epoch: 3, Batch: 253, Loss: 2868.7861328125\n",
      "Epoch: 3, Batch: 254, Loss: 1963.4007568359375\n",
      "Epoch: 3, Batch: 255, Loss: 2566.578125\n",
      "Epoch: 3, Batch: 256, Loss: 2429.2978515625\n",
      "Epoch: 3, Batch: 257, Loss: 2531.060546875\n",
      "Epoch: 3, Batch: 258, Loss: 2672.7783203125\n",
      "Epoch: 3, Batch: 259, Loss: 2205.05615234375\n",
      "Epoch: 3, Batch: 260, Loss: 2881.83544921875\n",
      "Epoch: 3, Batch: 261, Loss: 2892.673095703125\n",
      "Epoch: 3, Batch: 262, Loss: 2808.6455078125\n",
      "Epoch: 3, Batch: 263, Loss: 2714.650146484375\n",
      "Epoch: 3, Batch: 264, Loss: 2739.76611328125\n",
      "Epoch: 3, Batch: 265, Loss: 2386.24609375\n",
      "Epoch: 3, Batch: 266, Loss: 2706.91552734375\n",
      "Epoch: 3, Batch: 267, Loss: 2725.60498046875\n",
      "Epoch: 3, Batch: 268, Loss: 2268.31591796875\n",
      "Epoch: 3, Batch: 269, Loss: 2401.821533203125\n",
      "Epoch: 3, Batch: 270, Loss: 2427.907470703125\n",
      "Epoch: 3, Batch: 271, Loss: 2434.1708984375\n",
      "Epoch: 3, Batch: 272, Loss: 2665.42138671875\n",
      "Epoch: 3, Batch: 273, Loss: 2839.682861328125\n",
      "Epoch: 3, Batch: 274, Loss: 3124.83349609375\n",
      "Epoch: 3, Batch: 275, Loss: 2451.31494140625\n",
      "Epoch: 3, Batch: 276, Loss: 3254.502685546875\n",
      "Epoch: 3, Batch: 277, Loss: 2849.4609375\n",
      "Epoch: 3, Batch: 278, Loss: 2602.14404296875\n",
      "Epoch: 3, Batch: 279, Loss: 2076.19775390625\n",
      "Epoch: 3, Batch: 280, Loss: 2994.8603515625\n",
      "Epoch: 3, Batch: 281, Loss: 3179.137451171875\n",
      "Epoch: 3, Batch: 282, Loss: 2828.185791015625\n",
      "Epoch: 3, Batch: 283, Loss: 2971.943115234375\n",
      "Epoch: 3, Batch: 284, Loss: 2781.80517578125\n",
      "Epoch: 3, Batch: 285, Loss: 2661.476318359375\n",
      "Epoch: 3, Batch: 286, Loss: 2747.091552734375\n",
      "Epoch: 3, Batch: 287, Loss: 2897.319091796875\n",
      "Epoch: 3, Batch: 288, Loss: 2464.92236328125\n",
      "Epoch: 3, Batch: 289, Loss: 3076.58251953125\n",
      "Epoch: 3, Batch: 290, Loss: 1948.2928466796875\n",
      "Epoch: 3, Batch: 291, Loss: 2316.1650390625\n",
      "Epoch: 3, Batch: 292, Loss: 2954.9560546875\n",
      "Epoch: 3, Batch: 293, Loss: 2459.38916015625\n",
      "Epoch: 3, Batch: 294, Loss: 2283.768310546875\n",
      "Epoch: 3, Batch: 295, Loss: 2638.73876953125\n",
      "Epoch: 3, Batch: 296, Loss: 3077.964111328125\n",
      "Epoch: 3, Batch: 297, Loss: 2669.91455078125\n",
      "Epoch: 3, Batch: 298, Loss: 2875.705078125\n",
      "Epoch: 3, Batch: 299, Loss: 3325.809814453125\n",
      "Epoch: 3, Batch: 300, Loss: 2809.95068359375\n",
      "Epoch: 3, Batch: 301, Loss: 2761.41259765625\n",
      "Epoch: 3, Batch: 302, Loss: 2135.437255859375\n",
      "Epoch: 3, Batch: 303, Loss: 2331.30126953125\n",
      "Epoch: 3, Batch: 304, Loss: 2829.015869140625\n",
      "Epoch: 3, Batch: 305, Loss: 2410.01220703125\n",
      "Epoch: 3, Batch: 306, Loss: 2862.2216796875\n",
      "Epoch: 3, Batch: 307, Loss: 2191.25830078125\n",
      "Epoch: 3, Batch: 308, Loss: 2752.52880859375\n",
      "Epoch: 3, Batch: 309, Loss: 2530.854736328125\n",
      "Epoch: 3, Batch: 310, Loss: 3288.916259765625\n",
      "Epoch: 3, Batch: 311, Loss: 2742.994384765625\n",
      "Epoch: 3, Batch: 312, Loss: 2871.544921875\n",
      "Epoch: 3, Batch: 313, Loss: 2359.52587890625\n",
      "Epoch: 3, Batch: 314, Loss: 2223.372802734375\n",
      "Epoch: 3, Batch: 315, Loss: 2662.017822265625\n",
      "Epoch: 3, Batch: 316, Loss: 2870.433349609375\n",
      "Epoch: 3, Batch: 317, Loss: 2684.59814453125\n",
      "Epoch: 3, Batch: 318, Loss: 2726.1865234375\n",
      "Epoch: 3, Batch: 319, Loss: 2464.906982421875\n",
      "Epoch: 3, Batch: 320, Loss: 2610.66162109375\n",
      "Epoch: 3, Batch: 321, Loss: 2604.319091796875\n",
      "Epoch: 3, Batch: 322, Loss: 2303.447021484375\n",
      "Epoch: 3, Batch: 323, Loss: 2968.67529296875\n",
      "Epoch: 3, Batch: 324, Loss: 2365.945556640625\n",
      "Epoch: 3, Batch: 325, Loss: 2196.67236328125\n",
      "Epoch: 3, Batch: 326, Loss: 2128.399658203125\n",
      "Epoch: 3, Batch: 327, Loss: 2215.368408203125\n",
      "Epoch: 3, Batch: 328, Loss: 3105.26318359375\n",
      "Epoch: 3, Batch: 329, Loss: 2484.7138671875\n",
      "Epoch: 3, Batch: 330, Loss: 2646.67578125\n",
      "Epoch: 3, Batch: 331, Loss: 3099.849609375\n",
      "Epoch: 3, Batch: 332, Loss: 2595.425537109375\n",
      "Epoch: 3, Batch: 333, Loss: 2350.011474609375\n",
      "Epoch: 3, Batch: 334, Loss: 2149.011474609375\n",
      "Epoch: 3, Batch: 335, Loss: 2825.5087890625\n",
      "Epoch: 3, Batch: 336, Loss: 2962.6220703125\n",
      "Epoch: 3, Batch: 337, Loss: 2951.69189453125\n",
      "Epoch: 3, Batch: 338, Loss: 3217.14599609375\n",
      "Epoch: 3, Batch: 339, Loss: 2588.942626953125\n",
      "Epoch: 3, Batch: 340, Loss: 2191.805419921875\n",
      "Epoch: 3, Batch: 341, Loss: 2877.712158203125\n",
      "Epoch: 3, Batch: 342, Loss: 2578.392578125\n",
      "Epoch: 3, Batch: 343, Loss: 2986.41015625\n",
      "Epoch: 3, Batch: 344, Loss: 2403.220947265625\n",
      "Epoch: 3, Batch: 345, Loss: 2539.56103515625\n",
      "Epoch: 3, Batch: 346, Loss: 2384.50732421875\n",
      "Epoch: 3, Batch: 347, Loss: 1917.070556640625\n",
      "Epoch: 3, Batch: 348, Loss: 2417.693115234375\n",
      "Epoch: 3, Batch: 349, Loss: 3156.824462890625\n",
      "Epoch: 3, Batch: 350, Loss: 3230.098876953125\n",
      "Epoch: 3, Batch: 351, Loss: 2812.9990234375\n",
      "Epoch: 3, Batch: 352, Loss: 2517.910400390625\n",
      "Epoch: 3, Batch: 353, Loss: 2773.9130859375\n",
      "Epoch: 3, Batch: 354, Loss: 2433.72607421875\n",
      "Epoch: 3, Batch: 355, Loss: 2685.692138671875\n",
      "Epoch: 3, Batch: 356, Loss: 2675.60791015625\n",
      "Epoch: 3, Batch: 357, Loss: 2848.419677734375\n",
      "Epoch: 3, Batch: 358, Loss: 2203.02294921875\n",
      "Epoch: 3, Batch: 359, Loss: 2847.685302734375\n",
      "Epoch: 3, Batch: 360, Loss: 2672.05224609375\n",
      "Epoch: 3, Batch: 361, Loss: 2609.806884765625\n",
      "Epoch: 3, Batch: 362, Loss: 2531.99072265625\n",
      "Epoch: 3, Batch: 363, Loss: 2208.23046875\n",
      "Epoch: 3, Batch: 364, Loss: 2888.975830078125\n",
      "Epoch: 3, Batch: 365, Loss: 2336.53515625\n",
      "Epoch: 3, Batch: 366, Loss: 1826.61669921875\n",
      "Epoch: 3, Batch: 367, Loss: 2943.806396484375\n",
      "Epoch: 3, Batch: 368, Loss: 2943.267578125\n",
      "Epoch: 3, Batch: 369, Loss: 2784.28369140625\n",
      "Epoch: 3, Batch: 370, Loss: 2574.3720703125\n",
      "Epoch: 3, Batch: 371, Loss: 2229.13818359375\n",
      "Epoch: 3, Batch: 372, Loss: 2549.49609375\n",
      "Epoch: 3, Batch: 373, Loss: 1811.4033203125\n",
      "Epoch: 3, Batch: 374, Loss: 2350.628173828125\n",
      "Epoch: 3, Batch: 375, Loss: 2459.155029296875\n",
      "Epoch: 3, Batch: 376, Loss: 2787.509521484375\n",
      "Epoch: 3, Batch: 377, Loss: 2743.72705078125\n",
      "Epoch: 3, Batch: 378, Loss: 2313.506591796875\n",
      "Epoch: 3, Batch: 379, Loss: 3275.180908203125\n",
      "Epoch: 3, Batch: 380, Loss: 3127.248291015625\n",
      "Epoch: 3, Batch: 381, Loss: 2073.610595703125\n",
      "Epoch: 3, Batch: 382, Loss: 2320.272216796875\n",
      "Epoch: 3, Batch: 383, Loss: 2316.09423828125\n",
      "Epoch: 3, Batch: 384, Loss: 2987.271728515625\n",
      "Epoch: 3, Batch: 385, Loss: 2701.26318359375\n",
      "Epoch: 3, Batch: 386, Loss: 2866.979736328125\n",
      "Epoch: 3, Batch: 387, Loss: 2636.95947265625\n",
      "Epoch: 3, Batch: 388, Loss: 2398.6328125\n",
      "Epoch: 3, Batch: 389, Loss: 2746.552001953125\n",
      "Epoch: 3, Batch: 390, Loss: 2349.7275390625\n",
      "Epoch: 3, Batch: 391, Loss: 2305.09228515625\n",
      "Epoch: 3, Batch: 392, Loss: 2842.524169921875\n",
      "Epoch: 3, Batch: 393, Loss: 2280.85400390625\n",
      "Epoch: 3, Batch: 394, Loss: 2667.731201171875\n",
      "Epoch: 3, Batch: 395, Loss: 2660.83544921875\n",
      "Epoch: 3, Batch: 396, Loss: 2479.223388671875\n",
      "Epoch: 3, Batch: 397, Loss: 2450.4921875\n",
      "Epoch: 3, Batch: 398, Loss: 3154.9248046875\n",
      "Epoch: 3, Batch: 399, Loss: 2819.041259765625\n",
      "Epoch: 3, Batch: 400, Loss: 2542.847412109375\n",
      "Epoch: 3, Batch: 401, Loss: 2542.706298828125\n",
      "Epoch: 3, Batch: 402, Loss: 2727.848388671875\n",
      "Epoch: 3, Batch: 403, Loss: 3004.518798828125\n",
      "Epoch: 3, Batch: 404, Loss: 3474.347900390625\n",
      "Epoch: 3, Batch: 405, Loss: 2304.39697265625\n",
      "Epoch: 3, Batch: 406, Loss: 2292.051025390625\n",
      "Epoch: 3, Batch: 407, Loss: 2705.6767578125\n",
      "Epoch: 3, Batch: 408, Loss: 3450.962158203125\n",
      "Epoch: 3, Batch: 409, Loss: 2938.492431640625\n",
      "Epoch: 3, Batch: 410, Loss: 2555.72314453125\n",
      "Epoch: 3, Batch: 411, Loss: 2542.218017578125\n",
      "Epoch: 3, Batch: 412, Loss: 2378.994873046875\n",
      "Epoch: 3, Batch: 413, Loss: 2412.384521484375\n",
      "Epoch: 3, Batch: 414, Loss: 2525.023681640625\n",
      "Epoch: 3, Batch: 415, Loss: 2716.79541015625\n",
      "Epoch: 3, Batch: 416, Loss: 1957.5343017578125\n",
      "Epoch: 3, Batch: 417, Loss: 2432.60107421875\n",
      "Epoch: 3, Batch: 418, Loss: 2591.365478515625\n",
      "Epoch: 3, Batch: 419, Loss: 2172.966796875\n",
      "Epoch: 3, Batch: 420, Loss: 2375.255615234375\n",
      "Epoch: 3, Batch: 421, Loss: 2192.921142578125\n",
      "Epoch: 3, Batch: 422, Loss: 2702.6123046875\n",
      "Epoch: 3, Batch: 423, Loss: 3462.871826171875\n",
      "Epoch: 3, Batch: 424, Loss: 2812.473388671875\n",
      "Epoch: 3, Batch: 425, Loss: 2982.57080078125\n",
      "Epoch: 3, Batch: 426, Loss: 2599.917236328125\n",
      "Epoch: 3, Batch: 427, Loss: 2892.009521484375\n",
      "Epoch: 3, Batch: 428, Loss: 3390.808837890625\n",
      "Epoch: 3, Batch: 429, Loss: 2313.615234375\n",
      "Epoch: 3, Batch: 430, Loss: 2775.2431640625\n",
      "Epoch: 3, Batch: 431, Loss: 3072.095947265625\n",
      "Epoch: 3, Batch: 432, Loss: 2554.366943359375\n",
      "Epoch: 3, Batch: 433, Loss: 2311.387939453125\n",
      "Epoch: 3, Batch: 434, Loss: 2101.00537109375\n",
      "Epoch: 3, Batch: 435, Loss: 2234.71240234375\n",
      "Epoch: 3, Batch: 436, Loss: 2524.090087890625\n",
      "Epoch: 3, Batch: 437, Loss: 3187.801025390625\n",
      "Epoch: 3, Batch: 438, Loss: 2372.350341796875\n",
      "Epoch: 3, Batch: 439, Loss: 2303.234130859375\n",
      "Epoch: 3, Batch: 440, Loss: 3469.17041015625\n",
      "Epoch: 3, Batch: 441, Loss: 2738.22265625\n",
      "Epoch: 3, Batch: 442, Loss: 2467.625244140625\n",
      "Epoch: 3, Batch: 443, Loss: 2566.492919921875\n",
      "Epoch: 3, Batch: 444, Loss: 2925.694580078125\n",
      "Epoch: 3, Batch: 445, Loss: 2733.79833984375\n",
      "Epoch: 3, Batch: 446, Loss: 2386.85888671875\n",
      "Epoch: 3, Batch: 447, Loss: 2960.704345703125\n",
      "Epoch: 3, Batch: 448, Loss: 2246.33154296875\n",
      "Epoch: 3, Batch: 449, Loss: 3776.17919921875\n",
      "Epoch: 3, Batch: 450, Loss: 2709.82568359375\n",
      "Epoch: 3, Batch: 451, Loss: 2955.094482421875\n",
      "Epoch: 3, Batch: 452, Loss: 3038.454345703125\n",
      "Epoch: 3, Batch: 453, Loss: 2490.474853515625\n",
      "Epoch: 3, Batch: 454, Loss: 3018.972900390625\n",
      "Epoch: 3, Batch: 455, Loss: 2736.10107421875\n",
      "Epoch: 3, Batch: 456, Loss: 2410.12109375\n",
      "Epoch: 3, Batch: 457, Loss: 2451.606689453125\n",
      "Epoch: 3, Batch: 458, Loss: 2440.17529296875\n",
      "Epoch: 3, Batch: 459, Loss: 3184.29833984375\n",
      "Epoch: 3, Batch: 460, Loss: 3536.955810546875\n",
      "Epoch: 3, Batch: 461, Loss: 2629.17041015625\n",
      "Epoch: 3, Batch: 462, Loss: 2742.928955078125\n",
      "Epoch: 3, Batch: 463, Loss: 2416.238037109375\n",
      "Epoch: 3, Batch: 464, Loss: 2519.464599609375\n",
      "Epoch: 3, Batch: 465, Loss: 2337.81298828125\n",
      "Epoch: 3, Batch: 466, Loss: 2624.452392578125\n",
      "Epoch: 3, Batch: 467, Loss: 2412.224853515625\n",
      "Epoch: 3, Batch: 468, Loss: 2639.23486328125\n",
      "Epoch: 3, Batch: 469, Loss: 2837.164794921875\n",
      "Epoch: 3, Batch: 470, Loss: 2370.0166015625\n",
      "Epoch: 3, Batch: 471, Loss: 2851.16357421875\n",
      "Epoch: 3, Batch: 472, Loss: 2657.011474609375\n",
      "Epoch: 3, Batch: 473, Loss: 2333.676025390625\n",
      "Epoch: 3, Batch: 474, Loss: 2797.850830078125\n",
      "Epoch: 3, Batch: 475, Loss: 2967.935791015625\n",
      "Epoch: 3, Batch: 476, Loss: 2767.302001953125\n",
      "Epoch: 3, Batch: 477, Loss: 2370.254638671875\n",
      "Epoch: 3, Batch: 478, Loss: 2556.928466796875\n",
      "Epoch: 3, Batch: 479, Loss: 2650.5966796875\n",
      "Epoch: 3, Batch: 480, Loss: 2345.20556640625\n",
      "Epoch: 3, Batch: 481, Loss: 2795.606689453125\n",
      "Epoch: 3, Batch: 482, Loss: 2013.5511474609375\n",
      "Epoch: 3, Batch: 483, Loss: 2346.168701171875\n",
      "Epoch: 3, Batch: 484, Loss: 2969.26904296875\n",
      "Epoch: 3, Batch: 485, Loss: 2436.038818359375\n",
      "Epoch: 3, Batch: 486, Loss: 2489.840576171875\n",
      "Epoch: 3, Batch: 487, Loss: 2593.328369140625\n",
      "Epoch: 3, Batch: 488, Loss: 2973.38037109375\n",
      "Epoch: 3, Batch: 489, Loss: 2694.07470703125\n",
      "Epoch: 3, Batch: 490, Loss: 2073.52099609375\n",
      "Epoch: 3, Batch: 491, Loss: 2926.637939453125\n",
      "Epoch: 3, Batch: 492, Loss: 2539.494873046875\n",
      "Epoch: 3, Batch: 493, Loss: 2126.715576171875\n",
      "Epoch: 3, Batch: 494, Loss: 2556.862060546875\n",
      "Epoch: 3, Batch: 495, Loss: 2407.15234375\n",
      "Epoch: 3, Batch: 496, Loss: 2735.54150390625\n",
      "Epoch: 3, Batch: 497, Loss: 2516.55859375\n",
      "Epoch: 3, Batch: 498, Loss: 1851.6624755859375\n",
      "Epoch: 3, Batch: 499, Loss: 2661.739501953125\n",
      "Epoch: 3, Batch: 500, Loss: 2773.4951171875\n",
      "Epoch: 3, Batch: 501, Loss: 3076.4638671875\n",
      "Epoch: 3, Batch: 502, Loss: 2611.842041015625\n",
      "Epoch: 3, Batch: 503, Loss: 2122.584228515625\n",
      "Epoch: 3, Batch: 504, Loss: 2167.103515625\n",
      "Epoch: 3, Batch: 505, Loss: 2352.07568359375\n",
      "Epoch: 3, Batch: 506, Loss: 2805.78271484375\n",
      "Epoch: 3, Batch: 507, Loss: 2910.73095703125\n",
      "Epoch: 3, Batch: 508, Loss: 2563.645751953125\n",
      "Epoch: 3, Batch: 509, Loss: 3022.611328125\n",
      "Epoch: 3, Batch: 510, Loss: 2211.787109375\n",
      "Epoch: 3, Batch: 511, Loss: 2284.1201171875\n",
      "Epoch: 3, Batch: 512, Loss: 2697.715576171875\n",
      "Epoch: 3, Batch: 513, Loss: 2142.93310546875\n",
      "Epoch: 3, Batch: 514, Loss: 2938.5224609375\n",
      "Epoch: 3, Batch: 515, Loss: 2858.015380859375\n",
      "Epoch: 3, Batch: 516, Loss: 2534.53173828125\n",
      "Epoch: 3, Batch: 517, Loss: 2629.749755859375\n",
      "Epoch: 3, Batch: 518, Loss: 2649.395263671875\n",
      "Epoch: 3, Batch: 519, Loss: 2892.787841796875\n",
      "Epoch: 3, Batch: 520, Loss: 3110.879638671875\n",
      "Epoch: 3, Batch: 521, Loss: 2217.973388671875\n",
      "Epoch: 3, Batch: 522, Loss: 2930.08984375\n",
      "Epoch: 3, Batch: 523, Loss: 2819.72607421875\n",
      "Epoch: 3, Batch: 524, Loss: 2381.541259765625\n",
      "Epoch: 3, Batch: 525, Loss: 2577.537109375\n",
      "Epoch: 3, Batch: 526, Loss: 2212.84521484375\n",
      "Epoch: 3, Batch: 527, Loss: 2768.74462890625\n",
      "Epoch: 3, Batch: 528, Loss: 3186.990478515625\n",
      "Epoch: 3, Batch: 529, Loss: 2565.626708984375\n",
      "Epoch: 3, Batch: 530, Loss: 2631.993896484375\n",
      "Epoch: 3, Batch: 531, Loss: 2558.12353515625\n",
      "Epoch: 3, Batch: 532, Loss: 2924.109375\n",
      "Epoch: 3, Batch: 533, Loss: 2420.810791015625\n",
      "Epoch: 3, Batch: 534, Loss: 2504.144287109375\n",
      "Epoch: 3, Batch: 535, Loss: 2399.915771484375\n",
      "Epoch: 3, Batch: 536, Loss: 2790.869140625\n",
      "Epoch: 3, Batch: 537, Loss: 2568.939697265625\n",
      "Epoch: 3, Batch: 538, Loss: 2791.435791015625\n",
      "Epoch: 3, Batch: 539, Loss: 3074.026611328125\n",
      "Epoch: 3, Batch: 540, Loss: 2396.510986328125\n",
      "Epoch: 3, Batch: 541, Loss: 2529.00830078125\n",
      "Epoch: 3, Batch: 542, Loss: 3041.965576171875\n",
      "Epoch: 3, Batch: 543, Loss: 2486.962890625\n",
      "Epoch: 3, Batch: 544, Loss: 3010.12744140625\n",
      "Epoch: 3, Batch: 545, Loss: 2358.039794921875\n",
      "Epoch: 3, Batch: 546, Loss: 2662.2275390625\n",
      "Epoch: 3, Batch: 547, Loss: 2357.148193359375\n",
      "Epoch: 3, Batch: 548, Loss: 2652.510009765625\n",
      "Epoch: 3, Batch: 549, Loss: 2830.1083984375\n",
      "Epoch: 3, Batch: 550, Loss: 2344.970947265625\n",
      "Epoch: 3, Batch: 551, Loss: 2526.703857421875\n",
      "Epoch: 3, Batch: 552, Loss: 3313.728271484375\n",
      "Epoch: 3, Batch: 553, Loss: 2202.11181640625\n",
      "Epoch: 3, Batch: 554, Loss: 3076.068359375\n",
      "Epoch: 3, Batch: 555, Loss: 3137.335693359375\n",
      "Epoch: 3, Batch: 556, Loss: 2820.373779296875\n",
      "Epoch: 3, Batch: 557, Loss: 2712.056396484375\n",
      "Epoch: 3, Batch: 558, Loss: 2647.152099609375\n",
      "Epoch: 3, Batch: 559, Loss: 2621.2021484375\n",
      "Epoch: 3, Batch: 560, Loss: 2233.55712890625\n",
      "Epoch: 3, Batch: 561, Loss: 2806.7314453125\n",
      "Epoch: 3, Batch: 562, Loss: 2556.14990234375\n",
      "Epoch: 3, Batch: 563, Loss: 2484.74072265625\n",
      "Epoch: 3, Batch: 564, Loss: 2468.62353515625\n",
      "Epoch: 3, Batch: 565, Loss: 3003.218994140625\n",
      "Epoch: 3, Batch: 566, Loss: 2379.76416015625\n",
      "Epoch: 3, Batch: 567, Loss: 2482.5830078125\n",
      "Epoch: 3, Batch: 568, Loss: 2444.726318359375\n",
      "Epoch: 3, Batch: 569, Loss: 2952.52001953125\n",
      "Epoch: 3, Batch: 570, Loss: 2480.238037109375\n",
      "Epoch: 3, Batch: 571, Loss: 2526.614990234375\n",
      "Epoch: 3, Batch: 572, Loss: 3022.4306640625\n",
      "Epoch: 3, Batch: 573, Loss: 2735.31298828125\n",
      "Epoch: 3, Batch: 574, Loss: 3110.5654296875\n",
      "Epoch: 3, Batch: 575, Loss: 3205.145263671875\n",
      "Epoch: 3, Batch: 576, Loss: 2661.630615234375\n",
      "Epoch: 3, Batch: 577, Loss: 3284.384033203125\n",
      "Epoch: 3, Batch: 578, Loss: 2030.1009521484375\n",
      "Epoch: 3, Batch: 579, Loss: 2797.890625\n",
      "Epoch: 3, Batch: 580, Loss: 3158.1142578125\n",
      "Epoch: 3, Batch: 581, Loss: 2805.95947265625\n",
      "Epoch: 3, Batch: 582, Loss: 2695.683349609375\n",
      "Epoch: 3, Batch: 583, Loss: 2900.2431640625\n",
      "Epoch: 3, Batch: 584, Loss: 2573.62744140625\n",
      "Epoch: 3, Batch: 585, Loss: 2815.94287109375\n",
      "Epoch: 3, Batch: 586, Loss: 2698.7333984375\n",
      "Epoch: 3, Batch: 587, Loss: 2408.361328125\n",
      "Epoch: 3, Batch: 588, Loss: 2541.5693359375\n",
      "Epoch: 3, Batch: 589, Loss: 2772.559814453125\n",
      "Epoch: 3, Batch: 590, Loss: 2593.08251953125\n",
      "Epoch: 3, Batch: 591, Loss: 2655.302001953125\n",
      "Epoch: 3, Batch: 592, Loss: 2636.334716796875\n",
      "Epoch: 3, Batch: 593, Loss: 2316.53759765625\n",
      "Epoch: 3, Batch: 594, Loss: 2184.733154296875\n",
      "Epoch: 3, Batch: 595, Loss: 2178.052978515625\n",
      "Epoch: 3, Batch: 596, Loss: 2670.390869140625\n",
      "Epoch: 3, Batch: 597, Loss: 2562.776123046875\n",
      "Epoch: 3, Batch: 598, Loss: 2047.084716796875\n",
      "Epoch: 3, Batch: 599, Loss: 3004.80419921875\n",
      "Epoch: 3, Batch: 600, Loss: 2873.039794921875\n",
      "Epoch: 3, Batch: 601, Loss: 2550.83740234375\n",
      "Epoch: 3, Batch: 602, Loss: 2565.602294921875\n",
      "Epoch: 3, Batch: 603, Loss: 2841.46142578125\n",
      "Epoch: 3, Batch: 604, Loss: 2342.072998046875\n",
      "Epoch: 3, Batch: 605, Loss: 3145.154052734375\n",
      "Epoch: 3, Batch: 606, Loss: 2494.370849609375\n",
      "Epoch: 3, Batch: 607, Loss: 2877.96142578125\n",
      "Epoch: 3, Batch: 608, Loss: 2460.744140625\n",
      "Epoch: 3, Batch: 609, Loss: 2610.9111328125\n",
      "Epoch: 3, Batch: 610, Loss: 2321.015625\n",
      "Epoch: 3, Batch: 611, Loss: 3080.099609375\n",
      "Epoch: 3, Batch: 612, Loss: 2678.36865234375\n",
      "Epoch: 3, Batch: 613, Loss: 2261.91845703125\n",
      "Epoch: 3, Batch: 614, Loss: 2284.871826171875\n",
      "Epoch: 3, Batch: 615, Loss: 2438.2412109375\n",
      "Epoch: 3, Batch: 616, Loss: 2862.61865234375\n",
      "Epoch: 3, Batch: 617, Loss: 2759.551025390625\n",
      "Epoch: 3, Batch: 618, Loss: 2394.895263671875\n",
      "Epoch: 3, Batch: 619, Loss: 2501.234619140625\n",
      "Epoch: 3, Batch: 620, Loss: 2404.510498046875\n",
      "Epoch: 3, Batch: 621, Loss: 2458.4375\n",
      "Epoch: 3, Batch: 622, Loss: 2592.115478515625\n",
      "Epoch: 3, Batch: 623, Loss: 3079.894775390625\n",
      "Epoch: 3, Batch: 624, Loss: 2776.896728515625\n",
      "Epoch: 3, Batch: 625, Loss: 2614.006103515625\n",
      "Epoch: 3, Batch: 626, Loss: 2523.50830078125\n",
      "Epoch: 3, Batch: 627, Loss: 3221.440185546875\n",
      "Epoch: 3, Batch: 628, Loss: 2935.994140625\n",
      "Epoch: 3, Batch: 629, Loss: 2866.54541015625\n",
      "Epoch: 3, Batch: 630, Loss: 2820.1015625\n",
      "Epoch: 3, Batch: 631, Loss: 2053.80224609375\n",
      "Epoch: 3, Batch: 632, Loss: 2833.53564453125\n",
      "Epoch: 3, Batch: 633, Loss: 2651.529296875\n",
      "Epoch: 3, Batch: 634, Loss: 3134.175537109375\n",
      "Epoch: 3, Batch: 635, Loss: 2438.731201171875\n",
      "Epoch: 3, Batch: 636, Loss: 2937.95361328125\n",
      "Epoch: 3, Batch: 637, Loss: 2906.36962890625\n",
      "Epoch: 3, Batch: 638, Loss: 2499.6796875\n",
      "Epoch: 3, Batch: 639, Loss: 2574.5546875\n",
      "Epoch: 3, Batch: 640, Loss: 2559.12646484375\n",
      "Epoch: 3, Batch: 641, Loss: 2630.0205078125\n",
      "Epoch: 3, Batch: 642, Loss: 2663.79248046875\n",
      "Epoch: 3, Batch: 643, Loss: 2950.632080078125\n",
      "Epoch: 3, Batch: 644, Loss: 3021.35791015625\n",
      "Epoch: 3, Batch: 645, Loss: 3157.110107421875\n",
      "Epoch: 3, Batch: 646, Loss: 2157.932861328125\n",
      "Epoch: 3, Batch: 647, Loss: 2340.51318359375\n",
      "Epoch: 3, Batch: 648, Loss: 3062.54833984375\n",
      "Epoch: 3, Batch: 649, Loss: 2703.1005859375\n",
      "Epoch: 3, Batch: 650, Loss: 2640.27490234375\n",
      "Epoch: 3, Batch: 651, Loss: 2846.953125\n",
      "Epoch: 3, Batch: 652, Loss: 2846.243896484375\n",
      "Epoch: 3, Batch: 653, Loss: 2554.006591796875\n",
      "Epoch: 3, Batch: 654, Loss: 2735.92431640625\n",
      "Epoch: 3, Batch: 655, Loss: 2821.23779296875\n",
      "Epoch: 3, Batch: 656, Loss: 2566.572998046875\n",
      "Epoch: 3, Batch: 657, Loss: 3466.0703125\n",
      "Epoch: 3, Batch: 658, Loss: 3070.51416015625\n",
      "Epoch: 3, Batch: 659, Loss: 2591.292236328125\n",
      "Epoch: 3, Batch: 660, Loss: 2872.50341796875\n",
      "Epoch: 3, Batch: 661, Loss: 2639.3974609375\n",
      "Epoch: 3, Batch: 662, Loss: 2079.589111328125\n",
      "Epoch: 3, Batch: 663, Loss: 2721.603515625\n",
      "Epoch: 3, Batch: 664, Loss: 2579.877197265625\n",
      "Epoch: 3, Batch: 665, Loss: 2824.583740234375\n",
      "Epoch: 3, Batch: 666, Loss: 2645.579345703125\n",
      "Epoch: 3, Batch: 667, Loss: 2396.975341796875\n",
      "Epoch: 3, Batch: 668, Loss: 2145.063720703125\n",
      "Epoch: 3, Batch: 669, Loss: 2317.68505859375\n",
      "Epoch: 3, Batch: 670, Loss: 2590.08251953125\n",
      "Epoch: 3, Batch: 671, Loss: 2816.514892578125\n",
      "Epoch: 3, Batch: 672, Loss: 2464.290283203125\n",
      "Epoch: 3, Batch: 673, Loss: 3001.332275390625\n",
      "Epoch: 3, Batch: 674, Loss: 3002.7763671875\n",
      "Epoch: 3, Batch: 675, Loss: 2955.28857421875\n",
      "Epoch: 3, Batch: 676, Loss: 3045.2451171875\n",
      "Epoch: 3, Batch: 677, Loss: 2706.25830078125\n",
      "Epoch: 3, Batch: 678, Loss: 2792.52978515625\n",
      "Epoch: 3, Batch: 679, Loss: 2473.9853515625\n",
      "Epoch: 3, Batch: 680, Loss: 2861.042724609375\n",
      "Epoch: 3, Batch: 681, Loss: 3181.374755859375\n",
      "Epoch: 3, Batch: 682, Loss: 2592.197509765625\n",
      "Epoch: 3, Batch: 683, Loss: 2321.8408203125\n",
      "Epoch: 3, Batch: 684, Loss: 2609.77294921875\n",
      "Epoch: 3, Batch: 685, Loss: 2671.5595703125\n",
      "Epoch: 3, Batch: 686, Loss: 2258.814208984375\n",
      "Epoch: 3, Batch: 687, Loss: 2601.289306640625\n",
      "Epoch: 3, Batch: 688, Loss: 2872.5244140625\n",
      "Epoch: 3, Batch: 689, Loss: 2975.9931640625\n",
      "Epoch: 3, Batch: 690, Loss: 2756.95361328125\n",
      "Epoch: 3, Batch: 691, Loss: 2708.4716796875\n",
      "Epoch: 3, Batch: 692, Loss: 2766.16845703125\n",
      "Epoch: 3, Batch: 693, Loss: 2858.66845703125\n",
      "Epoch: 3, Batch: 694, Loss: 2713.819091796875\n",
      "Epoch: 3, Batch: 695, Loss: 2280.00634765625\n",
      "Epoch: 3, Batch: 696, Loss: 3062.185302734375\n",
      "Epoch: 3, Batch: 697, Loss: 2432.3701171875\n",
      "Epoch: 3, Batch: 698, Loss: 2804.8720703125\n",
      "Epoch: 3, Batch: 699, Loss: 2177.249267578125\n",
      "Epoch: 3, Batch: 700, Loss: 2462.961181640625\n",
      "Epoch: 3, Batch: 701, Loss: 2213.09033203125\n",
      "Epoch: 3, Batch: 702, Loss: 3188.978759765625\n",
      "Epoch: 3, Batch: 703, Loss: 2035.47216796875\n",
      "Epoch: 3, Batch: 704, Loss: 2542.79931640625\n",
      "Epoch: 3, Batch: 705, Loss: 1644.504150390625\n",
      "Epoch: 3, Batch: 706, Loss: 2305.672119140625\n",
      "Epoch: 3, Batch: 707, Loss: 2497.102294921875\n",
      "Epoch: 3, Batch: 708, Loss: 2715.6328125\n",
      "Epoch: 3, Batch: 709, Loss: 2671.771240234375\n",
      "Epoch: 3, Batch: 710, Loss: 2685.94091796875\n",
      "Epoch: 3, Batch: 711, Loss: 2827.554443359375\n",
      "Epoch: 3, Batch: 712, Loss: 2661.486572265625\n",
      "Epoch: 3, Batch: 713, Loss: 3077.2734375\n",
      "Epoch: 3, Batch: 714, Loss: 2734.17041015625\n",
      "Epoch: 3, Batch: 715, Loss: 2857.420166015625\n",
      "Epoch: 3, Batch: 716, Loss: 2910.3271484375\n",
      "Epoch: 3, Batch: 717, Loss: 2826.902587890625\n",
      "Epoch: 3, Batch: 718, Loss: 2685.931884765625\n",
      "Epoch: 3, Batch: 719, Loss: 2634.260009765625\n",
      "Epoch: 3, Batch: 720, Loss: 2566.48095703125\n",
      "Epoch: 3, Batch: 721, Loss: 2686.328125\n",
      "Epoch: 3, Batch: 722, Loss: 2860.5\n",
      "Epoch: 3, Batch: 723, Loss: 2543.337158203125\n",
      "Epoch: 3, Batch: 724, Loss: 2390.164794921875\n",
      "Epoch: 3, Batch: 725, Loss: 2789.552978515625\n",
      "Epoch: 3, Batch: 726, Loss: 2609.552978515625\n",
      "Epoch: 3, Batch: 727, Loss: 2730.887939453125\n",
      "Epoch: 3, Batch: 728, Loss: 2541.615478515625\n",
      "Epoch: 3, Batch: 729, Loss: 2560.953369140625\n",
      "Epoch: 3, Batch: 730, Loss: 2672.057861328125\n",
      "Epoch: 3, Batch: 731, Loss: 2628.70751953125\n",
      "Epoch: 3, Batch: 732, Loss: 2332.74462890625\n",
      "Epoch: 3, Batch: 733, Loss: 3387.01708984375\n",
      "Epoch: 3, Batch: 734, Loss: 3163.168212890625\n",
      "Epoch: 3, Batch: 735, Loss: 2880.189453125\n",
      "Epoch: 3, Batch: 736, Loss: 2870.58251953125\n",
      "Epoch: 3, Batch: 737, Loss: 2519.0390625\n",
      "Epoch: 3, Batch: 738, Loss: 2627.302734375\n",
      "Epoch: 3, Batch: 739, Loss: 3004.188232421875\n",
      "Epoch: 3, Batch: 740, Loss: 2623.859619140625\n",
      "Epoch: 3, Batch: 741, Loss: 2733.34375\n",
      "Epoch: 3, Batch: 742, Loss: 2753.49853515625\n",
      "Epoch: 3, Batch: 743, Loss: 2974.94970703125\n",
      "Epoch: 3, Batch: 744, Loss: 2444.22265625\n",
      "Epoch: 3, Batch: 745, Loss: 2346.339599609375\n",
      "Epoch: 3, Batch: 746, Loss: 2393.081787109375\n",
      "Epoch: 3, Batch: 747, Loss: 2406.655029296875\n",
      "Epoch: 3, Batch: 748, Loss: 2964.7705078125\n",
      "Epoch: 3, Batch: 749, Loss: 2406.30322265625\n",
      "Epoch: 3, Batch: 750, Loss: 3011.023681640625\n",
      "Epoch: 3, Batch: 751, Loss: 2344.26025390625\n",
      "Epoch: 3, Batch: 752, Loss: 2345.370361328125\n",
      "Epoch: 3, Batch: 753, Loss: 2199.734130859375\n",
      "Epoch: 3, Batch: 754, Loss: 2578.838134765625\n",
      "Epoch: 3, Batch: 755, Loss: 2908.3427734375\n",
      "Epoch: 3, Batch: 756, Loss: 2418.0859375\n",
      "Epoch: 3, Batch: 757, Loss: 2440.10693359375\n",
      "Epoch: 3, Batch: 758, Loss: 2295.51611328125\n",
      "Epoch: 3, Batch: 759, Loss: 2843.76220703125\n",
      "Epoch: 3, Batch: 760, Loss: 2780.2529296875\n",
      "Epoch: 3, Batch: 761, Loss: 2272.7529296875\n",
      "Epoch: 3, Batch: 762, Loss: 2486.331298828125\n",
      "Epoch: 3, Batch: 763, Loss: 2636.14794921875\n",
      "Epoch: 3, Batch: 764, Loss: 2666.243408203125\n",
      "Epoch: 3, Batch: 765, Loss: 2932.4130859375\n",
      "Epoch: 3, Batch: 766, Loss: 2732.80224609375\n",
      "Epoch: 3, Batch: 767, Loss: 2662.649169921875\n",
      "Epoch: 3, Batch: 768, Loss: 2388.556884765625\n",
      "Epoch: 3, Batch: 769, Loss: 2421.010009765625\n",
      "Epoch: 3, Batch: 770, Loss: 2615.0634765625\n",
      "Epoch: 3, Batch: 771, Loss: 2710.906494140625\n",
      "Epoch: 3, Batch: 772, Loss: 3480.86376953125\n",
      "Epoch: 3, Batch: 773, Loss: 2595.892822265625\n",
      "Epoch: 3, Batch: 774, Loss: 2882.76123046875\n",
      "Epoch: 3, Batch: 775, Loss: 2679.916015625\n",
      "Epoch: 3, Batch: 776, Loss: 2700.0185546875\n",
      "Epoch: 3, Batch: 777, Loss: 2518.33544921875\n",
      "Epoch: 3, Batch: 778, Loss: 2689.733154296875\n",
      "Epoch: 3, Batch: 779, Loss: 2888.22021484375\n",
      "Epoch: 3, Batch: 780, Loss: 1947.1551513671875\n",
      "Epoch: 3, Batch: 781, Loss: 3075.377197265625\n",
      "Epoch: 3, Batch: 782, Loss: 2178.165771484375\n",
      "Epoch: 3, Batch: 783, Loss: 3104.264404296875\n",
      "Epoch: 3, Batch: 784, Loss: 2790.54443359375\n",
      "Epoch: 3, Batch: 785, Loss: 2324.361572265625\n",
      "Epoch: 3, Batch: 786, Loss: 2478.05419921875\n",
      "Epoch: 3, Batch: 787, Loss: 2795.909912109375\n",
      "Epoch: 3, Batch: 788, Loss: 2815.571044921875\n",
      "Epoch: 3, Batch: 789, Loss: 2082.67724609375\n",
      "Epoch: 3, Batch: 790, Loss: 2534.961181640625\n",
      "Epoch: 3, Batch: 791, Loss: 2733.64892578125\n",
      "Epoch: 3, Batch: 792, Loss: 2839.493896484375\n",
      "Epoch: 3, Batch: 793, Loss: 2971.884033203125\n",
      "Epoch: 3, Batch: 794, Loss: 2380.012451171875\n",
      "Epoch: 3, Batch: 795, Loss: 2512.588134765625\n",
      "Epoch: 3, Batch: 796, Loss: 2559.001220703125\n",
      "Epoch: 3, Batch: 797, Loss: 2452.359130859375\n",
      "Epoch: 3, Batch: 798, Loss: 2320.964111328125\n",
      "Epoch: 3, Batch: 799, Loss: 2418.179931640625\n",
      "Epoch: 3, Batch: 800, Loss: 3054.09130859375\n",
      "Epoch: 3, Batch: 801, Loss: 2441.701171875\n",
      "Epoch: 3, Batch: 802, Loss: 3073.905517578125\n",
      "Epoch: 3, Batch: 803, Loss: 2938.197998046875\n",
      "Epoch: 3, Batch: 804, Loss: 2930.2158203125\n",
      "Epoch: 3, Batch: 805, Loss: 2964.89111328125\n",
      "Epoch: 3, Batch: 806, Loss: 3020.6630859375\n",
      "Epoch: 3, Batch: 807, Loss: 3066.1533203125\n",
      "Epoch: 3, Batch: 808, Loss: 2252.541015625\n",
      "Epoch: 3, Batch: 809, Loss: 3031.15673828125\n",
      "Epoch: 3, Batch: 810, Loss: 2939.875732421875\n",
      "Epoch: 3, Batch: 811, Loss: 2724.6689453125\n",
      "Epoch: 3, Batch: 812, Loss: 2560.8623046875\n",
      "Epoch: 3, Batch: 813, Loss: 2996.844482421875\n",
      "Epoch: 3, Batch: 814, Loss: 2283.167236328125\n",
      "Epoch: 3, Batch: 815, Loss: 2987.21142578125\n",
      "Epoch: 3, Batch: 816, Loss: 2380.55029296875\n",
      "Epoch: 3, Batch: 817, Loss: 2505.843994140625\n",
      "Epoch: 3, Batch: 818, Loss: 2285.62548828125\n",
      "Epoch: 3, Batch: 819, Loss: 3141.5703125\n",
      "Epoch: 3, Batch: 820, Loss: 2562.404296875\n",
      "Epoch: 3, Batch: 821, Loss: 2241.40478515625\n",
      "Epoch: 3, Batch: 822, Loss: 2824.70703125\n",
      "Epoch: 3, Batch: 823, Loss: 3004.007080078125\n",
      "Epoch: 3, Batch: 824, Loss: 2792.84619140625\n",
      "Epoch: 3, Batch: 825, Loss: 2735.470458984375\n",
      "Epoch: 3, Batch: 826, Loss: 2231.22021484375\n",
      "Epoch: 3, Batch: 827, Loss: 3271.73046875\n",
      "Epoch: 3, Batch: 828, Loss: 2735.849609375\n",
      "Epoch: 3, Batch: 829, Loss: 2909.959228515625\n",
      "Epoch: 3, Batch: 830, Loss: 2740.375\n",
      "Epoch: 3, Batch: 831, Loss: 2333.397705078125\n",
      "Epoch: 3, Batch: 832, Loss: 2630.93408203125\n",
      "Epoch: 3, Batch: 833, Loss: 2358.18896484375\n",
      "Epoch: 3, Batch: 834, Loss: 2117.576416015625\n",
      "Epoch: 3, Batch: 835, Loss: 2053.286376953125\n",
      "Epoch: 3, Batch: 836, Loss: 2820.759765625\n",
      "Epoch: 3, Batch: 837, Loss: 3099.162109375\n",
      "Epoch: 3, Batch: 838, Loss: 2770.514404296875\n",
      "Epoch: 3, Batch: 839, Loss: 2686.995849609375\n",
      "Epoch: 3, Batch: 840, Loss: 2507.155517578125\n",
      "Epoch: 3, Batch: 841, Loss: 2087.5234375\n",
      "Epoch: 3, Batch: 842, Loss: 2587.673583984375\n",
      "Epoch: 3, Batch: 843, Loss: 2395.1318359375\n",
      "Epoch: 3, Batch: 844, Loss: 3191.560302734375\n",
      "Epoch: 3, Batch: 845, Loss: 2430.672119140625\n",
      "Epoch: 3, Batch: 846, Loss: 2951.447998046875\n",
      "Epoch: 3, Batch: 847, Loss: 2674.37353515625\n",
      "Epoch: 3, Batch: 848, Loss: 3091.5615234375\n",
      "Epoch: 3, Batch: 849, Loss: 2845.1650390625\n",
      "Epoch: 3, Batch: 850, Loss: 2440.93408203125\n",
      "Epoch: 3, Batch: 851, Loss: 2489.374755859375\n",
      "Epoch: 3, Batch: 852, Loss: 2402.57177734375\n",
      "Epoch: 3, Batch: 853, Loss: 2977.15625\n",
      "Epoch: 3, Batch: 854, Loss: 2930.6494140625\n",
      "Epoch: 3, Batch: 855, Loss: 3050.485595703125\n",
      "Epoch: 3, Batch: 856, Loss: 2352.56494140625\n",
      "Epoch: 3, Batch: 857, Loss: 2840.44189453125\n",
      "Epoch: 3, Batch: 858, Loss: 3035.1728515625\n",
      "Epoch: 3, Batch: 859, Loss: 2716.37548828125\n",
      "Epoch: 3, Batch: 860, Loss: 2582.749267578125\n",
      "Epoch: 3, Batch: 861, Loss: 2200.269775390625\n",
      "Epoch: 3, Batch: 862, Loss: 2629.00146484375\n",
      "Epoch: 3, Batch: 863, Loss: 2553.264404296875\n",
      "Epoch: 3, Batch: 864, Loss: 2616.21337890625\n",
      "Epoch: 3, Batch: 865, Loss: 3048.6640625\n",
      "Epoch: 3, Batch: 866, Loss: 2296.08056640625\n",
      "Epoch: 3, Batch: 867, Loss: 2616.292724609375\n",
      "Epoch: 3, Batch: 868, Loss: 2993.66162109375\n",
      "Epoch: 3, Batch: 869, Loss: 2717.3359375\n",
      "Epoch: 3, Batch: 870, Loss: 2420.3193359375\n",
      "Epoch: 3, Batch: 871, Loss: 2960.146240234375\n",
      "Epoch: 3, Batch: 872, Loss: 3792.26318359375\n",
      "Epoch: 3, Batch: 873, Loss: 2676.18359375\n",
      "Epoch: 3, Batch: 874, Loss: 2854.693603515625\n",
      "Epoch: 3, Batch: 875, Loss: 2539.78857421875\n",
      "Epoch: 3, Batch: 876, Loss: 3046.58349609375\n",
      "Epoch: 3, Batch: 877, Loss: 2994.681396484375\n",
      "Epoch: 3, Batch: 878, Loss: 3106.343017578125\n",
      "Epoch: 3, Batch: 879, Loss: 2552.736572265625\n",
      "Epoch: 3, Batch: 880, Loss: 2355.790771484375\n",
      "Epoch: 3, Batch: 881, Loss: 2506.082763671875\n",
      "Epoch: 3, Batch: 882, Loss: 2656.50390625\n",
      "Epoch: 3, Batch: 883, Loss: 2942.890380859375\n",
      "Epoch: 3, Batch: 884, Loss: 2781.506591796875\n",
      "Epoch: 3, Batch: 885, Loss: 2765.18359375\n",
      "Epoch: 3, Batch: 886, Loss: 2166.9638671875\n",
      "Epoch: 3, Batch: 887, Loss: 2553.298095703125\n",
      "Epoch: 3, Batch: 888, Loss: 2913.0361328125\n",
      "Epoch: 3, Batch: 889, Loss: 2738.93408203125\n",
      "Epoch: 3, Batch: 890, Loss: 2255.742919921875\n",
      "Epoch: 3, Batch: 891, Loss: 2629.662841796875\n",
      "Epoch: 3, Batch: 892, Loss: 2587.11376953125\n",
      "Epoch: 3, Batch: 893, Loss: 2095.4384765625\n",
      "Epoch: 3, Batch: 894, Loss: 2883.9970703125\n",
      "Epoch: 3, Batch: 895, Loss: 2555.716796875\n",
      "Epoch: 3, Batch: 896, Loss: 2082.643798828125\n",
      "Epoch: 3, Batch: 897, Loss: 2303.535400390625\n",
      "Epoch: 3, Batch: 898, Loss: 2426.1318359375\n",
      "Epoch: 3, Batch: 899, Loss: 2462.892333984375\n",
      "Epoch: 3, Batch: 900, Loss: 2633.2177734375\n",
      "Epoch: 3, Batch: 901, Loss: 2322.750244140625\n",
      "Epoch: 3, Batch: 902, Loss: 2833.8291015625\n",
      "Epoch: 3, Batch: 903, Loss: 3048.864990234375\n",
      "Epoch: 3, Batch: 904, Loss: 2430.9814453125\n",
      "Epoch: 3, Batch: 905, Loss: 2501.615478515625\n",
      "Epoch: 3, Batch: 906, Loss: 2222.19677734375\n",
      "Epoch: 3, Batch: 907, Loss: 3205.976806640625\n",
      "Epoch: 3, Batch: 908, Loss: 2776.421630859375\n",
      "Epoch: 3, Batch: 909, Loss: 2451.904052734375\n",
      "Epoch: 3, Batch: 910, Loss: 2163.10009765625\n",
      "Epoch: 3, Batch: 911, Loss: 2871.33056640625\n",
      "Epoch: 3, Batch: 912, Loss: 3146.18701171875\n",
      "Epoch: 3, Batch: 913, Loss: 2785.132568359375\n",
      "Epoch: 3, Batch: 914, Loss: 3123.71435546875\n",
      "Epoch: 3, Batch: 915, Loss: 2430.219970703125\n",
      "Epoch: 3, Batch: 916, Loss: 3155.63818359375\n",
      "Epoch: 3, Batch: 917, Loss: 1996.21728515625\n",
      "Epoch: 3, Batch: 918, Loss: 2693.92529296875\n",
      "Epoch: 3, Batch: 919, Loss: 2851.18896484375\n",
      "Epoch: 3, Batch: 920, Loss: 2649.86767578125\n",
      "Epoch: 3, Batch: 921, Loss: 2604.15625\n",
      "Epoch: 3, Batch: 922, Loss: 1937.04345703125\n",
      "Epoch: 3, Batch: 923, Loss: 2655.25537109375\n",
      "Epoch: 3, Batch: 924, Loss: 2550.311279296875\n",
      "Epoch: 3, Batch: 925, Loss: 2625.37353515625\n",
      "Epoch: 3, Batch: 926, Loss: 2862.75732421875\n",
      "Epoch: 3, Batch: 927, Loss: 2267.8095703125\n",
      "Epoch: 3, Batch: 928, Loss: 2604.19580078125\n",
      "Epoch: 3, Batch: 929, Loss: 2750.40478515625\n",
      "Epoch: 3, Batch: 930, Loss: 2634.98974609375\n",
      "Epoch: 3, Batch: 931, Loss: 2331.45849609375\n",
      "Epoch: 3, Batch: 932, Loss: 2535.314453125\n",
      "Epoch: 3, Batch: 933, Loss: 2623.958251953125\n",
      "Epoch: 3, Batch: 934, Loss: 2444.690185546875\n",
      "Epoch: 3, Batch: 935, Loss: 3141.68212890625\n",
      "Epoch: 3, Batch: 936, Loss: 2716.920654296875\n",
      "Epoch: 3, Batch: 937, Loss: 2540.02197265625\n",
      "Epoch: 3, Batch: 938, Loss: 2825.93896484375\n",
      "Epoch: 3, Batch: 939, Loss: 2079.552734375\n",
      "Epoch: 3, Batch: 940, Loss: 2114.46240234375\n",
      "Epoch: 3, Batch: 941, Loss: 2564.64306640625\n",
      "Epoch: 3, Batch: 942, Loss: 2247.438232421875\n",
      "Epoch: 3, Batch: 943, Loss: 2812.3955078125\n",
      "Epoch: 3, Batch: 944, Loss: 2332.7353515625\n",
      "Epoch: 3, Batch: 945, Loss: 2857.900634765625\n",
      "Epoch: 3, Batch: 946, Loss: 2213.9677734375\n",
      "Epoch: 3, Batch: 947, Loss: 2936.590576171875\n",
      "Epoch: 3, Batch: 948, Loss: 2985.9716796875\n",
      "Epoch: 3, Batch: 949, Loss: 2849.40673828125\n",
      "Epoch: 3, Batch: 950, Loss: 2695.675537109375\n",
      "Epoch: 3, Batch: 951, Loss: 2290.5244140625\n",
      "Epoch: 3, Batch: 952, Loss: 2712.494384765625\n",
      "Epoch: 3, Batch: 953, Loss: 2436.117431640625\n",
      "Epoch: 3, Batch: 954, Loss: 2519.182373046875\n",
      "Epoch: 3, Batch: 955, Loss: 2909.8818359375\n",
      "Epoch: 3, Batch: 956, Loss: 2654.112060546875\n",
      "Epoch: 3, Batch: 957, Loss: 2395.925537109375\n",
      "Epoch: 3, Batch: 958, Loss: 2800.060791015625\n",
      "Epoch: 3, Batch: 959, Loss: 2337.89892578125\n",
      "Epoch: 3, Batch: 960, Loss: 2541.533447265625\n",
      "Epoch: 3, Batch: 961, Loss: 2862.846923828125\n",
      "Epoch: 3, Batch: 962, Loss: 2251.283203125\n",
      "Epoch: 3, Batch: 963, Loss: 2275.96923828125\n",
      "Epoch: 3, Batch: 964, Loss: 2058.197998046875\n",
      "Epoch: 3, Batch: 965, Loss: 2651.14990234375\n",
      "Epoch: 3, Batch: 966, Loss: 2316.755126953125\n",
      "Epoch: 3, Batch: 967, Loss: 2465.280029296875\n",
      "Epoch: 3, Batch: 968, Loss: 2473.797119140625\n",
      "Epoch: 3, Batch: 969, Loss: 2645.298095703125\n",
      "Epoch: 3, Batch: 970, Loss: 3318.93017578125\n",
      "Epoch: 3, Batch: 971, Loss: 2554.496337890625\n",
      "Epoch: 3, Batch: 972, Loss: 2173.142333984375\n",
      "Epoch: 3, Batch: 973, Loss: 2765.970947265625\n",
      "Epoch: 3, Batch: 974, Loss: 2616.26220703125\n",
      "Epoch: 3, Batch: 975, Loss: 3000.95654296875\n",
      "Epoch: 3, Batch: 976, Loss: 1956.09423828125\n",
      "Epoch: 3, Batch: 977, Loss: 3080.207275390625\n",
      "Epoch: 3, Batch: 978, Loss: 2918.706298828125\n",
      "Epoch: 3, Batch: 979, Loss: 3135.5390625\n",
      "Epoch: 3, Batch: 980, Loss: 2700.805419921875\n",
      "Epoch: 3, Batch: 981, Loss: 2618.76708984375\n",
      "Epoch: 3, Batch: 982, Loss: 3356.610595703125\n",
      "Epoch: 3, Batch: 983, Loss: 2607.689697265625\n",
      "Epoch: 3, Batch: 984, Loss: 2611.3046875\n",
      "Epoch: 3, Batch: 985, Loss: 2634.34765625\n",
      "Epoch: 3, Batch: 986, Loss: 2406.0703125\n",
      "Epoch: 3, Batch: 987, Loss: 2142.119140625\n",
      "Epoch: 3, Batch: 988, Loss: 2646.177490234375\n",
      "Epoch: 3, Batch: 989, Loss: 2643.5205078125\n",
      "Epoch: 3, Batch: 990, Loss: 2501.730712890625\n",
      "Epoch: 3, Batch: 991, Loss: 2852.640380859375\n",
      "Epoch: 3, Batch: 992, Loss: 2323.76513671875\n",
      "Epoch: 3, Batch: 993, Loss: 2659.96630859375\n",
      "Epoch: 3, Batch: 994, Loss: 2211.675048828125\n",
      "Epoch: 3, Batch: 995, Loss: 2177.16552734375\n",
      "Epoch: 3, Batch: 996, Loss: 2462.370361328125\n",
      "Epoch: 3, Batch: 997, Loss: 1501.802490234375\n",
      "Epoch: 3, Batch: 998, Loss: 2861.83056640625\n",
      "Epoch: 3, Batch: 999, Loss: 2385.682861328125\n",
      "Epoch: 4, Batch: 0, Loss: 2985.98583984375\n",
      "Epoch: 4, Batch: 1, Loss: 3153.0185546875\n",
      "Epoch: 4, Batch: 2, Loss: 2635.7021484375\n",
      "Epoch: 4, Batch: 3, Loss: 3138.022705078125\n",
      "Epoch: 4, Batch: 4, Loss: 2677.77099609375\n",
      "Epoch: 4, Batch: 5, Loss: 2726.751953125\n",
      "Epoch: 4, Batch: 6, Loss: 2633.2138671875\n",
      "Epoch: 4, Batch: 7, Loss: 2215.740966796875\n",
      "Epoch: 4, Batch: 8, Loss: 2722.53369140625\n",
      "Epoch: 4, Batch: 9, Loss: 2501.446533203125\n",
      "Epoch: 4, Batch: 10, Loss: 2353.607666015625\n",
      "Epoch: 4, Batch: 11, Loss: 2788.94384765625\n",
      "Epoch: 4, Batch: 12, Loss: 2299.307861328125\n",
      "Epoch: 4, Batch: 13, Loss: 2060.51025390625\n",
      "Epoch: 4, Batch: 14, Loss: 2600.10595703125\n",
      "Epoch: 4, Batch: 15, Loss: 2263.06689453125\n",
      "Epoch: 4, Batch: 16, Loss: 2533.971435546875\n",
      "Epoch: 4, Batch: 17, Loss: 3104.484375\n",
      "Epoch: 4, Batch: 18, Loss: 2148.990234375\n",
      "Epoch: 4, Batch: 19, Loss: 2849.841796875\n",
      "Epoch: 4, Batch: 20, Loss: 2540.383544921875\n",
      "Epoch: 4, Batch: 21, Loss: 3262.6015625\n",
      "Epoch: 4, Batch: 22, Loss: 2153.51953125\n",
      "Epoch: 4, Batch: 23, Loss: 2343.58447265625\n",
      "Epoch: 4, Batch: 24, Loss: 3089.1025390625\n",
      "Epoch: 4, Batch: 25, Loss: 2788.96044921875\n",
      "Epoch: 4, Batch: 26, Loss: 2545.463623046875\n",
      "Epoch: 4, Batch: 27, Loss: 2402.03076171875\n",
      "Epoch: 4, Batch: 28, Loss: 2817.551513671875\n",
      "Epoch: 4, Batch: 29, Loss: 2751.3037109375\n",
      "Epoch: 4, Batch: 30, Loss: 2656.836181640625\n",
      "Epoch: 4, Batch: 31, Loss: 1774.7095947265625\n",
      "Epoch: 4, Batch: 32, Loss: 2609.88037109375\n",
      "Epoch: 4, Batch: 33, Loss: 3227.611083984375\n",
      "Epoch: 4, Batch: 34, Loss: 2695.786865234375\n",
      "Epoch: 4, Batch: 35, Loss: 2413.733154296875\n",
      "Epoch: 4, Batch: 36, Loss: 2651.77783203125\n",
      "Epoch: 4, Batch: 37, Loss: 2242.424560546875\n",
      "Epoch: 4, Batch: 38, Loss: 2864.486328125\n",
      "Epoch: 4, Batch: 39, Loss: 2517.673095703125\n",
      "Epoch: 4, Batch: 40, Loss: 2520.90478515625\n",
      "Epoch: 4, Batch: 41, Loss: 2661.1826171875\n",
      "Epoch: 4, Batch: 42, Loss: 2855.5205078125\n",
      "Epoch: 4, Batch: 43, Loss: 3210.128173828125\n",
      "Epoch: 4, Batch: 44, Loss: 2173.12353515625\n",
      "Epoch: 4, Batch: 45, Loss: 2362.407470703125\n",
      "Epoch: 4, Batch: 46, Loss: 2492.531494140625\n",
      "Epoch: 4, Batch: 47, Loss: 2948.123291015625\n",
      "Epoch: 4, Batch: 48, Loss: 2655.017333984375\n",
      "Epoch: 4, Batch: 49, Loss: 2879.685546875\n",
      "Epoch: 4, Batch: 50, Loss: 2860.089599609375\n",
      "Epoch: 4, Batch: 51, Loss: 2735.600830078125\n",
      "Epoch: 4, Batch: 52, Loss: 2375.834228515625\n",
      "Epoch: 4, Batch: 53, Loss: 2864.471435546875\n",
      "Epoch: 4, Batch: 54, Loss: 3027.56982421875\n",
      "Epoch: 4, Batch: 55, Loss: 3184.584716796875\n",
      "Epoch: 4, Batch: 56, Loss: 2657.995849609375\n",
      "Epoch: 4, Batch: 57, Loss: 2750.069580078125\n",
      "Epoch: 4, Batch: 58, Loss: 2218.611083984375\n",
      "Epoch: 4, Batch: 59, Loss: 2625.458984375\n",
      "Epoch: 4, Batch: 60, Loss: 2891.47314453125\n",
      "Epoch: 4, Batch: 61, Loss: 2364.871337890625\n",
      "Epoch: 4, Batch: 62, Loss: 2982.513427734375\n",
      "Epoch: 4, Batch: 63, Loss: 2435.918212890625\n",
      "Epoch: 4, Batch: 64, Loss: 3040.685302734375\n",
      "Epoch: 4, Batch: 65, Loss: 3179.88671875\n",
      "Epoch: 4, Batch: 66, Loss: 2225.115234375\n",
      "Epoch: 4, Batch: 67, Loss: 2682.634765625\n",
      "Epoch: 4, Batch: 68, Loss: 2494.09375\n",
      "Epoch: 4, Batch: 69, Loss: 2681.86181640625\n",
      "Epoch: 4, Batch: 70, Loss: 2968.037353515625\n",
      "Epoch: 4, Batch: 71, Loss: 2499.95556640625\n",
      "Epoch: 4, Batch: 72, Loss: 2739.669921875\n",
      "Epoch: 4, Batch: 73, Loss: 3103.86962890625\n",
      "Epoch: 4, Batch: 74, Loss: 2508.58251953125\n",
      "Epoch: 4, Batch: 75, Loss: 2774.369140625\n",
      "Epoch: 4, Batch: 76, Loss: 2532.33984375\n",
      "Epoch: 4, Batch: 77, Loss: 2832.199951171875\n",
      "Epoch: 4, Batch: 78, Loss: 2474.895263671875\n",
      "Epoch: 4, Batch: 79, Loss: 2542.835693359375\n",
      "Epoch: 4, Batch: 80, Loss: 2685.96435546875\n",
      "Epoch: 4, Batch: 81, Loss: 2460.9599609375\n",
      "Epoch: 4, Batch: 82, Loss: 2642.1728515625\n",
      "Epoch: 4, Batch: 83, Loss: 2753.26416015625\n",
      "Epoch: 4, Batch: 84, Loss: 2386.75390625\n",
      "Epoch: 4, Batch: 85, Loss: 2504.2763671875\n",
      "Epoch: 4, Batch: 86, Loss: 2722.662109375\n",
      "Epoch: 4, Batch: 87, Loss: 2542.07470703125\n",
      "Epoch: 4, Batch: 88, Loss: 3051.17578125\n",
      "Epoch: 4, Batch: 89, Loss: 2557.545166015625\n",
      "Epoch: 4, Batch: 90, Loss: 2689.76123046875\n",
      "Epoch: 4, Batch: 91, Loss: 2884.066162109375\n",
      "Epoch: 4, Batch: 92, Loss: 2293.11181640625\n",
      "Epoch: 4, Batch: 93, Loss: 2064.7802734375\n",
      "Epoch: 4, Batch: 94, Loss: 3127.042236328125\n",
      "Epoch: 4, Batch: 95, Loss: 2891.7333984375\n",
      "Epoch: 4, Batch: 96, Loss: 3040.64794921875\n",
      "Epoch: 4, Batch: 97, Loss: 2468.122802734375\n",
      "Epoch: 4, Batch: 98, Loss: 2600.2578125\n",
      "Epoch: 4, Batch: 99, Loss: 2518.13916015625\n",
      "Epoch: 4, Batch: 100, Loss: 2719.42333984375\n",
      "Epoch: 4, Batch: 101, Loss: 2683.785888671875\n",
      "Epoch: 4, Batch: 102, Loss: 2988.7333984375\n",
      "Epoch: 4, Batch: 103, Loss: 2344.6044921875\n",
      "Epoch: 4, Batch: 104, Loss: 2169.4501953125\n",
      "Epoch: 4, Batch: 105, Loss: 1938.30859375\n",
      "Epoch: 4, Batch: 106, Loss: 2396.671875\n",
      "Epoch: 4, Batch: 107, Loss: 2440.706787109375\n",
      "Epoch: 4, Batch: 108, Loss: 2525.737548828125\n",
      "Epoch: 4, Batch: 109, Loss: 2559.0712890625\n",
      "Epoch: 4, Batch: 110, Loss: 1856.087646484375\n",
      "Epoch: 4, Batch: 111, Loss: 2779.1796875\n",
      "Epoch: 4, Batch: 112, Loss: 2664.72802734375\n",
      "Epoch: 4, Batch: 113, Loss: 2758.74609375\n",
      "Epoch: 4, Batch: 114, Loss: 2336.62109375\n",
      "Epoch: 4, Batch: 115, Loss: 2564.4296875\n",
      "Epoch: 4, Batch: 116, Loss: 2577.01806640625\n",
      "Epoch: 4, Batch: 117, Loss: 3020.9873046875\n",
      "Epoch: 4, Batch: 118, Loss: 2776.89501953125\n",
      "Epoch: 4, Batch: 119, Loss: 2371.199462890625\n",
      "Epoch: 4, Batch: 120, Loss: 3414.95654296875\n",
      "Epoch: 4, Batch: 121, Loss: 2431.05859375\n",
      "Epoch: 4, Batch: 122, Loss: 3065.35986328125\n",
      "Epoch: 4, Batch: 123, Loss: 2235.482421875\n",
      "Epoch: 4, Batch: 124, Loss: 3249.8193359375\n",
      "Epoch: 4, Batch: 125, Loss: 3218.28564453125\n",
      "Epoch: 4, Batch: 126, Loss: 3219.096923828125\n",
      "Epoch: 4, Batch: 127, Loss: 2265.056640625\n",
      "Epoch: 4, Batch: 128, Loss: 2435.89453125\n",
      "Epoch: 4, Batch: 129, Loss: 2564.289794921875\n",
      "Epoch: 4, Batch: 130, Loss: 2375.66455078125\n",
      "Epoch: 4, Batch: 131, Loss: 2184.602294921875\n",
      "Epoch: 4, Batch: 132, Loss: 2839.47119140625\n",
      "Epoch: 4, Batch: 133, Loss: 2483.548583984375\n",
      "Epoch: 4, Batch: 134, Loss: 2173.58544921875\n",
      "Epoch: 4, Batch: 135, Loss: 2737.174072265625\n",
      "Epoch: 4, Batch: 136, Loss: 2481.82470703125\n",
      "Epoch: 4, Batch: 137, Loss: 2931.45849609375\n",
      "Epoch: 4, Batch: 138, Loss: 2229.140625\n",
      "Epoch: 4, Batch: 139, Loss: 2744.350830078125\n",
      "Epoch: 4, Batch: 140, Loss: 2292.630126953125\n",
      "Epoch: 4, Batch: 141, Loss: 2690.3134765625\n",
      "Epoch: 4, Batch: 142, Loss: 2148.893310546875\n",
      "Epoch: 4, Batch: 143, Loss: 3095.236328125\n",
      "Epoch: 4, Batch: 144, Loss: 1772.25\n",
      "Epoch: 4, Batch: 145, Loss: 2392.10546875\n",
      "Epoch: 4, Batch: 146, Loss: 2492.946044921875\n",
      "Epoch: 4, Batch: 147, Loss: 2938.040771484375\n",
      "Epoch: 4, Batch: 148, Loss: 3186.14599609375\n",
      "Epoch: 4, Batch: 149, Loss: 2263.382568359375\n",
      "Epoch: 4, Batch: 150, Loss: 2498.392333984375\n",
      "Epoch: 4, Batch: 151, Loss: 2850.05419921875\n",
      "Epoch: 4, Batch: 152, Loss: 2825.734619140625\n",
      "Epoch: 4, Batch: 153, Loss: 2042.78173828125\n",
      "Epoch: 4, Batch: 154, Loss: 2095.80712890625\n",
      "Epoch: 4, Batch: 155, Loss: 2538.99609375\n",
      "Epoch: 4, Batch: 156, Loss: 2082.86328125\n",
      "Epoch: 4, Batch: 157, Loss: 2735.254638671875\n",
      "Epoch: 4, Batch: 158, Loss: 2571.287109375\n",
      "Epoch: 4, Batch: 159, Loss: 2971.46875\n",
      "Epoch: 4, Batch: 160, Loss: 2695.3154296875\n",
      "Epoch: 4, Batch: 161, Loss: 2721.87353515625\n",
      "Epoch: 4, Batch: 162, Loss: 2793.906005859375\n",
      "Epoch: 4, Batch: 163, Loss: 2719.95556640625\n",
      "Epoch: 4, Batch: 164, Loss: 2669.46728515625\n",
      "Epoch: 4, Batch: 165, Loss: 2763.079833984375\n",
      "Epoch: 4, Batch: 166, Loss: 2687.782958984375\n",
      "Epoch: 4, Batch: 167, Loss: 2775.1611328125\n",
      "Epoch: 4, Batch: 168, Loss: 2811.6767578125\n",
      "Epoch: 4, Batch: 169, Loss: 2339.4404296875\n",
      "Epoch: 4, Batch: 170, Loss: 2358.3369140625\n",
      "Epoch: 4, Batch: 171, Loss: 2378.17236328125\n",
      "Epoch: 4, Batch: 172, Loss: 2537.263427734375\n",
      "Epoch: 4, Batch: 173, Loss: 2556.000732421875\n",
      "Epoch: 4, Batch: 174, Loss: 2850.582763671875\n",
      "Epoch: 4, Batch: 175, Loss: 2748.635986328125\n",
      "Epoch: 4, Batch: 176, Loss: 2707.857666015625\n",
      "Epoch: 4, Batch: 177, Loss: 2424.264892578125\n",
      "Epoch: 4, Batch: 178, Loss: 2677.650146484375\n",
      "Epoch: 4, Batch: 179, Loss: 2880.552734375\n",
      "Epoch: 4, Batch: 180, Loss: 2645.673095703125\n",
      "Epoch: 4, Batch: 181, Loss: 3427.012939453125\n",
      "Epoch: 4, Batch: 182, Loss: 2464.703857421875\n",
      "Epoch: 4, Batch: 183, Loss: 2252.2099609375\n",
      "Epoch: 4, Batch: 184, Loss: 2297.56005859375\n",
      "Epoch: 4, Batch: 185, Loss: 2835.283935546875\n",
      "Epoch: 4, Batch: 186, Loss: 2282.881591796875\n",
      "Epoch: 4, Batch: 187, Loss: 2886.446533203125\n",
      "Epoch: 4, Batch: 188, Loss: 3276.34423828125\n",
      "Epoch: 4, Batch: 189, Loss: 2785.177490234375\n",
      "Epoch: 4, Batch: 190, Loss: 2283.177490234375\n",
      "Epoch: 4, Batch: 191, Loss: 2410.01171875\n",
      "Epoch: 4, Batch: 192, Loss: 2243.513916015625\n",
      "Epoch: 4, Batch: 193, Loss: 2851.740478515625\n",
      "Epoch: 4, Batch: 194, Loss: 2512.725341796875\n",
      "Epoch: 4, Batch: 195, Loss: 2280.943603515625\n",
      "Epoch: 4, Batch: 196, Loss: 2158.686767578125\n",
      "Epoch: 4, Batch: 197, Loss: 2390.02392578125\n",
      "Epoch: 4, Batch: 198, Loss: 2937.166259765625\n",
      "Epoch: 4, Batch: 199, Loss: 2564.066650390625\n",
      "Epoch: 4, Batch: 200, Loss: 2591.772216796875\n",
      "Epoch: 4, Batch: 201, Loss: 2984.12744140625\n",
      "Epoch: 4, Batch: 202, Loss: 2663.46923828125\n",
      "Epoch: 4, Batch: 203, Loss: 2022.6402587890625\n",
      "Epoch: 4, Batch: 204, Loss: 2090.81884765625\n",
      "Epoch: 4, Batch: 205, Loss: 2528.98974609375\n",
      "Epoch: 4, Batch: 206, Loss: 2719.157958984375\n",
      "Epoch: 4, Batch: 207, Loss: 2645.40087890625\n",
      "Epoch: 4, Batch: 208, Loss: 2530.133056640625\n",
      "Epoch: 4, Batch: 209, Loss: 2606.72314453125\n",
      "Epoch: 4, Batch: 210, Loss: 2498.126953125\n",
      "Epoch: 4, Batch: 211, Loss: 3109.745361328125\n",
      "Epoch: 4, Batch: 212, Loss: 2659.76806640625\n",
      "Epoch: 4, Batch: 213, Loss: 3096.935546875\n",
      "Epoch: 4, Batch: 214, Loss: 2165.644287109375\n",
      "Epoch: 4, Batch: 215, Loss: 2903.150390625\n",
      "Epoch: 4, Batch: 216, Loss: 2932.587890625\n",
      "Epoch: 4, Batch: 217, Loss: 2815.05029296875\n",
      "Epoch: 4, Batch: 218, Loss: 2760.333251953125\n",
      "Epoch: 4, Batch: 219, Loss: 2277.8583984375\n",
      "Epoch: 4, Batch: 220, Loss: 2403.3203125\n",
      "Epoch: 4, Batch: 221, Loss: 2754.41845703125\n",
      "Epoch: 4, Batch: 222, Loss: 2360.745849609375\n",
      "Epoch: 4, Batch: 223, Loss: 3040.385498046875\n",
      "Epoch: 4, Batch: 224, Loss: 2799.391845703125\n",
      "Epoch: 4, Batch: 225, Loss: 2398.386474609375\n",
      "Epoch: 4, Batch: 226, Loss: 2798.27099609375\n",
      "Epoch: 4, Batch: 227, Loss: 2682.19140625\n",
      "Epoch: 4, Batch: 228, Loss: 2833.002685546875\n",
      "Epoch: 4, Batch: 229, Loss: 2490.85009765625\n",
      "Epoch: 4, Batch: 230, Loss: 2963.93212890625\n",
      "Epoch: 4, Batch: 231, Loss: 2894.22412109375\n",
      "Epoch: 4, Batch: 232, Loss: 2637.433349609375\n",
      "Epoch: 4, Batch: 233, Loss: 2776.735595703125\n",
      "Epoch: 4, Batch: 234, Loss: 2701.083984375\n",
      "Epoch: 4, Batch: 235, Loss: 2362.113037109375\n",
      "Epoch: 4, Batch: 236, Loss: 2273.681640625\n",
      "Epoch: 4, Batch: 237, Loss: 2067.546875\n",
      "Epoch: 4, Batch: 238, Loss: 2477.049560546875\n",
      "Epoch: 4, Batch: 239, Loss: 2652.35791015625\n",
      "Epoch: 4, Batch: 240, Loss: 2789.30810546875\n",
      "Epoch: 4, Batch: 241, Loss: 2541.590087890625\n",
      "Epoch: 4, Batch: 242, Loss: 2661.085693359375\n",
      "Epoch: 4, Batch: 243, Loss: 2995.808349609375\n",
      "Epoch: 4, Batch: 244, Loss: 2215.18896484375\n",
      "Epoch: 4, Batch: 245, Loss: 2584.63427734375\n",
      "Epoch: 4, Batch: 246, Loss: 2781.0576171875\n",
      "Epoch: 4, Batch: 247, Loss: 3052.463623046875\n",
      "Epoch: 4, Batch: 248, Loss: 2381.539794921875\n",
      "Epoch: 4, Batch: 249, Loss: 2811.958984375\n",
      "Epoch: 4, Batch: 250, Loss: 2538.19970703125\n",
      "Epoch: 4, Batch: 251, Loss: 2366.491455078125\n",
      "Epoch: 4, Batch: 252, Loss: 2888.5615234375\n",
      "Epoch: 4, Batch: 253, Loss: 2868.7861328125\n",
      "Epoch: 4, Batch: 254, Loss: 1963.4007568359375\n",
      "Epoch: 4, Batch: 255, Loss: 2566.578125\n",
      "Epoch: 4, Batch: 256, Loss: 2429.2978515625\n",
      "Epoch: 4, Batch: 257, Loss: 2531.060546875\n",
      "Epoch: 4, Batch: 258, Loss: 2672.7783203125\n",
      "Epoch: 4, Batch: 259, Loss: 2205.05615234375\n",
      "Epoch: 4, Batch: 260, Loss: 2881.83544921875\n",
      "Epoch: 4, Batch: 261, Loss: 2892.673095703125\n",
      "Epoch: 4, Batch: 262, Loss: 2808.6455078125\n",
      "Epoch: 4, Batch: 263, Loss: 2714.650146484375\n",
      "Epoch: 4, Batch: 264, Loss: 2739.76611328125\n",
      "Epoch: 4, Batch: 265, Loss: 2386.24609375\n",
      "Epoch: 4, Batch: 266, Loss: 2706.91552734375\n",
      "Epoch: 4, Batch: 267, Loss: 2725.60498046875\n",
      "Epoch: 4, Batch: 268, Loss: 2268.31591796875\n",
      "Epoch: 4, Batch: 269, Loss: 2401.821533203125\n",
      "Epoch: 4, Batch: 270, Loss: 2427.907470703125\n",
      "Epoch: 4, Batch: 271, Loss: 2434.1708984375\n",
      "Epoch: 4, Batch: 272, Loss: 2665.42138671875\n",
      "Epoch: 4, Batch: 273, Loss: 2839.682861328125\n",
      "Epoch: 4, Batch: 274, Loss: 3124.83349609375\n",
      "Epoch: 4, Batch: 275, Loss: 2451.31494140625\n",
      "Epoch: 4, Batch: 276, Loss: 3254.502685546875\n",
      "Epoch: 4, Batch: 277, Loss: 2849.4609375\n",
      "Epoch: 4, Batch: 278, Loss: 2602.14404296875\n",
      "Epoch: 4, Batch: 279, Loss: 2076.19775390625\n",
      "Epoch: 4, Batch: 280, Loss: 2994.8603515625\n",
      "Epoch: 4, Batch: 281, Loss: 3179.137451171875\n",
      "Epoch: 4, Batch: 282, Loss: 2828.185791015625\n",
      "Epoch: 4, Batch: 283, Loss: 2971.943115234375\n",
      "Epoch: 4, Batch: 284, Loss: 2781.80517578125\n",
      "Epoch: 4, Batch: 285, Loss: 2661.476318359375\n",
      "Epoch: 4, Batch: 286, Loss: 2747.091552734375\n",
      "Epoch: 4, Batch: 287, Loss: 2897.319091796875\n",
      "Epoch: 4, Batch: 288, Loss: 2464.92236328125\n",
      "Epoch: 4, Batch: 289, Loss: 3076.58251953125\n",
      "Epoch: 4, Batch: 290, Loss: 1948.2928466796875\n",
      "Epoch: 4, Batch: 291, Loss: 2316.1650390625\n",
      "Epoch: 4, Batch: 292, Loss: 2954.9560546875\n",
      "Epoch: 4, Batch: 293, Loss: 2459.38916015625\n",
      "Epoch: 4, Batch: 294, Loss: 2283.768310546875\n",
      "Epoch: 4, Batch: 295, Loss: 2638.73876953125\n",
      "Epoch: 4, Batch: 296, Loss: 3077.964111328125\n",
      "Epoch: 4, Batch: 297, Loss: 2669.91455078125\n",
      "Epoch: 4, Batch: 298, Loss: 2875.705078125\n",
      "Epoch: 4, Batch: 299, Loss: 3325.809814453125\n",
      "Epoch: 4, Batch: 300, Loss: 2809.95068359375\n",
      "Epoch: 4, Batch: 301, Loss: 2761.41259765625\n",
      "Epoch: 4, Batch: 302, Loss: 2135.437255859375\n",
      "Epoch: 4, Batch: 303, Loss: 2331.30126953125\n",
      "Epoch: 4, Batch: 304, Loss: 2829.015869140625\n",
      "Epoch: 4, Batch: 305, Loss: 2410.01220703125\n",
      "Epoch: 4, Batch: 306, Loss: 2862.2216796875\n",
      "Epoch: 4, Batch: 307, Loss: 2191.25830078125\n",
      "Epoch: 4, Batch: 308, Loss: 2752.52880859375\n",
      "Epoch: 4, Batch: 309, Loss: 2530.854736328125\n",
      "Epoch: 4, Batch: 310, Loss: 3288.916259765625\n",
      "Epoch: 4, Batch: 311, Loss: 2742.994384765625\n",
      "Epoch: 4, Batch: 312, Loss: 2871.544921875\n",
      "Epoch: 4, Batch: 313, Loss: 2359.52587890625\n",
      "Epoch: 4, Batch: 314, Loss: 2223.372802734375\n",
      "Epoch: 4, Batch: 315, Loss: 2662.017822265625\n",
      "Epoch: 4, Batch: 316, Loss: 2870.433349609375\n",
      "Epoch: 4, Batch: 317, Loss: 2684.59814453125\n",
      "Epoch: 4, Batch: 318, Loss: 2726.1865234375\n",
      "Epoch: 4, Batch: 319, Loss: 2464.906982421875\n",
      "Epoch: 4, Batch: 320, Loss: 2610.66162109375\n",
      "Epoch: 4, Batch: 321, Loss: 2604.319091796875\n",
      "Epoch: 4, Batch: 322, Loss: 2303.447021484375\n",
      "Epoch: 4, Batch: 323, Loss: 2968.67529296875\n",
      "Epoch: 4, Batch: 324, Loss: 2365.945556640625\n",
      "Epoch: 4, Batch: 325, Loss: 2196.67236328125\n",
      "Epoch: 4, Batch: 326, Loss: 2128.399658203125\n",
      "Epoch: 4, Batch: 327, Loss: 2215.368408203125\n",
      "Epoch: 4, Batch: 328, Loss: 3105.26318359375\n",
      "Epoch: 4, Batch: 329, Loss: 2484.7138671875\n",
      "Epoch: 4, Batch: 330, Loss: 2646.67578125\n",
      "Epoch: 4, Batch: 331, Loss: 3099.849609375\n",
      "Epoch: 4, Batch: 332, Loss: 2595.425537109375\n",
      "Epoch: 4, Batch: 333, Loss: 2350.011474609375\n",
      "Epoch: 4, Batch: 334, Loss: 2149.011474609375\n",
      "Epoch: 4, Batch: 335, Loss: 2825.5087890625\n",
      "Epoch: 4, Batch: 336, Loss: 2962.6220703125\n",
      "Epoch: 4, Batch: 337, Loss: 2951.69189453125\n",
      "Epoch: 4, Batch: 338, Loss: 3217.14599609375\n",
      "Epoch: 4, Batch: 339, Loss: 2588.942626953125\n",
      "Epoch: 4, Batch: 340, Loss: 2191.805419921875\n",
      "Epoch: 4, Batch: 341, Loss: 2877.712158203125\n",
      "Epoch: 4, Batch: 342, Loss: 2578.392578125\n",
      "Epoch: 4, Batch: 343, Loss: 2986.41015625\n",
      "Epoch: 4, Batch: 344, Loss: 2403.220947265625\n",
      "Epoch: 4, Batch: 345, Loss: 2539.56103515625\n",
      "Epoch: 4, Batch: 346, Loss: 2384.50732421875\n",
      "Epoch: 4, Batch: 347, Loss: 1917.070556640625\n",
      "Epoch: 4, Batch: 348, Loss: 2417.693115234375\n",
      "Epoch: 4, Batch: 349, Loss: 3156.824462890625\n",
      "Epoch: 4, Batch: 350, Loss: 3230.098876953125\n",
      "Epoch: 4, Batch: 351, Loss: 2812.9990234375\n",
      "Epoch: 4, Batch: 352, Loss: 2517.910400390625\n",
      "Epoch: 4, Batch: 353, Loss: 2773.9130859375\n",
      "Epoch: 4, Batch: 354, Loss: 2433.72607421875\n",
      "Epoch: 4, Batch: 355, Loss: 2685.692138671875\n",
      "Epoch: 4, Batch: 356, Loss: 2675.60791015625\n",
      "Epoch: 4, Batch: 357, Loss: 2848.419677734375\n",
      "Epoch: 4, Batch: 358, Loss: 2203.02294921875\n",
      "Epoch: 4, Batch: 359, Loss: 2847.685302734375\n",
      "Epoch: 4, Batch: 360, Loss: 2672.05224609375\n",
      "Epoch: 4, Batch: 361, Loss: 2609.806884765625\n",
      "Epoch: 4, Batch: 362, Loss: 2531.99072265625\n",
      "Epoch: 4, Batch: 363, Loss: 2208.23046875\n",
      "Epoch: 4, Batch: 364, Loss: 2888.975830078125\n",
      "Epoch: 4, Batch: 365, Loss: 2336.53515625\n",
      "Epoch: 4, Batch: 366, Loss: 1826.61669921875\n",
      "Epoch: 4, Batch: 367, Loss: 2943.806396484375\n",
      "Epoch: 4, Batch: 368, Loss: 2943.267578125\n",
      "Epoch: 4, Batch: 369, Loss: 2784.28369140625\n",
      "Epoch: 4, Batch: 370, Loss: 2574.3720703125\n",
      "Epoch: 4, Batch: 371, Loss: 2229.13818359375\n",
      "Epoch: 4, Batch: 372, Loss: 2549.49609375\n",
      "Epoch: 4, Batch: 373, Loss: 1811.4033203125\n",
      "Epoch: 4, Batch: 374, Loss: 2350.628173828125\n",
      "Epoch: 4, Batch: 375, Loss: 2459.155029296875\n",
      "Epoch: 4, Batch: 376, Loss: 2787.509521484375\n",
      "Epoch: 4, Batch: 377, Loss: 2743.72705078125\n",
      "Epoch: 4, Batch: 378, Loss: 2313.506591796875\n",
      "Epoch: 4, Batch: 379, Loss: 3275.180908203125\n",
      "Epoch: 4, Batch: 380, Loss: 3127.248291015625\n",
      "Epoch: 4, Batch: 381, Loss: 2073.610595703125\n",
      "Epoch: 4, Batch: 382, Loss: 2320.272216796875\n",
      "Epoch: 4, Batch: 383, Loss: 2316.09423828125\n",
      "Epoch: 4, Batch: 384, Loss: 2987.271728515625\n",
      "Epoch: 4, Batch: 385, Loss: 2701.26318359375\n",
      "Epoch: 4, Batch: 386, Loss: 2866.979736328125\n",
      "Epoch: 4, Batch: 387, Loss: 2636.95947265625\n",
      "Epoch: 4, Batch: 388, Loss: 2398.6328125\n",
      "Epoch: 4, Batch: 389, Loss: 2746.552001953125\n",
      "Epoch: 4, Batch: 390, Loss: 2349.7275390625\n",
      "Epoch: 4, Batch: 391, Loss: 2305.09228515625\n",
      "Epoch: 4, Batch: 392, Loss: 2842.524169921875\n",
      "Epoch: 4, Batch: 393, Loss: 2280.85400390625\n",
      "Epoch: 4, Batch: 394, Loss: 2667.731201171875\n",
      "Epoch: 4, Batch: 395, Loss: 2660.83544921875\n",
      "Epoch: 4, Batch: 396, Loss: 2479.223388671875\n",
      "Epoch: 4, Batch: 397, Loss: 2450.4921875\n",
      "Epoch: 4, Batch: 398, Loss: 3154.9248046875\n",
      "Epoch: 4, Batch: 399, Loss: 2819.041259765625\n",
      "Epoch: 4, Batch: 400, Loss: 2542.847412109375\n",
      "Epoch: 4, Batch: 401, Loss: 2542.706298828125\n",
      "Epoch: 4, Batch: 402, Loss: 2727.848388671875\n",
      "Epoch: 4, Batch: 403, Loss: 3004.518798828125\n",
      "Epoch: 4, Batch: 404, Loss: 3474.347900390625\n",
      "Epoch: 4, Batch: 405, Loss: 2304.39697265625\n",
      "Epoch: 4, Batch: 406, Loss: 2292.051025390625\n",
      "Epoch: 4, Batch: 407, Loss: 2705.6767578125\n",
      "Epoch: 4, Batch: 408, Loss: 3450.962158203125\n",
      "Epoch: 4, Batch: 409, Loss: 2938.492431640625\n",
      "Epoch: 4, Batch: 410, Loss: 2555.72314453125\n",
      "Epoch: 4, Batch: 411, Loss: 2542.218017578125\n",
      "Epoch: 4, Batch: 412, Loss: 2378.994873046875\n",
      "Epoch: 4, Batch: 413, Loss: 2412.384521484375\n",
      "Epoch: 4, Batch: 414, Loss: 2525.023681640625\n",
      "Epoch: 4, Batch: 415, Loss: 2716.79541015625\n",
      "Epoch: 4, Batch: 416, Loss: 1957.5343017578125\n",
      "Epoch: 4, Batch: 417, Loss: 2432.60107421875\n",
      "Epoch: 4, Batch: 418, Loss: 2591.365478515625\n",
      "Epoch: 4, Batch: 419, Loss: 2172.966796875\n",
      "Epoch: 4, Batch: 420, Loss: 2375.255615234375\n",
      "Epoch: 4, Batch: 421, Loss: 2192.921142578125\n",
      "Epoch: 4, Batch: 422, Loss: 2702.6123046875\n",
      "Epoch: 4, Batch: 423, Loss: 3462.871826171875\n",
      "Epoch: 4, Batch: 424, Loss: 2812.473388671875\n",
      "Epoch: 4, Batch: 425, Loss: 2982.57080078125\n",
      "Epoch: 4, Batch: 426, Loss: 2599.917236328125\n",
      "Epoch: 4, Batch: 427, Loss: 2892.009521484375\n",
      "Epoch: 4, Batch: 428, Loss: 3390.808837890625\n",
      "Epoch: 4, Batch: 429, Loss: 2313.615234375\n",
      "Epoch: 4, Batch: 430, Loss: 2775.2431640625\n",
      "Epoch: 4, Batch: 431, Loss: 3072.095947265625\n",
      "Epoch: 4, Batch: 432, Loss: 2554.366943359375\n",
      "Epoch: 4, Batch: 433, Loss: 2311.387939453125\n",
      "Epoch: 4, Batch: 434, Loss: 2101.00537109375\n",
      "Epoch: 4, Batch: 435, Loss: 2234.71240234375\n",
      "Epoch: 4, Batch: 436, Loss: 2524.090087890625\n",
      "Epoch: 4, Batch: 437, Loss: 3187.801025390625\n",
      "Epoch: 4, Batch: 438, Loss: 2372.350341796875\n",
      "Epoch: 4, Batch: 439, Loss: 2303.234130859375\n",
      "Epoch: 4, Batch: 440, Loss: 3469.17041015625\n",
      "Epoch: 4, Batch: 441, Loss: 2738.22265625\n",
      "Epoch: 4, Batch: 442, Loss: 2467.625244140625\n",
      "Epoch: 4, Batch: 443, Loss: 2566.492919921875\n",
      "Epoch: 4, Batch: 444, Loss: 2925.694580078125\n",
      "Epoch: 4, Batch: 445, Loss: 2733.79833984375\n",
      "Epoch: 4, Batch: 446, Loss: 2386.85888671875\n",
      "Epoch: 4, Batch: 447, Loss: 2960.704345703125\n",
      "Epoch: 4, Batch: 448, Loss: 2246.33154296875\n",
      "Epoch: 4, Batch: 449, Loss: 3776.17919921875\n",
      "Epoch: 4, Batch: 450, Loss: 2709.82568359375\n",
      "Epoch: 4, Batch: 451, Loss: 2955.094482421875\n",
      "Epoch: 4, Batch: 452, Loss: 3038.454345703125\n",
      "Epoch: 4, Batch: 453, Loss: 2490.474853515625\n",
      "Epoch: 4, Batch: 454, Loss: 3018.972900390625\n",
      "Epoch: 4, Batch: 455, Loss: 2736.10107421875\n",
      "Epoch: 4, Batch: 456, Loss: 2410.12109375\n",
      "Epoch: 4, Batch: 457, Loss: 2451.606689453125\n",
      "Epoch: 4, Batch: 458, Loss: 2440.17529296875\n",
      "Epoch: 4, Batch: 459, Loss: 3184.29833984375\n",
      "Epoch: 4, Batch: 460, Loss: 3536.955810546875\n",
      "Epoch: 4, Batch: 461, Loss: 2629.17041015625\n",
      "Epoch: 4, Batch: 462, Loss: 2742.928955078125\n",
      "Epoch: 4, Batch: 463, Loss: 2416.238037109375\n",
      "Epoch: 4, Batch: 464, Loss: 2519.464599609375\n",
      "Epoch: 4, Batch: 465, Loss: 2337.81298828125\n",
      "Epoch: 4, Batch: 466, Loss: 2624.452392578125\n",
      "Epoch: 4, Batch: 467, Loss: 2412.224853515625\n",
      "Epoch: 4, Batch: 468, Loss: 2639.23486328125\n",
      "Epoch: 4, Batch: 469, Loss: 2837.164794921875\n",
      "Epoch: 4, Batch: 470, Loss: 2370.0166015625\n",
      "Epoch: 4, Batch: 471, Loss: 2851.16357421875\n",
      "Epoch: 4, Batch: 472, Loss: 2657.011474609375\n",
      "Epoch: 4, Batch: 473, Loss: 2333.676025390625\n",
      "Epoch: 4, Batch: 474, Loss: 2797.850830078125\n",
      "Epoch: 4, Batch: 475, Loss: 2967.935791015625\n",
      "Epoch: 4, Batch: 476, Loss: 2767.302001953125\n",
      "Epoch: 4, Batch: 477, Loss: 2370.254638671875\n",
      "Epoch: 4, Batch: 478, Loss: 2556.928466796875\n",
      "Epoch: 4, Batch: 479, Loss: 2650.5966796875\n",
      "Epoch: 4, Batch: 480, Loss: 2345.20556640625\n",
      "Epoch: 4, Batch: 481, Loss: 2795.606689453125\n",
      "Epoch: 4, Batch: 482, Loss: 2013.5511474609375\n",
      "Epoch: 4, Batch: 483, Loss: 2346.168701171875\n",
      "Epoch: 4, Batch: 484, Loss: 2969.26904296875\n",
      "Epoch: 4, Batch: 485, Loss: 2436.038818359375\n",
      "Epoch: 4, Batch: 486, Loss: 2489.840576171875\n",
      "Epoch: 4, Batch: 487, Loss: 2593.328369140625\n",
      "Epoch: 4, Batch: 488, Loss: 2973.38037109375\n",
      "Epoch: 4, Batch: 489, Loss: 2694.07470703125\n",
      "Epoch: 4, Batch: 490, Loss: 2073.52099609375\n",
      "Epoch: 4, Batch: 491, Loss: 2926.637939453125\n",
      "Epoch: 4, Batch: 492, Loss: 2539.494873046875\n",
      "Epoch: 4, Batch: 493, Loss: 2126.715576171875\n",
      "Epoch: 4, Batch: 494, Loss: 2556.862060546875\n",
      "Epoch: 4, Batch: 495, Loss: 2407.15234375\n",
      "Epoch: 4, Batch: 496, Loss: 2735.54150390625\n",
      "Epoch: 4, Batch: 497, Loss: 2516.55859375\n",
      "Epoch: 4, Batch: 498, Loss: 1851.6624755859375\n",
      "Epoch: 4, Batch: 499, Loss: 2661.739501953125\n",
      "Epoch: 4, Batch: 500, Loss: 2773.4951171875\n",
      "Epoch: 4, Batch: 501, Loss: 3076.4638671875\n",
      "Epoch: 4, Batch: 502, Loss: 2611.842041015625\n",
      "Epoch: 4, Batch: 503, Loss: 2122.584228515625\n",
      "Epoch: 4, Batch: 504, Loss: 2167.103515625\n",
      "Epoch: 4, Batch: 505, Loss: 2352.07568359375\n",
      "Epoch: 4, Batch: 506, Loss: 2805.78271484375\n",
      "Epoch: 4, Batch: 507, Loss: 2910.73095703125\n",
      "Epoch: 4, Batch: 508, Loss: 2563.645751953125\n",
      "Epoch: 4, Batch: 509, Loss: 3022.611328125\n",
      "Epoch: 4, Batch: 510, Loss: 2211.787109375\n",
      "Epoch: 4, Batch: 511, Loss: 2284.1201171875\n",
      "Epoch: 4, Batch: 512, Loss: 2697.715576171875\n",
      "Epoch: 4, Batch: 513, Loss: 2142.93310546875\n",
      "Epoch: 4, Batch: 514, Loss: 2938.5224609375\n",
      "Epoch: 4, Batch: 515, Loss: 2858.015380859375\n",
      "Epoch: 4, Batch: 516, Loss: 2534.53173828125\n",
      "Epoch: 4, Batch: 517, Loss: 2629.749755859375\n",
      "Epoch: 4, Batch: 518, Loss: 2649.395263671875\n",
      "Epoch: 4, Batch: 519, Loss: 2892.787841796875\n",
      "Epoch: 4, Batch: 520, Loss: 3110.879638671875\n",
      "Epoch: 4, Batch: 521, Loss: 2217.973388671875\n",
      "Epoch: 4, Batch: 522, Loss: 2930.08984375\n",
      "Epoch: 4, Batch: 523, Loss: 2819.72607421875\n",
      "Epoch: 4, Batch: 524, Loss: 2381.541259765625\n",
      "Epoch: 4, Batch: 525, Loss: 2577.537109375\n",
      "Epoch: 4, Batch: 526, Loss: 2212.84521484375\n",
      "Epoch: 4, Batch: 527, Loss: 2768.74462890625\n",
      "Epoch: 4, Batch: 528, Loss: 3186.990478515625\n",
      "Epoch: 4, Batch: 529, Loss: 2565.626708984375\n",
      "Epoch: 4, Batch: 530, Loss: 2631.993896484375\n",
      "Epoch: 4, Batch: 531, Loss: 2558.12353515625\n",
      "Epoch: 4, Batch: 532, Loss: 2924.109375\n",
      "Epoch: 4, Batch: 533, Loss: 2420.810791015625\n",
      "Epoch: 4, Batch: 534, Loss: 2504.144287109375\n",
      "Epoch: 4, Batch: 535, Loss: 2399.915771484375\n",
      "Epoch: 4, Batch: 536, Loss: 2790.869140625\n",
      "Epoch: 4, Batch: 537, Loss: 2568.939697265625\n",
      "Epoch: 4, Batch: 538, Loss: 2791.435791015625\n",
      "Epoch: 4, Batch: 539, Loss: 3074.026611328125\n",
      "Epoch: 4, Batch: 540, Loss: 2396.510986328125\n",
      "Epoch: 4, Batch: 541, Loss: 2529.00830078125\n",
      "Epoch: 4, Batch: 542, Loss: 3041.965576171875\n",
      "Epoch: 4, Batch: 543, Loss: 2486.962890625\n",
      "Epoch: 4, Batch: 544, Loss: 3010.12744140625\n",
      "Epoch: 4, Batch: 545, Loss: 2358.039794921875\n",
      "Epoch: 4, Batch: 546, Loss: 2662.2275390625\n",
      "Epoch: 4, Batch: 547, Loss: 2357.148193359375\n",
      "Epoch: 4, Batch: 548, Loss: 2652.510009765625\n",
      "Epoch: 4, Batch: 549, Loss: 2830.1083984375\n",
      "Epoch: 4, Batch: 550, Loss: 2344.970947265625\n",
      "Epoch: 4, Batch: 551, Loss: 2526.703857421875\n",
      "Epoch: 4, Batch: 552, Loss: 3313.728271484375\n",
      "Epoch: 4, Batch: 553, Loss: 2202.11181640625\n",
      "Epoch: 4, Batch: 554, Loss: 3076.068359375\n",
      "Epoch: 4, Batch: 555, Loss: 3137.335693359375\n",
      "Epoch: 4, Batch: 556, Loss: 2820.373779296875\n",
      "Epoch: 4, Batch: 557, Loss: 2712.056396484375\n",
      "Epoch: 4, Batch: 558, Loss: 2647.152099609375\n",
      "Epoch: 4, Batch: 559, Loss: 2621.2021484375\n",
      "Epoch: 4, Batch: 560, Loss: 2233.55712890625\n",
      "Epoch: 4, Batch: 561, Loss: 2806.7314453125\n",
      "Epoch: 4, Batch: 562, Loss: 2556.14990234375\n",
      "Epoch: 4, Batch: 563, Loss: 2484.74072265625\n",
      "Epoch: 4, Batch: 564, Loss: 2468.62353515625\n",
      "Epoch: 4, Batch: 565, Loss: 3003.218994140625\n",
      "Epoch: 4, Batch: 566, Loss: 2379.76416015625\n",
      "Epoch: 4, Batch: 567, Loss: 2482.5830078125\n",
      "Epoch: 4, Batch: 568, Loss: 2444.726318359375\n",
      "Epoch: 4, Batch: 569, Loss: 2952.52001953125\n",
      "Epoch: 4, Batch: 570, Loss: 2480.238037109375\n",
      "Epoch: 4, Batch: 571, Loss: 2526.614990234375\n",
      "Epoch: 4, Batch: 572, Loss: 3022.4306640625\n",
      "Epoch: 4, Batch: 573, Loss: 2735.31298828125\n",
      "Epoch: 4, Batch: 574, Loss: 3110.5654296875\n",
      "Epoch: 4, Batch: 575, Loss: 3205.145263671875\n",
      "Epoch: 4, Batch: 576, Loss: 2661.630615234375\n",
      "Epoch: 4, Batch: 577, Loss: 3284.384033203125\n",
      "Epoch: 4, Batch: 578, Loss: 2030.1009521484375\n",
      "Epoch: 4, Batch: 579, Loss: 2797.890625\n",
      "Epoch: 4, Batch: 580, Loss: 3158.1142578125\n",
      "Epoch: 4, Batch: 581, Loss: 2805.95947265625\n",
      "Epoch: 4, Batch: 582, Loss: 2695.683349609375\n",
      "Epoch: 4, Batch: 583, Loss: 2900.2431640625\n",
      "Epoch: 4, Batch: 584, Loss: 2573.62744140625\n",
      "Epoch: 4, Batch: 585, Loss: 2815.94287109375\n",
      "Epoch: 4, Batch: 586, Loss: 2698.7333984375\n",
      "Epoch: 4, Batch: 587, Loss: 2408.361328125\n",
      "Epoch: 4, Batch: 588, Loss: 2541.5693359375\n",
      "Epoch: 4, Batch: 589, Loss: 2772.559814453125\n",
      "Epoch: 4, Batch: 590, Loss: 2593.08251953125\n",
      "Epoch: 4, Batch: 591, Loss: 2655.302001953125\n",
      "Epoch: 4, Batch: 592, Loss: 2636.334716796875\n",
      "Epoch: 4, Batch: 593, Loss: 2316.53759765625\n",
      "Epoch: 4, Batch: 594, Loss: 2184.733154296875\n",
      "Epoch: 4, Batch: 595, Loss: 2178.052978515625\n",
      "Epoch: 4, Batch: 596, Loss: 2670.390869140625\n",
      "Epoch: 4, Batch: 597, Loss: 2562.776123046875\n",
      "Epoch: 4, Batch: 598, Loss: 2047.084716796875\n",
      "Epoch: 4, Batch: 599, Loss: 3004.80419921875\n",
      "Epoch: 4, Batch: 600, Loss: 2873.039794921875\n",
      "Epoch: 4, Batch: 601, Loss: 2550.83740234375\n",
      "Epoch: 4, Batch: 602, Loss: 2565.602294921875\n",
      "Epoch: 4, Batch: 603, Loss: 2841.46142578125\n",
      "Epoch: 4, Batch: 604, Loss: 2342.072998046875\n",
      "Epoch: 4, Batch: 605, Loss: 3145.154052734375\n",
      "Epoch: 4, Batch: 606, Loss: 2494.370849609375\n",
      "Epoch: 4, Batch: 607, Loss: 2877.96142578125\n",
      "Epoch: 4, Batch: 608, Loss: 2460.744140625\n",
      "Epoch: 4, Batch: 609, Loss: 2610.9111328125\n",
      "Epoch: 4, Batch: 610, Loss: 2321.015625\n",
      "Epoch: 4, Batch: 611, Loss: 3080.099609375\n",
      "Epoch: 4, Batch: 612, Loss: 2678.36865234375\n",
      "Epoch: 4, Batch: 613, Loss: 2261.91845703125\n",
      "Epoch: 4, Batch: 614, Loss: 2284.871826171875\n",
      "Epoch: 4, Batch: 615, Loss: 2438.2412109375\n",
      "Epoch: 4, Batch: 616, Loss: 2862.61865234375\n",
      "Epoch: 4, Batch: 617, Loss: 2759.551025390625\n",
      "Epoch: 4, Batch: 618, Loss: 2394.895263671875\n",
      "Epoch: 4, Batch: 619, Loss: 2501.234619140625\n",
      "Epoch: 4, Batch: 620, Loss: 2404.510498046875\n",
      "Epoch: 4, Batch: 621, Loss: 2458.4375\n",
      "Epoch: 4, Batch: 622, Loss: 2592.115478515625\n",
      "Epoch: 4, Batch: 623, Loss: 3079.894775390625\n",
      "Epoch: 4, Batch: 624, Loss: 2776.896728515625\n",
      "Epoch: 4, Batch: 625, Loss: 2614.006103515625\n",
      "Epoch: 4, Batch: 626, Loss: 2523.50830078125\n",
      "Epoch: 4, Batch: 627, Loss: 3221.440185546875\n",
      "Epoch: 4, Batch: 628, Loss: 2935.994140625\n",
      "Epoch: 4, Batch: 629, Loss: 2866.54541015625\n",
      "Epoch: 4, Batch: 630, Loss: 2820.1015625\n",
      "Epoch: 4, Batch: 631, Loss: 2053.80224609375\n",
      "Epoch: 4, Batch: 632, Loss: 2833.53564453125\n",
      "Epoch: 4, Batch: 633, Loss: 2651.529296875\n",
      "Epoch: 4, Batch: 634, Loss: 3134.175537109375\n",
      "Epoch: 4, Batch: 635, Loss: 2438.731201171875\n",
      "Epoch: 4, Batch: 636, Loss: 2937.95361328125\n",
      "Epoch: 4, Batch: 637, Loss: 2906.36962890625\n",
      "Epoch: 4, Batch: 638, Loss: 2499.6796875\n",
      "Epoch: 4, Batch: 639, Loss: 2574.5546875\n",
      "Epoch: 4, Batch: 640, Loss: 2559.12646484375\n",
      "Epoch: 4, Batch: 641, Loss: 2630.0205078125\n",
      "Epoch: 4, Batch: 642, Loss: 2663.79248046875\n",
      "Epoch: 4, Batch: 643, Loss: 2950.632080078125\n",
      "Epoch: 4, Batch: 644, Loss: 3021.35791015625\n",
      "Epoch: 4, Batch: 645, Loss: 3157.110107421875\n",
      "Epoch: 4, Batch: 646, Loss: 2157.932861328125\n",
      "Epoch: 4, Batch: 647, Loss: 2340.51318359375\n",
      "Epoch: 4, Batch: 648, Loss: 3062.54833984375\n",
      "Epoch: 4, Batch: 649, Loss: 2703.1005859375\n",
      "Epoch: 4, Batch: 650, Loss: 2640.27490234375\n",
      "Epoch: 4, Batch: 651, Loss: 2846.953125\n",
      "Epoch: 4, Batch: 652, Loss: 2846.243896484375\n",
      "Epoch: 4, Batch: 653, Loss: 2554.006591796875\n",
      "Epoch: 4, Batch: 654, Loss: 2735.92431640625\n",
      "Epoch: 4, Batch: 655, Loss: 2821.23779296875\n",
      "Epoch: 4, Batch: 656, Loss: 2566.572998046875\n",
      "Epoch: 4, Batch: 657, Loss: 3466.0703125\n",
      "Epoch: 4, Batch: 658, Loss: 3070.51416015625\n",
      "Epoch: 4, Batch: 659, Loss: 2591.292236328125\n",
      "Epoch: 4, Batch: 660, Loss: 2872.50341796875\n",
      "Epoch: 4, Batch: 661, Loss: 2639.3974609375\n",
      "Epoch: 4, Batch: 662, Loss: 2079.589111328125\n",
      "Epoch: 4, Batch: 663, Loss: 2721.603515625\n",
      "Epoch: 4, Batch: 664, Loss: 2579.877197265625\n",
      "Epoch: 4, Batch: 665, Loss: 2824.583740234375\n",
      "Epoch: 4, Batch: 666, Loss: 2645.579345703125\n",
      "Epoch: 4, Batch: 667, Loss: 2396.975341796875\n",
      "Epoch: 4, Batch: 668, Loss: 2145.063720703125\n",
      "Epoch: 4, Batch: 669, Loss: 2317.68505859375\n",
      "Epoch: 4, Batch: 670, Loss: 2590.08251953125\n",
      "Epoch: 4, Batch: 671, Loss: 2816.514892578125\n",
      "Epoch: 4, Batch: 672, Loss: 2464.290283203125\n",
      "Epoch: 4, Batch: 673, Loss: 3001.332275390625\n",
      "Epoch: 4, Batch: 674, Loss: 3002.7763671875\n",
      "Epoch: 4, Batch: 675, Loss: 2955.28857421875\n",
      "Epoch: 4, Batch: 676, Loss: 3045.2451171875\n",
      "Epoch: 4, Batch: 677, Loss: 2706.25830078125\n",
      "Epoch: 4, Batch: 678, Loss: 2792.52978515625\n",
      "Epoch: 4, Batch: 679, Loss: 2473.9853515625\n",
      "Epoch: 4, Batch: 680, Loss: 2861.042724609375\n",
      "Epoch: 4, Batch: 681, Loss: 3181.374755859375\n",
      "Epoch: 4, Batch: 682, Loss: 2592.197509765625\n",
      "Epoch: 4, Batch: 683, Loss: 2321.8408203125\n",
      "Epoch: 4, Batch: 684, Loss: 2609.77294921875\n",
      "Epoch: 4, Batch: 685, Loss: 2671.5595703125\n",
      "Epoch: 4, Batch: 686, Loss: 2258.814208984375\n",
      "Epoch: 4, Batch: 687, Loss: 2601.289306640625\n",
      "Epoch: 4, Batch: 688, Loss: 2872.5244140625\n",
      "Epoch: 4, Batch: 689, Loss: 2975.9931640625\n",
      "Epoch: 4, Batch: 690, Loss: 2756.95361328125\n",
      "Epoch: 4, Batch: 691, Loss: 2708.4716796875\n",
      "Epoch: 4, Batch: 692, Loss: 2766.16845703125\n",
      "Epoch: 4, Batch: 693, Loss: 2858.66845703125\n",
      "Epoch: 4, Batch: 694, Loss: 2713.819091796875\n",
      "Epoch: 4, Batch: 695, Loss: 2280.00634765625\n",
      "Epoch: 4, Batch: 696, Loss: 3062.185302734375\n",
      "Epoch: 4, Batch: 697, Loss: 2432.3701171875\n",
      "Epoch: 4, Batch: 698, Loss: 2804.8720703125\n",
      "Epoch: 4, Batch: 699, Loss: 2177.249267578125\n",
      "Epoch: 4, Batch: 700, Loss: 2462.961181640625\n",
      "Epoch: 4, Batch: 701, Loss: 2213.09033203125\n",
      "Epoch: 4, Batch: 702, Loss: 3188.978759765625\n",
      "Epoch: 4, Batch: 703, Loss: 2035.47216796875\n",
      "Epoch: 4, Batch: 704, Loss: 2542.79931640625\n",
      "Epoch: 4, Batch: 705, Loss: 1644.504150390625\n",
      "Epoch: 4, Batch: 706, Loss: 2305.672119140625\n",
      "Epoch: 4, Batch: 707, Loss: 2497.102294921875\n",
      "Epoch: 4, Batch: 708, Loss: 2715.6328125\n",
      "Epoch: 4, Batch: 709, Loss: 2671.771240234375\n",
      "Epoch: 4, Batch: 710, Loss: 2685.94091796875\n",
      "Epoch: 4, Batch: 711, Loss: 2827.554443359375\n",
      "Epoch: 4, Batch: 712, Loss: 2661.486572265625\n",
      "Epoch: 4, Batch: 713, Loss: 3077.2734375\n",
      "Epoch: 4, Batch: 714, Loss: 2734.17041015625\n",
      "Epoch: 4, Batch: 715, Loss: 2857.420166015625\n",
      "Epoch: 4, Batch: 716, Loss: 2910.3271484375\n",
      "Epoch: 4, Batch: 717, Loss: 2826.902587890625\n",
      "Epoch: 4, Batch: 718, Loss: 2685.931884765625\n",
      "Epoch: 4, Batch: 719, Loss: 2634.260009765625\n",
      "Epoch: 4, Batch: 720, Loss: 2566.48095703125\n",
      "Epoch: 4, Batch: 721, Loss: 2686.328125\n",
      "Epoch: 4, Batch: 722, Loss: 2860.5\n",
      "Epoch: 4, Batch: 723, Loss: 2543.337158203125\n",
      "Epoch: 4, Batch: 724, Loss: 2390.164794921875\n",
      "Epoch: 4, Batch: 725, Loss: 2789.552978515625\n",
      "Epoch: 4, Batch: 726, Loss: 2609.552978515625\n",
      "Epoch: 4, Batch: 727, Loss: 2730.887939453125\n",
      "Epoch: 4, Batch: 728, Loss: 2541.615478515625\n",
      "Epoch: 4, Batch: 729, Loss: 2560.953369140625\n",
      "Epoch: 4, Batch: 730, Loss: 2672.057861328125\n",
      "Epoch: 4, Batch: 731, Loss: 2628.70751953125\n",
      "Epoch: 4, Batch: 732, Loss: 2332.74462890625\n",
      "Epoch: 4, Batch: 733, Loss: 3387.01708984375\n",
      "Epoch: 4, Batch: 734, Loss: 3163.168212890625\n",
      "Epoch: 4, Batch: 735, Loss: 2880.189453125\n",
      "Epoch: 4, Batch: 736, Loss: 2870.58251953125\n",
      "Epoch: 4, Batch: 737, Loss: 2519.0390625\n",
      "Epoch: 4, Batch: 738, Loss: 2627.302734375\n",
      "Epoch: 4, Batch: 739, Loss: 3004.188232421875\n",
      "Epoch: 4, Batch: 740, Loss: 2623.859619140625\n",
      "Epoch: 4, Batch: 741, Loss: 2733.34375\n",
      "Epoch: 4, Batch: 742, Loss: 2753.49853515625\n",
      "Epoch: 4, Batch: 743, Loss: 2974.94970703125\n",
      "Epoch: 4, Batch: 744, Loss: 2444.22265625\n",
      "Epoch: 4, Batch: 745, Loss: 2346.339599609375\n",
      "Epoch: 4, Batch: 746, Loss: 2393.081787109375\n",
      "Epoch: 4, Batch: 747, Loss: 2406.655029296875\n",
      "Epoch: 4, Batch: 748, Loss: 2964.7705078125\n",
      "Epoch: 4, Batch: 749, Loss: 2406.30322265625\n",
      "Epoch: 4, Batch: 750, Loss: 3011.023681640625\n",
      "Epoch: 4, Batch: 751, Loss: 2344.26025390625\n",
      "Epoch: 4, Batch: 752, Loss: 2345.370361328125\n",
      "Epoch: 4, Batch: 753, Loss: 2199.734130859375\n",
      "Epoch: 4, Batch: 754, Loss: 2578.838134765625\n",
      "Epoch: 4, Batch: 755, Loss: 2908.3427734375\n",
      "Epoch: 4, Batch: 756, Loss: 2418.0859375\n",
      "Epoch: 4, Batch: 757, Loss: 2440.10693359375\n",
      "Epoch: 4, Batch: 758, Loss: 2295.51611328125\n",
      "Epoch: 4, Batch: 759, Loss: 2843.76220703125\n",
      "Epoch: 4, Batch: 760, Loss: 2780.2529296875\n",
      "Epoch: 4, Batch: 761, Loss: 2272.7529296875\n",
      "Epoch: 4, Batch: 762, Loss: 2486.331298828125\n",
      "Epoch: 4, Batch: 763, Loss: 2636.14794921875\n",
      "Epoch: 4, Batch: 764, Loss: 2666.243408203125\n",
      "Epoch: 4, Batch: 765, Loss: 2932.4130859375\n",
      "Epoch: 4, Batch: 766, Loss: 2732.80224609375\n",
      "Epoch: 4, Batch: 767, Loss: 2662.649169921875\n",
      "Epoch: 4, Batch: 768, Loss: 2388.556884765625\n",
      "Epoch: 4, Batch: 769, Loss: 2421.010009765625\n",
      "Epoch: 4, Batch: 770, Loss: 2615.0634765625\n",
      "Epoch: 4, Batch: 771, Loss: 2710.906494140625\n",
      "Epoch: 4, Batch: 772, Loss: 3480.86376953125\n",
      "Epoch: 4, Batch: 773, Loss: 2595.892822265625\n",
      "Epoch: 4, Batch: 774, Loss: 2882.76123046875\n",
      "Epoch: 4, Batch: 775, Loss: 2679.916015625\n",
      "Epoch: 4, Batch: 776, Loss: 2700.0185546875\n",
      "Epoch: 4, Batch: 777, Loss: 2518.33544921875\n",
      "Epoch: 4, Batch: 778, Loss: 2689.733154296875\n",
      "Epoch: 4, Batch: 779, Loss: 2888.22021484375\n",
      "Epoch: 4, Batch: 780, Loss: 1947.1551513671875\n",
      "Epoch: 4, Batch: 781, Loss: 3075.377197265625\n",
      "Epoch: 4, Batch: 782, Loss: 2178.165771484375\n",
      "Epoch: 4, Batch: 783, Loss: 3104.264404296875\n",
      "Epoch: 4, Batch: 784, Loss: 2790.54443359375\n",
      "Epoch: 4, Batch: 785, Loss: 2324.361572265625\n",
      "Epoch: 4, Batch: 786, Loss: 2478.05419921875\n",
      "Epoch: 4, Batch: 787, Loss: 2795.909912109375\n",
      "Epoch: 4, Batch: 788, Loss: 2815.571044921875\n",
      "Epoch: 4, Batch: 789, Loss: 2082.67724609375\n",
      "Epoch: 4, Batch: 790, Loss: 2534.961181640625\n",
      "Epoch: 4, Batch: 791, Loss: 2733.64892578125\n",
      "Epoch: 4, Batch: 792, Loss: 2839.493896484375\n",
      "Epoch: 4, Batch: 793, Loss: 2971.884033203125\n",
      "Epoch: 4, Batch: 794, Loss: 2380.012451171875\n",
      "Epoch: 4, Batch: 795, Loss: 2512.588134765625\n",
      "Epoch: 4, Batch: 796, Loss: 2559.001220703125\n",
      "Epoch: 4, Batch: 797, Loss: 2452.359130859375\n",
      "Epoch: 4, Batch: 798, Loss: 2320.964111328125\n",
      "Epoch: 4, Batch: 799, Loss: 2418.179931640625\n",
      "Epoch: 4, Batch: 800, Loss: 3054.09130859375\n",
      "Epoch: 4, Batch: 801, Loss: 2441.701171875\n",
      "Epoch: 4, Batch: 802, Loss: 3073.905517578125\n",
      "Epoch: 4, Batch: 803, Loss: 2938.197998046875\n",
      "Epoch: 4, Batch: 804, Loss: 2930.2158203125\n",
      "Epoch: 4, Batch: 805, Loss: 2964.89111328125\n",
      "Epoch: 4, Batch: 806, Loss: 3020.6630859375\n",
      "Epoch: 4, Batch: 807, Loss: 3066.1533203125\n",
      "Epoch: 4, Batch: 808, Loss: 2252.541015625\n",
      "Epoch: 4, Batch: 809, Loss: 3031.15673828125\n",
      "Epoch: 4, Batch: 810, Loss: 2939.875732421875\n",
      "Epoch: 4, Batch: 811, Loss: 2724.6689453125\n",
      "Epoch: 4, Batch: 812, Loss: 2560.8623046875\n",
      "Epoch: 4, Batch: 813, Loss: 2996.844482421875\n",
      "Epoch: 4, Batch: 814, Loss: 2283.167236328125\n",
      "Epoch: 4, Batch: 815, Loss: 2987.21142578125\n",
      "Epoch: 4, Batch: 816, Loss: 2380.55029296875\n",
      "Epoch: 4, Batch: 817, Loss: 2505.843994140625\n",
      "Epoch: 4, Batch: 818, Loss: 2285.62548828125\n",
      "Epoch: 4, Batch: 819, Loss: 3141.5703125\n",
      "Epoch: 4, Batch: 820, Loss: 2562.404296875\n",
      "Epoch: 4, Batch: 821, Loss: 2241.40478515625\n",
      "Epoch: 4, Batch: 822, Loss: 2824.70703125\n",
      "Epoch: 4, Batch: 823, Loss: 3004.007080078125\n",
      "Epoch: 4, Batch: 824, Loss: 2792.84619140625\n",
      "Epoch: 4, Batch: 825, Loss: 2735.470458984375\n",
      "Epoch: 4, Batch: 826, Loss: 2231.22021484375\n",
      "Epoch: 4, Batch: 827, Loss: 3271.73046875\n",
      "Epoch: 4, Batch: 828, Loss: 2735.849609375\n",
      "Epoch: 4, Batch: 829, Loss: 2909.959228515625\n",
      "Epoch: 4, Batch: 830, Loss: 2740.375\n",
      "Epoch: 4, Batch: 831, Loss: 2333.397705078125\n",
      "Epoch: 4, Batch: 832, Loss: 2630.93408203125\n",
      "Epoch: 4, Batch: 833, Loss: 2358.18896484375\n",
      "Epoch: 4, Batch: 834, Loss: 2117.576416015625\n",
      "Epoch: 4, Batch: 835, Loss: 2053.286376953125\n",
      "Epoch: 4, Batch: 836, Loss: 2820.759765625\n",
      "Epoch: 4, Batch: 837, Loss: 3099.162109375\n",
      "Epoch: 4, Batch: 838, Loss: 2770.514404296875\n",
      "Epoch: 4, Batch: 839, Loss: 2686.995849609375\n",
      "Epoch: 4, Batch: 840, Loss: 2507.155517578125\n",
      "Epoch: 4, Batch: 841, Loss: 2087.5234375\n",
      "Epoch: 4, Batch: 842, Loss: 2587.673583984375\n",
      "Epoch: 4, Batch: 843, Loss: 2395.1318359375\n",
      "Epoch: 4, Batch: 844, Loss: 3191.560302734375\n",
      "Epoch: 4, Batch: 845, Loss: 2430.672119140625\n",
      "Epoch: 4, Batch: 846, Loss: 2951.447998046875\n",
      "Epoch: 4, Batch: 847, Loss: 2674.37353515625\n",
      "Epoch: 4, Batch: 848, Loss: 3091.5615234375\n",
      "Epoch: 4, Batch: 849, Loss: 2845.1650390625\n",
      "Epoch: 4, Batch: 850, Loss: 2440.93408203125\n",
      "Epoch: 4, Batch: 851, Loss: 2489.374755859375\n",
      "Epoch: 4, Batch: 852, Loss: 2402.57177734375\n",
      "Epoch: 4, Batch: 853, Loss: 2977.15625\n",
      "Epoch: 4, Batch: 854, Loss: 2930.6494140625\n",
      "Epoch: 4, Batch: 855, Loss: 3050.485595703125\n",
      "Epoch: 4, Batch: 856, Loss: 2352.56494140625\n",
      "Epoch: 4, Batch: 857, Loss: 2840.44189453125\n",
      "Epoch: 4, Batch: 858, Loss: 3035.1728515625\n",
      "Epoch: 4, Batch: 859, Loss: 2716.37548828125\n",
      "Epoch: 4, Batch: 860, Loss: 2582.749267578125\n",
      "Epoch: 4, Batch: 861, Loss: 2200.269775390625\n",
      "Epoch: 4, Batch: 862, Loss: 2629.00146484375\n",
      "Epoch: 4, Batch: 863, Loss: 2553.264404296875\n",
      "Epoch: 4, Batch: 864, Loss: 2616.21337890625\n",
      "Epoch: 4, Batch: 865, Loss: 3048.6640625\n",
      "Epoch: 4, Batch: 866, Loss: 2296.08056640625\n",
      "Epoch: 4, Batch: 867, Loss: 2616.292724609375\n",
      "Epoch: 4, Batch: 868, Loss: 2993.66162109375\n",
      "Epoch: 4, Batch: 869, Loss: 2717.3359375\n",
      "Epoch: 4, Batch: 870, Loss: 2420.3193359375\n",
      "Epoch: 4, Batch: 871, Loss: 2960.146240234375\n",
      "Epoch: 4, Batch: 872, Loss: 3792.26318359375\n",
      "Epoch: 4, Batch: 873, Loss: 2676.18359375\n",
      "Epoch: 4, Batch: 874, Loss: 2854.693603515625\n",
      "Epoch: 4, Batch: 875, Loss: 2539.78857421875\n",
      "Epoch: 4, Batch: 876, Loss: 3046.58349609375\n",
      "Epoch: 4, Batch: 877, Loss: 2994.681396484375\n",
      "Epoch: 4, Batch: 878, Loss: 3106.343017578125\n",
      "Epoch: 4, Batch: 879, Loss: 2552.736572265625\n",
      "Epoch: 4, Batch: 880, Loss: 2355.790771484375\n",
      "Epoch: 4, Batch: 881, Loss: 2506.082763671875\n",
      "Epoch: 4, Batch: 882, Loss: 2656.50390625\n",
      "Epoch: 4, Batch: 883, Loss: 2942.890380859375\n",
      "Epoch: 4, Batch: 884, Loss: 2781.506591796875\n",
      "Epoch: 4, Batch: 885, Loss: 2765.18359375\n",
      "Epoch: 4, Batch: 886, Loss: 2166.9638671875\n",
      "Epoch: 4, Batch: 887, Loss: 2553.298095703125\n",
      "Epoch: 4, Batch: 888, Loss: 2913.0361328125\n",
      "Epoch: 4, Batch: 889, Loss: 2738.93408203125\n",
      "Epoch: 4, Batch: 890, Loss: 2255.742919921875\n",
      "Epoch: 4, Batch: 891, Loss: 2629.662841796875\n",
      "Epoch: 4, Batch: 892, Loss: 2587.11376953125\n",
      "Epoch: 4, Batch: 893, Loss: 2095.4384765625\n",
      "Epoch: 4, Batch: 894, Loss: 2883.9970703125\n",
      "Epoch: 4, Batch: 895, Loss: 2555.716796875\n",
      "Epoch: 4, Batch: 896, Loss: 2082.643798828125\n",
      "Epoch: 4, Batch: 897, Loss: 2303.535400390625\n",
      "Epoch: 4, Batch: 898, Loss: 2426.1318359375\n",
      "Epoch: 4, Batch: 899, Loss: 2462.892333984375\n",
      "Epoch: 4, Batch: 900, Loss: 2633.2177734375\n",
      "Epoch: 4, Batch: 901, Loss: 2322.750244140625\n",
      "Epoch: 4, Batch: 902, Loss: 2833.8291015625\n",
      "Epoch: 4, Batch: 903, Loss: 3048.864990234375\n",
      "Epoch: 4, Batch: 904, Loss: 2430.9814453125\n",
      "Epoch: 4, Batch: 905, Loss: 2501.615478515625\n",
      "Epoch: 4, Batch: 906, Loss: 2222.19677734375\n",
      "Epoch: 4, Batch: 907, Loss: 3205.976806640625\n",
      "Epoch: 4, Batch: 908, Loss: 2776.421630859375\n",
      "Epoch: 4, Batch: 909, Loss: 2451.904052734375\n",
      "Epoch: 4, Batch: 910, Loss: 2163.10009765625\n",
      "Epoch: 4, Batch: 911, Loss: 2871.33056640625\n",
      "Epoch: 4, Batch: 912, Loss: 3146.18701171875\n",
      "Epoch: 4, Batch: 913, Loss: 2785.132568359375\n",
      "Epoch: 4, Batch: 914, Loss: 3123.71435546875\n",
      "Epoch: 4, Batch: 915, Loss: 2430.219970703125\n",
      "Epoch: 4, Batch: 916, Loss: 3155.63818359375\n",
      "Epoch: 4, Batch: 917, Loss: 1996.21728515625\n",
      "Epoch: 4, Batch: 918, Loss: 2693.92529296875\n",
      "Epoch: 4, Batch: 919, Loss: 2851.18896484375\n",
      "Epoch: 4, Batch: 920, Loss: 2649.86767578125\n",
      "Epoch: 4, Batch: 921, Loss: 2604.15625\n",
      "Epoch: 4, Batch: 922, Loss: 1937.04345703125\n",
      "Epoch: 4, Batch: 923, Loss: 2655.25537109375\n",
      "Epoch: 4, Batch: 924, Loss: 2550.311279296875\n",
      "Epoch: 4, Batch: 925, Loss: 2625.37353515625\n",
      "Epoch: 4, Batch: 926, Loss: 2862.75732421875\n",
      "Epoch: 4, Batch: 927, Loss: 2267.8095703125\n",
      "Epoch: 4, Batch: 928, Loss: 2604.19580078125\n",
      "Epoch: 4, Batch: 929, Loss: 2750.40478515625\n",
      "Epoch: 4, Batch: 930, Loss: 2634.98974609375\n",
      "Epoch: 4, Batch: 931, Loss: 2331.45849609375\n",
      "Epoch: 4, Batch: 932, Loss: 2535.314453125\n",
      "Epoch: 4, Batch: 933, Loss: 2623.958251953125\n",
      "Epoch: 4, Batch: 934, Loss: 2444.690185546875\n",
      "Epoch: 4, Batch: 935, Loss: 3141.68212890625\n",
      "Epoch: 4, Batch: 936, Loss: 2716.920654296875\n",
      "Epoch: 4, Batch: 937, Loss: 2540.02197265625\n",
      "Epoch: 4, Batch: 938, Loss: 2825.93896484375\n",
      "Epoch: 4, Batch: 939, Loss: 2079.552734375\n",
      "Epoch: 4, Batch: 940, Loss: 2114.46240234375\n",
      "Epoch: 4, Batch: 941, Loss: 2564.64306640625\n",
      "Epoch: 4, Batch: 942, Loss: 2247.438232421875\n",
      "Epoch: 4, Batch: 943, Loss: 2812.3955078125\n",
      "Epoch: 4, Batch: 944, Loss: 2332.7353515625\n",
      "Epoch: 4, Batch: 945, Loss: 2857.900634765625\n",
      "Epoch: 4, Batch: 946, Loss: 2213.9677734375\n",
      "Epoch: 4, Batch: 947, Loss: 2936.590576171875\n",
      "Epoch: 4, Batch: 948, Loss: 2985.9716796875\n",
      "Epoch: 4, Batch: 949, Loss: 2849.40673828125\n",
      "Epoch: 4, Batch: 950, Loss: 2695.675537109375\n",
      "Epoch: 4, Batch: 951, Loss: 2290.5244140625\n",
      "Epoch: 4, Batch: 952, Loss: 2712.494384765625\n",
      "Epoch: 4, Batch: 953, Loss: 2436.117431640625\n",
      "Epoch: 4, Batch: 954, Loss: 2519.182373046875\n",
      "Epoch: 4, Batch: 955, Loss: 2909.8818359375\n",
      "Epoch: 4, Batch: 956, Loss: 2654.112060546875\n",
      "Epoch: 4, Batch: 957, Loss: 2395.925537109375\n",
      "Epoch: 4, Batch: 958, Loss: 2800.060791015625\n",
      "Epoch: 4, Batch: 959, Loss: 2337.89892578125\n",
      "Epoch: 4, Batch: 960, Loss: 2541.533447265625\n",
      "Epoch: 4, Batch: 961, Loss: 2862.846923828125\n",
      "Epoch: 4, Batch: 962, Loss: 2251.283203125\n",
      "Epoch: 4, Batch: 963, Loss: 2275.96923828125\n",
      "Epoch: 4, Batch: 964, Loss: 2058.197998046875\n",
      "Epoch: 4, Batch: 965, Loss: 2651.14990234375\n",
      "Epoch: 4, Batch: 966, Loss: 2316.755126953125\n",
      "Epoch: 4, Batch: 967, Loss: 2465.280029296875\n",
      "Epoch: 4, Batch: 968, Loss: 2473.797119140625\n",
      "Epoch: 4, Batch: 969, Loss: 2645.298095703125\n",
      "Epoch: 4, Batch: 970, Loss: 3318.93017578125\n",
      "Epoch: 4, Batch: 971, Loss: 2554.496337890625\n",
      "Epoch: 4, Batch: 972, Loss: 2173.142333984375\n",
      "Epoch: 4, Batch: 973, Loss: 2765.970947265625\n",
      "Epoch: 4, Batch: 974, Loss: 2616.26220703125\n",
      "Epoch: 4, Batch: 975, Loss: 3000.95654296875\n",
      "Epoch: 4, Batch: 976, Loss: 1956.09423828125\n",
      "Epoch: 4, Batch: 977, Loss: 3080.207275390625\n",
      "Epoch: 4, Batch: 978, Loss: 2918.706298828125\n",
      "Epoch: 4, Batch: 979, Loss: 3135.5390625\n",
      "Epoch: 4, Batch: 980, Loss: 2700.805419921875\n",
      "Epoch: 4, Batch: 981, Loss: 2618.76708984375\n",
      "Epoch: 4, Batch: 982, Loss: 3356.610595703125\n",
      "Epoch: 4, Batch: 983, Loss: 2607.689697265625\n",
      "Epoch: 4, Batch: 984, Loss: 2611.3046875\n",
      "Epoch: 4, Batch: 985, Loss: 2634.34765625\n",
      "Epoch: 4, Batch: 986, Loss: 2406.0703125\n",
      "Epoch: 4, Batch: 987, Loss: 2142.119140625\n",
      "Epoch: 4, Batch: 988, Loss: 2646.177490234375\n",
      "Epoch: 4, Batch: 989, Loss: 2643.5205078125\n",
      "Epoch: 4, Batch: 990, Loss: 2501.730712890625\n",
      "Epoch: 4, Batch: 991, Loss: 2852.640380859375\n",
      "Epoch: 4, Batch: 992, Loss: 2323.76513671875\n",
      "Epoch: 4, Batch: 993, Loss: 2659.96630859375\n",
      "Epoch: 4, Batch: 994, Loss: 2211.675048828125\n",
      "Epoch: 4, Batch: 995, Loss: 2177.16552734375\n",
      "Epoch: 4, Batch: 996, Loss: 2462.370361328125\n",
      "Epoch: 4, Batch: 997, Loss: 1501.802490234375\n",
      "Epoch: 4, Batch: 998, Loss: 2861.83056640625\n",
      "Epoch: 4, Batch: 999, Loss: 2385.682861328125\n",
      "Epoch: 5, Batch: 0, Loss: 2985.98583984375\n",
      "Epoch: 5, Batch: 1, Loss: 3153.0185546875\n",
      "Epoch: 5, Batch: 2, Loss: 2635.7021484375\n",
      "Epoch: 5, Batch: 3, Loss: 3138.022705078125\n",
      "Epoch: 5, Batch: 4, Loss: 2677.77099609375\n",
      "Epoch: 5, Batch: 5, Loss: 2726.751953125\n",
      "Epoch: 5, Batch: 6, Loss: 2633.2138671875\n",
      "Epoch: 5, Batch: 7, Loss: 2215.740966796875\n",
      "Epoch: 5, Batch: 8, Loss: 2722.53369140625\n",
      "Epoch: 5, Batch: 9, Loss: 2501.446533203125\n",
      "Epoch: 5, Batch: 10, Loss: 2353.607666015625\n",
      "Epoch: 5, Batch: 11, Loss: 2788.94384765625\n",
      "Epoch: 5, Batch: 12, Loss: 2299.307861328125\n",
      "Epoch: 5, Batch: 13, Loss: 2060.51025390625\n",
      "Epoch: 5, Batch: 14, Loss: 2600.10595703125\n",
      "Epoch: 5, Batch: 15, Loss: 2263.06689453125\n",
      "Epoch: 5, Batch: 16, Loss: 2533.971435546875\n",
      "Epoch: 5, Batch: 17, Loss: 3104.484375\n",
      "Epoch: 5, Batch: 18, Loss: 2148.990234375\n",
      "Epoch: 5, Batch: 19, Loss: 2849.841796875\n",
      "Epoch: 5, Batch: 20, Loss: 2540.383544921875\n",
      "Epoch: 5, Batch: 21, Loss: 3262.6015625\n",
      "Epoch: 5, Batch: 22, Loss: 2153.51953125\n",
      "Epoch: 5, Batch: 23, Loss: 2343.58447265625\n",
      "Epoch: 5, Batch: 24, Loss: 3089.1025390625\n",
      "Epoch: 5, Batch: 25, Loss: 2788.96044921875\n",
      "Epoch: 5, Batch: 26, Loss: 2545.463623046875\n",
      "Epoch: 5, Batch: 27, Loss: 2402.03076171875\n",
      "Epoch: 5, Batch: 28, Loss: 2817.551513671875\n",
      "Epoch: 5, Batch: 29, Loss: 2751.3037109375\n",
      "Epoch: 5, Batch: 30, Loss: 2656.836181640625\n",
      "Epoch: 5, Batch: 31, Loss: 1774.7095947265625\n",
      "Epoch: 5, Batch: 32, Loss: 2609.88037109375\n",
      "Epoch: 5, Batch: 33, Loss: 3227.611083984375\n",
      "Epoch: 5, Batch: 34, Loss: 2695.786865234375\n",
      "Epoch: 5, Batch: 35, Loss: 2413.733154296875\n",
      "Epoch: 5, Batch: 36, Loss: 2651.77783203125\n",
      "Epoch: 5, Batch: 37, Loss: 2242.424560546875\n",
      "Epoch: 5, Batch: 38, Loss: 2864.486328125\n",
      "Epoch: 5, Batch: 39, Loss: 2517.673095703125\n",
      "Epoch: 5, Batch: 40, Loss: 2520.90478515625\n",
      "Epoch: 5, Batch: 41, Loss: 2661.1826171875\n",
      "Epoch: 5, Batch: 42, Loss: 2855.5205078125\n",
      "Epoch: 5, Batch: 43, Loss: 3210.128173828125\n",
      "Epoch: 5, Batch: 44, Loss: 2173.12353515625\n",
      "Epoch: 5, Batch: 45, Loss: 2362.407470703125\n",
      "Epoch: 5, Batch: 46, Loss: 2492.531494140625\n",
      "Epoch: 5, Batch: 47, Loss: 2948.123291015625\n",
      "Epoch: 5, Batch: 48, Loss: 2655.017333984375\n",
      "Epoch: 5, Batch: 49, Loss: 2879.685546875\n",
      "Epoch: 5, Batch: 50, Loss: 2860.089599609375\n",
      "Epoch: 5, Batch: 51, Loss: 2735.600830078125\n",
      "Epoch: 5, Batch: 52, Loss: 2375.834228515625\n",
      "Epoch: 5, Batch: 53, Loss: 2864.471435546875\n",
      "Epoch: 5, Batch: 54, Loss: 3027.56982421875\n",
      "Epoch: 5, Batch: 55, Loss: 3184.584716796875\n",
      "Epoch: 5, Batch: 56, Loss: 2657.995849609375\n",
      "Epoch: 5, Batch: 57, Loss: 2750.069580078125\n",
      "Epoch: 5, Batch: 58, Loss: 2218.611083984375\n",
      "Epoch: 5, Batch: 59, Loss: 2625.458984375\n",
      "Epoch: 5, Batch: 60, Loss: 2891.47314453125\n",
      "Epoch: 5, Batch: 61, Loss: 2364.871337890625\n",
      "Epoch: 5, Batch: 62, Loss: 2982.513427734375\n",
      "Epoch: 5, Batch: 63, Loss: 2435.918212890625\n",
      "Epoch: 5, Batch: 64, Loss: 3040.685302734375\n",
      "Epoch: 5, Batch: 65, Loss: 3179.88671875\n",
      "Epoch: 5, Batch: 66, Loss: 2225.115234375\n",
      "Epoch: 5, Batch: 67, Loss: 2682.634765625\n",
      "Epoch: 5, Batch: 68, Loss: 2494.09375\n",
      "Epoch: 5, Batch: 69, Loss: 2681.86181640625\n",
      "Epoch: 5, Batch: 70, Loss: 2968.037353515625\n",
      "Epoch: 5, Batch: 71, Loss: 2499.95556640625\n",
      "Epoch: 5, Batch: 72, Loss: 2739.669921875\n",
      "Epoch: 5, Batch: 73, Loss: 3103.86962890625\n",
      "Epoch: 5, Batch: 74, Loss: 2508.58251953125\n",
      "Epoch: 5, Batch: 75, Loss: 2774.369140625\n",
      "Epoch: 5, Batch: 76, Loss: 2532.33984375\n",
      "Epoch: 5, Batch: 77, Loss: 2832.199951171875\n",
      "Epoch: 5, Batch: 78, Loss: 2474.895263671875\n",
      "Epoch: 5, Batch: 79, Loss: 2542.835693359375\n",
      "Epoch: 5, Batch: 80, Loss: 2685.96435546875\n",
      "Epoch: 5, Batch: 81, Loss: 2460.9599609375\n",
      "Epoch: 5, Batch: 82, Loss: 2642.1728515625\n",
      "Epoch: 5, Batch: 83, Loss: 2753.26416015625\n",
      "Epoch: 5, Batch: 84, Loss: 2386.75390625\n",
      "Epoch: 5, Batch: 85, Loss: 2504.2763671875\n",
      "Epoch: 5, Batch: 86, Loss: 2722.662109375\n",
      "Epoch: 5, Batch: 87, Loss: 2542.07470703125\n",
      "Epoch: 5, Batch: 88, Loss: 3051.17578125\n",
      "Epoch: 5, Batch: 89, Loss: 2557.545166015625\n",
      "Epoch: 5, Batch: 90, Loss: 2689.76123046875\n",
      "Epoch: 5, Batch: 91, Loss: 2884.066162109375\n",
      "Epoch: 5, Batch: 92, Loss: 2293.11181640625\n",
      "Epoch: 5, Batch: 93, Loss: 2064.7802734375\n",
      "Epoch: 5, Batch: 94, Loss: 3127.042236328125\n",
      "Epoch: 5, Batch: 95, Loss: 2891.7333984375\n",
      "Epoch: 5, Batch: 96, Loss: 3040.64794921875\n",
      "Epoch: 5, Batch: 97, Loss: 2468.122802734375\n",
      "Epoch: 5, Batch: 98, Loss: 2600.2578125\n",
      "Epoch: 5, Batch: 99, Loss: 2518.13916015625\n",
      "Epoch: 5, Batch: 100, Loss: 2719.42333984375\n",
      "Epoch: 5, Batch: 101, Loss: 2683.785888671875\n",
      "Epoch: 5, Batch: 102, Loss: 2988.7333984375\n",
      "Epoch: 5, Batch: 103, Loss: 2344.6044921875\n",
      "Epoch: 5, Batch: 104, Loss: 2169.4501953125\n",
      "Epoch: 5, Batch: 105, Loss: 1938.30859375\n",
      "Epoch: 5, Batch: 106, Loss: 2396.671875\n",
      "Epoch: 5, Batch: 107, Loss: 2440.706787109375\n",
      "Epoch: 5, Batch: 108, Loss: 2525.737548828125\n",
      "Epoch: 5, Batch: 109, Loss: 2559.0712890625\n",
      "Epoch: 5, Batch: 110, Loss: 1856.087646484375\n",
      "Epoch: 5, Batch: 111, Loss: 2779.1796875\n",
      "Epoch: 5, Batch: 112, Loss: 2664.72802734375\n",
      "Epoch: 5, Batch: 113, Loss: 2758.74609375\n",
      "Epoch: 5, Batch: 114, Loss: 2336.62109375\n",
      "Epoch: 5, Batch: 115, Loss: 2564.4296875\n",
      "Epoch: 5, Batch: 116, Loss: 2577.01806640625\n",
      "Epoch: 5, Batch: 117, Loss: 3020.9873046875\n",
      "Epoch: 5, Batch: 118, Loss: 2776.89501953125\n",
      "Epoch: 5, Batch: 119, Loss: 2371.199462890625\n",
      "Epoch: 5, Batch: 120, Loss: 3414.95654296875\n",
      "Epoch: 5, Batch: 121, Loss: 2431.05859375\n",
      "Epoch: 5, Batch: 122, Loss: 3065.35986328125\n",
      "Epoch: 5, Batch: 123, Loss: 2235.482421875\n",
      "Epoch: 5, Batch: 124, Loss: 3249.8193359375\n",
      "Epoch: 5, Batch: 125, Loss: 3218.28564453125\n",
      "Epoch: 5, Batch: 126, Loss: 3219.096923828125\n",
      "Epoch: 5, Batch: 127, Loss: 2265.056640625\n",
      "Epoch: 5, Batch: 128, Loss: 2435.89453125\n",
      "Epoch: 5, Batch: 129, Loss: 2564.289794921875\n",
      "Epoch: 5, Batch: 130, Loss: 2375.66455078125\n",
      "Epoch: 5, Batch: 131, Loss: 2184.602294921875\n",
      "Epoch: 5, Batch: 132, Loss: 2839.47119140625\n",
      "Epoch: 5, Batch: 133, Loss: 2483.548583984375\n",
      "Epoch: 5, Batch: 134, Loss: 2173.58544921875\n",
      "Epoch: 5, Batch: 135, Loss: 2737.174072265625\n",
      "Epoch: 5, Batch: 136, Loss: 2481.82470703125\n",
      "Epoch: 5, Batch: 137, Loss: 2931.45849609375\n",
      "Epoch: 5, Batch: 138, Loss: 2229.140625\n",
      "Epoch: 5, Batch: 139, Loss: 2744.350830078125\n",
      "Epoch: 5, Batch: 140, Loss: 2292.630126953125\n",
      "Epoch: 5, Batch: 141, Loss: 2690.3134765625\n",
      "Epoch: 5, Batch: 142, Loss: 2148.893310546875\n",
      "Epoch: 5, Batch: 143, Loss: 3095.236328125\n",
      "Epoch: 5, Batch: 144, Loss: 1772.25\n",
      "Epoch: 5, Batch: 145, Loss: 2392.10546875\n",
      "Epoch: 5, Batch: 146, Loss: 2492.946044921875\n",
      "Epoch: 5, Batch: 147, Loss: 2938.040771484375\n",
      "Epoch: 5, Batch: 148, Loss: 3186.14599609375\n",
      "Epoch: 5, Batch: 149, Loss: 2263.382568359375\n",
      "Epoch: 5, Batch: 150, Loss: 2498.392333984375\n",
      "Epoch: 5, Batch: 151, Loss: 2850.05419921875\n",
      "Epoch: 5, Batch: 152, Loss: 2825.734619140625\n",
      "Epoch: 5, Batch: 153, Loss: 2042.78173828125\n",
      "Epoch: 5, Batch: 154, Loss: 2095.80712890625\n",
      "Epoch: 5, Batch: 155, Loss: 2538.99609375\n",
      "Epoch: 5, Batch: 156, Loss: 2082.86328125\n",
      "Epoch: 5, Batch: 157, Loss: 2735.254638671875\n",
      "Epoch: 5, Batch: 158, Loss: 2571.287109375\n",
      "Epoch: 5, Batch: 159, Loss: 2971.46875\n",
      "Epoch: 5, Batch: 160, Loss: 2695.3154296875\n",
      "Epoch: 5, Batch: 161, Loss: 2721.87353515625\n",
      "Epoch: 5, Batch: 162, Loss: 2793.906005859375\n",
      "Epoch: 5, Batch: 163, Loss: 2719.95556640625\n",
      "Epoch: 5, Batch: 164, Loss: 2669.46728515625\n",
      "Epoch: 5, Batch: 165, Loss: 2763.079833984375\n",
      "Epoch: 5, Batch: 166, Loss: 2687.782958984375\n",
      "Epoch: 5, Batch: 167, Loss: 2775.1611328125\n",
      "Epoch: 5, Batch: 168, Loss: 2811.6767578125\n",
      "Epoch: 5, Batch: 169, Loss: 2339.4404296875\n",
      "Epoch: 5, Batch: 170, Loss: 2358.3369140625\n",
      "Epoch: 5, Batch: 171, Loss: 2378.17236328125\n",
      "Epoch: 5, Batch: 172, Loss: 2537.263427734375\n",
      "Epoch: 5, Batch: 173, Loss: 2556.000732421875\n",
      "Epoch: 5, Batch: 174, Loss: 2850.582763671875\n",
      "Epoch: 5, Batch: 175, Loss: 2748.635986328125\n",
      "Epoch: 5, Batch: 176, Loss: 2707.857666015625\n",
      "Epoch: 5, Batch: 177, Loss: 2424.264892578125\n",
      "Epoch: 5, Batch: 178, Loss: 2677.650146484375\n",
      "Epoch: 5, Batch: 179, Loss: 2880.552734375\n",
      "Epoch: 5, Batch: 180, Loss: 2645.673095703125\n",
      "Epoch: 5, Batch: 181, Loss: 3427.012939453125\n",
      "Epoch: 5, Batch: 182, Loss: 2464.703857421875\n",
      "Epoch: 5, Batch: 183, Loss: 2252.2099609375\n",
      "Epoch: 5, Batch: 184, Loss: 2297.56005859375\n",
      "Epoch: 5, Batch: 185, Loss: 2835.283935546875\n",
      "Epoch: 5, Batch: 186, Loss: 2282.881591796875\n",
      "Epoch: 5, Batch: 187, Loss: 2886.446533203125\n",
      "Epoch: 5, Batch: 188, Loss: 3276.34423828125\n",
      "Epoch: 5, Batch: 189, Loss: 2785.177490234375\n",
      "Epoch: 5, Batch: 190, Loss: 2283.177490234375\n",
      "Epoch: 5, Batch: 191, Loss: 2410.01171875\n",
      "Epoch: 5, Batch: 192, Loss: 2243.513916015625\n",
      "Epoch: 5, Batch: 193, Loss: 2851.740478515625\n",
      "Epoch: 5, Batch: 194, Loss: 2512.725341796875\n",
      "Epoch: 5, Batch: 195, Loss: 2280.943603515625\n",
      "Epoch: 5, Batch: 196, Loss: 2158.686767578125\n",
      "Epoch: 5, Batch: 197, Loss: 2390.02392578125\n",
      "Epoch: 5, Batch: 198, Loss: 2937.166259765625\n",
      "Epoch: 5, Batch: 199, Loss: 2564.066650390625\n",
      "Epoch: 5, Batch: 200, Loss: 2591.772216796875\n",
      "Epoch: 5, Batch: 201, Loss: 2984.12744140625\n",
      "Epoch: 5, Batch: 202, Loss: 2663.46923828125\n",
      "Epoch: 5, Batch: 203, Loss: 2022.6402587890625\n",
      "Epoch: 5, Batch: 204, Loss: 2090.81884765625\n",
      "Epoch: 5, Batch: 205, Loss: 2528.98974609375\n",
      "Epoch: 5, Batch: 206, Loss: 2719.157958984375\n",
      "Epoch: 5, Batch: 207, Loss: 2645.40087890625\n",
      "Epoch: 5, Batch: 208, Loss: 2530.133056640625\n",
      "Epoch: 5, Batch: 209, Loss: 2606.72314453125\n",
      "Epoch: 5, Batch: 210, Loss: 2498.126953125\n",
      "Epoch: 5, Batch: 211, Loss: 3109.745361328125\n",
      "Epoch: 5, Batch: 212, Loss: 2659.76806640625\n",
      "Epoch: 5, Batch: 213, Loss: 3096.935546875\n",
      "Epoch: 5, Batch: 214, Loss: 2165.644287109375\n",
      "Epoch: 5, Batch: 215, Loss: 2903.150390625\n",
      "Epoch: 5, Batch: 216, Loss: 2932.587890625\n",
      "Epoch: 5, Batch: 217, Loss: 2815.05029296875\n",
      "Epoch: 5, Batch: 218, Loss: 2760.333251953125\n",
      "Epoch: 5, Batch: 219, Loss: 2277.8583984375\n",
      "Epoch: 5, Batch: 220, Loss: 2403.3203125\n",
      "Epoch: 5, Batch: 221, Loss: 2754.41845703125\n",
      "Epoch: 5, Batch: 222, Loss: 2360.745849609375\n",
      "Epoch: 5, Batch: 223, Loss: 3040.385498046875\n",
      "Epoch: 5, Batch: 224, Loss: 2799.391845703125\n",
      "Epoch: 5, Batch: 225, Loss: 2398.386474609375\n",
      "Epoch: 5, Batch: 226, Loss: 2798.27099609375\n",
      "Epoch: 5, Batch: 227, Loss: 2682.19140625\n",
      "Epoch: 5, Batch: 228, Loss: 2833.002685546875\n",
      "Epoch: 5, Batch: 229, Loss: 2490.85009765625\n",
      "Epoch: 5, Batch: 230, Loss: 2963.93212890625\n",
      "Epoch: 5, Batch: 231, Loss: 2894.22412109375\n",
      "Epoch: 5, Batch: 232, Loss: 2637.433349609375\n",
      "Epoch: 5, Batch: 233, Loss: 2776.735595703125\n",
      "Epoch: 5, Batch: 234, Loss: 2701.083984375\n",
      "Epoch: 5, Batch: 235, Loss: 2362.113037109375\n",
      "Epoch: 5, Batch: 236, Loss: 2273.681640625\n",
      "Epoch: 5, Batch: 237, Loss: 2067.546875\n",
      "Epoch: 5, Batch: 238, Loss: 2477.049560546875\n",
      "Epoch: 5, Batch: 239, Loss: 2652.35791015625\n",
      "Epoch: 5, Batch: 240, Loss: 2789.30810546875\n",
      "Epoch: 5, Batch: 241, Loss: 2541.590087890625\n",
      "Epoch: 5, Batch: 242, Loss: 2661.085693359375\n",
      "Epoch: 5, Batch: 243, Loss: 2995.808349609375\n",
      "Epoch: 5, Batch: 244, Loss: 2215.18896484375\n",
      "Epoch: 5, Batch: 245, Loss: 2584.63427734375\n",
      "Epoch: 5, Batch: 246, Loss: 2781.0576171875\n",
      "Epoch: 5, Batch: 247, Loss: 3052.463623046875\n",
      "Epoch: 5, Batch: 248, Loss: 2381.539794921875\n",
      "Epoch: 5, Batch: 249, Loss: 2811.958984375\n",
      "Epoch: 5, Batch: 250, Loss: 2538.19970703125\n",
      "Epoch: 5, Batch: 251, Loss: 2366.491455078125\n",
      "Epoch: 5, Batch: 252, Loss: 2888.5615234375\n",
      "Epoch: 5, Batch: 253, Loss: 2868.7861328125\n",
      "Epoch: 5, Batch: 254, Loss: 1963.4007568359375\n",
      "Epoch: 5, Batch: 255, Loss: 2566.578125\n",
      "Epoch: 5, Batch: 256, Loss: 2429.2978515625\n",
      "Epoch: 5, Batch: 257, Loss: 2531.060546875\n",
      "Epoch: 5, Batch: 258, Loss: 2672.7783203125\n",
      "Epoch: 5, Batch: 259, Loss: 2205.05615234375\n",
      "Epoch: 5, Batch: 260, Loss: 2881.83544921875\n",
      "Epoch: 5, Batch: 261, Loss: 2892.673095703125\n",
      "Epoch: 5, Batch: 262, Loss: 2808.6455078125\n",
      "Epoch: 5, Batch: 263, Loss: 2714.650146484375\n",
      "Epoch: 5, Batch: 264, Loss: 2739.76611328125\n",
      "Epoch: 5, Batch: 265, Loss: 2386.24609375\n",
      "Epoch: 5, Batch: 266, Loss: 2706.91552734375\n",
      "Epoch: 5, Batch: 267, Loss: 2725.60498046875\n",
      "Epoch: 5, Batch: 268, Loss: 2268.31591796875\n",
      "Epoch: 5, Batch: 269, Loss: 2401.821533203125\n",
      "Epoch: 5, Batch: 270, Loss: 2427.907470703125\n",
      "Epoch: 5, Batch: 271, Loss: 2434.1708984375\n",
      "Epoch: 5, Batch: 272, Loss: 2665.42138671875\n",
      "Epoch: 5, Batch: 273, Loss: 2839.682861328125\n",
      "Epoch: 5, Batch: 274, Loss: 3124.83349609375\n",
      "Epoch: 5, Batch: 275, Loss: 2451.31494140625\n",
      "Epoch: 5, Batch: 276, Loss: 3254.502685546875\n",
      "Epoch: 5, Batch: 277, Loss: 2849.4609375\n",
      "Epoch: 5, Batch: 278, Loss: 2602.14404296875\n",
      "Epoch: 5, Batch: 279, Loss: 2076.19775390625\n",
      "Epoch: 5, Batch: 280, Loss: 2994.8603515625\n",
      "Epoch: 5, Batch: 281, Loss: 3179.137451171875\n",
      "Epoch: 5, Batch: 282, Loss: 2828.185791015625\n",
      "Epoch: 5, Batch: 283, Loss: 2971.943115234375\n",
      "Epoch: 5, Batch: 284, Loss: 2781.80517578125\n",
      "Epoch: 5, Batch: 285, Loss: 2661.476318359375\n",
      "Epoch: 5, Batch: 286, Loss: 2747.091552734375\n",
      "Epoch: 5, Batch: 287, Loss: 2897.319091796875\n",
      "Epoch: 5, Batch: 288, Loss: 2464.92236328125\n",
      "Epoch: 5, Batch: 289, Loss: 3076.58251953125\n",
      "Epoch: 5, Batch: 290, Loss: 1948.2928466796875\n",
      "Epoch: 5, Batch: 291, Loss: 2316.1650390625\n",
      "Epoch: 5, Batch: 292, Loss: 2954.9560546875\n",
      "Epoch: 5, Batch: 293, Loss: 2459.38916015625\n",
      "Epoch: 5, Batch: 294, Loss: 2283.768310546875\n",
      "Epoch: 5, Batch: 295, Loss: 2638.73876953125\n",
      "Epoch: 5, Batch: 296, Loss: 3077.964111328125\n",
      "Epoch: 5, Batch: 297, Loss: 2669.91455078125\n",
      "Epoch: 5, Batch: 298, Loss: 2875.705078125\n",
      "Epoch: 5, Batch: 299, Loss: 3325.809814453125\n",
      "Epoch: 5, Batch: 300, Loss: 2809.95068359375\n",
      "Epoch: 5, Batch: 301, Loss: 2761.41259765625\n",
      "Epoch: 5, Batch: 302, Loss: 2135.437255859375\n",
      "Epoch: 5, Batch: 303, Loss: 2331.30126953125\n",
      "Epoch: 5, Batch: 304, Loss: 2829.015869140625\n",
      "Epoch: 5, Batch: 305, Loss: 2410.01220703125\n",
      "Epoch: 5, Batch: 306, Loss: 2862.2216796875\n",
      "Epoch: 5, Batch: 307, Loss: 2191.25830078125\n",
      "Epoch: 5, Batch: 308, Loss: 2752.52880859375\n",
      "Epoch: 5, Batch: 309, Loss: 2530.854736328125\n",
      "Epoch: 5, Batch: 310, Loss: 3288.916259765625\n",
      "Epoch: 5, Batch: 311, Loss: 2742.994384765625\n",
      "Epoch: 5, Batch: 312, Loss: 2871.544921875\n",
      "Epoch: 5, Batch: 313, Loss: 2359.52587890625\n",
      "Epoch: 5, Batch: 314, Loss: 2223.372802734375\n",
      "Epoch: 5, Batch: 315, Loss: 2662.017822265625\n",
      "Epoch: 5, Batch: 316, Loss: 2870.433349609375\n",
      "Epoch: 5, Batch: 317, Loss: 2684.59814453125\n",
      "Epoch: 5, Batch: 318, Loss: 2726.1865234375\n",
      "Epoch: 5, Batch: 319, Loss: 2464.906982421875\n",
      "Epoch: 5, Batch: 320, Loss: 2610.66162109375\n",
      "Epoch: 5, Batch: 321, Loss: 2604.319091796875\n",
      "Epoch: 5, Batch: 322, Loss: 2303.447021484375\n",
      "Epoch: 5, Batch: 323, Loss: 2968.67529296875\n",
      "Epoch: 5, Batch: 324, Loss: 2365.945556640625\n",
      "Epoch: 5, Batch: 325, Loss: 2196.67236328125\n",
      "Epoch: 5, Batch: 326, Loss: 2128.399658203125\n",
      "Epoch: 5, Batch: 327, Loss: 2215.368408203125\n",
      "Epoch: 5, Batch: 328, Loss: 3105.26318359375\n",
      "Epoch: 5, Batch: 329, Loss: 2484.7138671875\n",
      "Epoch: 5, Batch: 330, Loss: 2646.67578125\n",
      "Epoch: 5, Batch: 331, Loss: 3099.849609375\n",
      "Epoch: 5, Batch: 332, Loss: 2595.425537109375\n",
      "Epoch: 5, Batch: 333, Loss: 2350.011474609375\n",
      "Epoch: 5, Batch: 334, Loss: 2149.011474609375\n",
      "Epoch: 5, Batch: 335, Loss: 2825.5087890625\n",
      "Epoch: 5, Batch: 336, Loss: 2962.6220703125\n",
      "Epoch: 5, Batch: 337, Loss: 2951.69189453125\n",
      "Epoch: 5, Batch: 338, Loss: 3217.14599609375\n",
      "Epoch: 5, Batch: 339, Loss: 2588.942626953125\n",
      "Epoch: 5, Batch: 340, Loss: 2191.805419921875\n",
      "Epoch: 5, Batch: 341, Loss: 2877.712158203125\n",
      "Epoch: 5, Batch: 342, Loss: 2578.392578125\n",
      "Epoch: 5, Batch: 343, Loss: 2986.41015625\n",
      "Epoch: 5, Batch: 344, Loss: 2403.220947265625\n",
      "Epoch: 5, Batch: 345, Loss: 2539.56103515625\n",
      "Epoch: 5, Batch: 346, Loss: 2384.50732421875\n",
      "Epoch: 5, Batch: 347, Loss: 1917.070556640625\n",
      "Epoch: 5, Batch: 348, Loss: 2417.693115234375\n",
      "Epoch: 5, Batch: 349, Loss: 3156.824462890625\n",
      "Epoch: 5, Batch: 350, Loss: 3230.098876953125\n",
      "Epoch: 5, Batch: 351, Loss: 2812.9990234375\n",
      "Epoch: 5, Batch: 352, Loss: 2517.910400390625\n",
      "Epoch: 5, Batch: 353, Loss: 2773.9130859375\n",
      "Epoch: 5, Batch: 354, Loss: 2433.72607421875\n",
      "Epoch: 5, Batch: 355, Loss: 2685.692138671875\n",
      "Epoch: 5, Batch: 356, Loss: 2675.60791015625\n",
      "Epoch: 5, Batch: 357, Loss: 2848.419677734375\n",
      "Epoch: 5, Batch: 358, Loss: 2203.02294921875\n",
      "Epoch: 5, Batch: 359, Loss: 2847.685302734375\n",
      "Epoch: 5, Batch: 360, Loss: 2672.05224609375\n",
      "Epoch: 5, Batch: 361, Loss: 2609.806884765625\n",
      "Epoch: 5, Batch: 362, Loss: 2531.99072265625\n",
      "Epoch: 5, Batch: 363, Loss: 2208.23046875\n",
      "Epoch: 5, Batch: 364, Loss: 2888.975830078125\n",
      "Epoch: 5, Batch: 365, Loss: 2336.53515625\n",
      "Epoch: 5, Batch: 366, Loss: 1826.61669921875\n",
      "Epoch: 5, Batch: 367, Loss: 2943.806396484375\n",
      "Epoch: 5, Batch: 368, Loss: 2943.267578125\n",
      "Epoch: 5, Batch: 369, Loss: 2784.28369140625\n",
      "Epoch: 5, Batch: 370, Loss: 2574.3720703125\n",
      "Epoch: 5, Batch: 371, Loss: 2229.13818359375\n",
      "Epoch: 5, Batch: 372, Loss: 2549.49609375\n",
      "Epoch: 5, Batch: 373, Loss: 1811.4033203125\n",
      "Epoch: 5, Batch: 374, Loss: 2350.628173828125\n",
      "Epoch: 5, Batch: 375, Loss: 2459.155029296875\n",
      "Epoch: 5, Batch: 376, Loss: 2787.509521484375\n",
      "Epoch: 5, Batch: 377, Loss: 2743.72705078125\n",
      "Epoch: 5, Batch: 378, Loss: 2313.506591796875\n",
      "Epoch: 5, Batch: 379, Loss: 3275.180908203125\n",
      "Epoch: 5, Batch: 380, Loss: 3127.248291015625\n",
      "Epoch: 5, Batch: 381, Loss: 2073.610595703125\n",
      "Epoch: 5, Batch: 382, Loss: 2320.272216796875\n",
      "Epoch: 5, Batch: 383, Loss: 2316.09423828125\n",
      "Epoch: 5, Batch: 384, Loss: 2987.271728515625\n",
      "Epoch: 5, Batch: 385, Loss: 2701.26318359375\n",
      "Epoch: 5, Batch: 386, Loss: 2866.979736328125\n",
      "Epoch: 5, Batch: 387, Loss: 2636.95947265625\n",
      "Epoch: 5, Batch: 388, Loss: 2398.6328125\n",
      "Epoch: 5, Batch: 389, Loss: 2746.552001953125\n",
      "Epoch: 5, Batch: 390, Loss: 2349.7275390625\n",
      "Epoch: 5, Batch: 391, Loss: 2305.09228515625\n",
      "Epoch: 5, Batch: 392, Loss: 2842.524169921875\n",
      "Epoch: 5, Batch: 393, Loss: 2280.85400390625\n",
      "Epoch: 5, Batch: 394, Loss: 2667.731201171875\n",
      "Epoch: 5, Batch: 395, Loss: 2660.83544921875\n",
      "Epoch: 5, Batch: 396, Loss: 2479.223388671875\n",
      "Epoch: 5, Batch: 397, Loss: 2450.4921875\n",
      "Epoch: 5, Batch: 398, Loss: 3154.9248046875\n",
      "Epoch: 5, Batch: 399, Loss: 2819.041259765625\n",
      "Epoch: 5, Batch: 400, Loss: 2542.847412109375\n",
      "Epoch: 5, Batch: 401, Loss: 2542.706298828125\n",
      "Epoch: 5, Batch: 402, Loss: 2727.848388671875\n",
      "Epoch: 5, Batch: 403, Loss: 3004.518798828125\n",
      "Epoch: 5, Batch: 404, Loss: 3474.347900390625\n",
      "Epoch: 5, Batch: 405, Loss: 2304.39697265625\n",
      "Epoch: 5, Batch: 406, Loss: 2292.051025390625\n",
      "Epoch: 5, Batch: 407, Loss: 2705.6767578125\n",
      "Epoch: 5, Batch: 408, Loss: 3450.962158203125\n",
      "Epoch: 5, Batch: 409, Loss: 2938.492431640625\n",
      "Epoch: 5, Batch: 410, Loss: 2555.72314453125\n",
      "Epoch: 5, Batch: 411, Loss: 2542.218017578125\n",
      "Epoch: 5, Batch: 412, Loss: 2378.994873046875\n",
      "Epoch: 5, Batch: 413, Loss: 2412.384521484375\n",
      "Epoch: 5, Batch: 414, Loss: 2525.023681640625\n",
      "Epoch: 5, Batch: 415, Loss: 2716.79541015625\n",
      "Epoch: 5, Batch: 416, Loss: 1957.5343017578125\n",
      "Epoch: 5, Batch: 417, Loss: 2432.60107421875\n",
      "Epoch: 5, Batch: 418, Loss: 2591.365478515625\n",
      "Epoch: 5, Batch: 419, Loss: 2172.966796875\n",
      "Epoch: 5, Batch: 420, Loss: 2375.255615234375\n",
      "Epoch: 5, Batch: 421, Loss: 2192.921142578125\n",
      "Epoch: 5, Batch: 422, Loss: 2702.6123046875\n",
      "Epoch: 5, Batch: 423, Loss: 3462.871826171875\n",
      "Epoch: 5, Batch: 424, Loss: 2812.473388671875\n",
      "Epoch: 5, Batch: 425, Loss: 2982.57080078125\n",
      "Epoch: 5, Batch: 426, Loss: 2599.917236328125\n",
      "Epoch: 5, Batch: 427, Loss: 2892.009521484375\n",
      "Epoch: 5, Batch: 428, Loss: 3390.808837890625\n",
      "Epoch: 5, Batch: 429, Loss: 2313.615234375\n",
      "Epoch: 5, Batch: 430, Loss: 2775.2431640625\n",
      "Epoch: 5, Batch: 431, Loss: 3072.095947265625\n",
      "Epoch: 5, Batch: 432, Loss: 2554.366943359375\n",
      "Epoch: 5, Batch: 433, Loss: 2311.387939453125\n",
      "Epoch: 5, Batch: 434, Loss: 2101.00537109375\n",
      "Epoch: 5, Batch: 435, Loss: 2234.71240234375\n",
      "Epoch: 5, Batch: 436, Loss: 2524.090087890625\n",
      "Epoch: 5, Batch: 437, Loss: 3187.801025390625\n",
      "Epoch: 5, Batch: 438, Loss: 2372.350341796875\n",
      "Epoch: 5, Batch: 439, Loss: 2303.234130859375\n",
      "Epoch: 5, Batch: 440, Loss: 3469.17041015625\n",
      "Epoch: 5, Batch: 441, Loss: 2738.22265625\n",
      "Epoch: 5, Batch: 442, Loss: 2467.625244140625\n",
      "Epoch: 5, Batch: 443, Loss: 2566.492919921875\n",
      "Epoch: 5, Batch: 444, Loss: 2925.694580078125\n",
      "Epoch: 5, Batch: 445, Loss: 2733.79833984375\n",
      "Epoch: 5, Batch: 446, Loss: 2386.85888671875\n",
      "Epoch: 5, Batch: 447, Loss: 2960.704345703125\n",
      "Epoch: 5, Batch: 448, Loss: 2246.33154296875\n",
      "Epoch: 5, Batch: 449, Loss: 3776.17919921875\n",
      "Epoch: 5, Batch: 450, Loss: 2709.82568359375\n",
      "Epoch: 5, Batch: 451, Loss: 2955.094482421875\n",
      "Epoch: 5, Batch: 452, Loss: 3038.454345703125\n",
      "Epoch: 5, Batch: 453, Loss: 2490.474853515625\n",
      "Epoch: 5, Batch: 454, Loss: 3018.972900390625\n",
      "Epoch: 5, Batch: 455, Loss: 2736.10107421875\n",
      "Epoch: 5, Batch: 456, Loss: 2410.12109375\n",
      "Epoch: 5, Batch: 457, Loss: 2451.606689453125\n",
      "Epoch: 5, Batch: 458, Loss: 2440.17529296875\n",
      "Epoch: 5, Batch: 459, Loss: 3184.29833984375\n",
      "Epoch: 5, Batch: 460, Loss: 3536.955810546875\n",
      "Epoch: 5, Batch: 461, Loss: 2629.17041015625\n",
      "Epoch: 5, Batch: 462, Loss: 2742.928955078125\n",
      "Epoch: 5, Batch: 463, Loss: 2416.238037109375\n",
      "Epoch: 5, Batch: 464, Loss: 2519.464599609375\n",
      "Epoch: 5, Batch: 465, Loss: 2337.81298828125\n",
      "Epoch: 5, Batch: 466, Loss: 2624.452392578125\n",
      "Epoch: 5, Batch: 467, Loss: 2412.224853515625\n",
      "Epoch: 5, Batch: 468, Loss: 2639.23486328125\n",
      "Epoch: 5, Batch: 469, Loss: 2837.164794921875\n",
      "Epoch: 5, Batch: 470, Loss: 2370.0166015625\n",
      "Epoch: 5, Batch: 471, Loss: 2851.16357421875\n",
      "Epoch: 5, Batch: 472, Loss: 2657.011474609375\n",
      "Epoch: 5, Batch: 473, Loss: 2333.676025390625\n",
      "Epoch: 5, Batch: 474, Loss: 2797.850830078125\n",
      "Epoch: 5, Batch: 475, Loss: 2967.935791015625\n",
      "Epoch: 5, Batch: 476, Loss: 2767.302001953125\n",
      "Epoch: 5, Batch: 477, Loss: 2370.254638671875\n",
      "Epoch: 5, Batch: 478, Loss: 2556.928466796875\n",
      "Epoch: 5, Batch: 479, Loss: 2650.5966796875\n",
      "Epoch: 5, Batch: 480, Loss: 2345.20556640625\n",
      "Epoch: 5, Batch: 481, Loss: 2795.606689453125\n",
      "Epoch: 5, Batch: 482, Loss: 2013.5511474609375\n",
      "Epoch: 5, Batch: 483, Loss: 2346.168701171875\n",
      "Epoch: 5, Batch: 484, Loss: 2969.26904296875\n",
      "Epoch: 5, Batch: 485, Loss: 2436.038818359375\n",
      "Epoch: 5, Batch: 486, Loss: 2489.840576171875\n",
      "Epoch: 5, Batch: 487, Loss: 2593.328369140625\n",
      "Epoch: 5, Batch: 488, Loss: 2973.38037109375\n",
      "Epoch: 5, Batch: 489, Loss: 2694.07470703125\n",
      "Epoch: 5, Batch: 490, Loss: 2073.52099609375\n",
      "Epoch: 5, Batch: 491, Loss: 2926.637939453125\n",
      "Epoch: 5, Batch: 492, Loss: 2539.494873046875\n",
      "Epoch: 5, Batch: 493, Loss: 2126.715576171875\n",
      "Epoch: 5, Batch: 494, Loss: 2556.862060546875\n",
      "Epoch: 5, Batch: 495, Loss: 2407.15234375\n",
      "Epoch: 5, Batch: 496, Loss: 2735.54150390625\n",
      "Epoch: 5, Batch: 497, Loss: 2516.55859375\n",
      "Epoch: 5, Batch: 498, Loss: 1851.6624755859375\n",
      "Epoch: 5, Batch: 499, Loss: 2661.739501953125\n",
      "Epoch: 5, Batch: 500, Loss: 2773.4951171875\n",
      "Epoch: 5, Batch: 501, Loss: 3076.4638671875\n",
      "Epoch: 5, Batch: 502, Loss: 2611.842041015625\n",
      "Epoch: 5, Batch: 503, Loss: 2122.584228515625\n",
      "Epoch: 5, Batch: 504, Loss: 2167.103515625\n",
      "Epoch: 5, Batch: 505, Loss: 2352.07568359375\n",
      "Epoch: 5, Batch: 506, Loss: 2805.78271484375\n",
      "Epoch: 5, Batch: 507, Loss: 2910.73095703125\n",
      "Epoch: 5, Batch: 508, Loss: 2563.645751953125\n",
      "Epoch: 5, Batch: 509, Loss: 3022.611328125\n",
      "Epoch: 5, Batch: 510, Loss: 2211.787109375\n",
      "Epoch: 5, Batch: 511, Loss: 2284.1201171875\n",
      "Epoch: 5, Batch: 512, Loss: 2697.715576171875\n",
      "Epoch: 5, Batch: 513, Loss: 2142.93310546875\n",
      "Epoch: 5, Batch: 514, Loss: 2938.5224609375\n",
      "Epoch: 5, Batch: 515, Loss: 2858.015380859375\n",
      "Epoch: 5, Batch: 516, Loss: 2534.53173828125\n",
      "Epoch: 5, Batch: 517, Loss: 2629.749755859375\n",
      "Epoch: 5, Batch: 518, Loss: 2649.395263671875\n",
      "Epoch: 5, Batch: 519, Loss: 2892.787841796875\n",
      "Epoch: 5, Batch: 520, Loss: 3110.879638671875\n",
      "Epoch: 5, Batch: 521, Loss: 2217.973388671875\n",
      "Epoch: 5, Batch: 522, Loss: 2930.08984375\n",
      "Epoch: 5, Batch: 523, Loss: 2819.72607421875\n",
      "Epoch: 5, Batch: 524, Loss: 2381.541259765625\n",
      "Epoch: 5, Batch: 525, Loss: 2577.537109375\n",
      "Epoch: 5, Batch: 526, Loss: 2212.84521484375\n",
      "Epoch: 5, Batch: 527, Loss: 2768.74462890625\n",
      "Epoch: 5, Batch: 528, Loss: 3186.990478515625\n",
      "Epoch: 5, Batch: 529, Loss: 2565.626708984375\n",
      "Epoch: 5, Batch: 530, Loss: 2631.993896484375\n",
      "Epoch: 5, Batch: 531, Loss: 2558.12353515625\n",
      "Epoch: 5, Batch: 532, Loss: 2924.109375\n",
      "Epoch: 5, Batch: 533, Loss: 2420.810791015625\n",
      "Epoch: 5, Batch: 534, Loss: 2504.144287109375\n",
      "Epoch: 5, Batch: 535, Loss: 2399.915771484375\n",
      "Epoch: 5, Batch: 536, Loss: 2790.869140625\n",
      "Epoch: 5, Batch: 537, Loss: 2568.939697265625\n",
      "Epoch: 5, Batch: 538, Loss: 2791.435791015625\n",
      "Epoch: 5, Batch: 539, Loss: 3074.026611328125\n",
      "Epoch: 5, Batch: 540, Loss: 2396.510986328125\n",
      "Epoch: 5, Batch: 541, Loss: 2529.00830078125\n",
      "Epoch: 5, Batch: 542, Loss: 3041.965576171875\n",
      "Epoch: 5, Batch: 543, Loss: 2486.962890625\n",
      "Epoch: 5, Batch: 544, Loss: 3010.12744140625\n",
      "Epoch: 5, Batch: 545, Loss: 2358.039794921875\n",
      "Epoch: 5, Batch: 546, Loss: 2662.2275390625\n",
      "Epoch: 5, Batch: 547, Loss: 2357.148193359375\n",
      "Epoch: 5, Batch: 548, Loss: 2652.510009765625\n",
      "Epoch: 5, Batch: 549, Loss: 2830.1083984375\n",
      "Epoch: 5, Batch: 550, Loss: 2344.970947265625\n",
      "Epoch: 5, Batch: 551, Loss: 2526.703857421875\n",
      "Epoch: 5, Batch: 552, Loss: 3313.728271484375\n",
      "Epoch: 5, Batch: 553, Loss: 2202.11181640625\n",
      "Epoch: 5, Batch: 554, Loss: 3076.068359375\n",
      "Epoch: 5, Batch: 555, Loss: 3137.335693359375\n",
      "Epoch: 5, Batch: 556, Loss: 2820.373779296875\n",
      "Epoch: 5, Batch: 557, Loss: 2712.056396484375\n",
      "Epoch: 5, Batch: 558, Loss: 2647.152099609375\n",
      "Epoch: 5, Batch: 559, Loss: 2621.2021484375\n",
      "Epoch: 5, Batch: 560, Loss: 2233.55712890625\n",
      "Epoch: 5, Batch: 561, Loss: 2806.7314453125\n",
      "Epoch: 5, Batch: 562, Loss: 2556.14990234375\n",
      "Epoch: 5, Batch: 563, Loss: 2484.74072265625\n",
      "Epoch: 5, Batch: 564, Loss: 2468.62353515625\n",
      "Epoch: 5, Batch: 565, Loss: 3003.218994140625\n",
      "Epoch: 5, Batch: 566, Loss: 2379.76416015625\n",
      "Epoch: 5, Batch: 567, Loss: 2482.5830078125\n",
      "Epoch: 5, Batch: 568, Loss: 2444.726318359375\n",
      "Epoch: 5, Batch: 569, Loss: 2952.52001953125\n",
      "Epoch: 5, Batch: 570, Loss: 2480.238037109375\n",
      "Epoch: 5, Batch: 571, Loss: 2526.614990234375\n",
      "Epoch: 5, Batch: 572, Loss: 3022.4306640625\n",
      "Epoch: 5, Batch: 573, Loss: 2735.31298828125\n",
      "Epoch: 5, Batch: 574, Loss: 3110.5654296875\n",
      "Epoch: 5, Batch: 575, Loss: 3205.145263671875\n",
      "Epoch: 5, Batch: 576, Loss: 2661.630615234375\n",
      "Epoch: 5, Batch: 577, Loss: 3284.384033203125\n",
      "Epoch: 5, Batch: 578, Loss: 2030.1009521484375\n",
      "Epoch: 5, Batch: 579, Loss: 2797.890625\n",
      "Epoch: 5, Batch: 580, Loss: 3158.1142578125\n",
      "Epoch: 5, Batch: 581, Loss: 2805.95947265625\n",
      "Epoch: 5, Batch: 582, Loss: 2695.683349609375\n",
      "Epoch: 5, Batch: 583, Loss: 2900.2431640625\n",
      "Epoch: 5, Batch: 584, Loss: 2573.62744140625\n",
      "Epoch: 5, Batch: 585, Loss: 2815.94287109375\n",
      "Epoch: 5, Batch: 586, Loss: 2698.7333984375\n",
      "Epoch: 5, Batch: 587, Loss: 2408.361328125\n",
      "Epoch: 5, Batch: 588, Loss: 2541.5693359375\n",
      "Epoch: 5, Batch: 589, Loss: 2772.559814453125\n",
      "Epoch: 5, Batch: 590, Loss: 2593.08251953125\n",
      "Epoch: 5, Batch: 591, Loss: 2655.302001953125\n",
      "Epoch: 5, Batch: 592, Loss: 2636.334716796875\n",
      "Epoch: 5, Batch: 593, Loss: 2316.53759765625\n",
      "Epoch: 5, Batch: 594, Loss: 2184.733154296875\n",
      "Epoch: 5, Batch: 595, Loss: 2178.052978515625\n",
      "Epoch: 5, Batch: 596, Loss: 2670.390869140625\n",
      "Epoch: 5, Batch: 597, Loss: 2562.776123046875\n",
      "Epoch: 5, Batch: 598, Loss: 2047.084716796875\n",
      "Epoch: 5, Batch: 599, Loss: 3004.80419921875\n",
      "Epoch: 5, Batch: 600, Loss: 2873.039794921875\n",
      "Epoch: 5, Batch: 601, Loss: 2550.83740234375\n",
      "Epoch: 5, Batch: 602, Loss: 2565.602294921875\n",
      "Epoch: 5, Batch: 603, Loss: 2841.46142578125\n",
      "Epoch: 5, Batch: 604, Loss: 2342.072998046875\n",
      "Epoch: 5, Batch: 605, Loss: 3145.154052734375\n",
      "Epoch: 5, Batch: 606, Loss: 2494.370849609375\n",
      "Epoch: 5, Batch: 607, Loss: 2877.96142578125\n",
      "Epoch: 5, Batch: 608, Loss: 2460.744140625\n",
      "Epoch: 5, Batch: 609, Loss: 2610.9111328125\n",
      "Epoch: 5, Batch: 610, Loss: 2321.015625\n",
      "Epoch: 5, Batch: 611, Loss: 3080.099609375\n",
      "Epoch: 5, Batch: 612, Loss: 2678.36865234375\n",
      "Epoch: 5, Batch: 613, Loss: 2261.91845703125\n",
      "Epoch: 5, Batch: 614, Loss: 2284.871826171875\n",
      "Epoch: 5, Batch: 615, Loss: 2438.2412109375\n",
      "Epoch: 5, Batch: 616, Loss: 2862.61865234375\n",
      "Epoch: 5, Batch: 617, Loss: 2759.551025390625\n",
      "Epoch: 5, Batch: 618, Loss: 2394.895263671875\n",
      "Epoch: 5, Batch: 619, Loss: 2501.234619140625\n",
      "Epoch: 5, Batch: 620, Loss: 2404.510498046875\n",
      "Epoch: 5, Batch: 621, Loss: 2458.4375\n",
      "Epoch: 5, Batch: 622, Loss: 2592.115478515625\n",
      "Epoch: 5, Batch: 623, Loss: 3079.894775390625\n",
      "Epoch: 5, Batch: 624, Loss: 2776.896728515625\n",
      "Epoch: 5, Batch: 625, Loss: 2614.006103515625\n",
      "Epoch: 5, Batch: 626, Loss: 2523.50830078125\n",
      "Epoch: 5, Batch: 627, Loss: 3221.440185546875\n",
      "Epoch: 5, Batch: 628, Loss: 2935.994140625\n",
      "Epoch: 5, Batch: 629, Loss: 2866.54541015625\n",
      "Epoch: 5, Batch: 630, Loss: 2820.1015625\n",
      "Epoch: 5, Batch: 631, Loss: 2053.80224609375\n",
      "Epoch: 5, Batch: 632, Loss: 2833.53564453125\n",
      "Epoch: 5, Batch: 633, Loss: 2651.529296875\n",
      "Epoch: 5, Batch: 634, Loss: 3134.175537109375\n",
      "Epoch: 5, Batch: 635, Loss: 2438.731201171875\n",
      "Epoch: 5, Batch: 636, Loss: 2937.95361328125\n",
      "Epoch: 5, Batch: 637, Loss: 2906.36962890625\n",
      "Epoch: 5, Batch: 638, Loss: 2499.6796875\n",
      "Epoch: 5, Batch: 639, Loss: 2574.5546875\n",
      "Epoch: 5, Batch: 640, Loss: 2559.12646484375\n",
      "Epoch: 5, Batch: 641, Loss: 2630.0205078125\n",
      "Epoch: 5, Batch: 642, Loss: 2663.79248046875\n",
      "Epoch: 5, Batch: 643, Loss: 2950.632080078125\n",
      "Epoch: 5, Batch: 644, Loss: 3021.35791015625\n",
      "Epoch: 5, Batch: 645, Loss: 3157.110107421875\n",
      "Epoch: 5, Batch: 646, Loss: 2157.932861328125\n",
      "Epoch: 5, Batch: 647, Loss: 2340.51318359375\n",
      "Epoch: 5, Batch: 648, Loss: 3062.54833984375\n",
      "Epoch: 5, Batch: 649, Loss: 2703.1005859375\n",
      "Epoch: 5, Batch: 650, Loss: 2640.27490234375\n",
      "Epoch: 5, Batch: 651, Loss: 2846.953125\n",
      "Epoch: 5, Batch: 652, Loss: 2846.243896484375\n",
      "Epoch: 5, Batch: 653, Loss: 2554.006591796875\n",
      "Epoch: 5, Batch: 654, Loss: 2735.92431640625\n",
      "Epoch: 5, Batch: 655, Loss: 2821.23779296875\n",
      "Epoch: 5, Batch: 656, Loss: 2566.572998046875\n",
      "Epoch: 5, Batch: 657, Loss: 3466.0703125\n",
      "Epoch: 5, Batch: 658, Loss: 3070.51416015625\n",
      "Epoch: 5, Batch: 659, Loss: 2591.292236328125\n",
      "Epoch: 5, Batch: 660, Loss: 2872.50341796875\n",
      "Epoch: 5, Batch: 661, Loss: 2639.3974609375\n",
      "Epoch: 5, Batch: 662, Loss: 2079.589111328125\n",
      "Epoch: 5, Batch: 663, Loss: 2721.603515625\n",
      "Epoch: 5, Batch: 664, Loss: 2579.877197265625\n",
      "Epoch: 5, Batch: 665, Loss: 2824.583740234375\n",
      "Epoch: 5, Batch: 666, Loss: 2645.579345703125\n",
      "Epoch: 5, Batch: 667, Loss: 2396.975341796875\n",
      "Epoch: 5, Batch: 668, Loss: 2145.063720703125\n",
      "Epoch: 5, Batch: 669, Loss: 2317.68505859375\n",
      "Epoch: 5, Batch: 670, Loss: 2590.08251953125\n",
      "Epoch: 5, Batch: 671, Loss: 2816.514892578125\n",
      "Epoch: 5, Batch: 672, Loss: 2464.290283203125\n",
      "Epoch: 5, Batch: 673, Loss: 3001.332275390625\n",
      "Epoch: 5, Batch: 674, Loss: 3002.7763671875\n",
      "Epoch: 5, Batch: 675, Loss: 2955.28857421875\n",
      "Epoch: 5, Batch: 676, Loss: 3045.2451171875\n",
      "Epoch: 5, Batch: 677, Loss: 2706.25830078125\n",
      "Epoch: 5, Batch: 678, Loss: 2792.52978515625\n",
      "Epoch: 5, Batch: 679, Loss: 2473.9853515625\n",
      "Epoch: 5, Batch: 680, Loss: 2861.042724609375\n",
      "Epoch: 5, Batch: 681, Loss: 3181.374755859375\n",
      "Epoch: 5, Batch: 682, Loss: 2592.197509765625\n",
      "Epoch: 5, Batch: 683, Loss: 2321.8408203125\n",
      "Epoch: 5, Batch: 684, Loss: 2609.77294921875\n",
      "Epoch: 5, Batch: 685, Loss: 2671.5595703125\n",
      "Epoch: 5, Batch: 686, Loss: 2258.814208984375\n",
      "Epoch: 5, Batch: 687, Loss: 2601.289306640625\n",
      "Epoch: 5, Batch: 688, Loss: 2872.5244140625\n",
      "Epoch: 5, Batch: 689, Loss: 2975.9931640625\n",
      "Epoch: 5, Batch: 690, Loss: 2756.95361328125\n",
      "Epoch: 5, Batch: 691, Loss: 2708.4716796875\n",
      "Epoch: 5, Batch: 692, Loss: 2766.16845703125\n",
      "Epoch: 5, Batch: 693, Loss: 2858.66845703125\n",
      "Epoch: 5, Batch: 694, Loss: 2713.819091796875\n",
      "Epoch: 5, Batch: 695, Loss: 2280.00634765625\n",
      "Epoch: 5, Batch: 696, Loss: 3062.185302734375\n",
      "Epoch: 5, Batch: 697, Loss: 2432.3701171875\n",
      "Epoch: 5, Batch: 698, Loss: 2804.8720703125\n",
      "Epoch: 5, Batch: 699, Loss: 2177.249267578125\n",
      "Epoch: 5, Batch: 700, Loss: 2462.961181640625\n",
      "Epoch: 5, Batch: 701, Loss: 2213.09033203125\n",
      "Epoch: 5, Batch: 702, Loss: 3188.978759765625\n",
      "Epoch: 5, Batch: 703, Loss: 2035.47216796875\n",
      "Epoch: 5, Batch: 704, Loss: 2542.79931640625\n",
      "Epoch: 5, Batch: 705, Loss: 1644.504150390625\n",
      "Epoch: 5, Batch: 706, Loss: 2305.672119140625\n",
      "Epoch: 5, Batch: 707, Loss: 2497.102294921875\n",
      "Epoch: 5, Batch: 708, Loss: 2715.6328125\n",
      "Epoch: 5, Batch: 709, Loss: 2671.771240234375\n",
      "Epoch: 5, Batch: 710, Loss: 2685.94091796875\n",
      "Epoch: 5, Batch: 711, Loss: 2827.554443359375\n",
      "Epoch: 5, Batch: 712, Loss: 2661.486572265625\n",
      "Epoch: 5, Batch: 713, Loss: 3077.2734375\n",
      "Epoch: 5, Batch: 714, Loss: 2734.17041015625\n",
      "Epoch: 5, Batch: 715, Loss: 2857.420166015625\n",
      "Epoch: 5, Batch: 716, Loss: 2910.3271484375\n",
      "Epoch: 5, Batch: 717, Loss: 2826.902587890625\n",
      "Epoch: 5, Batch: 718, Loss: 2685.931884765625\n",
      "Epoch: 5, Batch: 719, Loss: 2634.260009765625\n",
      "Epoch: 5, Batch: 720, Loss: 2566.48095703125\n",
      "Epoch: 5, Batch: 721, Loss: 2686.328125\n",
      "Epoch: 5, Batch: 722, Loss: 2860.5\n",
      "Epoch: 5, Batch: 723, Loss: 2543.337158203125\n",
      "Epoch: 5, Batch: 724, Loss: 2390.164794921875\n",
      "Epoch: 5, Batch: 725, Loss: 2789.552978515625\n",
      "Epoch: 5, Batch: 726, Loss: 2609.552978515625\n",
      "Epoch: 5, Batch: 727, Loss: 2730.887939453125\n",
      "Epoch: 5, Batch: 728, Loss: 2541.615478515625\n",
      "Epoch: 5, Batch: 729, Loss: 2560.953369140625\n",
      "Epoch: 5, Batch: 730, Loss: 2672.057861328125\n",
      "Epoch: 5, Batch: 731, Loss: 2628.70751953125\n",
      "Epoch: 5, Batch: 732, Loss: 2332.74462890625\n",
      "Epoch: 5, Batch: 733, Loss: 3387.01708984375\n",
      "Epoch: 5, Batch: 734, Loss: 3163.168212890625\n",
      "Epoch: 5, Batch: 735, Loss: 2880.189453125\n",
      "Epoch: 5, Batch: 736, Loss: 2870.58251953125\n",
      "Epoch: 5, Batch: 737, Loss: 2519.0390625\n",
      "Epoch: 5, Batch: 738, Loss: 2627.302734375\n",
      "Epoch: 5, Batch: 739, Loss: 3004.188232421875\n",
      "Epoch: 5, Batch: 740, Loss: 2623.859619140625\n",
      "Epoch: 5, Batch: 741, Loss: 2733.34375\n",
      "Epoch: 5, Batch: 742, Loss: 2753.49853515625\n",
      "Epoch: 5, Batch: 743, Loss: 2974.94970703125\n",
      "Epoch: 5, Batch: 744, Loss: 2444.22265625\n",
      "Epoch: 5, Batch: 745, Loss: 2346.339599609375\n",
      "Epoch: 5, Batch: 746, Loss: 2393.081787109375\n",
      "Epoch: 5, Batch: 747, Loss: 2406.655029296875\n",
      "Epoch: 5, Batch: 748, Loss: 2964.7705078125\n",
      "Epoch: 5, Batch: 749, Loss: 2406.30322265625\n",
      "Epoch: 5, Batch: 750, Loss: 3011.023681640625\n",
      "Epoch: 5, Batch: 751, Loss: 2344.26025390625\n",
      "Epoch: 5, Batch: 752, Loss: 2345.370361328125\n",
      "Epoch: 5, Batch: 753, Loss: 2199.734130859375\n",
      "Epoch: 5, Batch: 754, Loss: 2578.838134765625\n",
      "Epoch: 5, Batch: 755, Loss: 2908.3427734375\n",
      "Epoch: 5, Batch: 756, Loss: 2418.0859375\n",
      "Epoch: 5, Batch: 757, Loss: 2440.10693359375\n",
      "Epoch: 5, Batch: 758, Loss: 2295.51611328125\n",
      "Epoch: 5, Batch: 759, Loss: 2843.76220703125\n",
      "Epoch: 5, Batch: 760, Loss: 2780.2529296875\n",
      "Epoch: 5, Batch: 761, Loss: 2272.7529296875\n",
      "Epoch: 5, Batch: 762, Loss: 2486.331298828125\n",
      "Epoch: 5, Batch: 763, Loss: 2636.14794921875\n",
      "Epoch: 5, Batch: 764, Loss: 2666.243408203125\n",
      "Epoch: 5, Batch: 765, Loss: 2932.4130859375\n",
      "Epoch: 5, Batch: 766, Loss: 2732.80224609375\n",
      "Epoch: 5, Batch: 767, Loss: 2662.649169921875\n",
      "Epoch: 5, Batch: 768, Loss: 2388.556884765625\n",
      "Epoch: 5, Batch: 769, Loss: 2421.010009765625\n",
      "Epoch: 5, Batch: 770, Loss: 2615.0634765625\n",
      "Epoch: 5, Batch: 771, Loss: 2710.906494140625\n",
      "Epoch: 5, Batch: 772, Loss: 3480.86376953125\n",
      "Epoch: 5, Batch: 773, Loss: 2595.892822265625\n",
      "Epoch: 5, Batch: 774, Loss: 2882.76123046875\n",
      "Epoch: 5, Batch: 775, Loss: 2679.916015625\n",
      "Epoch: 5, Batch: 776, Loss: 2700.0185546875\n",
      "Epoch: 5, Batch: 777, Loss: 2518.33544921875\n",
      "Epoch: 5, Batch: 778, Loss: 2689.733154296875\n",
      "Epoch: 5, Batch: 779, Loss: 2888.22021484375\n",
      "Epoch: 5, Batch: 780, Loss: 1947.1551513671875\n",
      "Epoch: 5, Batch: 781, Loss: 3075.377197265625\n",
      "Epoch: 5, Batch: 782, Loss: 2178.165771484375\n",
      "Epoch: 5, Batch: 783, Loss: 3104.264404296875\n",
      "Epoch: 5, Batch: 784, Loss: 2790.54443359375\n",
      "Epoch: 5, Batch: 785, Loss: 2324.361572265625\n",
      "Epoch: 5, Batch: 786, Loss: 2478.05419921875\n",
      "Epoch: 5, Batch: 787, Loss: 2795.909912109375\n",
      "Epoch: 5, Batch: 788, Loss: 2815.571044921875\n",
      "Epoch: 5, Batch: 789, Loss: 2082.67724609375\n",
      "Epoch: 5, Batch: 790, Loss: 2534.961181640625\n",
      "Epoch: 5, Batch: 791, Loss: 2733.64892578125\n",
      "Epoch: 5, Batch: 792, Loss: 2839.493896484375\n",
      "Epoch: 5, Batch: 793, Loss: 2971.884033203125\n",
      "Epoch: 5, Batch: 794, Loss: 2380.012451171875\n",
      "Epoch: 5, Batch: 795, Loss: 2512.588134765625\n",
      "Epoch: 5, Batch: 796, Loss: 2559.001220703125\n",
      "Epoch: 5, Batch: 797, Loss: 2452.359130859375\n",
      "Epoch: 5, Batch: 798, Loss: 2320.964111328125\n",
      "Epoch: 5, Batch: 799, Loss: 2418.179931640625\n",
      "Epoch: 5, Batch: 800, Loss: 3054.09130859375\n",
      "Epoch: 5, Batch: 801, Loss: 2441.701171875\n",
      "Epoch: 5, Batch: 802, Loss: 3073.905517578125\n",
      "Epoch: 5, Batch: 803, Loss: 2938.197998046875\n",
      "Epoch: 5, Batch: 804, Loss: 2930.2158203125\n",
      "Epoch: 5, Batch: 805, Loss: 2964.89111328125\n",
      "Epoch: 5, Batch: 806, Loss: 3020.6630859375\n",
      "Epoch: 5, Batch: 807, Loss: 3066.1533203125\n",
      "Epoch: 5, Batch: 808, Loss: 2252.541015625\n",
      "Epoch: 5, Batch: 809, Loss: 3031.15673828125\n",
      "Epoch: 5, Batch: 810, Loss: 2939.875732421875\n",
      "Epoch: 5, Batch: 811, Loss: 2724.6689453125\n",
      "Epoch: 5, Batch: 812, Loss: 2560.8623046875\n",
      "Epoch: 5, Batch: 813, Loss: 2996.844482421875\n",
      "Epoch: 5, Batch: 814, Loss: 2283.167236328125\n",
      "Epoch: 5, Batch: 815, Loss: 2987.21142578125\n",
      "Epoch: 5, Batch: 816, Loss: 2380.55029296875\n",
      "Epoch: 5, Batch: 817, Loss: 2505.843994140625\n",
      "Epoch: 5, Batch: 818, Loss: 2285.62548828125\n",
      "Epoch: 5, Batch: 819, Loss: 3141.5703125\n",
      "Epoch: 5, Batch: 820, Loss: 2562.404296875\n",
      "Epoch: 5, Batch: 821, Loss: 2241.40478515625\n",
      "Epoch: 5, Batch: 822, Loss: 2824.70703125\n",
      "Epoch: 5, Batch: 823, Loss: 3004.007080078125\n",
      "Epoch: 5, Batch: 824, Loss: 2792.84619140625\n",
      "Epoch: 5, Batch: 825, Loss: 2735.470458984375\n",
      "Epoch: 5, Batch: 826, Loss: 2231.22021484375\n",
      "Epoch: 5, Batch: 827, Loss: 3271.73046875\n",
      "Epoch: 5, Batch: 828, Loss: 2735.849609375\n",
      "Epoch: 5, Batch: 829, Loss: 2909.959228515625\n",
      "Epoch: 5, Batch: 830, Loss: 2740.375\n",
      "Epoch: 5, Batch: 831, Loss: 2333.397705078125\n",
      "Epoch: 5, Batch: 832, Loss: 2630.93408203125\n",
      "Epoch: 5, Batch: 833, Loss: 2358.18896484375\n",
      "Epoch: 5, Batch: 834, Loss: 2117.576416015625\n",
      "Epoch: 5, Batch: 835, Loss: 2053.286376953125\n",
      "Epoch: 5, Batch: 836, Loss: 2820.759765625\n",
      "Epoch: 5, Batch: 837, Loss: 3099.162109375\n",
      "Epoch: 5, Batch: 838, Loss: 2770.514404296875\n",
      "Epoch: 5, Batch: 839, Loss: 2686.995849609375\n",
      "Epoch: 5, Batch: 840, Loss: 2507.155517578125\n",
      "Epoch: 5, Batch: 841, Loss: 2087.5234375\n",
      "Epoch: 5, Batch: 842, Loss: 2587.673583984375\n",
      "Epoch: 5, Batch: 843, Loss: 2395.1318359375\n",
      "Epoch: 5, Batch: 844, Loss: 3191.560302734375\n",
      "Epoch: 5, Batch: 845, Loss: 2430.672119140625\n",
      "Epoch: 5, Batch: 846, Loss: 2951.447998046875\n",
      "Epoch: 5, Batch: 847, Loss: 2674.37353515625\n",
      "Epoch: 5, Batch: 848, Loss: 3091.5615234375\n",
      "Epoch: 5, Batch: 849, Loss: 2845.1650390625\n",
      "Epoch: 5, Batch: 850, Loss: 2440.93408203125\n",
      "Epoch: 5, Batch: 851, Loss: 2489.374755859375\n",
      "Epoch: 5, Batch: 852, Loss: 2402.57177734375\n",
      "Epoch: 5, Batch: 853, Loss: 2977.15625\n",
      "Epoch: 5, Batch: 854, Loss: 2930.6494140625\n",
      "Epoch: 5, Batch: 855, Loss: 3050.485595703125\n",
      "Epoch: 5, Batch: 856, Loss: 2352.56494140625\n",
      "Epoch: 5, Batch: 857, Loss: 2840.44189453125\n",
      "Epoch: 5, Batch: 858, Loss: 3035.1728515625\n",
      "Epoch: 5, Batch: 859, Loss: 2716.37548828125\n",
      "Epoch: 5, Batch: 860, Loss: 2582.749267578125\n",
      "Epoch: 5, Batch: 861, Loss: 2200.269775390625\n",
      "Epoch: 5, Batch: 862, Loss: 2629.00146484375\n",
      "Epoch: 5, Batch: 863, Loss: 2553.264404296875\n",
      "Epoch: 5, Batch: 864, Loss: 2616.21337890625\n",
      "Epoch: 5, Batch: 865, Loss: 3048.6640625\n",
      "Epoch: 5, Batch: 866, Loss: 2296.08056640625\n",
      "Epoch: 5, Batch: 867, Loss: 2616.292724609375\n",
      "Epoch: 5, Batch: 868, Loss: 2993.66162109375\n",
      "Epoch: 5, Batch: 869, Loss: 2717.3359375\n",
      "Epoch: 5, Batch: 870, Loss: 2420.3193359375\n",
      "Epoch: 5, Batch: 871, Loss: 2960.146240234375\n",
      "Epoch: 5, Batch: 872, Loss: 3792.26318359375\n",
      "Epoch: 5, Batch: 873, Loss: 2676.18359375\n",
      "Epoch: 5, Batch: 874, Loss: 2854.693603515625\n",
      "Epoch: 5, Batch: 875, Loss: 2539.78857421875\n",
      "Epoch: 5, Batch: 876, Loss: 3046.58349609375\n",
      "Epoch: 5, Batch: 877, Loss: 2994.681396484375\n",
      "Epoch: 5, Batch: 878, Loss: 3106.343017578125\n",
      "Epoch: 5, Batch: 879, Loss: 2552.736572265625\n",
      "Epoch: 5, Batch: 880, Loss: 2355.790771484375\n",
      "Epoch: 5, Batch: 881, Loss: 2506.082763671875\n",
      "Epoch: 5, Batch: 882, Loss: 2656.50390625\n",
      "Epoch: 5, Batch: 883, Loss: 2942.890380859375\n",
      "Epoch: 5, Batch: 884, Loss: 2781.506591796875\n",
      "Epoch: 5, Batch: 885, Loss: 2765.18359375\n",
      "Epoch: 5, Batch: 886, Loss: 2166.9638671875\n",
      "Epoch: 5, Batch: 887, Loss: 2553.298095703125\n",
      "Epoch: 5, Batch: 888, Loss: 2913.0361328125\n",
      "Epoch: 5, Batch: 889, Loss: 2738.93408203125\n",
      "Epoch: 5, Batch: 890, Loss: 2255.742919921875\n",
      "Epoch: 5, Batch: 891, Loss: 2629.662841796875\n",
      "Epoch: 5, Batch: 892, Loss: 2587.11376953125\n",
      "Epoch: 5, Batch: 893, Loss: 2095.4384765625\n",
      "Epoch: 5, Batch: 894, Loss: 2883.9970703125\n",
      "Epoch: 5, Batch: 895, Loss: 2555.716796875\n",
      "Epoch: 5, Batch: 896, Loss: 2082.643798828125\n",
      "Epoch: 5, Batch: 897, Loss: 2303.535400390625\n",
      "Epoch: 5, Batch: 898, Loss: 2426.1318359375\n",
      "Epoch: 5, Batch: 899, Loss: 2462.892333984375\n",
      "Epoch: 5, Batch: 900, Loss: 2633.2177734375\n",
      "Epoch: 5, Batch: 901, Loss: 2322.750244140625\n",
      "Epoch: 5, Batch: 902, Loss: 2833.8291015625\n",
      "Epoch: 5, Batch: 903, Loss: 3048.864990234375\n",
      "Epoch: 5, Batch: 904, Loss: 2430.9814453125\n",
      "Epoch: 5, Batch: 905, Loss: 2501.615478515625\n",
      "Epoch: 5, Batch: 906, Loss: 2222.19677734375\n",
      "Epoch: 5, Batch: 907, Loss: 3205.976806640625\n",
      "Epoch: 5, Batch: 908, Loss: 2776.421630859375\n",
      "Epoch: 5, Batch: 909, Loss: 2451.904052734375\n",
      "Epoch: 5, Batch: 910, Loss: 2163.10009765625\n",
      "Epoch: 5, Batch: 911, Loss: 2871.33056640625\n",
      "Epoch: 5, Batch: 912, Loss: 3146.18701171875\n",
      "Epoch: 5, Batch: 913, Loss: 2785.132568359375\n",
      "Epoch: 5, Batch: 914, Loss: 3123.71435546875\n",
      "Epoch: 5, Batch: 915, Loss: 2430.219970703125\n",
      "Epoch: 5, Batch: 916, Loss: 3155.63818359375\n",
      "Epoch: 5, Batch: 917, Loss: 1996.21728515625\n",
      "Epoch: 5, Batch: 918, Loss: 2693.92529296875\n",
      "Epoch: 5, Batch: 919, Loss: 2851.18896484375\n",
      "Epoch: 5, Batch: 920, Loss: 2649.86767578125\n",
      "Epoch: 5, Batch: 921, Loss: 2604.15625\n",
      "Epoch: 5, Batch: 922, Loss: 1937.04345703125\n",
      "Epoch: 5, Batch: 923, Loss: 2655.25537109375\n",
      "Epoch: 5, Batch: 924, Loss: 2550.311279296875\n",
      "Epoch: 5, Batch: 925, Loss: 2625.37353515625\n",
      "Epoch: 5, Batch: 926, Loss: 2862.75732421875\n",
      "Epoch: 5, Batch: 927, Loss: 2267.8095703125\n",
      "Epoch: 5, Batch: 928, Loss: 2604.19580078125\n",
      "Epoch: 5, Batch: 929, Loss: 2750.40478515625\n",
      "Epoch: 5, Batch: 930, Loss: 2634.98974609375\n",
      "Epoch: 5, Batch: 931, Loss: 2331.45849609375\n",
      "Epoch: 5, Batch: 932, Loss: 2535.314453125\n",
      "Epoch: 5, Batch: 933, Loss: 2623.958251953125\n",
      "Epoch: 5, Batch: 934, Loss: 2444.690185546875\n",
      "Epoch: 5, Batch: 935, Loss: 3141.68212890625\n",
      "Epoch: 5, Batch: 936, Loss: 2716.920654296875\n",
      "Epoch: 5, Batch: 937, Loss: 2540.02197265625\n",
      "Epoch: 5, Batch: 938, Loss: 2825.93896484375\n",
      "Epoch: 5, Batch: 939, Loss: 2079.552734375\n",
      "Epoch: 5, Batch: 940, Loss: 2114.46240234375\n",
      "Epoch: 5, Batch: 941, Loss: 2564.64306640625\n",
      "Epoch: 5, Batch: 942, Loss: 2247.438232421875\n",
      "Epoch: 5, Batch: 943, Loss: 2812.3955078125\n",
      "Epoch: 5, Batch: 944, Loss: 2332.7353515625\n",
      "Epoch: 5, Batch: 945, Loss: 2857.900634765625\n",
      "Epoch: 5, Batch: 946, Loss: 2213.9677734375\n",
      "Epoch: 5, Batch: 947, Loss: 2936.590576171875\n",
      "Epoch: 5, Batch: 948, Loss: 2985.9716796875\n",
      "Epoch: 5, Batch: 949, Loss: 2849.40673828125\n",
      "Epoch: 5, Batch: 950, Loss: 2695.675537109375\n",
      "Epoch: 5, Batch: 951, Loss: 2290.5244140625\n",
      "Epoch: 5, Batch: 952, Loss: 2712.494384765625\n",
      "Epoch: 5, Batch: 953, Loss: 2436.117431640625\n",
      "Epoch: 5, Batch: 954, Loss: 2519.182373046875\n",
      "Epoch: 5, Batch: 955, Loss: 2909.8818359375\n",
      "Epoch: 5, Batch: 956, Loss: 2654.112060546875\n",
      "Epoch: 5, Batch: 957, Loss: 2395.925537109375\n",
      "Epoch: 5, Batch: 958, Loss: 2800.060791015625\n",
      "Epoch: 5, Batch: 959, Loss: 2337.89892578125\n",
      "Epoch: 5, Batch: 960, Loss: 2541.533447265625\n",
      "Epoch: 5, Batch: 961, Loss: 2862.846923828125\n",
      "Epoch: 5, Batch: 962, Loss: 2251.283203125\n",
      "Epoch: 5, Batch: 963, Loss: 2275.96923828125\n",
      "Epoch: 5, Batch: 964, Loss: 2058.197998046875\n",
      "Epoch: 5, Batch: 965, Loss: 2651.14990234375\n",
      "Epoch: 5, Batch: 966, Loss: 2316.755126953125\n",
      "Epoch: 5, Batch: 967, Loss: 2465.280029296875\n",
      "Epoch: 5, Batch: 968, Loss: 2473.797119140625\n",
      "Epoch: 5, Batch: 969, Loss: 2645.298095703125\n",
      "Epoch: 5, Batch: 970, Loss: 3318.93017578125\n",
      "Epoch: 5, Batch: 971, Loss: 2554.496337890625\n",
      "Epoch: 5, Batch: 972, Loss: 2173.142333984375\n",
      "Epoch: 5, Batch: 973, Loss: 2765.970947265625\n",
      "Epoch: 5, Batch: 974, Loss: 2616.26220703125\n",
      "Epoch: 5, Batch: 975, Loss: 3000.95654296875\n",
      "Epoch: 5, Batch: 976, Loss: 1956.09423828125\n",
      "Epoch: 5, Batch: 977, Loss: 3080.207275390625\n",
      "Epoch: 5, Batch: 978, Loss: 2918.706298828125\n",
      "Epoch: 5, Batch: 979, Loss: 3135.5390625\n",
      "Epoch: 5, Batch: 980, Loss: 2700.805419921875\n",
      "Epoch: 5, Batch: 981, Loss: 2618.76708984375\n",
      "Epoch: 5, Batch: 982, Loss: 3356.610595703125\n",
      "Epoch: 5, Batch: 983, Loss: 2607.689697265625\n",
      "Epoch: 5, Batch: 984, Loss: 2611.3046875\n",
      "Epoch: 5, Batch: 985, Loss: 2634.34765625\n",
      "Epoch: 5, Batch: 986, Loss: 2406.0703125\n",
      "Epoch: 5, Batch: 987, Loss: 2142.119140625\n",
      "Epoch: 5, Batch: 988, Loss: 2646.177490234375\n",
      "Epoch: 5, Batch: 989, Loss: 2643.5205078125\n",
      "Epoch: 5, Batch: 990, Loss: 2501.730712890625\n",
      "Epoch: 5, Batch: 991, Loss: 2852.640380859375\n",
      "Epoch: 5, Batch: 992, Loss: 2323.76513671875\n",
      "Epoch: 5, Batch: 993, Loss: 2659.96630859375\n",
      "Epoch: 5, Batch: 994, Loss: 2211.675048828125\n",
      "Epoch: 5, Batch: 995, Loss: 2177.16552734375\n",
      "Epoch: 5, Batch: 996, Loss: 2462.370361328125\n",
      "Epoch: 5, Batch: 997, Loss: 1501.802490234375\n",
      "Epoch: 5, Batch: 998, Loss: 2861.83056640625\n",
      "Epoch: 5, Batch: 999, Loss: 2385.682861328125\n",
      "Epoch: 6, Batch: 0, Loss: 2985.98583984375\n",
      "Epoch: 6, Batch: 1, Loss: 3153.0185546875\n",
      "Epoch: 6, Batch: 2, Loss: 2635.7021484375\n",
      "Epoch: 6, Batch: 3, Loss: 3138.022705078125\n",
      "Epoch: 6, Batch: 4, Loss: 2677.77099609375\n",
      "Epoch: 6, Batch: 5, Loss: 2726.751953125\n",
      "Epoch: 6, Batch: 6, Loss: 2633.2138671875\n",
      "Epoch: 6, Batch: 7, Loss: 2215.740966796875\n",
      "Epoch: 6, Batch: 8, Loss: 2722.53369140625\n",
      "Epoch: 6, Batch: 9, Loss: 2501.446533203125\n",
      "Epoch: 6, Batch: 10, Loss: 2353.607666015625\n",
      "Epoch: 6, Batch: 11, Loss: 2788.94384765625\n",
      "Epoch: 6, Batch: 12, Loss: 2299.307861328125\n",
      "Epoch: 6, Batch: 13, Loss: 2060.51025390625\n",
      "Epoch: 6, Batch: 14, Loss: 2600.10595703125\n",
      "Epoch: 6, Batch: 15, Loss: 2263.06689453125\n",
      "Epoch: 6, Batch: 16, Loss: 2533.971435546875\n",
      "Epoch: 6, Batch: 17, Loss: 3104.484375\n",
      "Epoch: 6, Batch: 18, Loss: 2148.990234375\n",
      "Epoch: 6, Batch: 19, Loss: 2849.841796875\n",
      "Epoch: 6, Batch: 20, Loss: 2540.383544921875\n",
      "Epoch: 6, Batch: 21, Loss: 3262.6015625\n",
      "Epoch: 6, Batch: 22, Loss: 2153.51953125\n",
      "Epoch: 6, Batch: 23, Loss: 2343.58447265625\n",
      "Epoch: 6, Batch: 24, Loss: 3089.1025390625\n",
      "Epoch: 6, Batch: 25, Loss: 2788.96044921875\n",
      "Epoch: 6, Batch: 26, Loss: 2545.463623046875\n",
      "Epoch: 6, Batch: 27, Loss: 2402.03076171875\n",
      "Epoch: 6, Batch: 28, Loss: 2817.551513671875\n",
      "Epoch: 6, Batch: 29, Loss: 2751.3037109375\n",
      "Epoch: 6, Batch: 30, Loss: 2656.836181640625\n",
      "Epoch: 6, Batch: 31, Loss: 1774.7095947265625\n",
      "Epoch: 6, Batch: 32, Loss: 2609.88037109375\n",
      "Epoch: 6, Batch: 33, Loss: 3227.611083984375\n",
      "Epoch: 6, Batch: 34, Loss: 2695.786865234375\n",
      "Epoch: 6, Batch: 35, Loss: 2413.733154296875\n",
      "Epoch: 6, Batch: 36, Loss: 2651.77783203125\n",
      "Epoch: 6, Batch: 37, Loss: 2242.424560546875\n",
      "Epoch: 6, Batch: 38, Loss: 2864.486328125\n",
      "Epoch: 6, Batch: 39, Loss: 2517.673095703125\n",
      "Epoch: 6, Batch: 40, Loss: 2520.90478515625\n",
      "Epoch: 6, Batch: 41, Loss: 2661.1826171875\n",
      "Epoch: 6, Batch: 42, Loss: 2855.5205078125\n",
      "Epoch: 6, Batch: 43, Loss: 3210.128173828125\n",
      "Epoch: 6, Batch: 44, Loss: 2173.12353515625\n",
      "Epoch: 6, Batch: 45, Loss: 2362.407470703125\n",
      "Epoch: 6, Batch: 46, Loss: 2492.531494140625\n",
      "Epoch: 6, Batch: 47, Loss: 2948.123291015625\n",
      "Epoch: 6, Batch: 48, Loss: 2655.017333984375\n",
      "Epoch: 6, Batch: 49, Loss: 2879.685546875\n",
      "Epoch: 6, Batch: 50, Loss: 2860.089599609375\n",
      "Epoch: 6, Batch: 51, Loss: 2735.600830078125\n",
      "Epoch: 6, Batch: 52, Loss: 2375.834228515625\n",
      "Epoch: 6, Batch: 53, Loss: 2864.471435546875\n",
      "Epoch: 6, Batch: 54, Loss: 3027.56982421875\n",
      "Epoch: 6, Batch: 55, Loss: 3184.584716796875\n",
      "Epoch: 6, Batch: 56, Loss: 2657.995849609375\n",
      "Epoch: 6, Batch: 57, Loss: 2750.069580078125\n",
      "Epoch: 6, Batch: 58, Loss: 2218.611083984375\n",
      "Epoch: 6, Batch: 59, Loss: 2625.458984375\n",
      "Epoch: 6, Batch: 60, Loss: 2891.47314453125\n",
      "Epoch: 6, Batch: 61, Loss: 2364.871337890625\n",
      "Epoch: 6, Batch: 62, Loss: 2982.513427734375\n",
      "Epoch: 6, Batch: 63, Loss: 2435.918212890625\n",
      "Epoch: 6, Batch: 64, Loss: 3040.685302734375\n",
      "Epoch: 6, Batch: 65, Loss: 3179.88671875\n",
      "Epoch: 6, Batch: 66, Loss: 2225.115234375\n",
      "Epoch: 6, Batch: 67, Loss: 2682.634765625\n",
      "Epoch: 6, Batch: 68, Loss: 2494.09375\n",
      "Epoch: 6, Batch: 69, Loss: 2681.86181640625\n",
      "Epoch: 6, Batch: 70, Loss: 2968.037353515625\n",
      "Epoch: 6, Batch: 71, Loss: 2499.95556640625\n",
      "Epoch: 6, Batch: 72, Loss: 2739.669921875\n",
      "Epoch: 6, Batch: 73, Loss: 3103.86962890625\n",
      "Epoch: 6, Batch: 74, Loss: 2508.58251953125\n",
      "Epoch: 6, Batch: 75, Loss: 2774.369140625\n",
      "Epoch: 6, Batch: 76, Loss: 2532.33984375\n",
      "Epoch: 6, Batch: 77, Loss: 2832.199951171875\n",
      "Epoch: 6, Batch: 78, Loss: 2474.895263671875\n",
      "Epoch: 6, Batch: 79, Loss: 2542.835693359375\n",
      "Epoch: 6, Batch: 80, Loss: 2685.96435546875\n",
      "Epoch: 6, Batch: 81, Loss: 2460.9599609375\n",
      "Epoch: 6, Batch: 82, Loss: 2642.1728515625\n",
      "Epoch: 6, Batch: 83, Loss: 2753.26416015625\n",
      "Epoch: 6, Batch: 84, Loss: 2386.75390625\n",
      "Epoch: 6, Batch: 85, Loss: 2504.2763671875\n",
      "Epoch: 6, Batch: 86, Loss: 2722.662109375\n",
      "Epoch: 6, Batch: 87, Loss: 2542.07470703125\n",
      "Epoch: 6, Batch: 88, Loss: 3051.17578125\n",
      "Epoch: 6, Batch: 89, Loss: 2557.545166015625\n",
      "Epoch: 6, Batch: 90, Loss: 2689.76123046875\n",
      "Epoch: 6, Batch: 91, Loss: 2884.066162109375\n",
      "Epoch: 6, Batch: 92, Loss: 2293.11181640625\n",
      "Epoch: 6, Batch: 93, Loss: 2064.7802734375\n",
      "Epoch: 6, Batch: 94, Loss: 3127.042236328125\n",
      "Epoch: 6, Batch: 95, Loss: 2891.7333984375\n",
      "Epoch: 6, Batch: 96, Loss: 3040.64794921875\n",
      "Epoch: 6, Batch: 97, Loss: 2468.122802734375\n",
      "Epoch: 6, Batch: 98, Loss: 2600.2578125\n",
      "Epoch: 6, Batch: 99, Loss: 2518.13916015625\n",
      "Epoch: 6, Batch: 100, Loss: 2719.42333984375\n",
      "Epoch: 6, Batch: 101, Loss: 2683.785888671875\n",
      "Epoch: 6, Batch: 102, Loss: 2988.7333984375\n",
      "Epoch: 6, Batch: 103, Loss: 2344.6044921875\n",
      "Epoch: 6, Batch: 104, Loss: 2169.4501953125\n",
      "Epoch: 6, Batch: 105, Loss: 1938.30859375\n",
      "Epoch: 6, Batch: 106, Loss: 2396.671875\n",
      "Epoch: 6, Batch: 107, Loss: 2440.706787109375\n",
      "Epoch: 6, Batch: 108, Loss: 2525.737548828125\n",
      "Epoch: 6, Batch: 109, Loss: 2559.0712890625\n",
      "Epoch: 6, Batch: 110, Loss: 1856.087646484375\n",
      "Epoch: 6, Batch: 111, Loss: 2779.1796875\n",
      "Epoch: 6, Batch: 112, Loss: 2664.72802734375\n",
      "Epoch: 6, Batch: 113, Loss: 2758.74609375\n",
      "Epoch: 6, Batch: 114, Loss: 2336.62109375\n",
      "Epoch: 6, Batch: 115, Loss: 2564.4296875\n",
      "Epoch: 6, Batch: 116, Loss: 2577.01806640625\n",
      "Epoch: 6, Batch: 117, Loss: 3020.9873046875\n",
      "Epoch: 6, Batch: 118, Loss: 2776.89501953125\n",
      "Epoch: 6, Batch: 119, Loss: 2371.199462890625\n",
      "Epoch: 6, Batch: 120, Loss: 3414.95654296875\n",
      "Epoch: 6, Batch: 121, Loss: 2431.05859375\n",
      "Epoch: 6, Batch: 122, Loss: 3065.35986328125\n",
      "Epoch: 6, Batch: 123, Loss: 2235.482421875\n",
      "Epoch: 6, Batch: 124, Loss: 3249.8193359375\n",
      "Epoch: 6, Batch: 125, Loss: 3218.28564453125\n",
      "Epoch: 6, Batch: 126, Loss: 3219.096923828125\n",
      "Epoch: 6, Batch: 127, Loss: 2265.056640625\n",
      "Epoch: 6, Batch: 128, Loss: 2435.89453125\n",
      "Epoch: 6, Batch: 129, Loss: 2564.289794921875\n",
      "Epoch: 6, Batch: 130, Loss: 2375.66455078125\n",
      "Epoch: 6, Batch: 131, Loss: 2184.602294921875\n",
      "Epoch: 6, Batch: 132, Loss: 2839.47119140625\n",
      "Epoch: 6, Batch: 133, Loss: 2483.548583984375\n",
      "Epoch: 6, Batch: 134, Loss: 2173.58544921875\n",
      "Epoch: 6, Batch: 135, Loss: 2737.174072265625\n",
      "Epoch: 6, Batch: 136, Loss: 2481.82470703125\n",
      "Epoch: 6, Batch: 137, Loss: 2931.45849609375\n",
      "Epoch: 6, Batch: 138, Loss: 2229.140625\n",
      "Epoch: 6, Batch: 139, Loss: 2744.350830078125\n",
      "Epoch: 6, Batch: 140, Loss: 2292.630126953125\n",
      "Epoch: 6, Batch: 141, Loss: 2690.3134765625\n",
      "Epoch: 6, Batch: 142, Loss: 2148.893310546875\n",
      "Epoch: 6, Batch: 143, Loss: 3095.236328125\n",
      "Epoch: 6, Batch: 144, Loss: 1772.25\n",
      "Epoch: 6, Batch: 145, Loss: 2392.10546875\n",
      "Epoch: 6, Batch: 146, Loss: 2492.946044921875\n",
      "Epoch: 6, Batch: 147, Loss: 2938.040771484375\n",
      "Epoch: 6, Batch: 148, Loss: 3186.14599609375\n",
      "Epoch: 6, Batch: 149, Loss: 2263.382568359375\n",
      "Epoch: 6, Batch: 150, Loss: 2498.392333984375\n",
      "Epoch: 6, Batch: 151, Loss: 2850.05419921875\n",
      "Epoch: 6, Batch: 152, Loss: 2825.734619140625\n",
      "Epoch: 6, Batch: 153, Loss: 2042.78173828125\n",
      "Epoch: 6, Batch: 154, Loss: 2095.80712890625\n",
      "Epoch: 6, Batch: 155, Loss: 2538.99609375\n",
      "Epoch: 6, Batch: 156, Loss: 2082.86328125\n",
      "Epoch: 6, Batch: 157, Loss: 2735.254638671875\n",
      "Epoch: 6, Batch: 158, Loss: 2571.287109375\n",
      "Epoch: 6, Batch: 159, Loss: 2971.46875\n",
      "Epoch: 6, Batch: 160, Loss: 2695.3154296875\n",
      "Epoch: 6, Batch: 161, Loss: 2721.87353515625\n",
      "Epoch: 6, Batch: 162, Loss: 2793.906005859375\n",
      "Epoch: 6, Batch: 163, Loss: 2719.95556640625\n",
      "Epoch: 6, Batch: 164, Loss: 2669.46728515625\n",
      "Epoch: 6, Batch: 165, Loss: 2763.079833984375\n",
      "Epoch: 6, Batch: 166, Loss: 2687.782958984375\n",
      "Epoch: 6, Batch: 167, Loss: 2775.1611328125\n",
      "Epoch: 6, Batch: 168, Loss: 2811.6767578125\n",
      "Epoch: 6, Batch: 169, Loss: 2339.4404296875\n",
      "Epoch: 6, Batch: 170, Loss: 2358.3369140625\n",
      "Epoch: 6, Batch: 171, Loss: 2378.17236328125\n",
      "Epoch: 6, Batch: 172, Loss: 2537.263427734375\n",
      "Epoch: 6, Batch: 173, Loss: 2556.000732421875\n",
      "Epoch: 6, Batch: 174, Loss: 2850.582763671875\n",
      "Epoch: 6, Batch: 175, Loss: 2748.635986328125\n",
      "Epoch: 6, Batch: 176, Loss: 2707.857666015625\n",
      "Epoch: 6, Batch: 177, Loss: 2424.264892578125\n",
      "Epoch: 6, Batch: 178, Loss: 2677.650146484375\n",
      "Epoch: 6, Batch: 179, Loss: 2880.552734375\n",
      "Epoch: 6, Batch: 180, Loss: 2645.673095703125\n",
      "Epoch: 6, Batch: 181, Loss: 3427.012939453125\n",
      "Epoch: 6, Batch: 182, Loss: 2464.703857421875\n",
      "Epoch: 6, Batch: 183, Loss: 2252.2099609375\n",
      "Epoch: 6, Batch: 184, Loss: 2297.56005859375\n",
      "Epoch: 6, Batch: 185, Loss: 2835.283935546875\n",
      "Epoch: 6, Batch: 186, Loss: 2282.881591796875\n",
      "Epoch: 6, Batch: 187, Loss: 2886.446533203125\n",
      "Epoch: 6, Batch: 188, Loss: 3276.34423828125\n",
      "Epoch: 6, Batch: 189, Loss: 2785.177490234375\n",
      "Epoch: 6, Batch: 190, Loss: 2283.177490234375\n",
      "Epoch: 6, Batch: 191, Loss: 2410.01171875\n",
      "Epoch: 6, Batch: 192, Loss: 2243.513916015625\n",
      "Epoch: 6, Batch: 193, Loss: 2851.740478515625\n",
      "Epoch: 6, Batch: 194, Loss: 2512.725341796875\n",
      "Epoch: 6, Batch: 195, Loss: 2280.943603515625\n",
      "Epoch: 6, Batch: 196, Loss: 2158.686767578125\n",
      "Epoch: 6, Batch: 197, Loss: 2390.02392578125\n",
      "Epoch: 6, Batch: 198, Loss: 2937.166259765625\n",
      "Epoch: 6, Batch: 199, Loss: 2564.066650390625\n",
      "Epoch: 6, Batch: 200, Loss: 2591.772216796875\n",
      "Epoch: 6, Batch: 201, Loss: 2984.12744140625\n",
      "Epoch: 6, Batch: 202, Loss: 2663.46923828125\n",
      "Epoch: 6, Batch: 203, Loss: 2022.6402587890625\n",
      "Epoch: 6, Batch: 204, Loss: 2090.81884765625\n",
      "Epoch: 6, Batch: 205, Loss: 2528.98974609375\n",
      "Epoch: 6, Batch: 206, Loss: 2719.157958984375\n",
      "Epoch: 6, Batch: 207, Loss: 2645.40087890625\n",
      "Epoch: 6, Batch: 208, Loss: 2530.133056640625\n",
      "Epoch: 6, Batch: 209, Loss: 2606.72314453125\n",
      "Epoch: 6, Batch: 210, Loss: 2498.126953125\n",
      "Epoch: 6, Batch: 211, Loss: 3109.745361328125\n",
      "Epoch: 6, Batch: 212, Loss: 2659.76806640625\n",
      "Epoch: 6, Batch: 213, Loss: 3096.935546875\n",
      "Epoch: 6, Batch: 214, Loss: 2165.644287109375\n",
      "Epoch: 6, Batch: 215, Loss: 2903.150390625\n",
      "Epoch: 6, Batch: 216, Loss: 2932.587890625\n",
      "Epoch: 6, Batch: 217, Loss: 2815.05029296875\n",
      "Epoch: 6, Batch: 218, Loss: 2760.333251953125\n",
      "Epoch: 6, Batch: 219, Loss: 2277.8583984375\n",
      "Epoch: 6, Batch: 220, Loss: 2403.3203125\n",
      "Epoch: 6, Batch: 221, Loss: 2754.41845703125\n",
      "Epoch: 6, Batch: 222, Loss: 2360.745849609375\n",
      "Epoch: 6, Batch: 223, Loss: 3040.385498046875\n",
      "Epoch: 6, Batch: 224, Loss: 2799.391845703125\n",
      "Epoch: 6, Batch: 225, Loss: 2398.386474609375\n",
      "Epoch: 6, Batch: 226, Loss: 2798.27099609375\n",
      "Epoch: 6, Batch: 227, Loss: 2682.19140625\n",
      "Epoch: 6, Batch: 228, Loss: 2833.002685546875\n",
      "Epoch: 6, Batch: 229, Loss: 2490.85009765625\n",
      "Epoch: 6, Batch: 230, Loss: 2963.93212890625\n",
      "Epoch: 6, Batch: 231, Loss: 2894.22412109375\n",
      "Epoch: 6, Batch: 232, Loss: 2637.433349609375\n",
      "Epoch: 6, Batch: 233, Loss: 2776.735595703125\n",
      "Epoch: 6, Batch: 234, Loss: 2701.083984375\n",
      "Epoch: 6, Batch: 235, Loss: 2362.113037109375\n",
      "Epoch: 6, Batch: 236, Loss: 2273.681640625\n",
      "Epoch: 6, Batch: 237, Loss: 2067.546875\n",
      "Epoch: 6, Batch: 238, Loss: 2477.049560546875\n",
      "Epoch: 6, Batch: 239, Loss: 2652.35791015625\n",
      "Epoch: 6, Batch: 240, Loss: 2789.30810546875\n",
      "Epoch: 6, Batch: 241, Loss: 2541.590087890625\n",
      "Epoch: 6, Batch: 242, Loss: 2661.085693359375\n",
      "Epoch: 6, Batch: 243, Loss: 2995.808349609375\n",
      "Epoch: 6, Batch: 244, Loss: 2215.18896484375\n",
      "Epoch: 6, Batch: 245, Loss: 2584.63427734375\n",
      "Epoch: 6, Batch: 246, Loss: 2781.0576171875\n",
      "Epoch: 6, Batch: 247, Loss: 3052.463623046875\n",
      "Epoch: 6, Batch: 248, Loss: 2381.539794921875\n",
      "Epoch: 6, Batch: 249, Loss: 2811.958984375\n",
      "Epoch: 6, Batch: 250, Loss: 2538.19970703125\n",
      "Epoch: 6, Batch: 251, Loss: 2366.491455078125\n",
      "Epoch: 6, Batch: 252, Loss: 2888.5615234375\n",
      "Epoch: 6, Batch: 253, Loss: 2868.7861328125\n",
      "Epoch: 6, Batch: 254, Loss: 1963.4007568359375\n",
      "Epoch: 6, Batch: 255, Loss: 2566.578125\n",
      "Epoch: 6, Batch: 256, Loss: 2429.2978515625\n",
      "Epoch: 6, Batch: 257, Loss: 2531.060546875\n",
      "Epoch: 6, Batch: 258, Loss: 2672.7783203125\n",
      "Epoch: 6, Batch: 259, Loss: 2205.05615234375\n",
      "Epoch: 6, Batch: 260, Loss: 2881.83544921875\n",
      "Epoch: 6, Batch: 261, Loss: 2892.673095703125\n",
      "Epoch: 6, Batch: 262, Loss: 2808.6455078125\n",
      "Epoch: 6, Batch: 263, Loss: 2714.650146484375\n",
      "Epoch: 6, Batch: 264, Loss: 2739.76611328125\n",
      "Epoch: 6, Batch: 265, Loss: 2386.24609375\n",
      "Epoch: 6, Batch: 266, Loss: 2706.91552734375\n",
      "Epoch: 6, Batch: 267, Loss: 2725.60498046875\n",
      "Epoch: 6, Batch: 268, Loss: 2268.31591796875\n",
      "Epoch: 6, Batch: 269, Loss: 2401.821533203125\n",
      "Epoch: 6, Batch: 270, Loss: 2427.907470703125\n",
      "Epoch: 6, Batch: 271, Loss: 2434.1708984375\n",
      "Epoch: 6, Batch: 272, Loss: 2665.42138671875\n",
      "Epoch: 6, Batch: 273, Loss: 2839.682861328125\n",
      "Epoch: 6, Batch: 274, Loss: 3124.83349609375\n",
      "Epoch: 6, Batch: 275, Loss: 2451.31494140625\n",
      "Epoch: 6, Batch: 276, Loss: 3254.502685546875\n",
      "Epoch: 6, Batch: 277, Loss: 2849.4609375\n",
      "Epoch: 6, Batch: 278, Loss: 2602.14404296875\n",
      "Epoch: 6, Batch: 279, Loss: 2076.19775390625\n",
      "Epoch: 6, Batch: 280, Loss: 2994.8603515625\n",
      "Epoch: 6, Batch: 281, Loss: 3179.137451171875\n",
      "Epoch: 6, Batch: 282, Loss: 2828.185791015625\n",
      "Epoch: 6, Batch: 283, Loss: 2971.943115234375\n",
      "Epoch: 6, Batch: 284, Loss: 2781.80517578125\n",
      "Epoch: 6, Batch: 285, Loss: 2661.476318359375\n",
      "Epoch: 6, Batch: 286, Loss: 2747.091552734375\n",
      "Epoch: 6, Batch: 287, Loss: 2897.319091796875\n",
      "Epoch: 6, Batch: 288, Loss: 2464.92236328125\n",
      "Epoch: 6, Batch: 289, Loss: 3076.58251953125\n",
      "Epoch: 6, Batch: 290, Loss: 1948.2928466796875\n",
      "Epoch: 6, Batch: 291, Loss: 2316.1650390625\n",
      "Epoch: 6, Batch: 292, Loss: 2954.9560546875\n",
      "Epoch: 6, Batch: 293, Loss: 2459.38916015625\n",
      "Epoch: 6, Batch: 294, Loss: 2283.768310546875\n",
      "Epoch: 6, Batch: 295, Loss: 2638.73876953125\n",
      "Epoch: 6, Batch: 296, Loss: 3077.964111328125\n",
      "Epoch: 6, Batch: 297, Loss: 2669.91455078125\n",
      "Epoch: 6, Batch: 298, Loss: 2875.705078125\n",
      "Epoch: 6, Batch: 299, Loss: 3325.809814453125\n",
      "Epoch: 6, Batch: 300, Loss: 2809.95068359375\n",
      "Epoch: 6, Batch: 301, Loss: 2761.41259765625\n",
      "Epoch: 6, Batch: 302, Loss: 2135.437255859375\n",
      "Epoch: 6, Batch: 303, Loss: 2331.30126953125\n",
      "Epoch: 6, Batch: 304, Loss: 2829.015869140625\n",
      "Epoch: 6, Batch: 305, Loss: 2410.01220703125\n",
      "Epoch: 6, Batch: 306, Loss: 2862.2216796875\n",
      "Epoch: 6, Batch: 307, Loss: 2191.25830078125\n",
      "Epoch: 6, Batch: 308, Loss: 2752.52880859375\n",
      "Epoch: 6, Batch: 309, Loss: 2530.854736328125\n",
      "Epoch: 6, Batch: 310, Loss: 3288.916259765625\n",
      "Epoch: 6, Batch: 311, Loss: 2742.994384765625\n",
      "Epoch: 6, Batch: 312, Loss: 2871.544921875\n",
      "Epoch: 6, Batch: 313, Loss: 2359.52587890625\n",
      "Epoch: 6, Batch: 314, Loss: 2223.372802734375\n",
      "Epoch: 6, Batch: 315, Loss: 2662.017822265625\n",
      "Epoch: 6, Batch: 316, Loss: 2870.433349609375\n",
      "Epoch: 6, Batch: 317, Loss: 2684.59814453125\n",
      "Epoch: 6, Batch: 318, Loss: 2726.1865234375\n",
      "Epoch: 6, Batch: 319, Loss: 2464.906982421875\n",
      "Epoch: 6, Batch: 320, Loss: 2610.66162109375\n",
      "Epoch: 6, Batch: 321, Loss: 2604.319091796875\n",
      "Epoch: 6, Batch: 322, Loss: 2303.447021484375\n",
      "Epoch: 6, Batch: 323, Loss: 2968.67529296875\n",
      "Epoch: 6, Batch: 324, Loss: 2365.945556640625\n",
      "Epoch: 6, Batch: 325, Loss: 2196.67236328125\n",
      "Epoch: 6, Batch: 326, Loss: 2128.399658203125\n",
      "Epoch: 6, Batch: 327, Loss: 2215.368408203125\n",
      "Epoch: 6, Batch: 328, Loss: 3105.26318359375\n",
      "Epoch: 6, Batch: 329, Loss: 2484.7138671875\n",
      "Epoch: 6, Batch: 330, Loss: 2646.67578125\n",
      "Epoch: 6, Batch: 331, Loss: 3099.849609375\n",
      "Epoch: 6, Batch: 332, Loss: 2595.425537109375\n",
      "Epoch: 6, Batch: 333, Loss: 2350.011474609375\n",
      "Epoch: 6, Batch: 334, Loss: 2149.011474609375\n",
      "Epoch: 6, Batch: 335, Loss: 2825.5087890625\n",
      "Epoch: 6, Batch: 336, Loss: 2962.6220703125\n",
      "Epoch: 6, Batch: 337, Loss: 2951.69189453125\n",
      "Epoch: 6, Batch: 338, Loss: 3217.14599609375\n",
      "Epoch: 6, Batch: 339, Loss: 2588.942626953125\n",
      "Epoch: 6, Batch: 340, Loss: 2191.805419921875\n",
      "Epoch: 6, Batch: 341, Loss: 2877.712158203125\n",
      "Epoch: 6, Batch: 342, Loss: 2578.392578125\n",
      "Epoch: 6, Batch: 343, Loss: 2986.41015625\n",
      "Epoch: 6, Batch: 344, Loss: 2403.220947265625\n",
      "Epoch: 6, Batch: 345, Loss: 2539.56103515625\n",
      "Epoch: 6, Batch: 346, Loss: 2384.50732421875\n",
      "Epoch: 6, Batch: 347, Loss: 1917.070556640625\n",
      "Epoch: 6, Batch: 348, Loss: 2417.693115234375\n",
      "Epoch: 6, Batch: 349, Loss: 3156.824462890625\n",
      "Epoch: 6, Batch: 350, Loss: 3230.098876953125\n",
      "Epoch: 6, Batch: 351, Loss: 2812.9990234375\n",
      "Epoch: 6, Batch: 352, Loss: 2517.910400390625\n",
      "Epoch: 6, Batch: 353, Loss: 2773.9130859375\n",
      "Epoch: 6, Batch: 354, Loss: 2433.72607421875\n",
      "Epoch: 6, Batch: 355, Loss: 2685.692138671875\n",
      "Epoch: 6, Batch: 356, Loss: 2675.60791015625\n",
      "Epoch: 6, Batch: 357, Loss: 2848.419677734375\n",
      "Epoch: 6, Batch: 358, Loss: 2203.02294921875\n",
      "Epoch: 6, Batch: 359, Loss: 2847.685302734375\n",
      "Epoch: 6, Batch: 360, Loss: 2672.05224609375\n",
      "Epoch: 6, Batch: 361, Loss: 2609.806884765625\n",
      "Epoch: 6, Batch: 362, Loss: 2531.99072265625\n",
      "Epoch: 6, Batch: 363, Loss: 2208.23046875\n",
      "Epoch: 6, Batch: 364, Loss: 2888.975830078125\n",
      "Epoch: 6, Batch: 365, Loss: 2336.53515625\n",
      "Epoch: 6, Batch: 366, Loss: 1826.61669921875\n",
      "Epoch: 6, Batch: 367, Loss: 2943.806396484375\n",
      "Epoch: 6, Batch: 368, Loss: 2943.267578125\n",
      "Epoch: 6, Batch: 369, Loss: 2784.28369140625\n",
      "Epoch: 6, Batch: 370, Loss: 2574.3720703125\n",
      "Epoch: 6, Batch: 371, Loss: 2229.13818359375\n",
      "Epoch: 6, Batch: 372, Loss: 2549.49609375\n",
      "Epoch: 6, Batch: 373, Loss: 1811.4033203125\n",
      "Epoch: 6, Batch: 374, Loss: 2350.628173828125\n",
      "Epoch: 6, Batch: 375, Loss: 2459.155029296875\n",
      "Epoch: 6, Batch: 376, Loss: 2787.509521484375\n",
      "Epoch: 6, Batch: 377, Loss: 2743.72705078125\n",
      "Epoch: 6, Batch: 378, Loss: 2313.506591796875\n",
      "Epoch: 6, Batch: 379, Loss: 3275.180908203125\n",
      "Epoch: 6, Batch: 380, Loss: 3127.248291015625\n",
      "Epoch: 6, Batch: 381, Loss: 2073.610595703125\n",
      "Epoch: 6, Batch: 382, Loss: 2320.272216796875\n",
      "Epoch: 6, Batch: 383, Loss: 2316.09423828125\n",
      "Epoch: 6, Batch: 384, Loss: 2987.271728515625\n",
      "Epoch: 6, Batch: 385, Loss: 2701.26318359375\n",
      "Epoch: 6, Batch: 386, Loss: 2866.979736328125\n",
      "Epoch: 6, Batch: 387, Loss: 2636.95947265625\n",
      "Epoch: 6, Batch: 388, Loss: 2398.6328125\n",
      "Epoch: 6, Batch: 389, Loss: 2746.552001953125\n",
      "Epoch: 6, Batch: 390, Loss: 2349.7275390625\n",
      "Epoch: 6, Batch: 391, Loss: 2305.09228515625\n",
      "Epoch: 6, Batch: 392, Loss: 2842.524169921875\n",
      "Epoch: 6, Batch: 393, Loss: 2280.85400390625\n",
      "Epoch: 6, Batch: 394, Loss: 2667.731201171875\n",
      "Epoch: 6, Batch: 395, Loss: 2660.83544921875\n",
      "Epoch: 6, Batch: 396, Loss: 2479.223388671875\n",
      "Epoch: 6, Batch: 397, Loss: 2450.4921875\n",
      "Epoch: 6, Batch: 398, Loss: 3154.9248046875\n",
      "Epoch: 6, Batch: 399, Loss: 2819.041259765625\n",
      "Epoch: 6, Batch: 400, Loss: 2542.847412109375\n",
      "Epoch: 6, Batch: 401, Loss: 2542.706298828125\n",
      "Epoch: 6, Batch: 402, Loss: 2727.848388671875\n",
      "Epoch: 6, Batch: 403, Loss: 3004.518798828125\n",
      "Epoch: 6, Batch: 404, Loss: 3474.347900390625\n",
      "Epoch: 6, Batch: 405, Loss: 2304.39697265625\n",
      "Epoch: 6, Batch: 406, Loss: 2292.051025390625\n",
      "Epoch: 6, Batch: 407, Loss: 2705.6767578125\n",
      "Epoch: 6, Batch: 408, Loss: 3450.962158203125\n",
      "Epoch: 6, Batch: 409, Loss: 2938.492431640625\n",
      "Epoch: 6, Batch: 410, Loss: 2555.72314453125\n",
      "Epoch: 6, Batch: 411, Loss: 2542.218017578125\n",
      "Epoch: 6, Batch: 412, Loss: 2378.994873046875\n",
      "Epoch: 6, Batch: 413, Loss: 2412.384521484375\n",
      "Epoch: 6, Batch: 414, Loss: 2525.023681640625\n",
      "Epoch: 6, Batch: 415, Loss: 2716.79541015625\n",
      "Epoch: 6, Batch: 416, Loss: 1957.5343017578125\n",
      "Epoch: 6, Batch: 417, Loss: 2432.60107421875\n",
      "Epoch: 6, Batch: 418, Loss: 2591.365478515625\n",
      "Epoch: 6, Batch: 419, Loss: 2172.966796875\n",
      "Epoch: 6, Batch: 420, Loss: 2375.255615234375\n",
      "Epoch: 6, Batch: 421, Loss: 2192.921142578125\n",
      "Epoch: 6, Batch: 422, Loss: 2702.6123046875\n",
      "Epoch: 6, Batch: 423, Loss: 3462.871826171875\n",
      "Epoch: 6, Batch: 424, Loss: 2812.473388671875\n",
      "Epoch: 6, Batch: 425, Loss: 2982.57080078125\n",
      "Epoch: 6, Batch: 426, Loss: 2599.917236328125\n",
      "Epoch: 6, Batch: 427, Loss: 2892.009521484375\n",
      "Epoch: 6, Batch: 428, Loss: 3390.808837890625\n",
      "Epoch: 6, Batch: 429, Loss: 2313.615234375\n",
      "Epoch: 6, Batch: 430, Loss: 2775.2431640625\n",
      "Epoch: 6, Batch: 431, Loss: 3072.095947265625\n",
      "Epoch: 6, Batch: 432, Loss: 2554.366943359375\n",
      "Epoch: 6, Batch: 433, Loss: 2311.387939453125\n",
      "Epoch: 6, Batch: 434, Loss: 2101.00537109375\n",
      "Epoch: 6, Batch: 435, Loss: 2234.71240234375\n",
      "Epoch: 6, Batch: 436, Loss: 2524.090087890625\n",
      "Epoch: 6, Batch: 437, Loss: 3187.801025390625\n",
      "Epoch: 6, Batch: 438, Loss: 2372.350341796875\n",
      "Epoch: 6, Batch: 439, Loss: 2303.234130859375\n",
      "Epoch: 6, Batch: 440, Loss: 3469.17041015625\n",
      "Epoch: 6, Batch: 441, Loss: 2738.22265625\n",
      "Epoch: 6, Batch: 442, Loss: 2467.625244140625\n",
      "Epoch: 6, Batch: 443, Loss: 2566.492919921875\n",
      "Epoch: 6, Batch: 444, Loss: 2925.694580078125\n",
      "Epoch: 6, Batch: 445, Loss: 2733.79833984375\n",
      "Epoch: 6, Batch: 446, Loss: 2386.85888671875\n",
      "Epoch: 6, Batch: 447, Loss: 2960.704345703125\n",
      "Epoch: 6, Batch: 448, Loss: 2246.33154296875\n",
      "Epoch: 6, Batch: 449, Loss: 3776.17919921875\n",
      "Epoch: 6, Batch: 450, Loss: 2709.82568359375\n",
      "Epoch: 6, Batch: 451, Loss: 2955.094482421875\n",
      "Epoch: 6, Batch: 452, Loss: 3038.454345703125\n",
      "Epoch: 6, Batch: 453, Loss: 2490.474853515625\n",
      "Epoch: 6, Batch: 454, Loss: 3018.972900390625\n",
      "Epoch: 6, Batch: 455, Loss: 2736.10107421875\n",
      "Epoch: 6, Batch: 456, Loss: 2410.12109375\n",
      "Epoch: 6, Batch: 457, Loss: 2451.606689453125\n",
      "Epoch: 6, Batch: 458, Loss: 2440.17529296875\n",
      "Epoch: 6, Batch: 459, Loss: 3184.29833984375\n",
      "Epoch: 6, Batch: 460, Loss: 3536.955810546875\n",
      "Epoch: 6, Batch: 461, Loss: 2629.17041015625\n",
      "Epoch: 6, Batch: 462, Loss: 2742.928955078125\n",
      "Epoch: 6, Batch: 463, Loss: 2416.238037109375\n",
      "Epoch: 6, Batch: 464, Loss: 2519.464599609375\n",
      "Epoch: 6, Batch: 465, Loss: 2337.81298828125\n",
      "Epoch: 6, Batch: 466, Loss: 2624.452392578125\n",
      "Epoch: 6, Batch: 467, Loss: 2412.224853515625\n",
      "Epoch: 6, Batch: 468, Loss: 2639.23486328125\n",
      "Epoch: 6, Batch: 469, Loss: 2837.164794921875\n",
      "Epoch: 6, Batch: 470, Loss: 2370.0166015625\n",
      "Epoch: 6, Batch: 471, Loss: 2851.16357421875\n",
      "Epoch: 6, Batch: 472, Loss: 2657.011474609375\n",
      "Epoch: 6, Batch: 473, Loss: 2333.676025390625\n",
      "Epoch: 6, Batch: 474, Loss: 2797.850830078125\n",
      "Epoch: 6, Batch: 475, Loss: 2967.935791015625\n",
      "Epoch: 6, Batch: 476, Loss: 2767.302001953125\n",
      "Epoch: 6, Batch: 477, Loss: 2370.254638671875\n",
      "Epoch: 6, Batch: 478, Loss: 2556.928466796875\n",
      "Epoch: 6, Batch: 479, Loss: 2650.5966796875\n",
      "Epoch: 6, Batch: 480, Loss: 2345.20556640625\n",
      "Epoch: 6, Batch: 481, Loss: 2795.606689453125\n",
      "Epoch: 6, Batch: 482, Loss: 2013.5511474609375\n",
      "Epoch: 6, Batch: 483, Loss: 2346.168701171875\n",
      "Epoch: 6, Batch: 484, Loss: 2969.26904296875\n",
      "Epoch: 6, Batch: 485, Loss: 2436.038818359375\n",
      "Epoch: 6, Batch: 486, Loss: 2489.840576171875\n",
      "Epoch: 6, Batch: 487, Loss: 2593.328369140625\n",
      "Epoch: 6, Batch: 488, Loss: 2973.38037109375\n",
      "Epoch: 6, Batch: 489, Loss: 2694.07470703125\n",
      "Epoch: 6, Batch: 490, Loss: 2073.52099609375\n",
      "Epoch: 6, Batch: 491, Loss: 2926.637939453125\n",
      "Epoch: 6, Batch: 492, Loss: 2539.494873046875\n",
      "Epoch: 6, Batch: 493, Loss: 2126.715576171875\n",
      "Epoch: 6, Batch: 494, Loss: 2556.862060546875\n",
      "Epoch: 6, Batch: 495, Loss: 2407.15234375\n",
      "Epoch: 6, Batch: 496, Loss: 2735.54150390625\n",
      "Epoch: 6, Batch: 497, Loss: 2516.55859375\n",
      "Epoch: 6, Batch: 498, Loss: 1851.6624755859375\n",
      "Epoch: 6, Batch: 499, Loss: 2661.739501953125\n",
      "Epoch: 6, Batch: 500, Loss: 2773.4951171875\n",
      "Epoch: 6, Batch: 501, Loss: 3076.4638671875\n",
      "Epoch: 6, Batch: 502, Loss: 2611.842041015625\n",
      "Epoch: 6, Batch: 503, Loss: 2122.584228515625\n",
      "Epoch: 6, Batch: 504, Loss: 2167.103515625\n",
      "Epoch: 6, Batch: 505, Loss: 2352.07568359375\n",
      "Epoch: 6, Batch: 506, Loss: 2805.78271484375\n",
      "Epoch: 6, Batch: 507, Loss: 2910.73095703125\n",
      "Epoch: 6, Batch: 508, Loss: 2563.645751953125\n",
      "Epoch: 6, Batch: 509, Loss: 3022.611328125\n",
      "Epoch: 6, Batch: 510, Loss: 2211.787109375\n",
      "Epoch: 6, Batch: 511, Loss: 2284.1201171875\n",
      "Epoch: 6, Batch: 512, Loss: 2697.715576171875\n",
      "Epoch: 6, Batch: 513, Loss: 2142.93310546875\n",
      "Epoch: 6, Batch: 514, Loss: 2938.5224609375\n",
      "Epoch: 6, Batch: 515, Loss: 2858.015380859375\n",
      "Epoch: 6, Batch: 516, Loss: 2534.53173828125\n",
      "Epoch: 6, Batch: 517, Loss: 2629.749755859375\n",
      "Epoch: 6, Batch: 518, Loss: 2649.395263671875\n",
      "Epoch: 6, Batch: 519, Loss: 2892.787841796875\n",
      "Epoch: 6, Batch: 520, Loss: 3110.879638671875\n",
      "Epoch: 6, Batch: 521, Loss: 2217.973388671875\n",
      "Epoch: 6, Batch: 522, Loss: 2930.08984375\n",
      "Epoch: 6, Batch: 523, Loss: 2819.72607421875\n",
      "Epoch: 6, Batch: 524, Loss: 2381.541259765625\n",
      "Epoch: 6, Batch: 525, Loss: 2577.537109375\n",
      "Epoch: 6, Batch: 526, Loss: 2212.84521484375\n",
      "Epoch: 6, Batch: 527, Loss: 2768.74462890625\n",
      "Epoch: 6, Batch: 528, Loss: 3186.990478515625\n",
      "Epoch: 6, Batch: 529, Loss: 2565.626708984375\n",
      "Epoch: 6, Batch: 530, Loss: 2631.993896484375\n",
      "Epoch: 6, Batch: 531, Loss: 2558.12353515625\n",
      "Epoch: 6, Batch: 532, Loss: 2924.109375\n",
      "Epoch: 6, Batch: 533, Loss: 2420.810791015625\n",
      "Epoch: 6, Batch: 534, Loss: 2504.144287109375\n",
      "Epoch: 6, Batch: 535, Loss: 2399.915771484375\n",
      "Epoch: 6, Batch: 536, Loss: 2790.869140625\n",
      "Epoch: 6, Batch: 537, Loss: 2568.939697265625\n",
      "Epoch: 6, Batch: 538, Loss: 2791.435791015625\n",
      "Epoch: 6, Batch: 539, Loss: 3074.026611328125\n",
      "Epoch: 6, Batch: 540, Loss: 2396.510986328125\n",
      "Epoch: 6, Batch: 541, Loss: 2529.00830078125\n",
      "Epoch: 6, Batch: 542, Loss: 3041.965576171875\n",
      "Epoch: 6, Batch: 543, Loss: 2486.962890625\n",
      "Epoch: 6, Batch: 544, Loss: 3010.12744140625\n",
      "Epoch: 6, Batch: 545, Loss: 2358.039794921875\n",
      "Epoch: 6, Batch: 546, Loss: 2662.2275390625\n",
      "Epoch: 6, Batch: 547, Loss: 2357.148193359375\n",
      "Epoch: 6, Batch: 548, Loss: 2652.510009765625\n",
      "Epoch: 6, Batch: 549, Loss: 2830.1083984375\n",
      "Epoch: 6, Batch: 550, Loss: 2344.970947265625\n",
      "Epoch: 6, Batch: 551, Loss: 2526.703857421875\n",
      "Epoch: 6, Batch: 552, Loss: 3313.728271484375\n",
      "Epoch: 6, Batch: 553, Loss: 2202.11181640625\n",
      "Epoch: 6, Batch: 554, Loss: 3076.068359375\n",
      "Epoch: 6, Batch: 555, Loss: 3137.335693359375\n",
      "Epoch: 6, Batch: 556, Loss: 2820.373779296875\n",
      "Epoch: 6, Batch: 557, Loss: 2712.056396484375\n",
      "Epoch: 6, Batch: 558, Loss: 2647.152099609375\n",
      "Epoch: 6, Batch: 559, Loss: 2621.2021484375\n",
      "Epoch: 6, Batch: 560, Loss: 2233.55712890625\n",
      "Epoch: 6, Batch: 561, Loss: 2806.7314453125\n",
      "Epoch: 6, Batch: 562, Loss: 2556.14990234375\n",
      "Epoch: 6, Batch: 563, Loss: 2484.74072265625\n",
      "Epoch: 6, Batch: 564, Loss: 2468.62353515625\n",
      "Epoch: 6, Batch: 565, Loss: 3003.218994140625\n",
      "Epoch: 6, Batch: 566, Loss: 2379.76416015625\n",
      "Epoch: 6, Batch: 567, Loss: 2482.5830078125\n",
      "Epoch: 6, Batch: 568, Loss: 2444.726318359375\n",
      "Epoch: 6, Batch: 569, Loss: 2952.52001953125\n",
      "Epoch: 6, Batch: 570, Loss: 2480.238037109375\n",
      "Epoch: 6, Batch: 571, Loss: 2526.614990234375\n",
      "Epoch: 6, Batch: 572, Loss: 3022.4306640625\n",
      "Epoch: 6, Batch: 573, Loss: 2735.31298828125\n",
      "Epoch: 6, Batch: 574, Loss: 3110.5654296875\n",
      "Epoch: 6, Batch: 575, Loss: 3205.145263671875\n",
      "Epoch: 6, Batch: 576, Loss: 2661.630615234375\n",
      "Epoch: 6, Batch: 577, Loss: 3284.384033203125\n",
      "Epoch: 6, Batch: 578, Loss: 2030.1009521484375\n",
      "Epoch: 6, Batch: 579, Loss: 2797.890625\n",
      "Epoch: 6, Batch: 580, Loss: 3158.1142578125\n",
      "Epoch: 6, Batch: 581, Loss: 2805.95947265625\n",
      "Epoch: 6, Batch: 582, Loss: 2695.683349609375\n",
      "Epoch: 6, Batch: 583, Loss: 2900.2431640625\n",
      "Epoch: 6, Batch: 584, Loss: 2573.62744140625\n",
      "Epoch: 6, Batch: 585, Loss: 2815.94287109375\n",
      "Epoch: 6, Batch: 586, Loss: 2698.7333984375\n",
      "Epoch: 6, Batch: 587, Loss: 2408.361328125\n",
      "Epoch: 6, Batch: 588, Loss: 2541.5693359375\n",
      "Epoch: 6, Batch: 589, Loss: 2772.559814453125\n",
      "Epoch: 6, Batch: 590, Loss: 2593.08251953125\n",
      "Epoch: 6, Batch: 591, Loss: 2655.302001953125\n",
      "Epoch: 6, Batch: 592, Loss: 2636.334716796875\n",
      "Epoch: 6, Batch: 593, Loss: 2316.53759765625\n",
      "Epoch: 6, Batch: 594, Loss: 2184.733154296875\n",
      "Epoch: 6, Batch: 595, Loss: 2178.052978515625\n",
      "Epoch: 6, Batch: 596, Loss: 2670.390869140625\n",
      "Epoch: 6, Batch: 597, Loss: 2562.776123046875\n",
      "Epoch: 6, Batch: 598, Loss: 2047.084716796875\n",
      "Epoch: 6, Batch: 599, Loss: 3004.80419921875\n",
      "Epoch: 6, Batch: 600, Loss: 2873.039794921875\n",
      "Epoch: 6, Batch: 601, Loss: 2550.83740234375\n",
      "Epoch: 6, Batch: 602, Loss: 2565.602294921875\n",
      "Epoch: 6, Batch: 603, Loss: 2841.46142578125\n",
      "Epoch: 6, Batch: 604, Loss: 2342.072998046875\n",
      "Epoch: 6, Batch: 605, Loss: 3145.154052734375\n",
      "Epoch: 6, Batch: 606, Loss: 2494.370849609375\n",
      "Epoch: 6, Batch: 607, Loss: 2877.96142578125\n",
      "Epoch: 6, Batch: 608, Loss: 2460.744140625\n",
      "Epoch: 6, Batch: 609, Loss: 2610.9111328125\n",
      "Epoch: 6, Batch: 610, Loss: 2321.015625\n",
      "Epoch: 6, Batch: 611, Loss: 3080.099609375\n",
      "Epoch: 6, Batch: 612, Loss: 2678.36865234375\n",
      "Epoch: 6, Batch: 613, Loss: 2261.91845703125\n",
      "Epoch: 6, Batch: 614, Loss: 2284.871826171875\n",
      "Epoch: 6, Batch: 615, Loss: 2438.2412109375\n",
      "Epoch: 6, Batch: 616, Loss: 2862.61865234375\n",
      "Epoch: 6, Batch: 617, Loss: 2759.551025390625\n",
      "Epoch: 6, Batch: 618, Loss: 2394.895263671875\n",
      "Epoch: 6, Batch: 619, Loss: 2501.234619140625\n",
      "Epoch: 6, Batch: 620, Loss: 2404.510498046875\n",
      "Epoch: 6, Batch: 621, Loss: 2458.4375\n",
      "Epoch: 6, Batch: 622, Loss: 2592.115478515625\n",
      "Epoch: 6, Batch: 623, Loss: 3079.894775390625\n",
      "Epoch: 6, Batch: 624, Loss: 2776.896728515625\n",
      "Epoch: 6, Batch: 625, Loss: 2614.006103515625\n",
      "Epoch: 6, Batch: 626, Loss: 2523.50830078125\n",
      "Epoch: 6, Batch: 627, Loss: 3221.440185546875\n",
      "Epoch: 6, Batch: 628, Loss: 2935.994140625\n",
      "Epoch: 6, Batch: 629, Loss: 2866.54541015625\n",
      "Epoch: 6, Batch: 630, Loss: 2820.1015625\n",
      "Epoch: 6, Batch: 631, Loss: 2053.80224609375\n",
      "Epoch: 6, Batch: 632, Loss: 2833.53564453125\n",
      "Epoch: 6, Batch: 633, Loss: 2651.529296875\n",
      "Epoch: 6, Batch: 634, Loss: 3134.175537109375\n",
      "Epoch: 6, Batch: 635, Loss: 2438.731201171875\n",
      "Epoch: 6, Batch: 636, Loss: 2937.95361328125\n",
      "Epoch: 6, Batch: 637, Loss: 2906.36962890625\n",
      "Epoch: 6, Batch: 638, Loss: 2499.6796875\n",
      "Epoch: 6, Batch: 639, Loss: 2574.5546875\n",
      "Epoch: 6, Batch: 640, Loss: 2559.12646484375\n",
      "Epoch: 6, Batch: 641, Loss: 2630.0205078125\n",
      "Epoch: 6, Batch: 642, Loss: 2663.79248046875\n",
      "Epoch: 6, Batch: 643, Loss: 2950.632080078125\n",
      "Epoch: 6, Batch: 644, Loss: 3021.35791015625\n",
      "Epoch: 6, Batch: 645, Loss: 3157.110107421875\n",
      "Epoch: 6, Batch: 646, Loss: 2157.932861328125\n",
      "Epoch: 6, Batch: 647, Loss: 2340.51318359375\n",
      "Epoch: 6, Batch: 648, Loss: 3062.54833984375\n",
      "Epoch: 6, Batch: 649, Loss: 2703.1005859375\n",
      "Epoch: 6, Batch: 650, Loss: 2640.27490234375\n",
      "Epoch: 6, Batch: 651, Loss: 2846.953125\n",
      "Epoch: 6, Batch: 652, Loss: 2846.243896484375\n",
      "Epoch: 6, Batch: 653, Loss: 2554.006591796875\n",
      "Epoch: 6, Batch: 654, Loss: 2735.92431640625\n",
      "Epoch: 6, Batch: 655, Loss: 2821.23779296875\n",
      "Epoch: 6, Batch: 656, Loss: 2566.572998046875\n",
      "Epoch: 6, Batch: 657, Loss: 3466.0703125\n",
      "Epoch: 6, Batch: 658, Loss: 3070.51416015625\n",
      "Epoch: 6, Batch: 659, Loss: 2591.292236328125\n",
      "Epoch: 6, Batch: 660, Loss: 2872.50341796875\n",
      "Epoch: 6, Batch: 661, Loss: 2639.3974609375\n",
      "Epoch: 6, Batch: 662, Loss: 2079.589111328125\n",
      "Epoch: 6, Batch: 663, Loss: 2721.603515625\n",
      "Epoch: 6, Batch: 664, Loss: 2579.877197265625\n",
      "Epoch: 6, Batch: 665, Loss: 2824.583740234375\n",
      "Epoch: 6, Batch: 666, Loss: 2645.579345703125\n",
      "Epoch: 6, Batch: 667, Loss: 2396.975341796875\n",
      "Epoch: 6, Batch: 668, Loss: 2145.063720703125\n",
      "Epoch: 6, Batch: 669, Loss: 2317.68505859375\n",
      "Epoch: 6, Batch: 670, Loss: 2590.08251953125\n",
      "Epoch: 6, Batch: 671, Loss: 2816.514892578125\n",
      "Epoch: 6, Batch: 672, Loss: 2464.290283203125\n",
      "Epoch: 6, Batch: 673, Loss: 3001.332275390625\n",
      "Epoch: 6, Batch: 674, Loss: 3002.7763671875\n",
      "Epoch: 6, Batch: 675, Loss: 2955.28857421875\n",
      "Epoch: 6, Batch: 676, Loss: 3045.2451171875\n",
      "Epoch: 6, Batch: 677, Loss: 2706.25830078125\n",
      "Epoch: 6, Batch: 678, Loss: 2792.52978515625\n",
      "Epoch: 6, Batch: 679, Loss: 2473.9853515625\n",
      "Epoch: 6, Batch: 680, Loss: 2861.042724609375\n",
      "Epoch: 6, Batch: 681, Loss: 3181.374755859375\n",
      "Epoch: 6, Batch: 682, Loss: 2592.197509765625\n",
      "Epoch: 6, Batch: 683, Loss: 2321.8408203125\n",
      "Epoch: 6, Batch: 684, Loss: 2609.77294921875\n",
      "Epoch: 6, Batch: 685, Loss: 2671.5595703125\n",
      "Epoch: 6, Batch: 686, Loss: 2258.814208984375\n",
      "Epoch: 6, Batch: 687, Loss: 2601.289306640625\n",
      "Epoch: 6, Batch: 688, Loss: 2872.5244140625\n",
      "Epoch: 6, Batch: 689, Loss: 2975.9931640625\n",
      "Epoch: 6, Batch: 690, Loss: 2756.95361328125\n",
      "Epoch: 6, Batch: 691, Loss: 2708.4716796875\n",
      "Epoch: 6, Batch: 692, Loss: 2766.16845703125\n",
      "Epoch: 6, Batch: 693, Loss: 2858.66845703125\n",
      "Epoch: 6, Batch: 694, Loss: 2713.819091796875\n",
      "Epoch: 6, Batch: 695, Loss: 2280.00634765625\n",
      "Epoch: 6, Batch: 696, Loss: 3062.185302734375\n",
      "Epoch: 6, Batch: 697, Loss: 2432.3701171875\n",
      "Epoch: 6, Batch: 698, Loss: 2804.8720703125\n",
      "Epoch: 6, Batch: 699, Loss: 2177.249267578125\n",
      "Epoch: 6, Batch: 700, Loss: 2462.961181640625\n",
      "Epoch: 6, Batch: 701, Loss: 2213.09033203125\n",
      "Epoch: 6, Batch: 702, Loss: 3188.978759765625\n",
      "Epoch: 6, Batch: 703, Loss: 2035.47216796875\n",
      "Epoch: 6, Batch: 704, Loss: 2542.79931640625\n",
      "Epoch: 6, Batch: 705, Loss: 1644.504150390625\n",
      "Epoch: 6, Batch: 706, Loss: 2305.672119140625\n",
      "Epoch: 6, Batch: 707, Loss: 2497.102294921875\n",
      "Epoch: 6, Batch: 708, Loss: 2715.6328125\n",
      "Epoch: 6, Batch: 709, Loss: 2671.771240234375\n",
      "Epoch: 6, Batch: 710, Loss: 2685.94091796875\n",
      "Epoch: 6, Batch: 711, Loss: 2827.554443359375\n",
      "Epoch: 6, Batch: 712, Loss: 2661.486572265625\n",
      "Epoch: 6, Batch: 713, Loss: 3077.2734375\n",
      "Epoch: 6, Batch: 714, Loss: 2734.17041015625\n",
      "Epoch: 6, Batch: 715, Loss: 2857.420166015625\n",
      "Epoch: 6, Batch: 716, Loss: 2910.3271484375\n",
      "Epoch: 6, Batch: 717, Loss: 2826.902587890625\n",
      "Epoch: 6, Batch: 718, Loss: 2685.931884765625\n",
      "Epoch: 6, Batch: 719, Loss: 2634.260009765625\n",
      "Epoch: 6, Batch: 720, Loss: 2566.48095703125\n",
      "Epoch: 6, Batch: 721, Loss: 2686.328125\n",
      "Epoch: 6, Batch: 722, Loss: 2860.5\n",
      "Epoch: 6, Batch: 723, Loss: 2543.337158203125\n",
      "Epoch: 6, Batch: 724, Loss: 2390.164794921875\n",
      "Epoch: 6, Batch: 725, Loss: 2789.552978515625\n",
      "Epoch: 6, Batch: 726, Loss: 2609.552978515625\n",
      "Epoch: 6, Batch: 727, Loss: 2730.887939453125\n",
      "Epoch: 6, Batch: 728, Loss: 2541.615478515625\n",
      "Epoch: 6, Batch: 729, Loss: 2560.953369140625\n",
      "Epoch: 6, Batch: 730, Loss: 2672.057861328125\n",
      "Epoch: 6, Batch: 731, Loss: 2628.70751953125\n",
      "Epoch: 6, Batch: 732, Loss: 2332.74462890625\n",
      "Epoch: 6, Batch: 733, Loss: 3387.01708984375\n",
      "Epoch: 6, Batch: 734, Loss: 3163.168212890625\n",
      "Epoch: 6, Batch: 735, Loss: 2880.189453125\n",
      "Epoch: 6, Batch: 736, Loss: 2870.58251953125\n",
      "Epoch: 6, Batch: 737, Loss: 2519.0390625\n",
      "Epoch: 6, Batch: 738, Loss: 2627.302734375\n",
      "Epoch: 6, Batch: 739, Loss: 3004.188232421875\n",
      "Epoch: 6, Batch: 740, Loss: 2623.859619140625\n",
      "Epoch: 6, Batch: 741, Loss: 2733.34375\n",
      "Epoch: 6, Batch: 742, Loss: 2753.49853515625\n",
      "Epoch: 6, Batch: 743, Loss: 2974.94970703125\n",
      "Epoch: 6, Batch: 744, Loss: 2444.22265625\n",
      "Epoch: 6, Batch: 745, Loss: 2346.339599609375\n",
      "Epoch: 6, Batch: 746, Loss: 2393.081787109375\n",
      "Epoch: 6, Batch: 747, Loss: 2406.655029296875\n",
      "Epoch: 6, Batch: 748, Loss: 2964.7705078125\n",
      "Epoch: 6, Batch: 749, Loss: 2406.30322265625\n",
      "Epoch: 6, Batch: 750, Loss: 3011.023681640625\n",
      "Epoch: 6, Batch: 751, Loss: 2344.26025390625\n",
      "Epoch: 6, Batch: 752, Loss: 2345.370361328125\n",
      "Epoch: 6, Batch: 753, Loss: 2199.734130859375\n",
      "Epoch: 6, Batch: 754, Loss: 2578.838134765625\n",
      "Epoch: 6, Batch: 755, Loss: 2908.3427734375\n",
      "Epoch: 6, Batch: 756, Loss: 2418.0859375\n",
      "Epoch: 6, Batch: 757, Loss: 2440.10693359375\n",
      "Epoch: 6, Batch: 758, Loss: 2295.51611328125\n",
      "Epoch: 6, Batch: 759, Loss: 2843.76220703125\n",
      "Epoch: 6, Batch: 760, Loss: 2780.2529296875\n",
      "Epoch: 6, Batch: 761, Loss: 2272.7529296875\n",
      "Epoch: 6, Batch: 762, Loss: 2486.331298828125\n",
      "Epoch: 6, Batch: 763, Loss: 2636.14794921875\n",
      "Epoch: 6, Batch: 764, Loss: 2666.243408203125\n",
      "Epoch: 6, Batch: 765, Loss: 2932.4130859375\n",
      "Epoch: 6, Batch: 766, Loss: 2732.80224609375\n",
      "Epoch: 6, Batch: 767, Loss: 2662.649169921875\n",
      "Epoch: 6, Batch: 768, Loss: 2388.556884765625\n",
      "Epoch: 6, Batch: 769, Loss: 2421.010009765625\n",
      "Epoch: 6, Batch: 770, Loss: 2615.0634765625\n",
      "Epoch: 6, Batch: 771, Loss: 2710.906494140625\n",
      "Epoch: 6, Batch: 772, Loss: 3480.86376953125\n",
      "Epoch: 6, Batch: 773, Loss: 2595.892822265625\n",
      "Epoch: 6, Batch: 774, Loss: 2882.76123046875\n",
      "Epoch: 6, Batch: 775, Loss: 2679.916015625\n",
      "Epoch: 6, Batch: 776, Loss: 2700.0185546875\n",
      "Epoch: 6, Batch: 777, Loss: 2518.33544921875\n",
      "Epoch: 6, Batch: 778, Loss: 2689.733154296875\n",
      "Epoch: 6, Batch: 779, Loss: 2888.22021484375\n",
      "Epoch: 6, Batch: 780, Loss: 1947.1551513671875\n",
      "Epoch: 6, Batch: 781, Loss: 3075.377197265625\n",
      "Epoch: 6, Batch: 782, Loss: 2178.165771484375\n",
      "Epoch: 6, Batch: 783, Loss: 3104.264404296875\n",
      "Epoch: 6, Batch: 784, Loss: 2790.54443359375\n",
      "Epoch: 6, Batch: 785, Loss: 2324.361572265625\n",
      "Epoch: 6, Batch: 786, Loss: 2478.05419921875\n",
      "Epoch: 6, Batch: 787, Loss: 2795.909912109375\n",
      "Epoch: 6, Batch: 788, Loss: 2815.571044921875\n",
      "Epoch: 6, Batch: 789, Loss: 2082.67724609375\n",
      "Epoch: 6, Batch: 790, Loss: 2534.961181640625\n",
      "Epoch: 6, Batch: 791, Loss: 2733.64892578125\n",
      "Epoch: 6, Batch: 792, Loss: 2839.493896484375\n",
      "Epoch: 6, Batch: 793, Loss: 2971.884033203125\n",
      "Epoch: 6, Batch: 794, Loss: 2380.012451171875\n",
      "Epoch: 6, Batch: 795, Loss: 2512.588134765625\n",
      "Epoch: 6, Batch: 796, Loss: 2559.001220703125\n",
      "Epoch: 6, Batch: 797, Loss: 2452.359130859375\n",
      "Epoch: 6, Batch: 798, Loss: 2320.964111328125\n",
      "Epoch: 6, Batch: 799, Loss: 2418.179931640625\n",
      "Epoch: 6, Batch: 800, Loss: 3054.09130859375\n",
      "Epoch: 6, Batch: 801, Loss: 2441.701171875\n",
      "Epoch: 6, Batch: 802, Loss: 3073.905517578125\n",
      "Epoch: 6, Batch: 803, Loss: 2938.197998046875\n",
      "Epoch: 6, Batch: 804, Loss: 2930.2158203125\n",
      "Epoch: 6, Batch: 805, Loss: 2964.89111328125\n",
      "Epoch: 6, Batch: 806, Loss: 3020.6630859375\n",
      "Epoch: 6, Batch: 807, Loss: 3066.1533203125\n",
      "Epoch: 6, Batch: 808, Loss: 2252.541015625\n",
      "Epoch: 6, Batch: 809, Loss: 3031.15673828125\n",
      "Epoch: 6, Batch: 810, Loss: 2939.875732421875\n",
      "Epoch: 6, Batch: 811, Loss: 2724.6689453125\n",
      "Epoch: 6, Batch: 812, Loss: 2560.8623046875\n",
      "Epoch: 6, Batch: 813, Loss: 2996.844482421875\n",
      "Epoch: 6, Batch: 814, Loss: 2283.167236328125\n",
      "Epoch: 6, Batch: 815, Loss: 2987.21142578125\n",
      "Epoch: 6, Batch: 816, Loss: 2380.55029296875\n",
      "Epoch: 6, Batch: 817, Loss: 2505.843994140625\n",
      "Epoch: 6, Batch: 818, Loss: 2285.62548828125\n",
      "Epoch: 6, Batch: 819, Loss: 3141.5703125\n",
      "Epoch: 6, Batch: 820, Loss: 2562.404296875\n",
      "Epoch: 6, Batch: 821, Loss: 2241.40478515625\n",
      "Epoch: 6, Batch: 822, Loss: 2824.70703125\n",
      "Epoch: 6, Batch: 823, Loss: 3004.007080078125\n",
      "Epoch: 6, Batch: 824, Loss: 2792.84619140625\n",
      "Epoch: 6, Batch: 825, Loss: 2735.470458984375\n",
      "Epoch: 6, Batch: 826, Loss: 2231.22021484375\n",
      "Epoch: 6, Batch: 827, Loss: 3271.73046875\n",
      "Epoch: 6, Batch: 828, Loss: 2735.849609375\n",
      "Epoch: 6, Batch: 829, Loss: 2909.959228515625\n",
      "Epoch: 6, Batch: 830, Loss: 2740.375\n",
      "Epoch: 6, Batch: 831, Loss: 2333.397705078125\n",
      "Epoch: 6, Batch: 832, Loss: 2630.93408203125\n",
      "Epoch: 6, Batch: 833, Loss: 2358.18896484375\n",
      "Epoch: 6, Batch: 834, Loss: 2117.576416015625\n",
      "Epoch: 6, Batch: 835, Loss: 2053.286376953125\n",
      "Epoch: 6, Batch: 836, Loss: 2820.759765625\n",
      "Epoch: 6, Batch: 837, Loss: 3099.162109375\n",
      "Epoch: 6, Batch: 838, Loss: 2770.514404296875\n",
      "Epoch: 6, Batch: 839, Loss: 2686.995849609375\n",
      "Epoch: 6, Batch: 840, Loss: 2507.155517578125\n",
      "Epoch: 6, Batch: 841, Loss: 2087.5234375\n",
      "Epoch: 6, Batch: 842, Loss: 2587.673583984375\n",
      "Epoch: 6, Batch: 843, Loss: 2395.1318359375\n",
      "Epoch: 6, Batch: 844, Loss: 3191.560302734375\n",
      "Epoch: 6, Batch: 845, Loss: 2430.672119140625\n",
      "Epoch: 6, Batch: 846, Loss: 2951.447998046875\n",
      "Epoch: 6, Batch: 847, Loss: 2674.37353515625\n",
      "Epoch: 6, Batch: 848, Loss: 3091.5615234375\n",
      "Epoch: 6, Batch: 849, Loss: 2845.1650390625\n",
      "Epoch: 6, Batch: 850, Loss: 2440.93408203125\n",
      "Epoch: 6, Batch: 851, Loss: 2489.374755859375\n",
      "Epoch: 6, Batch: 852, Loss: 2402.57177734375\n",
      "Epoch: 6, Batch: 853, Loss: 2977.15625\n",
      "Epoch: 6, Batch: 854, Loss: 2930.6494140625\n",
      "Epoch: 6, Batch: 855, Loss: 3050.485595703125\n",
      "Epoch: 6, Batch: 856, Loss: 2352.56494140625\n",
      "Epoch: 6, Batch: 857, Loss: 2840.44189453125\n",
      "Epoch: 6, Batch: 858, Loss: 3035.1728515625\n",
      "Epoch: 6, Batch: 859, Loss: 2716.37548828125\n",
      "Epoch: 6, Batch: 860, Loss: 2582.749267578125\n",
      "Epoch: 6, Batch: 861, Loss: 2200.269775390625\n",
      "Epoch: 6, Batch: 862, Loss: 2629.00146484375\n",
      "Epoch: 6, Batch: 863, Loss: 2553.264404296875\n",
      "Epoch: 6, Batch: 864, Loss: 2616.21337890625\n",
      "Epoch: 6, Batch: 865, Loss: 3048.6640625\n",
      "Epoch: 6, Batch: 866, Loss: 2296.08056640625\n",
      "Epoch: 6, Batch: 867, Loss: 2616.292724609375\n",
      "Epoch: 6, Batch: 868, Loss: 2993.66162109375\n",
      "Epoch: 6, Batch: 869, Loss: 2717.3359375\n",
      "Epoch: 6, Batch: 870, Loss: 2420.3193359375\n",
      "Epoch: 6, Batch: 871, Loss: 2960.146240234375\n",
      "Epoch: 6, Batch: 872, Loss: 3792.26318359375\n",
      "Epoch: 6, Batch: 873, Loss: 2676.18359375\n",
      "Epoch: 6, Batch: 874, Loss: 2854.693603515625\n",
      "Epoch: 6, Batch: 875, Loss: 2539.78857421875\n",
      "Epoch: 6, Batch: 876, Loss: 3046.58349609375\n",
      "Epoch: 6, Batch: 877, Loss: 2994.681396484375\n",
      "Epoch: 6, Batch: 878, Loss: 3106.343017578125\n",
      "Epoch: 6, Batch: 879, Loss: 2552.736572265625\n",
      "Epoch: 6, Batch: 880, Loss: 2355.790771484375\n",
      "Epoch: 6, Batch: 881, Loss: 2506.082763671875\n",
      "Epoch: 6, Batch: 882, Loss: 2656.50390625\n",
      "Epoch: 6, Batch: 883, Loss: 2942.890380859375\n",
      "Epoch: 6, Batch: 884, Loss: 2781.506591796875\n",
      "Epoch: 6, Batch: 885, Loss: 2765.18359375\n",
      "Epoch: 6, Batch: 886, Loss: 2166.9638671875\n",
      "Epoch: 6, Batch: 887, Loss: 2553.298095703125\n",
      "Epoch: 6, Batch: 888, Loss: 2913.0361328125\n",
      "Epoch: 6, Batch: 889, Loss: 2738.93408203125\n",
      "Epoch: 6, Batch: 890, Loss: 2255.742919921875\n",
      "Epoch: 6, Batch: 891, Loss: 2629.662841796875\n",
      "Epoch: 6, Batch: 892, Loss: 2587.11376953125\n",
      "Epoch: 6, Batch: 893, Loss: 2095.4384765625\n",
      "Epoch: 6, Batch: 894, Loss: 2883.9970703125\n",
      "Epoch: 6, Batch: 895, Loss: 2555.716796875\n",
      "Epoch: 6, Batch: 896, Loss: 2082.643798828125\n",
      "Epoch: 6, Batch: 897, Loss: 2303.535400390625\n",
      "Epoch: 6, Batch: 898, Loss: 2426.1318359375\n",
      "Epoch: 6, Batch: 899, Loss: 2462.892333984375\n",
      "Epoch: 6, Batch: 900, Loss: 2633.2177734375\n",
      "Epoch: 6, Batch: 901, Loss: 2322.750244140625\n",
      "Epoch: 6, Batch: 902, Loss: 2833.8291015625\n",
      "Epoch: 6, Batch: 903, Loss: 3048.864990234375\n",
      "Epoch: 6, Batch: 904, Loss: 2430.9814453125\n",
      "Epoch: 6, Batch: 905, Loss: 2501.615478515625\n",
      "Epoch: 6, Batch: 906, Loss: 2222.19677734375\n",
      "Epoch: 6, Batch: 907, Loss: 3205.976806640625\n",
      "Epoch: 6, Batch: 908, Loss: 2776.421630859375\n",
      "Epoch: 6, Batch: 909, Loss: 2451.904052734375\n",
      "Epoch: 6, Batch: 910, Loss: 2163.10009765625\n",
      "Epoch: 6, Batch: 911, Loss: 2871.33056640625\n",
      "Epoch: 6, Batch: 912, Loss: 3146.18701171875\n",
      "Epoch: 6, Batch: 913, Loss: 2785.132568359375\n",
      "Epoch: 6, Batch: 914, Loss: 3123.71435546875\n",
      "Epoch: 6, Batch: 915, Loss: 2430.219970703125\n",
      "Epoch: 6, Batch: 916, Loss: 3155.63818359375\n",
      "Epoch: 6, Batch: 917, Loss: 1996.21728515625\n",
      "Epoch: 6, Batch: 918, Loss: 2693.92529296875\n",
      "Epoch: 6, Batch: 919, Loss: 2851.18896484375\n",
      "Epoch: 6, Batch: 920, Loss: 2649.86767578125\n",
      "Epoch: 6, Batch: 921, Loss: 2604.15625\n",
      "Epoch: 6, Batch: 922, Loss: 1937.04345703125\n",
      "Epoch: 6, Batch: 923, Loss: 2655.25537109375\n",
      "Epoch: 6, Batch: 924, Loss: 2550.311279296875\n",
      "Epoch: 6, Batch: 925, Loss: 2625.37353515625\n",
      "Epoch: 6, Batch: 926, Loss: 2862.75732421875\n",
      "Epoch: 6, Batch: 927, Loss: 2267.8095703125\n",
      "Epoch: 6, Batch: 928, Loss: 2604.19580078125\n",
      "Epoch: 6, Batch: 929, Loss: 2750.40478515625\n",
      "Epoch: 6, Batch: 930, Loss: 2634.98974609375\n",
      "Epoch: 6, Batch: 931, Loss: 2331.45849609375\n",
      "Epoch: 6, Batch: 932, Loss: 2535.314453125\n",
      "Epoch: 6, Batch: 933, Loss: 2623.958251953125\n",
      "Epoch: 6, Batch: 934, Loss: 2444.690185546875\n",
      "Epoch: 6, Batch: 935, Loss: 3141.68212890625\n",
      "Epoch: 6, Batch: 936, Loss: 2716.920654296875\n",
      "Epoch: 6, Batch: 937, Loss: 2540.02197265625\n",
      "Epoch: 6, Batch: 938, Loss: 2825.93896484375\n",
      "Epoch: 6, Batch: 939, Loss: 2079.552734375\n",
      "Epoch: 6, Batch: 940, Loss: 2114.46240234375\n",
      "Epoch: 6, Batch: 941, Loss: 2564.64306640625\n",
      "Epoch: 6, Batch: 942, Loss: 2247.438232421875\n",
      "Epoch: 6, Batch: 943, Loss: 2812.3955078125\n",
      "Epoch: 6, Batch: 944, Loss: 2332.7353515625\n",
      "Epoch: 6, Batch: 945, Loss: 2857.900634765625\n",
      "Epoch: 6, Batch: 946, Loss: 2213.9677734375\n",
      "Epoch: 6, Batch: 947, Loss: 2936.590576171875\n",
      "Epoch: 6, Batch: 948, Loss: 2985.9716796875\n",
      "Epoch: 6, Batch: 949, Loss: 2849.40673828125\n",
      "Epoch: 6, Batch: 950, Loss: 2695.675537109375\n",
      "Epoch: 6, Batch: 951, Loss: 2290.5244140625\n",
      "Epoch: 6, Batch: 952, Loss: 2712.494384765625\n",
      "Epoch: 6, Batch: 953, Loss: 2436.117431640625\n",
      "Epoch: 6, Batch: 954, Loss: 2519.182373046875\n",
      "Epoch: 6, Batch: 955, Loss: 2909.8818359375\n",
      "Epoch: 6, Batch: 956, Loss: 2654.112060546875\n",
      "Epoch: 6, Batch: 957, Loss: 2395.925537109375\n",
      "Epoch: 6, Batch: 958, Loss: 2800.060791015625\n",
      "Epoch: 6, Batch: 959, Loss: 2337.89892578125\n",
      "Epoch: 6, Batch: 960, Loss: 2541.533447265625\n",
      "Epoch: 6, Batch: 961, Loss: 2862.846923828125\n",
      "Epoch: 6, Batch: 962, Loss: 2251.283203125\n",
      "Epoch: 6, Batch: 963, Loss: 2275.96923828125\n",
      "Epoch: 6, Batch: 964, Loss: 2058.197998046875\n",
      "Epoch: 6, Batch: 965, Loss: 2651.14990234375\n",
      "Epoch: 6, Batch: 966, Loss: 2316.755126953125\n",
      "Epoch: 6, Batch: 967, Loss: 2465.280029296875\n",
      "Epoch: 6, Batch: 968, Loss: 2473.797119140625\n",
      "Epoch: 6, Batch: 969, Loss: 2645.298095703125\n",
      "Epoch: 6, Batch: 970, Loss: 3318.93017578125\n",
      "Epoch: 6, Batch: 971, Loss: 2554.496337890625\n",
      "Epoch: 6, Batch: 972, Loss: 2173.142333984375\n",
      "Epoch: 6, Batch: 973, Loss: 2765.970947265625\n",
      "Epoch: 6, Batch: 974, Loss: 2616.26220703125\n",
      "Epoch: 6, Batch: 975, Loss: 3000.95654296875\n",
      "Epoch: 6, Batch: 976, Loss: 1956.09423828125\n",
      "Epoch: 6, Batch: 977, Loss: 3080.207275390625\n",
      "Epoch: 6, Batch: 978, Loss: 2918.706298828125\n",
      "Epoch: 6, Batch: 979, Loss: 3135.5390625\n",
      "Epoch: 6, Batch: 980, Loss: 2700.805419921875\n",
      "Epoch: 6, Batch: 981, Loss: 2618.76708984375\n",
      "Epoch: 6, Batch: 982, Loss: 3356.610595703125\n",
      "Epoch: 6, Batch: 983, Loss: 2607.689697265625\n",
      "Epoch: 6, Batch: 984, Loss: 2611.3046875\n",
      "Epoch: 6, Batch: 985, Loss: 2634.34765625\n",
      "Epoch: 6, Batch: 986, Loss: 2406.0703125\n",
      "Epoch: 6, Batch: 987, Loss: 2142.119140625\n",
      "Epoch: 6, Batch: 988, Loss: 2646.177490234375\n",
      "Epoch: 6, Batch: 989, Loss: 2643.5205078125\n",
      "Epoch: 6, Batch: 990, Loss: 2501.730712890625\n",
      "Epoch: 6, Batch: 991, Loss: 2852.640380859375\n",
      "Epoch: 6, Batch: 992, Loss: 2323.76513671875\n",
      "Epoch: 6, Batch: 993, Loss: 2659.96630859375\n",
      "Epoch: 6, Batch: 994, Loss: 2211.675048828125\n",
      "Epoch: 6, Batch: 995, Loss: 2177.16552734375\n",
      "Epoch: 6, Batch: 996, Loss: 2462.370361328125\n",
      "Epoch: 6, Batch: 997, Loss: 1501.802490234375\n",
      "Epoch: 6, Batch: 998, Loss: 2861.83056640625\n",
      "Epoch: 6, Batch: 999, Loss: 2385.682861328125\n",
      "Epoch: 7, Batch: 0, Loss: 2985.98583984375\n",
      "Epoch: 7, Batch: 1, Loss: 3153.0185546875\n",
      "Epoch: 7, Batch: 2, Loss: 2635.7021484375\n",
      "Epoch: 7, Batch: 3, Loss: 3138.022705078125\n",
      "Epoch: 7, Batch: 4, Loss: 2677.77099609375\n",
      "Epoch: 7, Batch: 5, Loss: 2726.751953125\n",
      "Epoch: 7, Batch: 6, Loss: 2633.2138671875\n",
      "Epoch: 7, Batch: 7, Loss: 2215.740966796875\n",
      "Epoch: 7, Batch: 8, Loss: 2722.53369140625\n",
      "Epoch: 7, Batch: 9, Loss: 2501.446533203125\n",
      "Epoch: 7, Batch: 10, Loss: 2353.607666015625\n",
      "Epoch: 7, Batch: 11, Loss: 2788.94384765625\n",
      "Epoch: 7, Batch: 12, Loss: 2299.307861328125\n",
      "Epoch: 7, Batch: 13, Loss: 2060.51025390625\n",
      "Epoch: 7, Batch: 14, Loss: 2600.10595703125\n",
      "Epoch: 7, Batch: 15, Loss: 2263.06689453125\n",
      "Epoch: 7, Batch: 16, Loss: 2533.971435546875\n",
      "Epoch: 7, Batch: 17, Loss: 3104.484375\n",
      "Epoch: 7, Batch: 18, Loss: 2148.990234375\n",
      "Epoch: 7, Batch: 19, Loss: 2849.841796875\n",
      "Epoch: 7, Batch: 20, Loss: 2540.383544921875\n",
      "Epoch: 7, Batch: 21, Loss: 3262.6015625\n",
      "Epoch: 7, Batch: 22, Loss: 2153.51953125\n",
      "Epoch: 7, Batch: 23, Loss: 2343.58447265625\n",
      "Epoch: 7, Batch: 24, Loss: 3089.1025390625\n",
      "Epoch: 7, Batch: 25, Loss: 2788.96044921875\n",
      "Epoch: 7, Batch: 26, Loss: 2545.463623046875\n",
      "Epoch: 7, Batch: 27, Loss: 2402.03076171875\n",
      "Epoch: 7, Batch: 28, Loss: 2817.551513671875\n",
      "Epoch: 7, Batch: 29, Loss: 2751.3037109375\n",
      "Epoch: 7, Batch: 30, Loss: 2656.836181640625\n",
      "Epoch: 7, Batch: 31, Loss: 1774.7095947265625\n",
      "Epoch: 7, Batch: 32, Loss: 2609.88037109375\n",
      "Epoch: 7, Batch: 33, Loss: 3227.611083984375\n",
      "Epoch: 7, Batch: 34, Loss: 2695.786865234375\n",
      "Epoch: 7, Batch: 35, Loss: 2413.733154296875\n",
      "Epoch: 7, Batch: 36, Loss: 2651.77783203125\n",
      "Epoch: 7, Batch: 37, Loss: 2242.424560546875\n",
      "Epoch: 7, Batch: 38, Loss: 2864.486328125\n",
      "Epoch: 7, Batch: 39, Loss: 2517.673095703125\n",
      "Epoch: 7, Batch: 40, Loss: 2520.90478515625\n",
      "Epoch: 7, Batch: 41, Loss: 2661.1826171875\n",
      "Epoch: 7, Batch: 42, Loss: 2855.5205078125\n",
      "Epoch: 7, Batch: 43, Loss: 3210.128173828125\n",
      "Epoch: 7, Batch: 44, Loss: 2173.12353515625\n",
      "Epoch: 7, Batch: 45, Loss: 2362.407470703125\n",
      "Epoch: 7, Batch: 46, Loss: 2492.531494140625\n",
      "Epoch: 7, Batch: 47, Loss: 2948.123291015625\n",
      "Epoch: 7, Batch: 48, Loss: 2655.017333984375\n",
      "Epoch: 7, Batch: 49, Loss: 2879.685546875\n",
      "Epoch: 7, Batch: 50, Loss: 2860.089599609375\n",
      "Epoch: 7, Batch: 51, Loss: 2735.600830078125\n",
      "Epoch: 7, Batch: 52, Loss: 2375.834228515625\n",
      "Epoch: 7, Batch: 53, Loss: 2864.471435546875\n",
      "Epoch: 7, Batch: 54, Loss: 3027.56982421875\n",
      "Epoch: 7, Batch: 55, Loss: 3184.584716796875\n",
      "Epoch: 7, Batch: 56, Loss: 2657.995849609375\n",
      "Epoch: 7, Batch: 57, Loss: 2750.069580078125\n",
      "Epoch: 7, Batch: 58, Loss: 2218.611083984375\n",
      "Epoch: 7, Batch: 59, Loss: 2625.458984375\n",
      "Epoch: 7, Batch: 60, Loss: 2891.47314453125\n",
      "Epoch: 7, Batch: 61, Loss: 2364.871337890625\n",
      "Epoch: 7, Batch: 62, Loss: 2982.513427734375\n",
      "Epoch: 7, Batch: 63, Loss: 2435.918212890625\n",
      "Epoch: 7, Batch: 64, Loss: 3040.685302734375\n",
      "Epoch: 7, Batch: 65, Loss: 3179.88671875\n",
      "Epoch: 7, Batch: 66, Loss: 2225.115234375\n",
      "Epoch: 7, Batch: 67, Loss: 2682.634765625\n",
      "Epoch: 7, Batch: 68, Loss: 2494.09375\n",
      "Epoch: 7, Batch: 69, Loss: 2681.86181640625\n",
      "Epoch: 7, Batch: 70, Loss: 2968.037353515625\n",
      "Epoch: 7, Batch: 71, Loss: 2499.95556640625\n",
      "Epoch: 7, Batch: 72, Loss: 2739.669921875\n",
      "Epoch: 7, Batch: 73, Loss: 3103.86962890625\n",
      "Epoch: 7, Batch: 74, Loss: 2508.58251953125\n",
      "Epoch: 7, Batch: 75, Loss: 2774.369140625\n",
      "Epoch: 7, Batch: 76, Loss: 2532.33984375\n",
      "Epoch: 7, Batch: 77, Loss: 2832.199951171875\n",
      "Epoch: 7, Batch: 78, Loss: 2474.895263671875\n",
      "Epoch: 7, Batch: 79, Loss: 2542.835693359375\n",
      "Epoch: 7, Batch: 80, Loss: 2685.96435546875\n",
      "Epoch: 7, Batch: 81, Loss: 2460.9599609375\n",
      "Epoch: 7, Batch: 82, Loss: 2642.1728515625\n",
      "Epoch: 7, Batch: 83, Loss: 2753.26416015625\n",
      "Epoch: 7, Batch: 84, Loss: 2386.75390625\n",
      "Epoch: 7, Batch: 85, Loss: 2504.2763671875\n",
      "Epoch: 7, Batch: 86, Loss: 2722.662109375\n",
      "Epoch: 7, Batch: 87, Loss: 2542.07470703125\n",
      "Epoch: 7, Batch: 88, Loss: 3051.17578125\n",
      "Epoch: 7, Batch: 89, Loss: 2557.545166015625\n",
      "Epoch: 7, Batch: 90, Loss: 2689.76123046875\n",
      "Epoch: 7, Batch: 91, Loss: 2884.066162109375\n",
      "Epoch: 7, Batch: 92, Loss: 2293.11181640625\n",
      "Epoch: 7, Batch: 93, Loss: 2064.7802734375\n",
      "Epoch: 7, Batch: 94, Loss: 3127.042236328125\n",
      "Epoch: 7, Batch: 95, Loss: 2891.7333984375\n",
      "Epoch: 7, Batch: 96, Loss: 3040.64794921875\n",
      "Epoch: 7, Batch: 97, Loss: 2468.122802734375\n",
      "Epoch: 7, Batch: 98, Loss: 2600.2578125\n",
      "Epoch: 7, Batch: 99, Loss: 2518.13916015625\n",
      "Epoch: 7, Batch: 100, Loss: 2719.42333984375\n",
      "Epoch: 7, Batch: 101, Loss: 2683.785888671875\n",
      "Epoch: 7, Batch: 102, Loss: 2988.7333984375\n",
      "Epoch: 7, Batch: 103, Loss: 2344.6044921875\n",
      "Epoch: 7, Batch: 104, Loss: 2169.4501953125\n",
      "Epoch: 7, Batch: 105, Loss: 1938.30859375\n",
      "Epoch: 7, Batch: 106, Loss: 2396.671875\n",
      "Epoch: 7, Batch: 107, Loss: 2440.706787109375\n",
      "Epoch: 7, Batch: 108, Loss: 2525.737548828125\n",
      "Epoch: 7, Batch: 109, Loss: 2559.0712890625\n",
      "Epoch: 7, Batch: 110, Loss: 1856.087646484375\n",
      "Epoch: 7, Batch: 111, Loss: 2779.1796875\n",
      "Epoch: 7, Batch: 112, Loss: 2664.72802734375\n",
      "Epoch: 7, Batch: 113, Loss: 2758.74609375\n",
      "Epoch: 7, Batch: 114, Loss: 2336.62109375\n",
      "Epoch: 7, Batch: 115, Loss: 2564.4296875\n",
      "Epoch: 7, Batch: 116, Loss: 2577.01806640625\n",
      "Epoch: 7, Batch: 117, Loss: 3020.9873046875\n",
      "Epoch: 7, Batch: 118, Loss: 2776.89501953125\n",
      "Epoch: 7, Batch: 119, Loss: 2371.199462890625\n",
      "Epoch: 7, Batch: 120, Loss: 3414.95654296875\n",
      "Epoch: 7, Batch: 121, Loss: 2431.05859375\n",
      "Epoch: 7, Batch: 122, Loss: 3065.35986328125\n",
      "Epoch: 7, Batch: 123, Loss: 2235.482421875\n",
      "Epoch: 7, Batch: 124, Loss: 3249.8193359375\n",
      "Epoch: 7, Batch: 125, Loss: 3218.28564453125\n",
      "Epoch: 7, Batch: 126, Loss: 3219.096923828125\n",
      "Epoch: 7, Batch: 127, Loss: 2265.056640625\n",
      "Epoch: 7, Batch: 128, Loss: 2435.89453125\n",
      "Epoch: 7, Batch: 129, Loss: 2564.289794921875\n",
      "Epoch: 7, Batch: 130, Loss: 2375.66455078125\n",
      "Epoch: 7, Batch: 131, Loss: 2184.602294921875\n",
      "Epoch: 7, Batch: 132, Loss: 2839.47119140625\n",
      "Epoch: 7, Batch: 133, Loss: 2483.548583984375\n",
      "Epoch: 7, Batch: 134, Loss: 2173.58544921875\n",
      "Epoch: 7, Batch: 135, Loss: 2737.174072265625\n",
      "Epoch: 7, Batch: 136, Loss: 2481.82470703125\n",
      "Epoch: 7, Batch: 137, Loss: 2931.45849609375\n",
      "Epoch: 7, Batch: 138, Loss: 2229.140625\n",
      "Epoch: 7, Batch: 139, Loss: 2744.350830078125\n",
      "Epoch: 7, Batch: 140, Loss: 2292.630126953125\n",
      "Epoch: 7, Batch: 141, Loss: 2690.3134765625\n",
      "Epoch: 7, Batch: 142, Loss: 2148.893310546875\n",
      "Epoch: 7, Batch: 143, Loss: 3095.236328125\n",
      "Epoch: 7, Batch: 144, Loss: 1772.25\n",
      "Epoch: 7, Batch: 145, Loss: 2392.10546875\n",
      "Epoch: 7, Batch: 146, Loss: 2492.946044921875\n",
      "Epoch: 7, Batch: 147, Loss: 2938.040771484375\n",
      "Epoch: 7, Batch: 148, Loss: 3186.14599609375\n",
      "Epoch: 7, Batch: 149, Loss: 2263.382568359375\n",
      "Epoch: 7, Batch: 150, Loss: 2498.392333984375\n",
      "Epoch: 7, Batch: 151, Loss: 2850.05419921875\n",
      "Epoch: 7, Batch: 152, Loss: 2825.734619140625\n",
      "Epoch: 7, Batch: 153, Loss: 2042.78173828125\n",
      "Epoch: 7, Batch: 154, Loss: 2095.80712890625\n",
      "Epoch: 7, Batch: 155, Loss: 2538.99609375\n",
      "Epoch: 7, Batch: 156, Loss: 2082.86328125\n",
      "Epoch: 7, Batch: 157, Loss: 2735.254638671875\n",
      "Epoch: 7, Batch: 158, Loss: 2571.287109375\n",
      "Epoch: 7, Batch: 159, Loss: 2971.46875\n",
      "Epoch: 7, Batch: 160, Loss: 2695.3154296875\n",
      "Epoch: 7, Batch: 161, Loss: 2721.87353515625\n",
      "Epoch: 7, Batch: 162, Loss: 2793.906005859375\n",
      "Epoch: 7, Batch: 163, Loss: 2719.95556640625\n",
      "Epoch: 7, Batch: 164, Loss: 2669.46728515625\n",
      "Epoch: 7, Batch: 165, Loss: 2763.079833984375\n",
      "Epoch: 7, Batch: 166, Loss: 2687.782958984375\n",
      "Epoch: 7, Batch: 167, Loss: 2775.1611328125\n",
      "Epoch: 7, Batch: 168, Loss: 2811.6767578125\n",
      "Epoch: 7, Batch: 169, Loss: 2339.4404296875\n",
      "Epoch: 7, Batch: 170, Loss: 2358.3369140625\n",
      "Epoch: 7, Batch: 171, Loss: 2378.17236328125\n",
      "Epoch: 7, Batch: 172, Loss: 2537.263427734375\n",
      "Epoch: 7, Batch: 173, Loss: 2556.000732421875\n",
      "Epoch: 7, Batch: 174, Loss: 2850.582763671875\n",
      "Epoch: 7, Batch: 175, Loss: 2748.635986328125\n",
      "Epoch: 7, Batch: 176, Loss: 2707.857666015625\n",
      "Epoch: 7, Batch: 177, Loss: 2424.264892578125\n",
      "Epoch: 7, Batch: 178, Loss: 2677.650146484375\n",
      "Epoch: 7, Batch: 179, Loss: 2880.552734375\n",
      "Epoch: 7, Batch: 180, Loss: 2645.673095703125\n",
      "Epoch: 7, Batch: 181, Loss: 3427.012939453125\n",
      "Epoch: 7, Batch: 182, Loss: 2464.703857421875\n",
      "Epoch: 7, Batch: 183, Loss: 2252.2099609375\n",
      "Epoch: 7, Batch: 184, Loss: 2297.56005859375\n",
      "Epoch: 7, Batch: 185, Loss: 2835.283935546875\n",
      "Epoch: 7, Batch: 186, Loss: 2282.881591796875\n",
      "Epoch: 7, Batch: 187, Loss: 2886.446533203125\n",
      "Epoch: 7, Batch: 188, Loss: 3276.34423828125\n",
      "Epoch: 7, Batch: 189, Loss: 2785.177490234375\n",
      "Epoch: 7, Batch: 190, Loss: 2283.177490234375\n",
      "Epoch: 7, Batch: 191, Loss: 2410.01171875\n",
      "Epoch: 7, Batch: 192, Loss: 2243.513916015625\n",
      "Epoch: 7, Batch: 193, Loss: 2851.740478515625\n",
      "Epoch: 7, Batch: 194, Loss: 2512.725341796875\n",
      "Epoch: 7, Batch: 195, Loss: 2280.943603515625\n",
      "Epoch: 7, Batch: 196, Loss: 2158.686767578125\n",
      "Epoch: 7, Batch: 197, Loss: 2390.02392578125\n",
      "Epoch: 7, Batch: 198, Loss: 2937.166259765625\n",
      "Epoch: 7, Batch: 199, Loss: 2564.066650390625\n",
      "Epoch: 7, Batch: 200, Loss: 2591.772216796875\n",
      "Epoch: 7, Batch: 201, Loss: 2984.12744140625\n",
      "Epoch: 7, Batch: 202, Loss: 2663.46923828125\n",
      "Epoch: 7, Batch: 203, Loss: 2022.6402587890625\n",
      "Epoch: 7, Batch: 204, Loss: 2090.81884765625\n",
      "Epoch: 7, Batch: 205, Loss: 2528.98974609375\n",
      "Epoch: 7, Batch: 206, Loss: 2719.157958984375\n",
      "Epoch: 7, Batch: 207, Loss: 2645.40087890625\n",
      "Epoch: 7, Batch: 208, Loss: 2530.133056640625\n",
      "Epoch: 7, Batch: 209, Loss: 2606.72314453125\n",
      "Epoch: 7, Batch: 210, Loss: 2498.126953125\n",
      "Epoch: 7, Batch: 211, Loss: 3109.745361328125\n",
      "Epoch: 7, Batch: 212, Loss: 2659.76806640625\n",
      "Epoch: 7, Batch: 213, Loss: 3096.935546875\n",
      "Epoch: 7, Batch: 214, Loss: 2165.644287109375\n",
      "Epoch: 7, Batch: 215, Loss: 2903.150390625\n",
      "Epoch: 7, Batch: 216, Loss: 2932.587890625\n",
      "Epoch: 7, Batch: 217, Loss: 2815.05029296875\n",
      "Epoch: 7, Batch: 218, Loss: 2760.333251953125\n",
      "Epoch: 7, Batch: 219, Loss: 2277.8583984375\n",
      "Epoch: 7, Batch: 220, Loss: 2403.3203125\n",
      "Epoch: 7, Batch: 221, Loss: 2754.41845703125\n",
      "Epoch: 7, Batch: 222, Loss: 2360.745849609375\n",
      "Epoch: 7, Batch: 223, Loss: 3040.385498046875\n",
      "Epoch: 7, Batch: 224, Loss: 2799.391845703125\n",
      "Epoch: 7, Batch: 225, Loss: 2398.386474609375\n",
      "Epoch: 7, Batch: 226, Loss: 2798.27099609375\n",
      "Epoch: 7, Batch: 227, Loss: 2682.19140625\n",
      "Epoch: 7, Batch: 228, Loss: 2833.002685546875\n",
      "Epoch: 7, Batch: 229, Loss: 2490.85009765625\n",
      "Epoch: 7, Batch: 230, Loss: 2963.93212890625\n",
      "Epoch: 7, Batch: 231, Loss: 2894.22412109375\n",
      "Epoch: 7, Batch: 232, Loss: 2637.433349609375\n",
      "Epoch: 7, Batch: 233, Loss: 2776.735595703125\n",
      "Epoch: 7, Batch: 234, Loss: 2701.083984375\n",
      "Epoch: 7, Batch: 235, Loss: 2362.113037109375\n",
      "Epoch: 7, Batch: 236, Loss: 2273.681640625\n",
      "Epoch: 7, Batch: 237, Loss: 2067.546875\n",
      "Epoch: 7, Batch: 238, Loss: 2477.049560546875\n",
      "Epoch: 7, Batch: 239, Loss: 2652.35791015625\n",
      "Epoch: 7, Batch: 240, Loss: 2789.30810546875\n",
      "Epoch: 7, Batch: 241, Loss: 2541.590087890625\n",
      "Epoch: 7, Batch: 242, Loss: 2661.085693359375\n",
      "Epoch: 7, Batch: 243, Loss: 2995.808349609375\n",
      "Epoch: 7, Batch: 244, Loss: 2215.18896484375\n",
      "Epoch: 7, Batch: 245, Loss: 2584.63427734375\n",
      "Epoch: 7, Batch: 246, Loss: 2781.0576171875\n",
      "Epoch: 7, Batch: 247, Loss: 3052.463623046875\n",
      "Epoch: 7, Batch: 248, Loss: 2381.539794921875\n",
      "Epoch: 7, Batch: 249, Loss: 2811.958984375\n",
      "Epoch: 7, Batch: 250, Loss: 2538.19970703125\n",
      "Epoch: 7, Batch: 251, Loss: 2366.491455078125\n",
      "Epoch: 7, Batch: 252, Loss: 2888.5615234375\n",
      "Epoch: 7, Batch: 253, Loss: 2868.7861328125\n",
      "Epoch: 7, Batch: 254, Loss: 1963.4007568359375\n",
      "Epoch: 7, Batch: 255, Loss: 2566.578125\n",
      "Epoch: 7, Batch: 256, Loss: 2429.2978515625\n",
      "Epoch: 7, Batch: 257, Loss: 2531.060546875\n",
      "Epoch: 7, Batch: 258, Loss: 2672.7783203125\n",
      "Epoch: 7, Batch: 259, Loss: 2205.05615234375\n",
      "Epoch: 7, Batch: 260, Loss: 2881.83544921875\n",
      "Epoch: 7, Batch: 261, Loss: 2892.673095703125\n",
      "Epoch: 7, Batch: 262, Loss: 2808.6455078125\n",
      "Epoch: 7, Batch: 263, Loss: 2714.650146484375\n",
      "Epoch: 7, Batch: 264, Loss: 2739.76611328125\n",
      "Epoch: 7, Batch: 265, Loss: 2386.24609375\n",
      "Epoch: 7, Batch: 266, Loss: 2706.91552734375\n",
      "Epoch: 7, Batch: 267, Loss: 2725.60498046875\n",
      "Epoch: 7, Batch: 268, Loss: 2268.31591796875\n",
      "Epoch: 7, Batch: 269, Loss: 2401.821533203125\n",
      "Epoch: 7, Batch: 270, Loss: 2427.907470703125\n",
      "Epoch: 7, Batch: 271, Loss: 2434.1708984375\n",
      "Epoch: 7, Batch: 272, Loss: 2665.42138671875\n",
      "Epoch: 7, Batch: 273, Loss: 2839.682861328125\n",
      "Epoch: 7, Batch: 274, Loss: 3124.83349609375\n",
      "Epoch: 7, Batch: 275, Loss: 2451.31494140625\n",
      "Epoch: 7, Batch: 276, Loss: 3254.502685546875\n",
      "Epoch: 7, Batch: 277, Loss: 2849.4609375\n",
      "Epoch: 7, Batch: 278, Loss: 2602.14404296875\n",
      "Epoch: 7, Batch: 279, Loss: 2076.19775390625\n",
      "Epoch: 7, Batch: 280, Loss: 2994.8603515625\n",
      "Epoch: 7, Batch: 281, Loss: 3179.137451171875\n",
      "Epoch: 7, Batch: 282, Loss: 2828.185791015625\n",
      "Epoch: 7, Batch: 283, Loss: 2971.943115234375\n",
      "Epoch: 7, Batch: 284, Loss: 2781.80517578125\n",
      "Epoch: 7, Batch: 285, Loss: 2661.476318359375\n",
      "Epoch: 7, Batch: 286, Loss: 2747.091552734375\n",
      "Epoch: 7, Batch: 287, Loss: 2897.319091796875\n",
      "Epoch: 7, Batch: 288, Loss: 2464.92236328125\n",
      "Epoch: 7, Batch: 289, Loss: 3076.58251953125\n",
      "Epoch: 7, Batch: 290, Loss: 1948.2928466796875\n",
      "Epoch: 7, Batch: 291, Loss: 2316.1650390625\n",
      "Epoch: 7, Batch: 292, Loss: 2954.9560546875\n",
      "Epoch: 7, Batch: 293, Loss: 2459.38916015625\n",
      "Epoch: 7, Batch: 294, Loss: 2283.768310546875\n",
      "Epoch: 7, Batch: 295, Loss: 2638.73876953125\n",
      "Epoch: 7, Batch: 296, Loss: 3077.964111328125\n",
      "Epoch: 7, Batch: 297, Loss: 2669.91455078125\n",
      "Epoch: 7, Batch: 298, Loss: 2875.705078125\n",
      "Epoch: 7, Batch: 299, Loss: 3325.809814453125\n",
      "Epoch: 7, Batch: 300, Loss: 2809.95068359375\n",
      "Epoch: 7, Batch: 301, Loss: 2761.41259765625\n",
      "Epoch: 7, Batch: 302, Loss: 2135.437255859375\n",
      "Epoch: 7, Batch: 303, Loss: 2331.30126953125\n",
      "Epoch: 7, Batch: 304, Loss: 2829.015869140625\n",
      "Epoch: 7, Batch: 305, Loss: 2410.01220703125\n",
      "Epoch: 7, Batch: 306, Loss: 2862.2216796875\n",
      "Epoch: 7, Batch: 307, Loss: 2191.25830078125\n",
      "Epoch: 7, Batch: 308, Loss: 2752.52880859375\n",
      "Epoch: 7, Batch: 309, Loss: 2530.854736328125\n",
      "Epoch: 7, Batch: 310, Loss: 3288.916259765625\n",
      "Epoch: 7, Batch: 311, Loss: 2742.994384765625\n",
      "Epoch: 7, Batch: 312, Loss: 2871.544921875\n",
      "Epoch: 7, Batch: 313, Loss: 2359.52587890625\n",
      "Epoch: 7, Batch: 314, Loss: 2223.372802734375\n",
      "Epoch: 7, Batch: 315, Loss: 2662.017822265625\n",
      "Epoch: 7, Batch: 316, Loss: 2870.433349609375\n",
      "Epoch: 7, Batch: 317, Loss: 2684.59814453125\n",
      "Epoch: 7, Batch: 318, Loss: 2726.1865234375\n",
      "Epoch: 7, Batch: 319, Loss: 2464.906982421875\n",
      "Epoch: 7, Batch: 320, Loss: 2610.66162109375\n",
      "Epoch: 7, Batch: 321, Loss: 2604.319091796875\n",
      "Epoch: 7, Batch: 322, Loss: 2303.447021484375\n",
      "Epoch: 7, Batch: 323, Loss: 2968.67529296875\n",
      "Epoch: 7, Batch: 324, Loss: 2365.945556640625\n",
      "Epoch: 7, Batch: 325, Loss: 2196.67236328125\n",
      "Epoch: 7, Batch: 326, Loss: 2128.399658203125\n",
      "Epoch: 7, Batch: 327, Loss: 2215.368408203125\n",
      "Epoch: 7, Batch: 328, Loss: 3105.26318359375\n",
      "Epoch: 7, Batch: 329, Loss: 2484.7138671875\n",
      "Epoch: 7, Batch: 330, Loss: 2646.67578125\n",
      "Epoch: 7, Batch: 331, Loss: 3099.849609375\n",
      "Epoch: 7, Batch: 332, Loss: 2595.425537109375\n",
      "Epoch: 7, Batch: 333, Loss: 2350.011474609375\n",
      "Epoch: 7, Batch: 334, Loss: 2149.011474609375\n",
      "Epoch: 7, Batch: 335, Loss: 2825.5087890625\n",
      "Epoch: 7, Batch: 336, Loss: 2962.6220703125\n",
      "Epoch: 7, Batch: 337, Loss: 2951.69189453125\n",
      "Epoch: 7, Batch: 338, Loss: 3217.14599609375\n",
      "Epoch: 7, Batch: 339, Loss: 2588.942626953125\n",
      "Epoch: 7, Batch: 340, Loss: 2191.805419921875\n",
      "Epoch: 7, Batch: 341, Loss: 2877.712158203125\n",
      "Epoch: 7, Batch: 342, Loss: 2578.392578125\n",
      "Epoch: 7, Batch: 343, Loss: 2986.41015625\n",
      "Epoch: 7, Batch: 344, Loss: 2403.220947265625\n",
      "Epoch: 7, Batch: 345, Loss: 2539.56103515625\n",
      "Epoch: 7, Batch: 346, Loss: 2384.50732421875\n",
      "Epoch: 7, Batch: 347, Loss: 1917.070556640625\n",
      "Epoch: 7, Batch: 348, Loss: 2417.693115234375\n",
      "Epoch: 7, Batch: 349, Loss: 3156.824462890625\n",
      "Epoch: 7, Batch: 350, Loss: 3230.098876953125\n",
      "Epoch: 7, Batch: 351, Loss: 2812.9990234375\n",
      "Epoch: 7, Batch: 352, Loss: 2517.910400390625\n",
      "Epoch: 7, Batch: 353, Loss: 2773.9130859375\n",
      "Epoch: 7, Batch: 354, Loss: 2433.72607421875\n",
      "Epoch: 7, Batch: 355, Loss: 2685.692138671875\n",
      "Epoch: 7, Batch: 356, Loss: 2675.60791015625\n",
      "Epoch: 7, Batch: 357, Loss: 2848.419677734375\n",
      "Epoch: 7, Batch: 358, Loss: 2203.02294921875\n",
      "Epoch: 7, Batch: 359, Loss: 2847.685302734375\n",
      "Epoch: 7, Batch: 360, Loss: 2672.05224609375\n",
      "Epoch: 7, Batch: 361, Loss: 2609.806884765625\n",
      "Epoch: 7, Batch: 362, Loss: 2531.99072265625\n",
      "Epoch: 7, Batch: 363, Loss: 2208.23046875\n",
      "Epoch: 7, Batch: 364, Loss: 2888.975830078125\n",
      "Epoch: 7, Batch: 365, Loss: 2336.53515625\n",
      "Epoch: 7, Batch: 366, Loss: 1826.61669921875\n",
      "Epoch: 7, Batch: 367, Loss: 2943.806396484375\n",
      "Epoch: 7, Batch: 368, Loss: 2943.267578125\n",
      "Epoch: 7, Batch: 369, Loss: 2784.28369140625\n",
      "Epoch: 7, Batch: 370, Loss: 2574.3720703125\n",
      "Epoch: 7, Batch: 371, Loss: 2229.13818359375\n",
      "Epoch: 7, Batch: 372, Loss: 2549.49609375\n",
      "Epoch: 7, Batch: 373, Loss: 1811.4033203125\n",
      "Epoch: 7, Batch: 374, Loss: 2350.628173828125\n",
      "Epoch: 7, Batch: 375, Loss: 2459.155029296875\n",
      "Epoch: 7, Batch: 376, Loss: 2787.509521484375\n",
      "Epoch: 7, Batch: 377, Loss: 2743.72705078125\n",
      "Epoch: 7, Batch: 378, Loss: 2313.506591796875\n",
      "Epoch: 7, Batch: 379, Loss: 3275.180908203125\n",
      "Epoch: 7, Batch: 380, Loss: 3127.248291015625\n",
      "Epoch: 7, Batch: 381, Loss: 2073.610595703125\n",
      "Epoch: 7, Batch: 382, Loss: 2320.272216796875\n",
      "Epoch: 7, Batch: 383, Loss: 2316.09423828125\n",
      "Epoch: 7, Batch: 384, Loss: 2987.271728515625\n",
      "Epoch: 7, Batch: 385, Loss: 2701.26318359375\n",
      "Epoch: 7, Batch: 386, Loss: 2866.979736328125\n",
      "Epoch: 7, Batch: 387, Loss: 2636.95947265625\n",
      "Epoch: 7, Batch: 388, Loss: 2398.6328125\n",
      "Epoch: 7, Batch: 389, Loss: 2746.552001953125\n",
      "Epoch: 7, Batch: 390, Loss: 2349.7275390625\n",
      "Epoch: 7, Batch: 391, Loss: 2305.09228515625\n",
      "Epoch: 7, Batch: 392, Loss: 2842.524169921875\n",
      "Epoch: 7, Batch: 393, Loss: 2280.85400390625\n",
      "Epoch: 7, Batch: 394, Loss: 2667.731201171875\n",
      "Epoch: 7, Batch: 395, Loss: 2660.83544921875\n",
      "Epoch: 7, Batch: 396, Loss: 2479.223388671875\n",
      "Epoch: 7, Batch: 397, Loss: 2450.4921875\n",
      "Epoch: 7, Batch: 398, Loss: 3154.9248046875\n",
      "Epoch: 7, Batch: 399, Loss: 2819.041259765625\n",
      "Epoch: 7, Batch: 400, Loss: 2542.847412109375\n",
      "Epoch: 7, Batch: 401, Loss: 2542.706298828125\n",
      "Epoch: 7, Batch: 402, Loss: 2727.848388671875\n",
      "Epoch: 7, Batch: 403, Loss: 3004.518798828125\n",
      "Epoch: 7, Batch: 404, Loss: 3474.347900390625\n",
      "Epoch: 7, Batch: 405, Loss: 2304.39697265625\n",
      "Epoch: 7, Batch: 406, Loss: 2292.051025390625\n",
      "Epoch: 7, Batch: 407, Loss: 2705.6767578125\n",
      "Epoch: 7, Batch: 408, Loss: 3450.962158203125\n",
      "Epoch: 7, Batch: 409, Loss: 2938.492431640625\n",
      "Epoch: 7, Batch: 410, Loss: 2555.72314453125\n",
      "Epoch: 7, Batch: 411, Loss: 2542.218017578125\n",
      "Epoch: 7, Batch: 412, Loss: 2378.994873046875\n",
      "Epoch: 7, Batch: 413, Loss: 2412.384521484375\n",
      "Epoch: 7, Batch: 414, Loss: 2525.023681640625\n",
      "Epoch: 7, Batch: 415, Loss: 2716.79541015625\n",
      "Epoch: 7, Batch: 416, Loss: 1957.5343017578125\n",
      "Epoch: 7, Batch: 417, Loss: 2432.60107421875\n",
      "Epoch: 7, Batch: 418, Loss: 2591.365478515625\n",
      "Epoch: 7, Batch: 419, Loss: 2172.966796875\n",
      "Epoch: 7, Batch: 420, Loss: 2375.255615234375\n",
      "Epoch: 7, Batch: 421, Loss: 2192.921142578125\n",
      "Epoch: 7, Batch: 422, Loss: 2702.6123046875\n",
      "Epoch: 7, Batch: 423, Loss: 3462.871826171875\n",
      "Epoch: 7, Batch: 424, Loss: 2812.473388671875\n",
      "Epoch: 7, Batch: 425, Loss: 2982.57080078125\n",
      "Epoch: 7, Batch: 426, Loss: 2599.917236328125\n",
      "Epoch: 7, Batch: 427, Loss: 2892.009521484375\n",
      "Epoch: 7, Batch: 428, Loss: 3390.808837890625\n",
      "Epoch: 7, Batch: 429, Loss: 2313.615234375\n",
      "Epoch: 7, Batch: 430, Loss: 2775.2431640625\n",
      "Epoch: 7, Batch: 431, Loss: 3072.095947265625\n",
      "Epoch: 7, Batch: 432, Loss: 2554.366943359375\n",
      "Epoch: 7, Batch: 433, Loss: 2311.387939453125\n",
      "Epoch: 7, Batch: 434, Loss: 2101.00537109375\n",
      "Epoch: 7, Batch: 435, Loss: 2234.71240234375\n",
      "Epoch: 7, Batch: 436, Loss: 2524.090087890625\n",
      "Epoch: 7, Batch: 437, Loss: 3187.801025390625\n",
      "Epoch: 7, Batch: 438, Loss: 2372.350341796875\n",
      "Epoch: 7, Batch: 439, Loss: 2303.234130859375\n",
      "Epoch: 7, Batch: 440, Loss: 3469.17041015625\n",
      "Epoch: 7, Batch: 441, Loss: 2738.22265625\n",
      "Epoch: 7, Batch: 442, Loss: 2467.625244140625\n",
      "Epoch: 7, Batch: 443, Loss: 2566.492919921875\n",
      "Epoch: 7, Batch: 444, Loss: 2925.694580078125\n",
      "Epoch: 7, Batch: 445, Loss: 2733.79833984375\n",
      "Epoch: 7, Batch: 446, Loss: 2386.85888671875\n",
      "Epoch: 7, Batch: 447, Loss: 2960.704345703125\n",
      "Epoch: 7, Batch: 448, Loss: 2246.33154296875\n",
      "Epoch: 7, Batch: 449, Loss: 3776.17919921875\n",
      "Epoch: 7, Batch: 450, Loss: 2709.82568359375\n",
      "Epoch: 7, Batch: 451, Loss: 2955.094482421875\n",
      "Epoch: 7, Batch: 452, Loss: 3038.454345703125\n",
      "Epoch: 7, Batch: 453, Loss: 2490.474853515625\n",
      "Epoch: 7, Batch: 454, Loss: 3018.972900390625\n",
      "Epoch: 7, Batch: 455, Loss: 2736.10107421875\n",
      "Epoch: 7, Batch: 456, Loss: 2410.12109375\n",
      "Epoch: 7, Batch: 457, Loss: 2451.606689453125\n",
      "Epoch: 7, Batch: 458, Loss: 2440.17529296875\n",
      "Epoch: 7, Batch: 459, Loss: 3184.29833984375\n",
      "Epoch: 7, Batch: 460, Loss: 3536.955810546875\n",
      "Epoch: 7, Batch: 461, Loss: 2629.17041015625\n",
      "Epoch: 7, Batch: 462, Loss: 2742.928955078125\n",
      "Epoch: 7, Batch: 463, Loss: 2416.238037109375\n",
      "Epoch: 7, Batch: 464, Loss: 2519.464599609375\n",
      "Epoch: 7, Batch: 465, Loss: 2337.81298828125\n",
      "Epoch: 7, Batch: 466, Loss: 2624.452392578125\n",
      "Epoch: 7, Batch: 467, Loss: 2412.224853515625\n",
      "Epoch: 7, Batch: 468, Loss: 2639.23486328125\n",
      "Epoch: 7, Batch: 469, Loss: 2837.164794921875\n",
      "Epoch: 7, Batch: 470, Loss: 2370.0166015625\n",
      "Epoch: 7, Batch: 471, Loss: 2851.16357421875\n",
      "Epoch: 7, Batch: 472, Loss: 2657.011474609375\n",
      "Epoch: 7, Batch: 473, Loss: 2333.676025390625\n",
      "Epoch: 7, Batch: 474, Loss: 2797.850830078125\n",
      "Epoch: 7, Batch: 475, Loss: 2967.935791015625\n",
      "Epoch: 7, Batch: 476, Loss: 2767.302001953125\n",
      "Epoch: 7, Batch: 477, Loss: 2370.254638671875\n",
      "Epoch: 7, Batch: 478, Loss: 2556.928466796875\n",
      "Epoch: 7, Batch: 479, Loss: 2650.5966796875\n",
      "Epoch: 7, Batch: 480, Loss: 2345.20556640625\n",
      "Epoch: 7, Batch: 481, Loss: 2795.606689453125\n",
      "Epoch: 7, Batch: 482, Loss: 2013.5511474609375\n",
      "Epoch: 7, Batch: 483, Loss: 2346.168701171875\n",
      "Epoch: 7, Batch: 484, Loss: 2969.26904296875\n",
      "Epoch: 7, Batch: 485, Loss: 2436.038818359375\n",
      "Epoch: 7, Batch: 486, Loss: 2489.840576171875\n",
      "Epoch: 7, Batch: 487, Loss: 2593.328369140625\n",
      "Epoch: 7, Batch: 488, Loss: 2973.38037109375\n",
      "Epoch: 7, Batch: 489, Loss: 2694.07470703125\n",
      "Epoch: 7, Batch: 490, Loss: 2073.52099609375\n",
      "Epoch: 7, Batch: 491, Loss: 2926.637939453125\n",
      "Epoch: 7, Batch: 492, Loss: 2539.494873046875\n",
      "Epoch: 7, Batch: 493, Loss: 2126.715576171875\n",
      "Epoch: 7, Batch: 494, Loss: 2556.862060546875\n",
      "Epoch: 7, Batch: 495, Loss: 2407.15234375\n",
      "Epoch: 7, Batch: 496, Loss: 2735.54150390625\n",
      "Epoch: 7, Batch: 497, Loss: 2516.55859375\n",
      "Epoch: 7, Batch: 498, Loss: 1851.6624755859375\n",
      "Epoch: 7, Batch: 499, Loss: 2661.739501953125\n",
      "Epoch: 7, Batch: 500, Loss: 2773.4951171875\n",
      "Epoch: 7, Batch: 501, Loss: 3076.4638671875\n",
      "Epoch: 7, Batch: 502, Loss: 2611.842041015625\n",
      "Epoch: 7, Batch: 503, Loss: 2122.584228515625\n",
      "Epoch: 7, Batch: 504, Loss: 2167.103515625\n",
      "Epoch: 7, Batch: 505, Loss: 2352.07568359375\n",
      "Epoch: 7, Batch: 506, Loss: 2805.78271484375\n",
      "Epoch: 7, Batch: 507, Loss: 2910.73095703125\n",
      "Epoch: 7, Batch: 508, Loss: 2563.645751953125\n",
      "Epoch: 7, Batch: 509, Loss: 3022.611328125\n",
      "Epoch: 7, Batch: 510, Loss: 2211.787109375\n",
      "Epoch: 7, Batch: 511, Loss: 2284.1201171875\n",
      "Epoch: 7, Batch: 512, Loss: 2697.715576171875\n",
      "Epoch: 7, Batch: 513, Loss: 2142.93310546875\n",
      "Epoch: 7, Batch: 514, Loss: 2938.5224609375\n",
      "Epoch: 7, Batch: 515, Loss: 2858.015380859375\n",
      "Epoch: 7, Batch: 516, Loss: 2534.53173828125\n",
      "Epoch: 7, Batch: 517, Loss: 2629.749755859375\n",
      "Epoch: 7, Batch: 518, Loss: 2649.395263671875\n",
      "Epoch: 7, Batch: 519, Loss: 2892.787841796875\n",
      "Epoch: 7, Batch: 520, Loss: 3110.879638671875\n",
      "Epoch: 7, Batch: 521, Loss: 2217.973388671875\n",
      "Epoch: 7, Batch: 522, Loss: 2930.08984375\n",
      "Epoch: 7, Batch: 523, Loss: 2819.72607421875\n",
      "Epoch: 7, Batch: 524, Loss: 2381.541259765625\n",
      "Epoch: 7, Batch: 525, Loss: 2577.537109375\n",
      "Epoch: 7, Batch: 526, Loss: 2212.84521484375\n",
      "Epoch: 7, Batch: 527, Loss: 2768.74462890625\n",
      "Epoch: 7, Batch: 528, Loss: 3186.990478515625\n",
      "Epoch: 7, Batch: 529, Loss: 2565.626708984375\n",
      "Epoch: 7, Batch: 530, Loss: 2631.993896484375\n",
      "Epoch: 7, Batch: 531, Loss: 2558.12353515625\n",
      "Epoch: 7, Batch: 532, Loss: 2924.109375\n",
      "Epoch: 7, Batch: 533, Loss: 2420.810791015625\n",
      "Epoch: 7, Batch: 534, Loss: 2504.144287109375\n",
      "Epoch: 7, Batch: 535, Loss: 2399.915771484375\n",
      "Epoch: 7, Batch: 536, Loss: 2790.869140625\n",
      "Epoch: 7, Batch: 537, Loss: 2568.939697265625\n",
      "Epoch: 7, Batch: 538, Loss: 2791.435791015625\n",
      "Epoch: 7, Batch: 539, Loss: 3074.026611328125\n",
      "Epoch: 7, Batch: 540, Loss: 2396.510986328125\n",
      "Epoch: 7, Batch: 541, Loss: 2529.00830078125\n",
      "Epoch: 7, Batch: 542, Loss: 3041.965576171875\n",
      "Epoch: 7, Batch: 543, Loss: 2486.962890625\n",
      "Epoch: 7, Batch: 544, Loss: 3010.12744140625\n",
      "Epoch: 7, Batch: 545, Loss: 2358.039794921875\n",
      "Epoch: 7, Batch: 546, Loss: 2662.2275390625\n",
      "Epoch: 7, Batch: 547, Loss: 2357.148193359375\n",
      "Epoch: 7, Batch: 548, Loss: 2652.510009765625\n",
      "Epoch: 7, Batch: 549, Loss: 2830.1083984375\n",
      "Epoch: 7, Batch: 550, Loss: 2344.970947265625\n",
      "Epoch: 7, Batch: 551, Loss: 2526.703857421875\n",
      "Epoch: 7, Batch: 552, Loss: 3313.728271484375\n",
      "Epoch: 7, Batch: 553, Loss: 2202.11181640625\n",
      "Epoch: 7, Batch: 554, Loss: 3076.068359375\n",
      "Epoch: 7, Batch: 555, Loss: 3137.335693359375\n",
      "Epoch: 7, Batch: 556, Loss: 2820.373779296875\n",
      "Epoch: 7, Batch: 557, Loss: 2712.056396484375\n",
      "Epoch: 7, Batch: 558, Loss: 2647.152099609375\n",
      "Epoch: 7, Batch: 559, Loss: 2621.2021484375\n",
      "Epoch: 7, Batch: 560, Loss: 2233.55712890625\n",
      "Epoch: 7, Batch: 561, Loss: 2806.7314453125\n",
      "Epoch: 7, Batch: 562, Loss: 2556.14990234375\n",
      "Epoch: 7, Batch: 563, Loss: 2484.74072265625\n",
      "Epoch: 7, Batch: 564, Loss: 2468.62353515625\n",
      "Epoch: 7, Batch: 565, Loss: 3003.218994140625\n",
      "Epoch: 7, Batch: 566, Loss: 2379.76416015625\n",
      "Epoch: 7, Batch: 567, Loss: 2482.5830078125\n",
      "Epoch: 7, Batch: 568, Loss: 2444.726318359375\n",
      "Epoch: 7, Batch: 569, Loss: 2952.52001953125\n",
      "Epoch: 7, Batch: 570, Loss: 2480.238037109375\n",
      "Epoch: 7, Batch: 571, Loss: 2526.614990234375\n",
      "Epoch: 7, Batch: 572, Loss: 3022.4306640625\n",
      "Epoch: 7, Batch: 573, Loss: 2735.31298828125\n",
      "Epoch: 7, Batch: 574, Loss: 3110.5654296875\n",
      "Epoch: 7, Batch: 575, Loss: 3205.145263671875\n",
      "Epoch: 7, Batch: 576, Loss: 2661.630615234375\n",
      "Epoch: 7, Batch: 577, Loss: 3284.384033203125\n",
      "Epoch: 7, Batch: 578, Loss: 2030.1009521484375\n",
      "Epoch: 7, Batch: 579, Loss: 2797.890625\n",
      "Epoch: 7, Batch: 580, Loss: 3158.1142578125\n",
      "Epoch: 7, Batch: 581, Loss: 2805.95947265625\n",
      "Epoch: 7, Batch: 582, Loss: 2695.683349609375\n",
      "Epoch: 7, Batch: 583, Loss: 2900.2431640625\n",
      "Epoch: 7, Batch: 584, Loss: 2573.62744140625\n",
      "Epoch: 7, Batch: 585, Loss: 2815.94287109375\n",
      "Epoch: 7, Batch: 586, Loss: 2698.7333984375\n",
      "Epoch: 7, Batch: 587, Loss: 2408.361328125\n",
      "Epoch: 7, Batch: 588, Loss: 2541.5693359375\n",
      "Epoch: 7, Batch: 589, Loss: 2772.559814453125\n",
      "Epoch: 7, Batch: 590, Loss: 2593.08251953125\n",
      "Epoch: 7, Batch: 591, Loss: 2655.302001953125\n",
      "Epoch: 7, Batch: 592, Loss: 2636.334716796875\n",
      "Epoch: 7, Batch: 593, Loss: 2316.53759765625\n",
      "Epoch: 7, Batch: 594, Loss: 2184.733154296875\n",
      "Epoch: 7, Batch: 595, Loss: 2178.052978515625\n",
      "Epoch: 7, Batch: 596, Loss: 2670.390869140625\n",
      "Epoch: 7, Batch: 597, Loss: 2562.776123046875\n",
      "Epoch: 7, Batch: 598, Loss: 2047.084716796875\n",
      "Epoch: 7, Batch: 599, Loss: 3004.80419921875\n",
      "Epoch: 7, Batch: 600, Loss: 2873.039794921875\n",
      "Epoch: 7, Batch: 601, Loss: 2550.83740234375\n",
      "Epoch: 7, Batch: 602, Loss: 2565.602294921875\n",
      "Epoch: 7, Batch: 603, Loss: 2841.46142578125\n",
      "Epoch: 7, Batch: 604, Loss: 2342.072998046875\n",
      "Epoch: 7, Batch: 605, Loss: 3145.154052734375\n",
      "Epoch: 7, Batch: 606, Loss: 2494.370849609375\n",
      "Epoch: 7, Batch: 607, Loss: 2877.96142578125\n",
      "Epoch: 7, Batch: 608, Loss: 2460.744140625\n",
      "Epoch: 7, Batch: 609, Loss: 2610.9111328125\n",
      "Epoch: 7, Batch: 610, Loss: 2321.015625\n",
      "Epoch: 7, Batch: 611, Loss: 3080.099609375\n",
      "Epoch: 7, Batch: 612, Loss: 2678.36865234375\n",
      "Epoch: 7, Batch: 613, Loss: 2261.91845703125\n",
      "Epoch: 7, Batch: 614, Loss: 2284.871826171875\n",
      "Epoch: 7, Batch: 615, Loss: 2438.2412109375\n",
      "Epoch: 7, Batch: 616, Loss: 2862.61865234375\n",
      "Epoch: 7, Batch: 617, Loss: 2759.551025390625\n",
      "Epoch: 7, Batch: 618, Loss: 2394.895263671875\n",
      "Epoch: 7, Batch: 619, Loss: 2501.234619140625\n",
      "Epoch: 7, Batch: 620, Loss: 2404.510498046875\n",
      "Epoch: 7, Batch: 621, Loss: 2458.4375\n",
      "Epoch: 7, Batch: 622, Loss: 2592.115478515625\n",
      "Epoch: 7, Batch: 623, Loss: 3079.894775390625\n",
      "Epoch: 7, Batch: 624, Loss: 2776.896728515625\n",
      "Epoch: 7, Batch: 625, Loss: 2614.006103515625\n",
      "Epoch: 7, Batch: 626, Loss: 2523.50830078125\n",
      "Epoch: 7, Batch: 627, Loss: 3221.440185546875\n",
      "Epoch: 7, Batch: 628, Loss: 2935.994140625\n",
      "Epoch: 7, Batch: 629, Loss: 2866.54541015625\n",
      "Epoch: 7, Batch: 630, Loss: 2820.1015625\n",
      "Epoch: 7, Batch: 631, Loss: 2053.80224609375\n",
      "Epoch: 7, Batch: 632, Loss: 2833.53564453125\n",
      "Epoch: 7, Batch: 633, Loss: 2651.529296875\n",
      "Epoch: 7, Batch: 634, Loss: 3134.175537109375\n",
      "Epoch: 7, Batch: 635, Loss: 2438.731201171875\n",
      "Epoch: 7, Batch: 636, Loss: 2937.95361328125\n",
      "Epoch: 7, Batch: 637, Loss: 2906.36962890625\n",
      "Epoch: 7, Batch: 638, Loss: 2499.6796875\n",
      "Epoch: 7, Batch: 639, Loss: 2574.5546875\n",
      "Epoch: 7, Batch: 640, Loss: 2559.12646484375\n",
      "Epoch: 7, Batch: 641, Loss: 2630.0205078125\n",
      "Epoch: 7, Batch: 642, Loss: 2663.79248046875\n",
      "Epoch: 7, Batch: 643, Loss: 2950.632080078125\n",
      "Epoch: 7, Batch: 644, Loss: 3021.35791015625\n",
      "Epoch: 7, Batch: 645, Loss: 3157.110107421875\n",
      "Epoch: 7, Batch: 646, Loss: 2157.932861328125\n",
      "Epoch: 7, Batch: 647, Loss: 2340.51318359375\n",
      "Epoch: 7, Batch: 648, Loss: 3062.54833984375\n",
      "Epoch: 7, Batch: 649, Loss: 2703.1005859375\n",
      "Epoch: 7, Batch: 650, Loss: 2640.27490234375\n",
      "Epoch: 7, Batch: 651, Loss: 2846.953125\n",
      "Epoch: 7, Batch: 652, Loss: 2846.243896484375\n",
      "Epoch: 7, Batch: 653, Loss: 2554.006591796875\n",
      "Epoch: 7, Batch: 654, Loss: 2735.92431640625\n",
      "Epoch: 7, Batch: 655, Loss: 2821.23779296875\n",
      "Epoch: 7, Batch: 656, Loss: 2566.572998046875\n",
      "Epoch: 7, Batch: 657, Loss: 3466.0703125\n",
      "Epoch: 7, Batch: 658, Loss: 3070.51416015625\n",
      "Epoch: 7, Batch: 659, Loss: 2591.292236328125\n",
      "Epoch: 7, Batch: 660, Loss: 2872.50341796875\n",
      "Epoch: 7, Batch: 661, Loss: 2639.3974609375\n",
      "Epoch: 7, Batch: 662, Loss: 2079.589111328125\n",
      "Epoch: 7, Batch: 663, Loss: 2721.603515625\n",
      "Epoch: 7, Batch: 664, Loss: 2579.877197265625\n",
      "Epoch: 7, Batch: 665, Loss: 2824.583740234375\n",
      "Epoch: 7, Batch: 666, Loss: 2645.579345703125\n",
      "Epoch: 7, Batch: 667, Loss: 2396.975341796875\n",
      "Epoch: 7, Batch: 668, Loss: 2145.063720703125\n",
      "Epoch: 7, Batch: 669, Loss: 2317.68505859375\n",
      "Epoch: 7, Batch: 670, Loss: 2590.08251953125\n",
      "Epoch: 7, Batch: 671, Loss: 2816.514892578125\n",
      "Epoch: 7, Batch: 672, Loss: 2464.290283203125\n",
      "Epoch: 7, Batch: 673, Loss: 3001.332275390625\n",
      "Epoch: 7, Batch: 674, Loss: 3002.7763671875\n",
      "Epoch: 7, Batch: 675, Loss: 2955.28857421875\n",
      "Epoch: 7, Batch: 676, Loss: 3045.2451171875\n",
      "Epoch: 7, Batch: 677, Loss: 2706.25830078125\n",
      "Epoch: 7, Batch: 678, Loss: 2792.52978515625\n",
      "Epoch: 7, Batch: 679, Loss: 2473.9853515625\n",
      "Epoch: 7, Batch: 680, Loss: 2861.042724609375\n",
      "Epoch: 7, Batch: 681, Loss: 3181.374755859375\n",
      "Epoch: 7, Batch: 682, Loss: 2592.197509765625\n",
      "Epoch: 7, Batch: 683, Loss: 2321.8408203125\n",
      "Epoch: 7, Batch: 684, Loss: 2609.77294921875\n",
      "Epoch: 7, Batch: 685, Loss: 2671.5595703125\n",
      "Epoch: 7, Batch: 686, Loss: 2258.814208984375\n",
      "Epoch: 7, Batch: 687, Loss: 2601.289306640625\n",
      "Epoch: 7, Batch: 688, Loss: 2872.5244140625\n",
      "Epoch: 7, Batch: 689, Loss: 2975.9931640625\n",
      "Epoch: 7, Batch: 690, Loss: 2756.95361328125\n",
      "Epoch: 7, Batch: 691, Loss: 2708.4716796875\n",
      "Epoch: 7, Batch: 692, Loss: 2766.16845703125\n",
      "Epoch: 7, Batch: 693, Loss: 2858.66845703125\n",
      "Epoch: 7, Batch: 694, Loss: 2713.819091796875\n",
      "Epoch: 7, Batch: 695, Loss: 2280.00634765625\n",
      "Epoch: 7, Batch: 696, Loss: 3062.185302734375\n",
      "Epoch: 7, Batch: 697, Loss: 2432.3701171875\n",
      "Epoch: 7, Batch: 698, Loss: 2804.8720703125\n",
      "Epoch: 7, Batch: 699, Loss: 2177.249267578125\n",
      "Epoch: 7, Batch: 700, Loss: 2462.961181640625\n",
      "Epoch: 7, Batch: 701, Loss: 2213.09033203125\n",
      "Epoch: 7, Batch: 702, Loss: 3188.978759765625\n",
      "Epoch: 7, Batch: 703, Loss: 2035.47216796875\n",
      "Epoch: 7, Batch: 704, Loss: 2542.79931640625\n",
      "Epoch: 7, Batch: 705, Loss: 1644.504150390625\n",
      "Epoch: 7, Batch: 706, Loss: 2305.672119140625\n",
      "Epoch: 7, Batch: 707, Loss: 2497.102294921875\n",
      "Epoch: 7, Batch: 708, Loss: 2715.6328125\n",
      "Epoch: 7, Batch: 709, Loss: 2671.771240234375\n",
      "Epoch: 7, Batch: 710, Loss: 2685.94091796875\n",
      "Epoch: 7, Batch: 711, Loss: 2827.554443359375\n",
      "Epoch: 7, Batch: 712, Loss: 2661.486572265625\n",
      "Epoch: 7, Batch: 713, Loss: 3077.2734375\n",
      "Epoch: 7, Batch: 714, Loss: 2734.17041015625\n",
      "Epoch: 7, Batch: 715, Loss: 2857.420166015625\n",
      "Epoch: 7, Batch: 716, Loss: 2910.3271484375\n",
      "Epoch: 7, Batch: 717, Loss: 2826.902587890625\n",
      "Epoch: 7, Batch: 718, Loss: 2685.931884765625\n",
      "Epoch: 7, Batch: 719, Loss: 2634.260009765625\n",
      "Epoch: 7, Batch: 720, Loss: 2566.48095703125\n",
      "Epoch: 7, Batch: 721, Loss: 2686.328125\n",
      "Epoch: 7, Batch: 722, Loss: 2860.5\n",
      "Epoch: 7, Batch: 723, Loss: 2543.337158203125\n",
      "Epoch: 7, Batch: 724, Loss: 2390.164794921875\n",
      "Epoch: 7, Batch: 725, Loss: 2789.552978515625\n",
      "Epoch: 7, Batch: 726, Loss: 2609.552978515625\n",
      "Epoch: 7, Batch: 727, Loss: 2730.887939453125\n",
      "Epoch: 7, Batch: 728, Loss: 2541.615478515625\n",
      "Epoch: 7, Batch: 729, Loss: 2560.953369140625\n",
      "Epoch: 7, Batch: 730, Loss: 2672.057861328125\n",
      "Epoch: 7, Batch: 731, Loss: 2628.70751953125\n",
      "Epoch: 7, Batch: 732, Loss: 2332.74462890625\n",
      "Epoch: 7, Batch: 733, Loss: 3387.01708984375\n",
      "Epoch: 7, Batch: 734, Loss: 3163.168212890625\n",
      "Epoch: 7, Batch: 735, Loss: 2880.189453125\n",
      "Epoch: 7, Batch: 736, Loss: 2870.58251953125\n",
      "Epoch: 7, Batch: 737, Loss: 2519.0390625\n",
      "Epoch: 7, Batch: 738, Loss: 2627.302734375\n",
      "Epoch: 7, Batch: 739, Loss: 3004.188232421875\n",
      "Epoch: 7, Batch: 740, Loss: 2623.859619140625\n",
      "Epoch: 7, Batch: 741, Loss: 2733.34375\n",
      "Epoch: 7, Batch: 742, Loss: 2753.49853515625\n",
      "Epoch: 7, Batch: 743, Loss: 2974.94970703125\n",
      "Epoch: 7, Batch: 744, Loss: 2444.22265625\n",
      "Epoch: 7, Batch: 745, Loss: 2346.339599609375\n",
      "Epoch: 7, Batch: 746, Loss: 2393.081787109375\n",
      "Epoch: 7, Batch: 747, Loss: 2406.655029296875\n",
      "Epoch: 7, Batch: 748, Loss: 2964.7705078125\n",
      "Epoch: 7, Batch: 749, Loss: 2406.30322265625\n",
      "Epoch: 7, Batch: 750, Loss: 3011.023681640625\n",
      "Epoch: 7, Batch: 751, Loss: 2344.26025390625\n",
      "Epoch: 7, Batch: 752, Loss: 2345.370361328125\n",
      "Epoch: 7, Batch: 753, Loss: 2199.734130859375\n",
      "Epoch: 7, Batch: 754, Loss: 2578.838134765625\n",
      "Epoch: 7, Batch: 755, Loss: 2908.3427734375\n",
      "Epoch: 7, Batch: 756, Loss: 2418.0859375\n",
      "Epoch: 7, Batch: 757, Loss: 2440.10693359375\n",
      "Epoch: 7, Batch: 758, Loss: 2295.51611328125\n",
      "Epoch: 7, Batch: 759, Loss: 2843.76220703125\n",
      "Epoch: 7, Batch: 760, Loss: 2780.2529296875\n",
      "Epoch: 7, Batch: 761, Loss: 2272.7529296875\n",
      "Epoch: 7, Batch: 762, Loss: 2486.331298828125\n",
      "Epoch: 7, Batch: 763, Loss: 2636.14794921875\n",
      "Epoch: 7, Batch: 764, Loss: 2666.243408203125\n",
      "Epoch: 7, Batch: 765, Loss: 2932.4130859375\n",
      "Epoch: 7, Batch: 766, Loss: 2732.80224609375\n",
      "Epoch: 7, Batch: 767, Loss: 2662.649169921875\n",
      "Epoch: 7, Batch: 768, Loss: 2388.556884765625\n",
      "Epoch: 7, Batch: 769, Loss: 2421.010009765625\n",
      "Epoch: 7, Batch: 770, Loss: 2615.0634765625\n",
      "Epoch: 7, Batch: 771, Loss: 2710.906494140625\n",
      "Epoch: 7, Batch: 772, Loss: 3480.86376953125\n",
      "Epoch: 7, Batch: 773, Loss: 2595.892822265625\n",
      "Epoch: 7, Batch: 774, Loss: 2882.76123046875\n",
      "Epoch: 7, Batch: 775, Loss: 2679.916015625\n",
      "Epoch: 7, Batch: 776, Loss: 2700.0185546875\n",
      "Epoch: 7, Batch: 777, Loss: 2518.33544921875\n",
      "Epoch: 7, Batch: 778, Loss: 2689.733154296875\n",
      "Epoch: 7, Batch: 779, Loss: 2888.22021484375\n",
      "Epoch: 7, Batch: 780, Loss: 1947.1551513671875\n",
      "Epoch: 7, Batch: 781, Loss: 3075.377197265625\n",
      "Epoch: 7, Batch: 782, Loss: 2178.165771484375\n",
      "Epoch: 7, Batch: 783, Loss: 3104.264404296875\n",
      "Epoch: 7, Batch: 784, Loss: 2790.54443359375\n",
      "Epoch: 7, Batch: 785, Loss: 2324.361572265625\n",
      "Epoch: 7, Batch: 786, Loss: 2478.05419921875\n",
      "Epoch: 7, Batch: 787, Loss: 2795.909912109375\n",
      "Epoch: 7, Batch: 788, Loss: 2815.571044921875\n",
      "Epoch: 7, Batch: 789, Loss: 2082.67724609375\n",
      "Epoch: 7, Batch: 790, Loss: 2534.961181640625\n",
      "Epoch: 7, Batch: 791, Loss: 2733.64892578125\n",
      "Epoch: 7, Batch: 792, Loss: 2839.493896484375\n",
      "Epoch: 7, Batch: 793, Loss: 2971.884033203125\n",
      "Epoch: 7, Batch: 794, Loss: 2380.012451171875\n",
      "Epoch: 7, Batch: 795, Loss: 2512.588134765625\n",
      "Epoch: 7, Batch: 796, Loss: 2559.001220703125\n",
      "Epoch: 7, Batch: 797, Loss: 2452.359130859375\n",
      "Epoch: 7, Batch: 798, Loss: 2320.964111328125\n",
      "Epoch: 7, Batch: 799, Loss: 2418.179931640625\n",
      "Epoch: 7, Batch: 800, Loss: 3054.09130859375\n",
      "Epoch: 7, Batch: 801, Loss: 2441.701171875\n",
      "Epoch: 7, Batch: 802, Loss: 3073.905517578125\n",
      "Epoch: 7, Batch: 803, Loss: 2938.197998046875\n",
      "Epoch: 7, Batch: 804, Loss: 2930.2158203125\n",
      "Epoch: 7, Batch: 805, Loss: 2964.89111328125\n",
      "Epoch: 7, Batch: 806, Loss: 3020.6630859375\n",
      "Epoch: 7, Batch: 807, Loss: 3066.1533203125\n",
      "Epoch: 7, Batch: 808, Loss: 2252.541015625\n",
      "Epoch: 7, Batch: 809, Loss: 3031.15673828125\n",
      "Epoch: 7, Batch: 810, Loss: 2939.875732421875\n",
      "Epoch: 7, Batch: 811, Loss: 2724.6689453125\n",
      "Epoch: 7, Batch: 812, Loss: 2560.8623046875\n",
      "Epoch: 7, Batch: 813, Loss: 2996.844482421875\n",
      "Epoch: 7, Batch: 814, Loss: 2283.167236328125\n",
      "Epoch: 7, Batch: 815, Loss: 2987.21142578125\n",
      "Epoch: 7, Batch: 816, Loss: 2380.55029296875\n",
      "Epoch: 7, Batch: 817, Loss: 2505.843994140625\n",
      "Epoch: 7, Batch: 818, Loss: 2285.62548828125\n",
      "Epoch: 7, Batch: 819, Loss: 3141.5703125\n",
      "Epoch: 7, Batch: 820, Loss: 2562.404296875\n",
      "Epoch: 7, Batch: 821, Loss: 2241.40478515625\n",
      "Epoch: 7, Batch: 822, Loss: 2824.70703125\n",
      "Epoch: 7, Batch: 823, Loss: 3004.007080078125\n",
      "Epoch: 7, Batch: 824, Loss: 2792.84619140625\n",
      "Epoch: 7, Batch: 825, Loss: 2735.470458984375\n",
      "Epoch: 7, Batch: 826, Loss: 2231.22021484375\n",
      "Epoch: 7, Batch: 827, Loss: 3271.73046875\n",
      "Epoch: 7, Batch: 828, Loss: 2735.849609375\n",
      "Epoch: 7, Batch: 829, Loss: 2909.959228515625\n",
      "Epoch: 7, Batch: 830, Loss: 2740.375\n",
      "Epoch: 7, Batch: 831, Loss: 2333.397705078125\n",
      "Epoch: 7, Batch: 832, Loss: 2630.93408203125\n",
      "Epoch: 7, Batch: 833, Loss: 2358.18896484375\n",
      "Epoch: 7, Batch: 834, Loss: 2117.576416015625\n",
      "Epoch: 7, Batch: 835, Loss: 2053.286376953125\n",
      "Epoch: 7, Batch: 836, Loss: 2820.759765625\n",
      "Epoch: 7, Batch: 837, Loss: 3099.162109375\n",
      "Epoch: 7, Batch: 838, Loss: 2770.514404296875\n",
      "Epoch: 7, Batch: 839, Loss: 2686.995849609375\n",
      "Epoch: 7, Batch: 840, Loss: 2507.155517578125\n",
      "Epoch: 7, Batch: 841, Loss: 2087.5234375\n",
      "Epoch: 7, Batch: 842, Loss: 2587.673583984375\n",
      "Epoch: 7, Batch: 843, Loss: 2395.1318359375\n",
      "Epoch: 7, Batch: 844, Loss: 3191.560302734375\n",
      "Epoch: 7, Batch: 845, Loss: 2430.672119140625\n",
      "Epoch: 7, Batch: 846, Loss: 2951.447998046875\n",
      "Epoch: 7, Batch: 847, Loss: 2674.37353515625\n",
      "Epoch: 7, Batch: 848, Loss: 3091.5615234375\n",
      "Epoch: 7, Batch: 849, Loss: 2845.1650390625\n",
      "Epoch: 7, Batch: 850, Loss: 2440.93408203125\n",
      "Epoch: 7, Batch: 851, Loss: 2489.374755859375\n",
      "Epoch: 7, Batch: 852, Loss: 2402.57177734375\n",
      "Epoch: 7, Batch: 853, Loss: 2977.15625\n",
      "Epoch: 7, Batch: 854, Loss: 2930.6494140625\n",
      "Epoch: 7, Batch: 855, Loss: 3050.485595703125\n",
      "Epoch: 7, Batch: 856, Loss: 2352.56494140625\n",
      "Epoch: 7, Batch: 857, Loss: 2840.44189453125\n",
      "Epoch: 7, Batch: 858, Loss: 3035.1728515625\n",
      "Epoch: 7, Batch: 859, Loss: 2716.37548828125\n",
      "Epoch: 7, Batch: 860, Loss: 2582.749267578125\n",
      "Epoch: 7, Batch: 861, Loss: 2200.269775390625\n",
      "Epoch: 7, Batch: 862, Loss: 2629.00146484375\n",
      "Epoch: 7, Batch: 863, Loss: 2553.264404296875\n",
      "Epoch: 7, Batch: 864, Loss: 2616.21337890625\n",
      "Epoch: 7, Batch: 865, Loss: 3048.6640625\n",
      "Epoch: 7, Batch: 866, Loss: 2296.08056640625\n",
      "Epoch: 7, Batch: 867, Loss: 2616.292724609375\n",
      "Epoch: 7, Batch: 868, Loss: 2993.66162109375\n",
      "Epoch: 7, Batch: 869, Loss: 2717.3359375\n",
      "Epoch: 7, Batch: 870, Loss: 2420.3193359375\n",
      "Epoch: 7, Batch: 871, Loss: 2960.146240234375\n",
      "Epoch: 7, Batch: 872, Loss: 3792.26318359375\n",
      "Epoch: 7, Batch: 873, Loss: 2676.18359375\n",
      "Epoch: 7, Batch: 874, Loss: 2854.693603515625\n",
      "Epoch: 7, Batch: 875, Loss: 2539.78857421875\n",
      "Epoch: 7, Batch: 876, Loss: 3046.58349609375\n",
      "Epoch: 7, Batch: 877, Loss: 2994.681396484375\n",
      "Epoch: 7, Batch: 878, Loss: 3106.343017578125\n",
      "Epoch: 7, Batch: 879, Loss: 2552.736572265625\n",
      "Epoch: 7, Batch: 880, Loss: 2355.790771484375\n",
      "Epoch: 7, Batch: 881, Loss: 2506.082763671875\n",
      "Epoch: 7, Batch: 882, Loss: 2656.50390625\n",
      "Epoch: 7, Batch: 883, Loss: 2942.890380859375\n",
      "Epoch: 7, Batch: 884, Loss: 2781.506591796875\n",
      "Epoch: 7, Batch: 885, Loss: 2765.18359375\n",
      "Epoch: 7, Batch: 886, Loss: 2166.9638671875\n",
      "Epoch: 7, Batch: 887, Loss: 2553.298095703125\n",
      "Epoch: 7, Batch: 888, Loss: 2913.0361328125\n",
      "Epoch: 7, Batch: 889, Loss: 2738.93408203125\n",
      "Epoch: 7, Batch: 890, Loss: 2255.742919921875\n",
      "Epoch: 7, Batch: 891, Loss: 2629.662841796875\n",
      "Epoch: 7, Batch: 892, Loss: 2587.11376953125\n",
      "Epoch: 7, Batch: 893, Loss: 2095.4384765625\n",
      "Epoch: 7, Batch: 894, Loss: 2883.9970703125\n",
      "Epoch: 7, Batch: 895, Loss: 2555.716796875\n",
      "Epoch: 7, Batch: 896, Loss: 2082.643798828125\n",
      "Epoch: 7, Batch: 897, Loss: 2303.535400390625\n",
      "Epoch: 7, Batch: 898, Loss: 2426.1318359375\n",
      "Epoch: 7, Batch: 899, Loss: 2462.892333984375\n",
      "Epoch: 7, Batch: 900, Loss: 2633.2177734375\n",
      "Epoch: 7, Batch: 901, Loss: 2322.750244140625\n",
      "Epoch: 7, Batch: 902, Loss: 2833.8291015625\n",
      "Epoch: 7, Batch: 903, Loss: 3048.864990234375\n",
      "Epoch: 7, Batch: 904, Loss: 2430.9814453125\n",
      "Epoch: 7, Batch: 905, Loss: 2501.615478515625\n",
      "Epoch: 7, Batch: 906, Loss: 2222.19677734375\n",
      "Epoch: 7, Batch: 907, Loss: 3205.976806640625\n",
      "Epoch: 7, Batch: 908, Loss: 2776.421630859375\n",
      "Epoch: 7, Batch: 909, Loss: 2451.904052734375\n",
      "Epoch: 7, Batch: 910, Loss: 2163.10009765625\n",
      "Epoch: 7, Batch: 911, Loss: 2871.33056640625\n",
      "Epoch: 7, Batch: 912, Loss: 3146.18701171875\n",
      "Epoch: 7, Batch: 913, Loss: 2785.132568359375\n",
      "Epoch: 7, Batch: 914, Loss: 3123.71435546875\n",
      "Epoch: 7, Batch: 915, Loss: 2430.219970703125\n",
      "Epoch: 7, Batch: 916, Loss: 3155.63818359375\n",
      "Epoch: 7, Batch: 917, Loss: 1996.21728515625\n",
      "Epoch: 7, Batch: 918, Loss: 2693.92529296875\n",
      "Epoch: 7, Batch: 919, Loss: 2851.18896484375\n",
      "Epoch: 7, Batch: 920, Loss: 2649.86767578125\n",
      "Epoch: 7, Batch: 921, Loss: 2604.15625\n",
      "Epoch: 7, Batch: 922, Loss: 1937.04345703125\n",
      "Epoch: 7, Batch: 923, Loss: 2655.25537109375\n",
      "Epoch: 7, Batch: 924, Loss: 2550.311279296875\n",
      "Epoch: 7, Batch: 925, Loss: 2625.37353515625\n",
      "Epoch: 7, Batch: 926, Loss: 2862.75732421875\n",
      "Epoch: 7, Batch: 927, Loss: 2267.8095703125\n",
      "Epoch: 7, Batch: 928, Loss: 2604.19580078125\n",
      "Epoch: 7, Batch: 929, Loss: 2750.40478515625\n",
      "Epoch: 7, Batch: 930, Loss: 2634.98974609375\n",
      "Epoch: 7, Batch: 931, Loss: 2331.45849609375\n",
      "Epoch: 7, Batch: 932, Loss: 2535.314453125\n",
      "Epoch: 7, Batch: 933, Loss: 2623.958251953125\n",
      "Epoch: 7, Batch: 934, Loss: 2444.690185546875\n",
      "Epoch: 7, Batch: 935, Loss: 3141.68212890625\n",
      "Epoch: 7, Batch: 936, Loss: 2716.920654296875\n",
      "Epoch: 7, Batch: 937, Loss: 2540.02197265625\n",
      "Epoch: 7, Batch: 938, Loss: 2825.93896484375\n",
      "Epoch: 7, Batch: 939, Loss: 2079.552734375\n",
      "Epoch: 7, Batch: 940, Loss: 2114.46240234375\n",
      "Epoch: 7, Batch: 941, Loss: 2564.64306640625\n",
      "Epoch: 7, Batch: 942, Loss: 2247.438232421875\n",
      "Epoch: 7, Batch: 943, Loss: 2812.3955078125\n",
      "Epoch: 7, Batch: 944, Loss: 2332.7353515625\n",
      "Epoch: 7, Batch: 945, Loss: 2857.900634765625\n",
      "Epoch: 7, Batch: 946, Loss: 2213.9677734375\n",
      "Epoch: 7, Batch: 947, Loss: 2936.590576171875\n",
      "Epoch: 7, Batch: 948, Loss: 2985.9716796875\n",
      "Epoch: 7, Batch: 949, Loss: 2849.40673828125\n",
      "Epoch: 7, Batch: 950, Loss: 2695.675537109375\n",
      "Epoch: 7, Batch: 951, Loss: 2290.5244140625\n",
      "Epoch: 7, Batch: 952, Loss: 2712.494384765625\n",
      "Epoch: 7, Batch: 953, Loss: 2436.117431640625\n",
      "Epoch: 7, Batch: 954, Loss: 2519.182373046875\n",
      "Epoch: 7, Batch: 955, Loss: 2909.8818359375\n",
      "Epoch: 7, Batch: 956, Loss: 2654.112060546875\n",
      "Epoch: 7, Batch: 957, Loss: 2395.925537109375\n",
      "Epoch: 7, Batch: 958, Loss: 2800.060791015625\n",
      "Epoch: 7, Batch: 959, Loss: 2337.89892578125\n",
      "Epoch: 7, Batch: 960, Loss: 2541.533447265625\n",
      "Epoch: 7, Batch: 961, Loss: 2862.846923828125\n",
      "Epoch: 7, Batch: 962, Loss: 2251.283203125\n",
      "Epoch: 7, Batch: 963, Loss: 2275.96923828125\n",
      "Epoch: 7, Batch: 964, Loss: 2058.197998046875\n",
      "Epoch: 7, Batch: 965, Loss: 2651.14990234375\n",
      "Epoch: 7, Batch: 966, Loss: 2316.755126953125\n",
      "Epoch: 7, Batch: 967, Loss: 2465.280029296875\n",
      "Epoch: 7, Batch: 968, Loss: 2473.797119140625\n",
      "Epoch: 7, Batch: 969, Loss: 2645.298095703125\n",
      "Epoch: 7, Batch: 970, Loss: 3318.93017578125\n",
      "Epoch: 7, Batch: 971, Loss: 2554.496337890625\n",
      "Epoch: 7, Batch: 972, Loss: 2173.142333984375\n",
      "Epoch: 7, Batch: 973, Loss: 2765.970947265625\n",
      "Epoch: 7, Batch: 974, Loss: 2616.26220703125\n",
      "Epoch: 7, Batch: 975, Loss: 3000.95654296875\n",
      "Epoch: 7, Batch: 976, Loss: 1956.09423828125\n",
      "Epoch: 7, Batch: 977, Loss: 3080.207275390625\n",
      "Epoch: 7, Batch: 978, Loss: 2918.706298828125\n",
      "Epoch: 7, Batch: 979, Loss: 3135.5390625\n",
      "Epoch: 7, Batch: 980, Loss: 2700.805419921875\n",
      "Epoch: 7, Batch: 981, Loss: 2618.76708984375\n",
      "Epoch: 7, Batch: 982, Loss: 3356.610595703125\n",
      "Epoch: 7, Batch: 983, Loss: 2607.689697265625\n",
      "Epoch: 7, Batch: 984, Loss: 2611.3046875\n",
      "Epoch: 7, Batch: 985, Loss: 2634.34765625\n",
      "Epoch: 7, Batch: 986, Loss: 2406.0703125\n",
      "Epoch: 7, Batch: 987, Loss: 2142.119140625\n",
      "Epoch: 7, Batch: 988, Loss: 2646.177490234375\n",
      "Epoch: 7, Batch: 989, Loss: 2643.5205078125\n",
      "Epoch: 7, Batch: 990, Loss: 2501.730712890625\n",
      "Epoch: 7, Batch: 991, Loss: 2852.640380859375\n",
      "Epoch: 7, Batch: 992, Loss: 2323.76513671875\n",
      "Epoch: 7, Batch: 993, Loss: 2659.96630859375\n",
      "Epoch: 7, Batch: 994, Loss: 2211.675048828125\n",
      "Epoch: 7, Batch: 995, Loss: 2177.16552734375\n",
      "Epoch: 7, Batch: 996, Loss: 2462.370361328125\n",
      "Epoch: 7, Batch: 997, Loss: 1501.802490234375\n",
      "Epoch: 7, Batch: 998, Loss: 2861.83056640625\n",
      "Epoch: 7, Batch: 999, Loss: 2385.682861328125\n",
      "Epoch: 8, Batch: 0, Loss: 2985.98583984375\n",
      "Epoch: 8, Batch: 1, Loss: 3153.0185546875\n",
      "Epoch: 8, Batch: 2, Loss: 2635.7021484375\n",
      "Epoch: 8, Batch: 3, Loss: 3138.022705078125\n",
      "Epoch: 8, Batch: 4, Loss: 2677.77099609375\n",
      "Epoch: 8, Batch: 5, Loss: 2726.751953125\n",
      "Epoch: 8, Batch: 6, Loss: 2633.2138671875\n",
      "Epoch: 8, Batch: 7, Loss: 2215.740966796875\n",
      "Epoch: 8, Batch: 8, Loss: 2722.53369140625\n",
      "Epoch: 8, Batch: 9, Loss: 2501.446533203125\n",
      "Epoch: 8, Batch: 10, Loss: 2353.607666015625\n",
      "Epoch: 8, Batch: 11, Loss: 2788.94384765625\n",
      "Epoch: 8, Batch: 12, Loss: 2299.307861328125\n",
      "Epoch: 8, Batch: 13, Loss: 2060.51025390625\n",
      "Epoch: 8, Batch: 14, Loss: 2600.10595703125\n",
      "Epoch: 8, Batch: 15, Loss: 2263.06689453125\n",
      "Epoch: 8, Batch: 16, Loss: 2533.971435546875\n",
      "Epoch: 8, Batch: 17, Loss: 3104.484375\n",
      "Epoch: 8, Batch: 18, Loss: 2148.990234375\n",
      "Epoch: 8, Batch: 19, Loss: 2849.841796875\n",
      "Epoch: 8, Batch: 20, Loss: 2540.383544921875\n",
      "Epoch: 8, Batch: 21, Loss: 3262.6015625\n",
      "Epoch: 8, Batch: 22, Loss: 2153.51953125\n",
      "Epoch: 8, Batch: 23, Loss: 2343.58447265625\n",
      "Epoch: 8, Batch: 24, Loss: 3089.1025390625\n",
      "Epoch: 8, Batch: 25, Loss: 2788.96044921875\n",
      "Epoch: 8, Batch: 26, Loss: 2545.463623046875\n",
      "Epoch: 8, Batch: 27, Loss: 2402.03076171875\n",
      "Epoch: 8, Batch: 28, Loss: 2817.551513671875\n",
      "Epoch: 8, Batch: 29, Loss: 2751.3037109375\n",
      "Epoch: 8, Batch: 30, Loss: 2656.836181640625\n",
      "Epoch: 8, Batch: 31, Loss: 1774.7095947265625\n",
      "Epoch: 8, Batch: 32, Loss: 2609.88037109375\n",
      "Epoch: 8, Batch: 33, Loss: 3227.611083984375\n",
      "Epoch: 8, Batch: 34, Loss: 2695.786865234375\n",
      "Epoch: 8, Batch: 35, Loss: 2413.733154296875\n",
      "Epoch: 8, Batch: 36, Loss: 2651.77783203125\n",
      "Epoch: 8, Batch: 37, Loss: 2242.424560546875\n",
      "Epoch: 8, Batch: 38, Loss: 2864.486328125\n",
      "Epoch: 8, Batch: 39, Loss: 2517.673095703125\n",
      "Epoch: 8, Batch: 40, Loss: 2520.90478515625\n",
      "Epoch: 8, Batch: 41, Loss: 2661.1826171875\n",
      "Epoch: 8, Batch: 42, Loss: 2855.5205078125\n",
      "Epoch: 8, Batch: 43, Loss: 3210.128173828125\n",
      "Epoch: 8, Batch: 44, Loss: 2173.12353515625\n",
      "Epoch: 8, Batch: 45, Loss: 2362.407470703125\n",
      "Epoch: 8, Batch: 46, Loss: 2492.531494140625\n",
      "Epoch: 8, Batch: 47, Loss: 2948.123291015625\n",
      "Epoch: 8, Batch: 48, Loss: 2655.017333984375\n",
      "Epoch: 8, Batch: 49, Loss: 2879.685546875\n",
      "Epoch: 8, Batch: 50, Loss: 2860.089599609375\n",
      "Epoch: 8, Batch: 51, Loss: 2735.600830078125\n",
      "Epoch: 8, Batch: 52, Loss: 2375.834228515625\n",
      "Epoch: 8, Batch: 53, Loss: 2864.471435546875\n",
      "Epoch: 8, Batch: 54, Loss: 3027.56982421875\n",
      "Epoch: 8, Batch: 55, Loss: 3184.584716796875\n",
      "Epoch: 8, Batch: 56, Loss: 2657.995849609375\n",
      "Epoch: 8, Batch: 57, Loss: 2750.069580078125\n",
      "Epoch: 8, Batch: 58, Loss: 2218.611083984375\n",
      "Epoch: 8, Batch: 59, Loss: 2625.458984375\n",
      "Epoch: 8, Batch: 60, Loss: 2891.47314453125\n",
      "Epoch: 8, Batch: 61, Loss: 2364.871337890625\n",
      "Epoch: 8, Batch: 62, Loss: 2982.513427734375\n",
      "Epoch: 8, Batch: 63, Loss: 2435.918212890625\n",
      "Epoch: 8, Batch: 64, Loss: 3040.685302734375\n",
      "Epoch: 8, Batch: 65, Loss: 3179.88671875\n",
      "Epoch: 8, Batch: 66, Loss: 2225.115234375\n",
      "Epoch: 8, Batch: 67, Loss: 2682.634765625\n",
      "Epoch: 8, Batch: 68, Loss: 2494.09375\n",
      "Epoch: 8, Batch: 69, Loss: 2681.86181640625\n",
      "Epoch: 8, Batch: 70, Loss: 2968.037353515625\n",
      "Epoch: 8, Batch: 71, Loss: 2499.95556640625\n",
      "Epoch: 8, Batch: 72, Loss: 2739.669921875\n",
      "Epoch: 8, Batch: 73, Loss: 3103.86962890625\n",
      "Epoch: 8, Batch: 74, Loss: 2508.58251953125\n",
      "Epoch: 8, Batch: 75, Loss: 2774.369140625\n",
      "Epoch: 8, Batch: 76, Loss: 2532.33984375\n",
      "Epoch: 8, Batch: 77, Loss: 2832.199951171875\n",
      "Epoch: 8, Batch: 78, Loss: 2474.895263671875\n",
      "Epoch: 8, Batch: 79, Loss: 2542.835693359375\n",
      "Epoch: 8, Batch: 80, Loss: 2685.96435546875\n",
      "Epoch: 8, Batch: 81, Loss: 2460.9599609375\n",
      "Epoch: 8, Batch: 82, Loss: 2642.1728515625\n",
      "Epoch: 8, Batch: 83, Loss: 2753.26416015625\n",
      "Epoch: 8, Batch: 84, Loss: 2386.75390625\n",
      "Epoch: 8, Batch: 85, Loss: 2504.2763671875\n",
      "Epoch: 8, Batch: 86, Loss: 2722.662109375\n",
      "Epoch: 8, Batch: 87, Loss: 2542.07470703125\n",
      "Epoch: 8, Batch: 88, Loss: 3051.17578125\n",
      "Epoch: 8, Batch: 89, Loss: 2557.545166015625\n",
      "Epoch: 8, Batch: 90, Loss: 2689.76123046875\n",
      "Epoch: 8, Batch: 91, Loss: 2884.066162109375\n",
      "Epoch: 8, Batch: 92, Loss: 2293.11181640625\n",
      "Epoch: 8, Batch: 93, Loss: 2064.7802734375\n",
      "Epoch: 8, Batch: 94, Loss: 3127.042236328125\n",
      "Epoch: 8, Batch: 95, Loss: 2891.7333984375\n",
      "Epoch: 8, Batch: 96, Loss: 3040.64794921875\n",
      "Epoch: 8, Batch: 97, Loss: 2468.122802734375\n",
      "Epoch: 8, Batch: 98, Loss: 2600.2578125\n",
      "Epoch: 8, Batch: 99, Loss: 2518.13916015625\n",
      "Epoch: 8, Batch: 100, Loss: 2719.42333984375\n",
      "Epoch: 8, Batch: 101, Loss: 2683.785888671875\n",
      "Epoch: 8, Batch: 102, Loss: 2988.7333984375\n",
      "Epoch: 8, Batch: 103, Loss: 2344.6044921875\n",
      "Epoch: 8, Batch: 104, Loss: 2169.4501953125\n",
      "Epoch: 8, Batch: 105, Loss: 1938.30859375\n",
      "Epoch: 8, Batch: 106, Loss: 2396.671875\n",
      "Epoch: 8, Batch: 107, Loss: 2440.706787109375\n",
      "Epoch: 8, Batch: 108, Loss: 2525.737548828125\n",
      "Epoch: 8, Batch: 109, Loss: 2559.0712890625\n",
      "Epoch: 8, Batch: 110, Loss: 1856.087646484375\n",
      "Epoch: 8, Batch: 111, Loss: 2779.1796875\n",
      "Epoch: 8, Batch: 112, Loss: 2664.72802734375\n",
      "Epoch: 8, Batch: 113, Loss: 2758.74609375\n",
      "Epoch: 8, Batch: 114, Loss: 2336.62109375\n",
      "Epoch: 8, Batch: 115, Loss: 2564.4296875\n",
      "Epoch: 8, Batch: 116, Loss: 2577.01806640625\n",
      "Epoch: 8, Batch: 117, Loss: 3020.9873046875\n",
      "Epoch: 8, Batch: 118, Loss: 2776.89501953125\n",
      "Epoch: 8, Batch: 119, Loss: 2371.199462890625\n",
      "Epoch: 8, Batch: 120, Loss: 3414.95654296875\n",
      "Epoch: 8, Batch: 121, Loss: 2431.05859375\n",
      "Epoch: 8, Batch: 122, Loss: 3065.35986328125\n",
      "Epoch: 8, Batch: 123, Loss: 2235.482421875\n",
      "Epoch: 8, Batch: 124, Loss: 3249.8193359375\n",
      "Epoch: 8, Batch: 125, Loss: 3218.28564453125\n",
      "Epoch: 8, Batch: 126, Loss: 3219.096923828125\n",
      "Epoch: 8, Batch: 127, Loss: 2265.056640625\n",
      "Epoch: 8, Batch: 128, Loss: 2435.89453125\n",
      "Epoch: 8, Batch: 129, Loss: 2564.289794921875\n",
      "Epoch: 8, Batch: 130, Loss: 2375.66455078125\n",
      "Epoch: 8, Batch: 131, Loss: 2184.602294921875\n",
      "Epoch: 8, Batch: 132, Loss: 2839.47119140625\n",
      "Epoch: 8, Batch: 133, Loss: 2483.548583984375\n",
      "Epoch: 8, Batch: 134, Loss: 2173.58544921875\n",
      "Epoch: 8, Batch: 135, Loss: 2737.174072265625\n",
      "Epoch: 8, Batch: 136, Loss: 2481.82470703125\n",
      "Epoch: 8, Batch: 137, Loss: 2931.45849609375\n",
      "Epoch: 8, Batch: 138, Loss: 2229.140625\n",
      "Epoch: 8, Batch: 139, Loss: 2744.350830078125\n",
      "Epoch: 8, Batch: 140, Loss: 2292.630126953125\n",
      "Epoch: 8, Batch: 141, Loss: 2690.3134765625\n",
      "Epoch: 8, Batch: 142, Loss: 2148.893310546875\n",
      "Epoch: 8, Batch: 143, Loss: 3095.236328125\n",
      "Epoch: 8, Batch: 144, Loss: 1772.25\n",
      "Epoch: 8, Batch: 145, Loss: 2392.10546875\n",
      "Epoch: 8, Batch: 146, Loss: 2492.946044921875\n",
      "Epoch: 8, Batch: 147, Loss: 2938.040771484375\n",
      "Epoch: 8, Batch: 148, Loss: 3186.14599609375\n",
      "Epoch: 8, Batch: 149, Loss: 2263.382568359375\n",
      "Epoch: 8, Batch: 150, Loss: 2498.392333984375\n",
      "Epoch: 8, Batch: 151, Loss: 2850.05419921875\n",
      "Epoch: 8, Batch: 152, Loss: 2825.734619140625\n",
      "Epoch: 8, Batch: 153, Loss: 2042.78173828125\n",
      "Epoch: 8, Batch: 154, Loss: 2095.80712890625\n",
      "Epoch: 8, Batch: 155, Loss: 2538.99609375\n",
      "Epoch: 8, Batch: 156, Loss: 2082.86328125\n",
      "Epoch: 8, Batch: 157, Loss: 2735.254638671875\n",
      "Epoch: 8, Batch: 158, Loss: 2571.287109375\n",
      "Epoch: 8, Batch: 159, Loss: 2971.46875\n",
      "Epoch: 8, Batch: 160, Loss: 2695.3154296875\n",
      "Epoch: 8, Batch: 161, Loss: 2721.87353515625\n",
      "Epoch: 8, Batch: 162, Loss: 2793.906005859375\n",
      "Epoch: 8, Batch: 163, Loss: 2719.95556640625\n",
      "Epoch: 8, Batch: 164, Loss: 2669.46728515625\n",
      "Epoch: 8, Batch: 165, Loss: 2763.079833984375\n",
      "Epoch: 8, Batch: 166, Loss: 2687.782958984375\n",
      "Epoch: 8, Batch: 167, Loss: 2775.1611328125\n",
      "Epoch: 8, Batch: 168, Loss: 2811.6767578125\n",
      "Epoch: 8, Batch: 169, Loss: 2339.4404296875\n",
      "Epoch: 8, Batch: 170, Loss: 2358.3369140625\n",
      "Epoch: 8, Batch: 171, Loss: 2378.17236328125\n",
      "Epoch: 8, Batch: 172, Loss: 2537.263427734375\n",
      "Epoch: 8, Batch: 173, Loss: 2556.000732421875\n",
      "Epoch: 8, Batch: 174, Loss: 2850.582763671875\n",
      "Epoch: 8, Batch: 175, Loss: 2748.635986328125\n",
      "Epoch: 8, Batch: 176, Loss: 2707.857666015625\n",
      "Epoch: 8, Batch: 177, Loss: 2424.264892578125\n",
      "Epoch: 8, Batch: 178, Loss: 2677.650146484375\n",
      "Epoch: 8, Batch: 179, Loss: 2880.552734375\n",
      "Epoch: 8, Batch: 180, Loss: 2645.673095703125\n",
      "Epoch: 8, Batch: 181, Loss: 3427.012939453125\n",
      "Epoch: 8, Batch: 182, Loss: 2464.703857421875\n",
      "Epoch: 8, Batch: 183, Loss: 2252.2099609375\n",
      "Epoch: 8, Batch: 184, Loss: 2297.56005859375\n",
      "Epoch: 8, Batch: 185, Loss: 2835.283935546875\n",
      "Epoch: 8, Batch: 186, Loss: 2282.881591796875\n",
      "Epoch: 8, Batch: 187, Loss: 2886.446533203125\n",
      "Epoch: 8, Batch: 188, Loss: 3276.34423828125\n",
      "Epoch: 8, Batch: 189, Loss: 2785.177490234375\n",
      "Epoch: 8, Batch: 190, Loss: 2283.177490234375\n",
      "Epoch: 8, Batch: 191, Loss: 2410.01171875\n",
      "Epoch: 8, Batch: 192, Loss: 2243.513916015625\n",
      "Epoch: 8, Batch: 193, Loss: 2851.740478515625\n",
      "Epoch: 8, Batch: 194, Loss: 2512.725341796875\n",
      "Epoch: 8, Batch: 195, Loss: 2280.943603515625\n",
      "Epoch: 8, Batch: 196, Loss: 2158.686767578125\n",
      "Epoch: 8, Batch: 197, Loss: 2390.02392578125\n",
      "Epoch: 8, Batch: 198, Loss: 2937.166259765625\n",
      "Epoch: 8, Batch: 199, Loss: 2564.066650390625\n",
      "Epoch: 8, Batch: 200, Loss: 2591.772216796875\n",
      "Epoch: 8, Batch: 201, Loss: 2984.12744140625\n",
      "Epoch: 8, Batch: 202, Loss: 2663.46923828125\n",
      "Epoch: 8, Batch: 203, Loss: 2022.6402587890625\n",
      "Epoch: 8, Batch: 204, Loss: 2090.81884765625\n",
      "Epoch: 8, Batch: 205, Loss: 2528.98974609375\n",
      "Epoch: 8, Batch: 206, Loss: 2719.157958984375\n",
      "Epoch: 8, Batch: 207, Loss: 2645.40087890625\n",
      "Epoch: 8, Batch: 208, Loss: 2530.133056640625\n",
      "Epoch: 8, Batch: 209, Loss: 2606.72314453125\n",
      "Epoch: 8, Batch: 210, Loss: 2498.126953125\n",
      "Epoch: 8, Batch: 211, Loss: 3109.745361328125\n",
      "Epoch: 8, Batch: 212, Loss: 2659.76806640625\n",
      "Epoch: 8, Batch: 213, Loss: 3096.935546875\n",
      "Epoch: 8, Batch: 214, Loss: 2165.644287109375\n",
      "Epoch: 8, Batch: 215, Loss: 2903.150390625\n",
      "Epoch: 8, Batch: 216, Loss: 2932.587890625\n",
      "Epoch: 8, Batch: 217, Loss: 2815.05029296875\n",
      "Epoch: 8, Batch: 218, Loss: 2760.333251953125\n",
      "Epoch: 8, Batch: 219, Loss: 2277.8583984375\n",
      "Epoch: 8, Batch: 220, Loss: 2403.3203125\n",
      "Epoch: 8, Batch: 221, Loss: 2754.41845703125\n",
      "Epoch: 8, Batch: 222, Loss: 2360.745849609375\n",
      "Epoch: 8, Batch: 223, Loss: 3040.385498046875\n",
      "Epoch: 8, Batch: 224, Loss: 2799.391845703125\n",
      "Epoch: 8, Batch: 225, Loss: 2398.386474609375\n",
      "Epoch: 8, Batch: 226, Loss: 2798.27099609375\n",
      "Epoch: 8, Batch: 227, Loss: 2682.19140625\n",
      "Epoch: 8, Batch: 228, Loss: 2833.002685546875\n",
      "Epoch: 8, Batch: 229, Loss: 2490.85009765625\n",
      "Epoch: 8, Batch: 230, Loss: 2963.93212890625\n",
      "Epoch: 8, Batch: 231, Loss: 2894.22412109375\n",
      "Epoch: 8, Batch: 232, Loss: 2637.433349609375\n",
      "Epoch: 8, Batch: 233, Loss: 2776.735595703125\n",
      "Epoch: 8, Batch: 234, Loss: 2701.083984375\n",
      "Epoch: 8, Batch: 235, Loss: 2362.113037109375\n",
      "Epoch: 8, Batch: 236, Loss: 2273.681640625\n",
      "Epoch: 8, Batch: 237, Loss: 2067.546875\n",
      "Epoch: 8, Batch: 238, Loss: 2477.049560546875\n",
      "Epoch: 8, Batch: 239, Loss: 2652.35791015625\n",
      "Epoch: 8, Batch: 240, Loss: 2789.30810546875\n",
      "Epoch: 8, Batch: 241, Loss: 2541.590087890625\n",
      "Epoch: 8, Batch: 242, Loss: 2661.085693359375\n",
      "Epoch: 8, Batch: 243, Loss: 2995.808349609375\n",
      "Epoch: 8, Batch: 244, Loss: 2215.18896484375\n",
      "Epoch: 8, Batch: 245, Loss: 2584.63427734375\n",
      "Epoch: 8, Batch: 246, Loss: 2781.0576171875\n",
      "Epoch: 8, Batch: 247, Loss: 3052.463623046875\n",
      "Epoch: 8, Batch: 248, Loss: 2381.539794921875\n",
      "Epoch: 8, Batch: 249, Loss: 2811.958984375\n",
      "Epoch: 8, Batch: 250, Loss: 2538.19970703125\n",
      "Epoch: 8, Batch: 251, Loss: 2366.491455078125\n",
      "Epoch: 8, Batch: 252, Loss: 2888.5615234375\n",
      "Epoch: 8, Batch: 253, Loss: 2868.7861328125\n",
      "Epoch: 8, Batch: 254, Loss: 1963.4007568359375\n",
      "Epoch: 8, Batch: 255, Loss: 2566.578125\n",
      "Epoch: 8, Batch: 256, Loss: 2429.2978515625\n",
      "Epoch: 8, Batch: 257, Loss: 2531.060546875\n",
      "Epoch: 8, Batch: 258, Loss: 2672.7783203125\n",
      "Epoch: 8, Batch: 259, Loss: 2205.05615234375\n",
      "Epoch: 8, Batch: 260, Loss: 2881.83544921875\n",
      "Epoch: 8, Batch: 261, Loss: 2892.673095703125\n",
      "Epoch: 8, Batch: 262, Loss: 2808.6455078125\n",
      "Epoch: 8, Batch: 263, Loss: 2714.650146484375\n",
      "Epoch: 8, Batch: 264, Loss: 2739.76611328125\n",
      "Epoch: 8, Batch: 265, Loss: 2386.24609375\n",
      "Epoch: 8, Batch: 266, Loss: 2706.91552734375\n",
      "Epoch: 8, Batch: 267, Loss: 2725.60498046875\n",
      "Epoch: 8, Batch: 268, Loss: 2268.31591796875\n",
      "Epoch: 8, Batch: 269, Loss: 2401.821533203125\n",
      "Epoch: 8, Batch: 270, Loss: 2427.907470703125\n",
      "Epoch: 8, Batch: 271, Loss: 2434.1708984375\n",
      "Epoch: 8, Batch: 272, Loss: 2665.42138671875\n",
      "Epoch: 8, Batch: 273, Loss: 2839.682861328125\n",
      "Epoch: 8, Batch: 274, Loss: 3124.83349609375\n",
      "Epoch: 8, Batch: 275, Loss: 2451.31494140625\n",
      "Epoch: 8, Batch: 276, Loss: 3254.502685546875\n",
      "Epoch: 8, Batch: 277, Loss: 2849.4609375\n",
      "Epoch: 8, Batch: 278, Loss: 2602.14404296875\n",
      "Epoch: 8, Batch: 279, Loss: 2076.19775390625\n",
      "Epoch: 8, Batch: 280, Loss: 2994.8603515625\n",
      "Epoch: 8, Batch: 281, Loss: 3179.137451171875\n",
      "Epoch: 8, Batch: 282, Loss: 2828.185791015625\n",
      "Epoch: 8, Batch: 283, Loss: 2971.943115234375\n",
      "Epoch: 8, Batch: 284, Loss: 2781.80517578125\n",
      "Epoch: 8, Batch: 285, Loss: 2661.476318359375\n",
      "Epoch: 8, Batch: 286, Loss: 2747.091552734375\n",
      "Epoch: 8, Batch: 287, Loss: 2897.319091796875\n",
      "Epoch: 8, Batch: 288, Loss: 2464.92236328125\n",
      "Epoch: 8, Batch: 289, Loss: 3076.58251953125\n",
      "Epoch: 8, Batch: 290, Loss: 1948.2928466796875\n",
      "Epoch: 8, Batch: 291, Loss: 2316.1650390625\n",
      "Epoch: 8, Batch: 292, Loss: 2954.9560546875\n",
      "Epoch: 8, Batch: 293, Loss: 2459.38916015625\n",
      "Epoch: 8, Batch: 294, Loss: 2283.768310546875\n",
      "Epoch: 8, Batch: 295, Loss: 2638.73876953125\n",
      "Epoch: 8, Batch: 296, Loss: 3077.964111328125\n",
      "Epoch: 8, Batch: 297, Loss: 2669.91455078125\n",
      "Epoch: 8, Batch: 298, Loss: 2875.705078125\n",
      "Epoch: 8, Batch: 299, Loss: 3325.809814453125\n",
      "Epoch: 8, Batch: 300, Loss: 2809.95068359375\n",
      "Epoch: 8, Batch: 301, Loss: 2761.41259765625\n",
      "Epoch: 8, Batch: 302, Loss: 2135.437255859375\n",
      "Epoch: 8, Batch: 303, Loss: 2331.30126953125\n",
      "Epoch: 8, Batch: 304, Loss: 2829.015869140625\n",
      "Epoch: 8, Batch: 305, Loss: 2410.01220703125\n",
      "Epoch: 8, Batch: 306, Loss: 2862.2216796875\n",
      "Epoch: 8, Batch: 307, Loss: 2191.25830078125\n",
      "Epoch: 8, Batch: 308, Loss: 2752.52880859375\n",
      "Epoch: 8, Batch: 309, Loss: 2530.854736328125\n",
      "Epoch: 8, Batch: 310, Loss: 3288.916259765625\n",
      "Epoch: 8, Batch: 311, Loss: 2742.994384765625\n",
      "Epoch: 8, Batch: 312, Loss: 2871.544921875\n",
      "Epoch: 8, Batch: 313, Loss: 2359.52587890625\n",
      "Epoch: 8, Batch: 314, Loss: 2223.372802734375\n",
      "Epoch: 8, Batch: 315, Loss: 2662.017822265625\n",
      "Epoch: 8, Batch: 316, Loss: 2870.433349609375\n",
      "Epoch: 8, Batch: 317, Loss: 2684.59814453125\n",
      "Epoch: 8, Batch: 318, Loss: 2726.1865234375\n",
      "Epoch: 8, Batch: 319, Loss: 2464.906982421875\n",
      "Epoch: 8, Batch: 320, Loss: 2610.66162109375\n",
      "Epoch: 8, Batch: 321, Loss: 2604.319091796875\n",
      "Epoch: 8, Batch: 322, Loss: 2303.447021484375\n",
      "Epoch: 8, Batch: 323, Loss: 2968.67529296875\n",
      "Epoch: 8, Batch: 324, Loss: 2365.945556640625\n",
      "Epoch: 8, Batch: 325, Loss: 2196.67236328125\n",
      "Epoch: 8, Batch: 326, Loss: 2128.399658203125\n",
      "Epoch: 8, Batch: 327, Loss: 2215.368408203125\n",
      "Epoch: 8, Batch: 328, Loss: 3105.26318359375\n",
      "Epoch: 8, Batch: 329, Loss: 2484.7138671875\n",
      "Epoch: 8, Batch: 330, Loss: 2646.67578125\n",
      "Epoch: 8, Batch: 331, Loss: 3099.849609375\n",
      "Epoch: 8, Batch: 332, Loss: 2595.425537109375\n",
      "Epoch: 8, Batch: 333, Loss: 2350.011474609375\n",
      "Epoch: 8, Batch: 334, Loss: 2149.011474609375\n",
      "Epoch: 8, Batch: 335, Loss: 2825.5087890625\n",
      "Epoch: 8, Batch: 336, Loss: 2962.6220703125\n",
      "Epoch: 8, Batch: 337, Loss: 2951.69189453125\n",
      "Epoch: 8, Batch: 338, Loss: 3217.14599609375\n",
      "Epoch: 8, Batch: 339, Loss: 2588.942626953125\n",
      "Epoch: 8, Batch: 340, Loss: 2191.805419921875\n",
      "Epoch: 8, Batch: 341, Loss: 2877.712158203125\n",
      "Epoch: 8, Batch: 342, Loss: 2578.392578125\n",
      "Epoch: 8, Batch: 343, Loss: 2986.41015625\n",
      "Epoch: 8, Batch: 344, Loss: 2403.220947265625\n",
      "Epoch: 8, Batch: 345, Loss: 2539.56103515625\n",
      "Epoch: 8, Batch: 346, Loss: 2384.50732421875\n",
      "Epoch: 8, Batch: 347, Loss: 1917.070556640625\n",
      "Epoch: 8, Batch: 348, Loss: 2417.693115234375\n",
      "Epoch: 8, Batch: 349, Loss: 3156.824462890625\n",
      "Epoch: 8, Batch: 350, Loss: 3230.098876953125\n",
      "Epoch: 8, Batch: 351, Loss: 2812.9990234375\n",
      "Epoch: 8, Batch: 352, Loss: 2517.910400390625\n",
      "Epoch: 8, Batch: 353, Loss: 2773.9130859375\n",
      "Epoch: 8, Batch: 354, Loss: 2433.72607421875\n",
      "Epoch: 8, Batch: 355, Loss: 2685.692138671875\n",
      "Epoch: 8, Batch: 356, Loss: 2675.60791015625\n",
      "Epoch: 8, Batch: 357, Loss: 2848.419677734375\n",
      "Epoch: 8, Batch: 358, Loss: 2203.02294921875\n",
      "Epoch: 8, Batch: 359, Loss: 2847.685302734375\n",
      "Epoch: 8, Batch: 360, Loss: 2672.05224609375\n",
      "Epoch: 8, Batch: 361, Loss: 2609.806884765625\n",
      "Epoch: 8, Batch: 362, Loss: 2531.99072265625\n",
      "Epoch: 8, Batch: 363, Loss: 2208.23046875\n",
      "Epoch: 8, Batch: 364, Loss: 2888.975830078125\n",
      "Epoch: 8, Batch: 365, Loss: 2336.53515625\n",
      "Epoch: 8, Batch: 366, Loss: 1826.61669921875\n",
      "Epoch: 8, Batch: 367, Loss: 2943.806396484375\n",
      "Epoch: 8, Batch: 368, Loss: 2943.267578125\n",
      "Epoch: 8, Batch: 369, Loss: 2784.28369140625\n",
      "Epoch: 8, Batch: 370, Loss: 2574.3720703125\n",
      "Epoch: 8, Batch: 371, Loss: 2229.13818359375\n",
      "Epoch: 8, Batch: 372, Loss: 2549.49609375\n",
      "Epoch: 8, Batch: 373, Loss: 1811.4033203125\n",
      "Epoch: 8, Batch: 374, Loss: 2350.628173828125\n",
      "Epoch: 8, Batch: 375, Loss: 2459.155029296875\n",
      "Epoch: 8, Batch: 376, Loss: 2787.509521484375\n",
      "Epoch: 8, Batch: 377, Loss: 2743.72705078125\n",
      "Epoch: 8, Batch: 378, Loss: 2313.506591796875\n",
      "Epoch: 8, Batch: 379, Loss: 3275.180908203125\n",
      "Epoch: 8, Batch: 380, Loss: 3127.248291015625\n",
      "Epoch: 8, Batch: 381, Loss: 2073.610595703125\n",
      "Epoch: 8, Batch: 382, Loss: 2320.272216796875\n",
      "Epoch: 8, Batch: 383, Loss: 2316.09423828125\n",
      "Epoch: 8, Batch: 384, Loss: 2987.271728515625\n",
      "Epoch: 8, Batch: 385, Loss: 2701.26318359375\n",
      "Epoch: 8, Batch: 386, Loss: 2866.979736328125\n",
      "Epoch: 8, Batch: 387, Loss: 2636.95947265625\n",
      "Epoch: 8, Batch: 388, Loss: 2398.6328125\n",
      "Epoch: 8, Batch: 389, Loss: 2746.552001953125\n",
      "Epoch: 8, Batch: 390, Loss: 2349.7275390625\n",
      "Epoch: 8, Batch: 391, Loss: 2305.09228515625\n",
      "Epoch: 8, Batch: 392, Loss: 2842.524169921875\n",
      "Epoch: 8, Batch: 393, Loss: 2280.85400390625\n",
      "Epoch: 8, Batch: 394, Loss: 2667.731201171875\n",
      "Epoch: 8, Batch: 395, Loss: 2660.83544921875\n",
      "Epoch: 8, Batch: 396, Loss: 2479.223388671875\n",
      "Epoch: 8, Batch: 397, Loss: 2450.4921875\n",
      "Epoch: 8, Batch: 398, Loss: 3154.9248046875\n",
      "Epoch: 8, Batch: 399, Loss: 2819.041259765625\n",
      "Epoch: 8, Batch: 400, Loss: 2542.847412109375\n",
      "Epoch: 8, Batch: 401, Loss: 2542.706298828125\n",
      "Epoch: 8, Batch: 402, Loss: 2727.848388671875\n",
      "Epoch: 8, Batch: 403, Loss: 3004.518798828125\n",
      "Epoch: 8, Batch: 404, Loss: 3474.347900390625\n",
      "Epoch: 8, Batch: 405, Loss: 2304.39697265625\n",
      "Epoch: 8, Batch: 406, Loss: 2292.051025390625\n",
      "Epoch: 8, Batch: 407, Loss: 2705.6767578125\n",
      "Epoch: 8, Batch: 408, Loss: 3450.962158203125\n",
      "Epoch: 8, Batch: 409, Loss: 2938.492431640625\n",
      "Epoch: 8, Batch: 410, Loss: 2555.72314453125\n",
      "Epoch: 8, Batch: 411, Loss: 2542.218017578125\n",
      "Epoch: 8, Batch: 412, Loss: 2378.994873046875\n",
      "Epoch: 8, Batch: 413, Loss: 2412.384521484375\n",
      "Epoch: 8, Batch: 414, Loss: 2525.023681640625\n",
      "Epoch: 8, Batch: 415, Loss: 2716.79541015625\n",
      "Epoch: 8, Batch: 416, Loss: 1957.5343017578125\n",
      "Epoch: 8, Batch: 417, Loss: 2432.60107421875\n",
      "Epoch: 8, Batch: 418, Loss: 2591.365478515625\n",
      "Epoch: 8, Batch: 419, Loss: 2172.966796875\n",
      "Epoch: 8, Batch: 420, Loss: 2375.255615234375\n",
      "Epoch: 8, Batch: 421, Loss: 2192.921142578125\n",
      "Epoch: 8, Batch: 422, Loss: 2702.6123046875\n",
      "Epoch: 8, Batch: 423, Loss: 3462.871826171875\n",
      "Epoch: 8, Batch: 424, Loss: 2812.473388671875\n",
      "Epoch: 8, Batch: 425, Loss: 2982.57080078125\n",
      "Epoch: 8, Batch: 426, Loss: 2599.917236328125\n",
      "Epoch: 8, Batch: 427, Loss: 2892.009521484375\n",
      "Epoch: 8, Batch: 428, Loss: 3390.808837890625\n",
      "Epoch: 8, Batch: 429, Loss: 2313.615234375\n",
      "Epoch: 8, Batch: 430, Loss: 2775.2431640625\n",
      "Epoch: 8, Batch: 431, Loss: 3072.095947265625\n",
      "Epoch: 8, Batch: 432, Loss: 2554.366943359375\n",
      "Epoch: 8, Batch: 433, Loss: 2311.387939453125\n",
      "Epoch: 8, Batch: 434, Loss: 2101.00537109375\n",
      "Epoch: 8, Batch: 435, Loss: 2234.71240234375\n",
      "Epoch: 8, Batch: 436, Loss: 2524.090087890625\n",
      "Epoch: 8, Batch: 437, Loss: 3187.801025390625\n",
      "Epoch: 8, Batch: 438, Loss: 2372.350341796875\n",
      "Epoch: 8, Batch: 439, Loss: 2303.234130859375\n",
      "Epoch: 8, Batch: 440, Loss: 3469.17041015625\n",
      "Epoch: 8, Batch: 441, Loss: 2738.22265625\n",
      "Epoch: 8, Batch: 442, Loss: 2467.625244140625\n",
      "Epoch: 8, Batch: 443, Loss: 2566.492919921875\n",
      "Epoch: 8, Batch: 444, Loss: 2925.694580078125\n",
      "Epoch: 8, Batch: 445, Loss: 2733.79833984375\n",
      "Epoch: 8, Batch: 446, Loss: 2386.85888671875\n",
      "Epoch: 8, Batch: 447, Loss: 2960.704345703125\n",
      "Epoch: 8, Batch: 448, Loss: 2246.33154296875\n",
      "Epoch: 8, Batch: 449, Loss: 3776.17919921875\n",
      "Epoch: 8, Batch: 450, Loss: 2709.82568359375\n",
      "Epoch: 8, Batch: 451, Loss: 2955.094482421875\n",
      "Epoch: 8, Batch: 452, Loss: 3038.454345703125\n",
      "Epoch: 8, Batch: 453, Loss: 2490.474853515625\n",
      "Epoch: 8, Batch: 454, Loss: 3018.972900390625\n",
      "Epoch: 8, Batch: 455, Loss: 2736.10107421875\n",
      "Epoch: 8, Batch: 456, Loss: 2410.12109375\n",
      "Epoch: 8, Batch: 457, Loss: 2451.606689453125\n",
      "Epoch: 8, Batch: 458, Loss: 2440.17529296875\n",
      "Epoch: 8, Batch: 459, Loss: 3184.29833984375\n",
      "Epoch: 8, Batch: 460, Loss: 3536.955810546875\n",
      "Epoch: 8, Batch: 461, Loss: 2629.17041015625\n",
      "Epoch: 8, Batch: 462, Loss: 2742.928955078125\n",
      "Epoch: 8, Batch: 463, Loss: 2416.238037109375\n",
      "Epoch: 8, Batch: 464, Loss: 2519.464599609375\n",
      "Epoch: 8, Batch: 465, Loss: 2337.81298828125\n",
      "Epoch: 8, Batch: 466, Loss: 2624.452392578125\n",
      "Epoch: 8, Batch: 467, Loss: 2412.224853515625\n",
      "Epoch: 8, Batch: 468, Loss: 2639.23486328125\n",
      "Epoch: 8, Batch: 469, Loss: 2837.164794921875\n",
      "Epoch: 8, Batch: 470, Loss: 2370.0166015625\n",
      "Epoch: 8, Batch: 471, Loss: 2851.16357421875\n",
      "Epoch: 8, Batch: 472, Loss: 2657.011474609375\n",
      "Epoch: 8, Batch: 473, Loss: 2333.676025390625\n",
      "Epoch: 8, Batch: 474, Loss: 2797.850830078125\n",
      "Epoch: 8, Batch: 475, Loss: 2967.935791015625\n",
      "Epoch: 8, Batch: 476, Loss: 2767.302001953125\n",
      "Epoch: 8, Batch: 477, Loss: 2370.254638671875\n",
      "Epoch: 8, Batch: 478, Loss: 2556.928466796875\n",
      "Epoch: 8, Batch: 479, Loss: 2650.5966796875\n",
      "Epoch: 8, Batch: 480, Loss: 2345.20556640625\n",
      "Epoch: 8, Batch: 481, Loss: 2795.606689453125\n",
      "Epoch: 8, Batch: 482, Loss: 2013.5511474609375\n",
      "Epoch: 8, Batch: 483, Loss: 2346.168701171875\n",
      "Epoch: 8, Batch: 484, Loss: 2969.26904296875\n",
      "Epoch: 8, Batch: 485, Loss: 2436.038818359375\n",
      "Epoch: 8, Batch: 486, Loss: 2489.840576171875\n",
      "Epoch: 8, Batch: 487, Loss: 2593.328369140625\n",
      "Epoch: 8, Batch: 488, Loss: 2973.38037109375\n",
      "Epoch: 8, Batch: 489, Loss: 2694.07470703125\n",
      "Epoch: 8, Batch: 490, Loss: 2073.52099609375\n",
      "Epoch: 8, Batch: 491, Loss: 2926.637939453125\n",
      "Epoch: 8, Batch: 492, Loss: 2539.494873046875\n",
      "Epoch: 8, Batch: 493, Loss: 2126.715576171875\n",
      "Epoch: 8, Batch: 494, Loss: 2556.862060546875\n",
      "Epoch: 8, Batch: 495, Loss: 2407.15234375\n",
      "Epoch: 8, Batch: 496, Loss: 2735.54150390625\n",
      "Epoch: 8, Batch: 497, Loss: 2516.55859375\n",
      "Epoch: 8, Batch: 498, Loss: 1851.6624755859375\n",
      "Epoch: 8, Batch: 499, Loss: 2661.739501953125\n",
      "Epoch: 8, Batch: 500, Loss: 2773.4951171875\n",
      "Epoch: 8, Batch: 501, Loss: 3076.4638671875\n",
      "Epoch: 8, Batch: 502, Loss: 2611.842041015625\n",
      "Epoch: 8, Batch: 503, Loss: 2122.584228515625\n",
      "Epoch: 8, Batch: 504, Loss: 2167.103515625\n",
      "Epoch: 8, Batch: 505, Loss: 2352.07568359375\n",
      "Epoch: 8, Batch: 506, Loss: 2805.78271484375\n",
      "Epoch: 8, Batch: 507, Loss: 2910.73095703125\n",
      "Epoch: 8, Batch: 508, Loss: 2563.645751953125\n",
      "Epoch: 8, Batch: 509, Loss: 3022.611328125\n",
      "Epoch: 8, Batch: 510, Loss: 2211.787109375\n",
      "Epoch: 8, Batch: 511, Loss: 2284.1201171875\n",
      "Epoch: 8, Batch: 512, Loss: 2697.715576171875\n",
      "Epoch: 8, Batch: 513, Loss: 2142.93310546875\n",
      "Epoch: 8, Batch: 514, Loss: 2938.5224609375\n",
      "Epoch: 8, Batch: 515, Loss: 2858.015380859375\n",
      "Epoch: 8, Batch: 516, Loss: 2534.53173828125\n",
      "Epoch: 8, Batch: 517, Loss: 2629.749755859375\n",
      "Epoch: 8, Batch: 518, Loss: 2649.395263671875\n",
      "Epoch: 8, Batch: 519, Loss: 2892.787841796875\n",
      "Epoch: 8, Batch: 520, Loss: 3110.879638671875\n",
      "Epoch: 8, Batch: 521, Loss: 2217.973388671875\n",
      "Epoch: 8, Batch: 522, Loss: 2930.08984375\n",
      "Epoch: 8, Batch: 523, Loss: 2819.72607421875\n",
      "Epoch: 8, Batch: 524, Loss: 2381.541259765625\n",
      "Epoch: 8, Batch: 525, Loss: 2577.537109375\n",
      "Epoch: 8, Batch: 526, Loss: 2212.84521484375\n",
      "Epoch: 8, Batch: 527, Loss: 2768.74462890625\n",
      "Epoch: 8, Batch: 528, Loss: 3186.990478515625\n",
      "Epoch: 8, Batch: 529, Loss: 2565.626708984375\n",
      "Epoch: 8, Batch: 530, Loss: 2631.993896484375\n",
      "Epoch: 8, Batch: 531, Loss: 2558.12353515625\n",
      "Epoch: 8, Batch: 532, Loss: 2924.109375\n",
      "Epoch: 8, Batch: 533, Loss: 2420.810791015625\n",
      "Epoch: 8, Batch: 534, Loss: 2504.144287109375\n",
      "Epoch: 8, Batch: 535, Loss: 2399.915771484375\n",
      "Epoch: 8, Batch: 536, Loss: 2790.869140625\n",
      "Epoch: 8, Batch: 537, Loss: 2568.939697265625\n",
      "Epoch: 8, Batch: 538, Loss: 2791.435791015625\n",
      "Epoch: 8, Batch: 539, Loss: 3074.026611328125\n",
      "Epoch: 8, Batch: 540, Loss: 2396.510986328125\n",
      "Epoch: 8, Batch: 541, Loss: 2529.00830078125\n",
      "Epoch: 8, Batch: 542, Loss: 3041.965576171875\n",
      "Epoch: 8, Batch: 543, Loss: 2486.962890625\n",
      "Epoch: 8, Batch: 544, Loss: 3010.12744140625\n",
      "Epoch: 8, Batch: 545, Loss: 2358.039794921875\n",
      "Epoch: 8, Batch: 546, Loss: 2662.2275390625\n",
      "Epoch: 8, Batch: 547, Loss: 2357.148193359375\n",
      "Epoch: 8, Batch: 548, Loss: 2652.510009765625\n",
      "Epoch: 8, Batch: 549, Loss: 2830.1083984375\n",
      "Epoch: 8, Batch: 550, Loss: 2344.970947265625\n",
      "Epoch: 8, Batch: 551, Loss: 2526.703857421875\n",
      "Epoch: 8, Batch: 552, Loss: 3313.728271484375\n",
      "Epoch: 8, Batch: 553, Loss: 2202.11181640625\n",
      "Epoch: 8, Batch: 554, Loss: 3076.068359375\n",
      "Epoch: 8, Batch: 555, Loss: 3137.335693359375\n",
      "Epoch: 8, Batch: 556, Loss: 2820.373779296875\n",
      "Epoch: 8, Batch: 557, Loss: 2712.056396484375\n",
      "Epoch: 8, Batch: 558, Loss: 2647.152099609375\n",
      "Epoch: 8, Batch: 559, Loss: 2621.2021484375\n",
      "Epoch: 8, Batch: 560, Loss: 2233.55712890625\n",
      "Epoch: 8, Batch: 561, Loss: 2806.7314453125\n",
      "Epoch: 8, Batch: 562, Loss: 2556.14990234375\n",
      "Epoch: 8, Batch: 563, Loss: 2484.74072265625\n",
      "Epoch: 8, Batch: 564, Loss: 2468.62353515625\n",
      "Epoch: 8, Batch: 565, Loss: 3003.218994140625\n",
      "Epoch: 8, Batch: 566, Loss: 2379.76416015625\n",
      "Epoch: 8, Batch: 567, Loss: 2482.5830078125\n",
      "Epoch: 8, Batch: 568, Loss: 2444.726318359375\n",
      "Epoch: 8, Batch: 569, Loss: 2952.52001953125\n",
      "Epoch: 8, Batch: 570, Loss: 2480.238037109375\n",
      "Epoch: 8, Batch: 571, Loss: 2526.614990234375\n",
      "Epoch: 8, Batch: 572, Loss: 3022.4306640625\n",
      "Epoch: 8, Batch: 573, Loss: 2735.31298828125\n",
      "Epoch: 8, Batch: 574, Loss: 3110.5654296875\n",
      "Epoch: 8, Batch: 575, Loss: 3205.145263671875\n",
      "Epoch: 8, Batch: 576, Loss: 2661.630615234375\n",
      "Epoch: 8, Batch: 577, Loss: 3284.384033203125\n",
      "Epoch: 8, Batch: 578, Loss: 2030.1009521484375\n",
      "Epoch: 8, Batch: 579, Loss: 2797.890625\n",
      "Epoch: 8, Batch: 580, Loss: 3158.1142578125\n",
      "Epoch: 8, Batch: 581, Loss: 2805.95947265625\n",
      "Epoch: 8, Batch: 582, Loss: 2695.683349609375\n",
      "Epoch: 8, Batch: 583, Loss: 2900.2431640625\n",
      "Epoch: 8, Batch: 584, Loss: 2573.62744140625\n",
      "Epoch: 8, Batch: 585, Loss: 2815.94287109375\n",
      "Epoch: 8, Batch: 586, Loss: 2698.7333984375\n",
      "Epoch: 8, Batch: 587, Loss: 2408.361328125\n",
      "Epoch: 8, Batch: 588, Loss: 2541.5693359375\n",
      "Epoch: 8, Batch: 589, Loss: 2772.559814453125\n",
      "Epoch: 8, Batch: 590, Loss: 2593.08251953125\n",
      "Epoch: 8, Batch: 591, Loss: 2655.302001953125\n",
      "Epoch: 8, Batch: 592, Loss: 2636.334716796875\n",
      "Epoch: 8, Batch: 593, Loss: 2316.53759765625\n",
      "Epoch: 8, Batch: 594, Loss: 2184.733154296875\n",
      "Epoch: 8, Batch: 595, Loss: 2178.052978515625\n",
      "Epoch: 8, Batch: 596, Loss: 2670.390869140625\n",
      "Epoch: 8, Batch: 597, Loss: 2562.776123046875\n",
      "Epoch: 8, Batch: 598, Loss: 2047.084716796875\n",
      "Epoch: 8, Batch: 599, Loss: 3004.80419921875\n",
      "Epoch: 8, Batch: 600, Loss: 2873.039794921875\n",
      "Epoch: 8, Batch: 601, Loss: 2550.83740234375\n",
      "Epoch: 8, Batch: 602, Loss: 2565.602294921875\n",
      "Epoch: 8, Batch: 603, Loss: 2841.46142578125\n",
      "Epoch: 8, Batch: 604, Loss: 2342.072998046875\n",
      "Epoch: 8, Batch: 605, Loss: 3145.154052734375\n",
      "Epoch: 8, Batch: 606, Loss: 2494.370849609375\n",
      "Epoch: 8, Batch: 607, Loss: 2877.96142578125\n",
      "Epoch: 8, Batch: 608, Loss: 2460.744140625\n",
      "Epoch: 8, Batch: 609, Loss: 2610.9111328125\n",
      "Epoch: 8, Batch: 610, Loss: 2321.015625\n",
      "Epoch: 8, Batch: 611, Loss: 3080.099609375\n",
      "Epoch: 8, Batch: 612, Loss: 2678.36865234375\n",
      "Epoch: 8, Batch: 613, Loss: 2261.91845703125\n",
      "Epoch: 8, Batch: 614, Loss: 2284.871826171875\n",
      "Epoch: 8, Batch: 615, Loss: 2438.2412109375\n",
      "Epoch: 8, Batch: 616, Loss: 2862.61865234375\n",
      "Epoch: 8, Batch: 617, Loss: 2759.551025390625\n",
      "Epoch: 8, Batch: 618, Loss: 2394.895263671875\n",
      "Epoch: 8, Batch: 619, Loss: 2501.234619140625\n",
      "Epoch: 8, Batch: 620, Loss: 2404.510498046875\n",
      "Epoch: 8, Batch: 621, Loss: 2458.4375\n",
      "Epoch: 8, Batch: 622, Loss: 2592.115478515625\n",
      "Epoch: 8, Batch: 623, Loss: 3079.894775390625\n",
      "Epoch: 8, Batch: 624, Loss: 2776.896728515625\n",
      "Epoch: 8, Batch: 625, Loss: 2614.006103515625\n",
      "Epoch: 8, Batch: 626, Loss: 2523.50830078125\n",
      "Epoch: 8, Batch: 627, Loss: 3221.440185546875\n",
      "Epoch: 8, Batch: 628, Loss: 2935.994140625\n",
      "Epoch: 8, Batch: 629, Loss: 2866.54541015625\n",
      "Epoch: 8, Batch: 630, Loss: 2820.1015625\n",
      "Epoch: 8, Batch: 631, Loss: 2053.80224609375\n",
      "Epoch: 8, Batch: 632, Loss: 2833.53564453125\n",
      "Epoch: 8, Batch: 633, Loss: 2651.529296875\n",
      "Epoch: 8, Batch: 634, Loss: 3134.175537109375\n",
      "Epoch: 8, Batch: 635, Loss: 2438.731201171875\n",
      "Epoch: 8, Batch: 636, Loss: 2937.95361328125\n",
      "Epoch: 8, Batch: 637, Loss: 2906.36962890625\n",
      "Epoch: 8, Batch: 638, Loss: 2499.6796875\n",
      "Epoch: 8, Batch: 639, Loss: 2574.5546875\n",
      "Epoch: 8, Batch: 640, Loss: 2559.12646484375\n",
      "Epoch: 8, Batch: 641, Loss: 2630.0205078125\n",
      "Epoch: 8, Batch: 642, Loss: 2663.79248046875\n",
      "Epoch: 8, Batch: 643, Loss: 2950.632080078125\n",
      "Epoch: 8, Batch: 644, Loss: 3021.35791015625\n",
      "Epoch: 8, Batch: 645, Loss: 3157.110107421875\n",
      "Epoch: 8, Batch: 646, Loss: 2157.932861328125\n",
      "Epoch: 8, Batch: 647, Loss: 2340.51318359375\n",
      "Epoch: 8, Batch: 648, Loss: 3062.54833984375\n",
      "Epoch: 8, Batch: 649, Loss: 2703.1005859375\n",
      "Epoch: 8, Batch: 650, Loss: 2640.27490234375\n",
      "Epoch: 8, Batch: 651, Loss: 2846.953125\n",
      "Epoch: 8, Batch: 652, Loss: 2846.243896484375\n",
      "Epoch: 8, Batch: 653, Loss: 2554.006591796875\n",
      "Epoch: 8, Batch: 654, Loss: 2735.92431640625\n",
      "Epoch: 8, Batch: 655, Loss: 2821.23779296875\n",
      "Epoch: 8, Batch: 656, Loss: 2566.572998046875\n",
      "Epoch: 8, Batch: 657, Loss: 3466.0703125\n",
      "Epoch: 8, Batch: 658, Loss: 3070.51416015625\n",
      "Epoch: 8, Batch: 659, Loss: 2591.292236328125\n",
      "Epoch: 8, Batch: 660, Loss: 2872.50341796875\n",
      "Epoch: 8, Batch: 661, Loss: 2639.3974609375\n",
      "Epoch: 8, Batch: 662, Loss: 2079.589111328125\n",
      "Epoch: 8, Batch: 663, Loss: 2721.603515625\n",
      "Epoch: 8, Batch: 664, Loss: 2579.877197265625\n",
      "Epoch: 8, Batch: 665, Loss: 2824.583740234375\n",
      "Epoch: 8, Batch: 666, Loss: 2645.579345703125\n",
      "Epoch: 8, Batch: 667, Loss: 2396.975341796875\n",
      "Epoch: 8, Batch: 668, Loss: 2145.063720703125\n",
      "Epoch: 8, Batch: 669, Loss: 2317.68505859375\n",
      "Epoch: 8, Batch: 670, Loss: 2590.08251953125\n",
      "Epoch: 8, Batch: 671, Loss: 2816.514892578125\n",
      "Epoch: 8, Batch: 672, Loss: 2464.290283203125\n",
      "Epoch: 8, Batch: 673, Loss: 3001.332275390625\n",
      "Epoch: 8, Batch: 674, Loss: 3002.7763671875\n",
      "Epoch: 8, Batch: 675, Loss: 2955.28857421875\n",
      "Epoch: 8, Batch: 676, Loss: 3045.2451171875\n",
      "Epoch: 8, Batch: 677, Loss: 2706.25830078125\n",
      "Epoch: 8, Batch: 678, Loss: 2792.52978515625\n",
      "Epoch: 8, Batch: 679, Loss: 2473.9853515625\n",
      "Epoch: 8, Batch: 680, Loss: 2861.042724609375\n",
      "Epoch: 8, Batch: 681, Loss: 3181.374755859375\n",
      "Epoch: 8, Batch: 682, Loss: 2592.197509765625\n",
      "Epoch: 8, Batch: 683, Loss: 2321.8408203125\n",
      "Epoch: 8, Batch: 684, Loss: 2609.77294921875\n",
      "Epoch: 8, Batch: 685, Loss: 2671.5595703125\n",
      "Epoch: 8, Batch: 686, Loss: 2258.814208984375\n",
      "Epoch: 8, Batch: 687, Loss: 2601.289306640625\n",
      "Epoch: 8, Batch: 688, Loss: 2872.5244140625\n",
      "Epoch: 8, Batch: 689, Loss: 2975.9931640625\n",
      "Epoch: 8, Batch: 690, Loss: 2756.95361328125\n",
      "Epoch: 8, Batch: 691, Loss: 2708.4716796875\n",
      "Epoch: 8, Batch: 692, Loss: 2766.16845703125\n",
      "Epoch: 8, Batch: 693, Loss: 2858.66845703125\n",
      "Epoch: 8, Batch: 694, Loss: 2713.819091796875\n",
      "Epoch: 8, Batch: 695, Loss: 2280.00634765625\n",
      "Epoch: 8, Batch: 696, Loss: 3062.185302734375\n",
      "Epoch: 8, Batch: 697, Loss: 2432.3701171875\n",
      "Epoch: 8, Batch: 698, Loss: 2804.8720703125\n",
      "Epoch: 8, Batch: 699, Loss: 2177.249267578125\n",
      "Epoch: 8, Batch: 700, Loss: 2462.961181640625\n",
      "Epoch: 8, Batch: 701, Loss: 2213.09033203125\n",
      "Epoch: 8, Batch: 702, Loss: 3188.978759765625\n",
      "Epoch: 8, Batch: 703, Loss: 2035.47216796875\n",
      "Epoch: 8, Batch: 704, Loss: 2542.79931640625\n",
      "Epoch: 8, Batch: 705, Loss: 1644.504150390625\n",
      "Epoch: 8, Batch: 706, Loss: 2305.672119140625\n",
      "Epoch: 8, Batch: 707, Loss: 2497.102294921875\n",
      "Epoch: 8, Batch: 708, Loss: 2715.6328125\n",
      "Epoch: 8, Batch: 709, Loss: 2671.771240234375\n",
      "Epoch: 8, Batch: 710, Loss: 2685.94091796875\n",
      "Epoch: 8, Batch: 711, Loss: 2827.554443359375\n",
      "Epoch: 8, Batch: 712, Loss: 2661.486572265625\n",
      "Epoch: 8, Batch: 713, Loss: 3077.2734375\n",
      "Epoch: 8, Batch: 714, Loss: 2734.17041015625\n",
      "Epoch: 8, Batch: 715, Loss: 2857.420166015625\n",
      "Epoch: 8, Batch: 716, Loss: 2910.3271484375\n",
      "Epoch: 8, Batch: 717, Loss: 2826.902587890625\n",
      "Epoch: 8, Batch: 718, Loss: 2685.931884765625\n",
      "Epoch: 8, Batch: 719, Loss: 2634.260009765625\n",
      "Epoch: 8, Batch: 720, Loss: 2566.48095703125\n",
      "Epoch: 8, Batch: 721, Loss: 2686.328125\n",
      "Epoch: 8, Batch: 722, Loss: 2860.5\n",
      "Epoch: 8, Batch: 723, Loss: 2543.337158203125\n",
      "Epoch: 8, Batch: 724, Loss: 2390.164794921875\n",
      "Epoch: 8, Batch: 725, Loss: 2789.552978515625\n",
      "Epoch: 8, Batch: 726, Loss: 2609.552978515625\n",
      "Epoch: 8, Batch: 727, Loss: 2730.887939453125\n",
      "Epoch: 8, Batch: 728, Loss: 2541.615478515625\n",
      "Epoch: 8, Batch: 729, Loss: 2560.953369140625\n",
      "Epoch: 8, Batch: 730, Loss: 2672.057861328125\n",
      "Epoch: 8, Batch: 731, Loss: 2628.70751953125\n",
      "Epoch: 8, Batch: 732, Loss: 2332.74462890625\n",
      "Epoch: 8, Batch: 733, Loss: 3387.01708984375\n",
      "Epoch: 8, Batch: 734, Loss: 3163.168212890625\n",
      "Epoch: 8, Batch: 735, Loss: 2880.189453125\n",
      "Epoch: 8, Batch: 736, Loss: 2870.58251953125\n",
      "Epoch: 8, Batch: 737, Loss: 2519.0390625\n",
      "Epoch: 8, Batch: 738, Loss: 2627.302734375\n",
      "Epoch: 8, Batch: 739, Loss: 3004.188232421875\n",
      "Epoch: 8, Batch: 740, Loss: 2623.859619140625\n",
      "Epoch: 8, Batch: 741, Loss: 2733.34375\n",
      "Epoch: 8, Batch: 742, Loss: 2753.49853515625\n",
      "Epoch: 8, Batch: 743, Loss: 2974.94970703125\n",
      "Epoch: 8, Batch: 744, Loss: 2444.22265625\n",
      "Epoch: 8, Batch: 745, Loss: 2346.339599609375\n",
      "Epoch: 8, Batch: 746, Loss: 2393.081787109375\n",
      "Epoch: 8, Batch: 747, Loss: 2406.655029296875\n",
      "Epoch: 8, Batch: 748, Loss: 2964.7705078125\n",
      "Epoch: 8, Batch: 749, Loss: 2406.30322265625\n",
      "Epoch: 8, Batch: 750, Loss: 3011.023681640625\n",
      "Epoch: 8, Batch: 751, Loss: 2344.26025390625\n",
      "Epoch: 8, Batch: 752, Loss: 2345.370361328125\n",
      "Epoch: 8, Batch: 753, Loss: 2199.734130859375\n",
      "Epoch: 8, Batch: 754, Loss: 2578.838134765625\n",
      "Epoch: 8, Batch: 755, Loss: 2908.3427734375\n",
      "Epoch: 8, Batch: 756, Loss: 2418.0859375\n",
      "Epoch: 8, Batch: 757, Loss: 2440.10693359375\n",
      "Epoch: 8, Batch: 758, Loss: 2295.51611328125\n",
      "Epoch: 8, Batch: 759, Loss: 2843.76220703125\n",
      "Epoch: 8, Batch: 760, Loss: 2780.2529296875\n",
      "Epoch: 8, Batch: 761, Loss: 2272.7529296875\n",
      "Epoch: 8, Batch: 762, Loss: 2486.331298828125\n",
      "Epoch: 8, Batch: 763, Loss: 2636.14794921875\n",
      "Epoch: 8, Batch: 764, Loss: 2666.243408203125\n",
      "Epoch: 8, Batch: 765, Loss: 2932.4130859375\n",
      "Epoch: 8, Batch: 766, Loss: 2732.80224609375\n",
      "Epoch: 8, Batch: 767, Loss: 2662.649169921875\n",
      "Epoch: 8, Batch: 768, Loss: 2388.556884765625\n",
      "Epoch: 8, Batch: 769, Loss: 2421.010009765625\n",
      "Epoch: 8, Batch: 770, Loss: 2615.0634765625\n",
      "Epoch: 8, Batch: 771, Loss: 2710.906494140625\n",
      "Epoch: 8, Batch: 772, Loss: 3480.86376953125\n",
      "Epoch: 8, Batch: 773, Loss: 2595.892822265625\n",
      "Epoch: 8, Batch: 774, Loss: 2882.76123046875\n",
      "Epoch: 8, Batch: 775, Loss: 2679.916015625\n",
      "Epoch: 8, Batch: 776, Loss: 2700.0185546875\n",
      "Epoch: 8, Batch: 777, Loss: 2518.33544921875\n",
      "Epoch: 8, Batch: 778, Loss: 2689.733154296875\n",
      "Epoch: 8, Batch: 779, Loss: 2888.22021484375\n",
      "Epoch: 8, Batch: 780, Loss: 1947.1551513671875\n",
      "Epoch: 8, Batch: 781, Loss: 3075.377197265625\n",
      "Epoch: 8, Batch: 782, Loss: 2178.165771484375\n",
      "Epoch: 8, Batch: 783, Loss: 3104.264404296875\n",
      "Epoch: 8, Batch: 784, Loss: 2790.54443359375\n",
      "Epoch: 8, Batch: 785, Loss: 2324.361572265625\n",
      "Epoch: 8, Batch: 786, Loss: 2478.05419921875\n",
      "Epoch: 8, Batch: 787, Loss: 2795.909912109375\n",
      "Epoch: 8, Batch: 788, Loss: 2815.571044921875\n",
      "Epoch: 8, Batch: 789, Loss: 2082.67724609375\n",
      "Epoch: 8, Batch: 790, Loss: 2534.961181640625\n",
      "Epoch: 8, Batch: 791, Loss: 2733.64892578125\n",
      "Epoch: 8, Batch: 792, Loss: 2839.493896484375\n",
      "Epoch: 8, Batch: 793, Loss: 2971.884033203125\n",
      "Epoch: 8, Batch: 794, Loss: 2380.012451171875\n",
      "Epoch: 8, Batch: 795, Loss: 2512.588134765625\n",
      "Epoch: 8, Batch: 796, Loss: 2559.001220703125\n",
      "Epoch: 8, Batch: 797, Loss: 2452.359130859375\n",
      "Epoch: 8, Batch: 798, Loss: 2320.964111328125\n",
      "Epoch: 8, Batch: 799, Loss: 2418.179931640625\n",
      "Epoch: 8, Batch: 800, Loss: 3054.09130859375\n",
      "Epoch: 8, Batch: 801, Loss: 2441.701171875\n",
      "Epoch: 8, Batch: 802, Loss: 3073.905517578125\n",
      "Epoch: 8, Batch: 803, Loss: 2938.197998046875\n",
      "Epoch: 8, Batch: 804, Loss: 2930.2158203125\n",
      "Epoch: 8, Batch: 805, Loss: 2964.89111328125\n",
      "Epoch: 8, Batch: 806, Loss: 3020.6630859375\n",
      "Epoch: 8, Batch: 807, Loss: 3066.1533203125\n",
      "Epoch: 8, Batch: 808, Loss: 2252.541015625\n",
      "Epoch: 8, Batch: 809, Loss: 3031.15673828125\n",
      "Epoch: 8, Batch: 810, Loss: 2939.875732421875\n",
      "Epoch: 8, Batch: 811, Loss: 2724.6689453125\n",
      "Epoch: 8, Batch: 812, Loss: 2560.8623046875\n",
      "Epoch: 8, Batch: 813, Loss: 2996.844482421875\n",
      "Epoch: 8, Batch: 814, Loss: 2283.167236328125\n",
      "Epoch: 8, Batch: 815, Loss: 2987.21142578125\n",
      "Epoch: 8, Batch: 816, Loss: 2380.55029296875\n",
      "Epoch: 8, Batch: 817, Loss: 2505.843994140625\n",
      "Epoch: 8, Batch: 818, Loss: 2285.62548828125\n",
      "Epoch: 8, Batch: 819, Loss: 3141.5703125\n",
      "Epoch: 8, Batch: 820, Loss: 2562.404296875\n",
      "Epoch: 8, Batch: 821, Loss: 2241.40478515625\n",
      "Epoch: 8, Batch: 822, Loss: 2824.70703125\n",
      "Epoch: 8, Batch: 823, Loss: 3004.007080078125\n",
      "Epoch: 8, Batch: 824, Loss: 2792.84619140625\n",
      "Epoch: 8, Batch: 825, Loss: 2735.470458984375\n",
      "Epoch: 8, Batch: 826, Loss: 2231.22021484375\n",
      "Epoch: 8, Batch: 827, Loss: 3271.73046875\n",
      "Epoch: 8, Batch: 828, Loss: 2735.849609375\n",
      "Epoch: 8, Batch: 829, Loss: 2909.959228515625\n",
      "Epoch: 8, Batch: 830, Loss: 2740.375\n",
      "Epoch: 8, Batch: 831, Loss: 2333.397705078125\n",
      "Epoch: 8, Batch: 832, Loss: 2630.93408203125\n",
      "Epoch: 8, Batch: 833, Loss: 2358.18896484375\n",
      "Epoch: 8, Batch: 834, Loss: 2117.576416015625\n",
      "Epoch: 8, Batch: 835, Loss: 2053.286376953125\n",
      "Epoch: 8, Batch: 836, Loss: 2820.759765625\n",
      "Epoch: 8, Batch: 837, Loss: 3099.162109375\n",
      "Epoch: 8, Batch: 838, Loss: 2770.514404296875\n",
      "Epoch: 8, Batch: 839, Loss: 2686.995849609375\n",
      "Epoch: 8, Batch: 840, Loss: 2507.155517578125\n",
      "Epoch: 8, Batch: 841, Loss: 2087.5234375\n",
      "Epoch: 8, Batch: 842, Loss: 2587.673583984375\n",
      "Epoch: 8, Batch: 843, Loss: 2395.1318359375\n",
      "Epoch: 8, Batch: 844, Loss: 3191.560302734375\n",
      "Epoch: 8, Batch: 845, Loss: 2430.672119140625\n",
      "Epoch: 8, Batch: 846, Loss: 2951.447998046875\n",
      "Epoch: 8, Batch: 847, Loss: 2674.37353515625\n",
      "Epoch: 8, Batch: 848, Loss: 3091.5615234375\n",
      "Epoch: 8, Batch: 849, Loss: 2845.1650390625\n",
      "Epoch: 8, Batch: 850, Loss: 2440.93408203125\n",
      "Epoch: 8, Batch: 851, Loss: 2489.374755859375\n",
      "Epoch: 8, Batch: 852, Loss: 2402.57177734375\n",
      "Epoch: 8, Batch: 853, Loss: 2977.15625\n",
      "Epoch: 8, Batch: 854, Loss: 2930.6494140625\n",
      "Epoch: 8, Batch: 855, Loss: 3050.485595703125\n",
      "Epoch: 8, Batch: 856, Loss: 2352.56494140625\n",
      "Epoch: 8, Batch: 857, Loss: 2840.44189453125\n",
      "Epoch: 8, Batch: 858, Loss: 3035.1728515625\n",
      "Epoch: 8, Batch: 859, Loss: 2716.37548828125\n",
      "Epoch: 8, Batch: 860, Loss: 2582.749267578125\n",
      "Epoch: 8, Batch: 861, Loss: 2200.269775390625\n",
      "Epoch: 8, Batch: 862, Loss: 2629.00146484375\n",
      "Epoch: 8, Batch: 863, Loss: 2553.264404296875\n",
      "Epoch: 8, Batch: 864, Loss: 2616.21337890625\n",
      "Epoch: 8, Batch: 865, Loss: 3048.6640625\n",
      "Epoch: 8, Batch: 866, Loss: 2296.08056640625\n",
      "Epoch: 8, Batch: 867, Loss: 2616.292724609375\n",
      "Epoch: 8, Batch: 868, Loss: 2993.66162109375\n",
      "Epoch: 8, Batch: 869, Loss: 2717.3359375\n",
      "Epoch: 8, Batch: 870, Loss: 2420.3193359375\n",
      "Epoch: 8, Batch: 871, Loss: 2960.146240234375\n",
      "Epoch: 8, Batch: 872, Loss: 3792.26318359375\n",
      "Epoch: 8, Batch: 873, Loss: 2676.18359375\n",
      "Epoch: 8, Batch: 874, Loss: 2854.693603515625\n",
      "Epoch: 8, Batch: 875, Loss: 2539.78857421875\n",
      "Epoch: 8, Batch: 876, Loss: 3046.58349609375\n",
      "Epoch: 8, Batch: 877, Loss: 2994.681396484375\n",
      "Epoch: 8, Batch: 878, Loss: 3106.343017578125\n",
      "Epoch: 8, Batch: 879, Loss: 2552.736572265625\n",
      "Epoch: 8, Batch: 880, Loss: 2355.790771484375\n",
      "Epoch: 8, Batch: 881, Loss: 2506.082763671875\n",
      "Epoch: 8, Batch: 882, Loss: 2656.50390625\n",
      "Epoch: 8, Batch: 883, Loss: 2942.890380859375\n",
      "Epoch: 8, Batch: 884, Loss: 2781.506591796875\n",
      "Epoch: 8, Batch: 885, Loss: 2765.18359375\n",
      "Epoch: 8, Batch: 886, Loss: 2166.9638671875\n",
      "Epoch: 8, Batch: 887, Loss: 2553.298095703125\n",
      "Epoch: 8, Batch: 888, Loss: 2913.0361328125\n",
      "Epoch: 8, Batch: 889, Loss: 2738.93408203125\n",
      "Epoch: 8, Batch: 890, Loss: 2255.742919921875\n",
      "Epoch: 8, Batch: 891, Loss: 2629.662841796875\n",
      "Epoch: 8, Batch: 892, Loss: 2587.11376953125\n",
      "Epoch: 8, Batch: 893, Loss: 2095.4384765625\n",
      "Epoch: 8, Batch: 894, Loss: 2883.9970703125\n",
      "Epoch: 8, Batch: 895, Loss: 2555.716796875\n",
      "Epoch: 8, Batch: 896, Loss: 2082.643798828125\n",
      "Epoch: 8, Batch: 897, Loss: 2303.535400390625\n",
      "Epoch: 8, Batch: 898, Loss: 2426.1318359375\n",
      "Epoch: 8, Batch: 899, Loss: 2462.892333984375\n",
      "Epoch: 8, Batch: 900, Loss: 2633.2177734375\n",
      "Epoch: 8, Batch: 901, Loss: 2322.750244140625\n",
      "Epoch: 8, Batch: 902, Loss: 2833.8291015625\n",
      "Epoch: 8, Batch: 903, Loss: 3048.864990234375\n",
      "Epoch: 8, Batch: 904, Loss: 2430.9814453125\n",
      "Epoch: 8, Batch: 905, Loss: 2501.615478515625\n",
      "Epoch: 8, Batch: 906, Loss: 2222.19677734375\n",
      "Epoch: 8, Batch: 907, Loss: 3205.976806640625\n",
      "Epoch: 8, Batch: 908, Loss: 2776.421630859375\n",
      "Epoch: 8, Batch: 909, Loss: 2451.904052734375\n",
      "Epoch: 8, Batch: 910, Loss: 2163.10009765625\n",
      "Epoch: 8, Batch: 911, Loss: 2871.33056640625\n",
      "Epoch: 8, Batch: 912, Loss: 3146.18701171875\n",
      "Epoch: 8, Batch: 913, Loss: 2785.132568359375\n",
      "Epoch: 8, Batch: 914, Loss: 3123.71435546875\n",
      "Epoch: 8, Batch: 915, Loss: 2430.219970703125\n",
      "Epoch: 8, Batch: 916, Loss: 3155.63818359375\n",
      "Epoch: 8, Batch: 917, Loss: 1996.21728515625\n",
      "Epoch: 8, Batch: 918, Loss: 2693.92529296875\n",
      "Epoch: 8, Batch: 919, Loss: 2851.18896484375\n",
      "Epoch: 8, Batch: 920, Loss: 2649.86767578125\n",
      "Epoch: 8, Batch: 921, Loss: 2604.15625\n",
      "Epoch: 8, Batch: 922, Loss: 1937.04345703125\n",
      "Epoch: 8, Batch: 923, Loss: 2655.25537109375\n",
      "Epoch: 8, Batch: 924, Loss: 2550.311279296875\n",
      "Epoch: 8, Batch: 925, Loss: 2625.37353515625\n",
      "Epoch: 8, Batch: 926, Loss: 2862.75732421875\n",
      "Epoch: 8, Batch: 927, Loss: 2267.8095703125\n",
      "Epoch: 8, Batch: 928, Loss: 2604.19580078125\n",
      "Epoch: 8, Batch: 929, Loss: 2750.40478515625\n",
      "Epoch: 8, Batch: 930, Loss: 2634.98974609375\n",
      "Epoch: 8, Batch: 931, Loss: 2331.45849609375\n",
      "Epoch: 8, Batch: 932, Loss: 2535.314453125\n",
      "Epoch: 8, Batch: 933, Loss: 2623.958251953125\n",
      "Epoch: 8, Batch: 934, Loss: 2444.690185546875\n",
      "Epoch: 8, Batch: 935, Loss: 3141.68212890625\n",
      "Epoch: 8, Batch: 936, Loss: 2716.920654296875\n",
      "Epoch: 8, Batch: 937, Loss: 2540.02197265625\n",
      "Epoch: 8, Batch: 938, Loss: 2825.93896484375\n",
      "Epoch: 8, Batch: 939, Loss: 2079.552734375\n",
      "Epoch: 8, Batch: 940, Loss: 2114.46240234375\n",
      "Epoch: 8, Batch: 941, Loss: 2564.64306640625\n",
      "Epoch: 8, Batch: 942, Loss: 2247.438232421875\n",
      "Epoch: 8, Batch: 943, Loss: 2812.3955078125\n",
      "Epoch: 8, Batch: 944, Loss: 2332.7353515625\n",
      "Epoch: 8, Batch: 945, Loss: 2857.900634765625\n",
      "Epoch: 8, Batch: 946, Loss: 2213.9677734375\n",
      "Epoch: 8, Batch: 947, Loss: 2936.590576171875\n",
      "Epoch: 8, Batch: 948, Loss: 2985.9716796875\n",
      "Epoch: 8, Batch: 949, Loss: 2849.40673828125\n",
      "Epoch: 8, Batch: 950, Loss: 2695.675537109375\n",
      "Epoch: 8, Batch: 951, Loss: 2290.5244140625\n",
      "Epoch: 8, Batch: 952, Loss: 2712.494384765625\n",
      "Epoch: 8, Batch: 953, Loss: 2436.117431640625\n",
      "Epoch: 8, Batch: 954, Loss: 2519.182373046875\n",
      "Epoch: 8, Batch: 955, Loss: 2909.8818359375\n",
      "Epoch: 8, Batch: 956, Loss: 2654.112060546875\n",
      "Epoch: 8, Batch: 957, Loss: 2395.925537109375\n",
      "Epoch: 8, Batch: 958, Loss: 2800.060791015625\n",
      "Epoch: 8, Batch: 959, Loss: 2337.89892578125\n",
      "Epoch: 8, Batch: 960, Loss: 2541.533447265625\n",
      "Epoch: 8, Batch: 961, Loss: 2862.846923828125\n",
      "Epoch: 8, Batch: 962, Loss: 2251.283203125\n",
      "Epoch: 8, Batch: 963, Loss: 2275.96923828125\n",
      "Epoch: 8, Batch: 964, Loss: 2058.197998046875\n",
      "Epoch: 8, Batch: 965, Loss: 2651.14990234375\n",
      "Epoch: 8, Batch: 966, Loss: 2316.755126953125\n",
      "Epoch: 8, Batch: 967, Loss: 2465.280029296875\n",
      "Epoch: 8, Batch: 968, Loss: 2473.797119140625\n",
      "Epoch: 8, Batch: 969, Loss: 2645.298095703125\n",
      "Epoch: 8, Batch: 970, Loss: 3318.93017578125\n",
      "Epoch: 8, Batch: 971, Loss: 2554.496337890625\n",
      "Epoch: 8, Batch: 972, Loss: 2173.142333984375\n",
      "Epoch: 8, Batch: 973, Loss: 2765.970947265625\n",
      "Epoch: 8, Batch: 974, Loss: 2616.26220703125\n",
      "Epoch: 8, Batch: 975, Loss: 3000.95654296875\n",
      "Epoch: 8, Batch: 976, Loss: 1956.09423828125\n",
      "Epoch: 8, Batch: 977, Loss: 3080.207275390625\n",
      "Epoch: 8, Batch: 978, Loss: 2918.706298828125\n",
      "Epoch: 8, Batch: 979, Loss: 3135.5390625\n",
      "Epoch: 8, Batch: 980, Loss: 2700.805419921875\n",
      "Epoch: 8, Batch: 981, Loss: 2618.76708984375\n",
      "Epoch: 8, Batch: 982, Loss: 3356.610595703125\n",
      "Epoch: 8, Batch: 983, Loss: 2607.689697265625\n",
      "Epoch: 8, Batch: 984, Loss: 2611.3046875\n",
      "Epoch: 8, Batch: 985, Loss: 2634.34765625\n",
      "Epoch: 8, Batch: 986, Loss: 2406.0703125\n",
      "Epoch: 8, Batch: 987, Loss: 2142.119140625\n",
      "Epoch: 8, Batch: 988, Loss: 2646.177490234375\n",
      "Epoch: 8, Batch: 989, Loss: 2643.5205078125\n",
      "Epoch: 8, Batch: 990, Loss: 2501.730712890625\n",
      "Epoch: 8, Batch: 991, Loss: 2852.640380859375\n",
      "Epoch: 8, Batch: 992, Loss: 2323.76513671875\n",
      "Epoch: 8, Batch: 993, Loss: 2659.96630859375\n",
      "Epoch: 8, Batch: 994, Loss: 2211.675048828125\n",
      "Epoch: 8, Batch: 995, Loss: 2177.16552734375\n",
      "Epoch: 8, Batch: 996, Loss: 2462.370361328125\n",
      "Epoch: 8, Batch: 997, Loss: 1501.802490234375\n",
      "Epoch: 8, Batch: 998, Loss: 2861.83056640625\n",
      "Epoch: 8, Batch: 999, Loss: 2385.682861328125\n",
      "Epoch: 9, Batch: 0, Loss: 2985.98583984375\n",
      "Epoch: 9, Batch: 1, Loss: 3153.0185546875\n",
      "Epoch: 9, Batch: 2, Loss: 2635.7021484375\n",
      "Epoch: 9, Batch: 3, Loss: 3138.022705078125\n",
      "Epoch: 9, Batch: 4, Loss: 2677.77099609375\n",
      "Epoch: 9, Batch: 5, Loss: 2726.751953125\n",
      "Epoch: 9, Batch: 6, Loss: 2633.2138671875\n",
      "Epoch: 9, Batch: 7, Loss: 2215.740966796875\n",
      "Epoch: 9, Batch: 8, Loss: 2722.53369140625\n",
      "Epoch: 9, Batch: 9, Loss: 2501.446533203125\n",
      "Epoch: 9, Batch: 10, Loss: 2353.607666015625\n",
      "Epoch: 9, Batch: 11, Loss: 2788.94384765625\n",
      "Epoch: 9, Batch: 12, Loss: 2299.307861328125\n",
      "Epoch: 9, Batch: 13, Loss: 2060.51025390625\n",
      "Epoch: 9, Batch: 14, Loss: 2600.10595703125\n",
      "Epoch: 9, Batch: 15, Loss: 2263.06689453125\n",
      "Epoch: 9, Batch: 16, Loss: 2533.971435546875\n",
      "Epoch: 9, Batch: 17, Loss: 3104.484375\n",
      "Epoch: 9, Batch: 18, Loss: 2148.990234375\n",
      "Epoch: 9, Batch: 19, Loss: 2849.841796875\n",
      "Epoch: 9, Batch: 20, Loss: 2540.383544921875\n",
      "Epoch: 9, Batch: 21, Loss: 3262.6015625\n",
      "Epoch: 9, Batch: 22, Loss: 2153.51953125\n",
      "Epoch: 9, Batch: 23, Loss: 2343.58447265625\n",
      "Epoch: 9, Batch: 24, Loss: 3089.1025390625\n",
      "Epoch: 9, Batch: 25, Loss: 2788.96044921875\n",
      "Epoch: 9, Batch: 26, Loss: 2545.463623046875\n",
      "Epoch: 9, Batch: 27, Loss: 2402.03076171875\n",
      "Epoch: 9, Batch: 28, Loss: 2817.551513671875\n",
      "Epoch: 9, Batch: 29, Loss: 2751.3037109375\n",
      "Epoch: 9, Batch: 30, Loss: 2656.836181640625\n",
      "Epoch: 9, Batch: 31, Loss: 1774.7095947265625\n",
      "Epoch: 9, Batch: 32, Loss: 2609.88037109375\n",
      "Epoch: 9, Batch: 33, Loss: 3227.611083984375\n",
      "Epoch: 9, Batch: 34, Loss: 2695.786865234375\n",
      "Epoch: 9, Batch: 35, Loss: 2413.733154296875\n",
      "Epoch: 9, Batch: 36, Loss: 2651.77783203125\n",
      "Epoch: 9, Batch: 37, Loss: 2242.424560546875\n",
      "Epoch: 9, Batch: 38, Loss: 2864.486328125\n",
      "Epoch: 9, Batch: 39, Loss: 2517.673095703125\n",
      "Epoch: 9, Batch: 40, Loss: 2520.90478515625\n",
      "Epoch: 9, Batch: 41, Loss: 2661.1826171875\n",
      "Epoch: 9, Batch: 42, Loss: 2855.5205078125\n",
      "Epoch: 9, Batch: 43, Loss: 3210.128173828125\n",
      "Epoch: 9, Batch: 44, Loss: 2173.12353515625\n",
      "Epoch: 9, Batch: 45, Loss: 2362.407470703125\n",
      "Epoch: 9, Batch: 46, Loss: 2492.531494140625\n",
      "Epoch: 9, Batch: 47, Loss: 2948.123291015625\n",
      "Epoch: 9, Batch: 48, Loss: 2655.017333984375\n",
      "Epoch: 9, Batch: 49, Loss: 2879.685546875\n",
      "Epoch: 9, Batch: 50, Loss: 2860.089599609375\n",
      "Epoch: 9, Batch: 51, Loss: 2735.600830078125\n",
      "Epoch: 9, Batch: 52, Loss: 2375.834228515625\n",
      "Epoch: 9, Batch: 53, Loss: 2864.471435546875\n",
      "Epoch: 9, Batch: 54, Loss: 3027.56982421875\n",
      "Epoch: 9, Batch: 55, Loss: 3184.584716796875\n",
      "Epoch: 9, Batch: 56, Loss: 2657.995849609375\n",
      "Epoch: 9, Batch: 57, Loss: 2750.069580078125\n",
      "Epoch: 9, Batch: 58, Loss: 2218.611083984375\n",
      "Epoch: 9, Batch: 59, Loss: 2625.458984375\n",
      "Epoch: 9, Batch: 60, Loss: 2891.47314453125\n",
      "Epoch: 9, Batch: 61, Loss: 2364.871337890625\n",
      "Epoch: 9, Batch: 62, Loss: 2982.513427734375\n",
      "Epoch: 9, Batch: 63, Loss: 2435.918212890625\n",
      "Epoch: 9, Batch: 64, Loss: 3040.685302734375\n",
      "Epoch: 9, Batch: 65, Loss: 3179.88671875\n",
      "Epoch: 9, Batch: 66, Loss: 2225.115234375\n",
      "Epoch: 9, Batch: 67, Loss: 2682.634765625\n",
      "Epoch: 9, Batch: 68, Loss: 2494.09375\n",
      "Epoch: 9, Batch: 69, Loss: 2681.86181640625\n",
      "Epoch: 9, Batch: 70, Loss: 2968.037353515625\n",
      "Epoch: 9, Batch: 71, Loss: 2499.95556640625\n",
      "Epoch: 9, Batch: 72, Loss: 2739.669921875\n",
      "Epoch: 9, Batch: 73, Loss: 3103.86962890625\n",
      "Epoch: 9, Batch: 74, Loss: 2508.58251953125\n",
      "Epoch: 9, Batch: 75, Loss: 2774.369140625\n",
      "Epoch: 9, Batch: 76, Loss: 2532.33984375\n",
      "Epoch: 9, Batch: 77, Loss: 2832.199951171875\n",
      "Epoch: 9, Batch: 78, Loss: 2474.895263671875\n",
      "Epoch: 9, Batch: 79, Loss: 2542.835693359375\n",
      "Epoch: 9, Batch: 80, Loss: 2685.96435546875\n",
      "Epoch: 9, Batch: 81, Loss: 2460.9599609375\n",
      "Epoch: 9, Batch: 82, Loss: 2642.1728515625\n",
      "Epoch: 9, Batch: 83, Loss: 2753.26416015625\n",
      "Epoch: 9, Batch: 84, Loss: 2386.75390625\n",
      "Epoch: 9, Batch: 85, Loss: 2504.2763671875\n",
      "Epoch: 9, Batch: 86, Loss: 2722.662109375\n",
      "Epoch: 9, Batch: 87, Loss: 2542.07470703125\n",
      "Epoch: 9, Batch: 88, Loss: 3051.17578125\n",
      "Epoch: 9, Batch: 89, Loss: 2557.545166015625\n",
      "Epoch: 9, Batch: 90, Loss: 2689.76123046875\n",
      "Epoch: 9, Batch: 91, Loss: 2884.066162109375\n",
      "Epoch: 9, Batch: 92, Loss: 2293.11181640625\n",
      "Epoch: 9, Batch: 93, Loss: 2064.7802734375\n",
      "Epoch: 9, Batch: 94, Loss: 3127.042236328125\n",
      "Epoch: 9, Batch: 95, Loss: 2891.7333984375\n",
      "Epoch: 9, Batch: 96, Loss: 3040.64794921875\n",
      "Epoch: 9, Batch: 97, Loss: 2468.122802734375\n",
      "Epoch: 9, Batch: 98, Loss: 2600.2578125\n",
      "Epoch: 9, Batch: 99, Loss: 2518.13916015625\n",
      "Epoch: 9, Batch: 100, Loss: 2719.42333984375\n",
      "Epoch: 9, Batch: 101, Loss: 2683.785888671875\n",
      "Epoch: 9, Batch: 102, Loss: 2988.7333984375\n",
      "Epoch: 9, Batch: 103, Loss: 2344.6044921875\n",
      "Epoch: 9, Batch: 104, Loss: 2169.4501953125\n",
      "Epoch: 9, Batch: 105, Loss: 1938.30859375\n",
      "Epoch: 9, Batch: 106, Loss: 2396.671875\n",
      "Epoch: 9, Batch: 107, Loss: 2440.706787109375\n",
      "Epoch: 9, Batch: 108, Loss: 2525.737548828125\n",
      "Epoch: 9, Batch: 109, Loss: 2559.0712890625\n",
      "Epoch: 9, Batch: 110, Loss: 1856.087646484375\n",
      "Epoch: 9, Batch: 111, Loss: 2779.1796875\n",
      "Epoch: 9, Batch: 112, Loss: 2664.72802734375\n",
      "Epoch: 9, Batch: 113, Loss: 2758.74609375\n",
      "Epoch: 9, Batch: 114, Loss: 2336.62109375\n",
      "Epoch: 9, Batch: 115, Loss: 2564.4296875\n",
      "Epoch: 9, Batch: 116, Loss: 2577.01806640625\n",
      "Epoch: 9, Batch: 117, Loss: 3020.9873046875\n",
      "Epoch: 9, Batch: 118, Loss: 2776.89501953125\n",
      "Epoch: 9, Batch: 119, Loss: 2371.199462890625\n",
      "Epoch: 9, Batch: 120, Loss: 3414.95654296875\n",
      "Epoch: 9, Batch: 121, Loss: 2431.05859375\n",
      "Epoch: 9, Batch: 122, Loss: 3065.35986328125\n",
      "Epoch: 9, Batch: 123, Loss: 2235.482421875\n",
      "Epoch: 9, Batch: 124, Loss: 3249.8193359375\n",
      "Epoch: 9, Batch: 125, Loss: 3218.28564453125\n",
      "Epoch: 9, Batch: 126, Loss: 3219.096923828125\n",
      "Epoch: 9, Batch: 127, Loss: 2265.056640625\n",
      "Epoch: 9, Batch: 128, Loss: 2435.89453125\n",
      "Epoch: 9, Batch: 129, Loss: 2564.289794921875\n",
      "Epoch: 9, Batch: 130, Loss: 2375.66455078125\n",
      "Epoch: 9, Batch: 131, Loss: 2184.602294921875\n",
      "Epoch: 9, Batch: 132, Loss: 2839.47119140625\n",
      "Epoch: 9, Batch: 133, Loss: 2483.548583984375\n",
      "Epoch: 9, Batch: 134, Loss: 2173.58544921875\n",
      "Epoch: 9, Batch: 135, Loss: 2737.174072265625\n",
      "Epoch: 9, Batch: 136, Loss: 2481.82470703125\n",
      "Epoch: 9, Batch: 137, Loss: 2931.45849609375\n",
      "Epoch: 9, Batch: 138, Loss: 2229.140625\n",
      "Epoch: 9, Batch: 139, Loss: 2744.350830078125\n",
      "Epoch: 9, Batch: 140, Loss: 2292.630126953125\n",
      "Epoch: 9, Batch: 141, Loss: 2690.3134765625\n",
      "Epoch: 9, Batch: 142, Loss: 2148.893310546875\n",
      "Epoch: 9, Batch: 143, Loss: 3095.236328125\n",
      "Epoch: 9, Batch: 144, Loss: 1772.25\n",
      "Epoch: 9, Batch: 145, Loss: 2392.10546875\n",
      "Epoch: 9, Batch: 146, Loss: 2492.946044921875\n",
      "Epoch: 9, Batch: 147, Loss: 2938.040771484375\n",
      "Epoch: 9, Batch: 148, Loss: 3186.14599609375\n",
      "Epoch: 9, Batch: 149, Loss: 2263.382568359375\n",
      "Epoch: 9, Batch: 150, Loss: 2498.392333984375\n",
      "Epoch: 9, Batch: 151, Loss: 2850.05419921875\n",
      "Epoch: 9, Batch: 152, Loss: 2825.734619140625\n",
      "Epoch: 9, Batch: 153, Loss: 2042.78173828125\n",
      "Epoch: 9, Batch: 154, Loss: 2095.80712890625\n",
      "Epoch: 9, Batch: 155, Loss: 2538.99609375\n",
      "Epoch: 9, Batch: 156, Loss: 2082.86328125\n",
      "Epoch: 9, Batch: 157, Loss: 2735.254638671875\n",
      "Epoch: 9, Batch: 158, Loss: 2571.287109375\n",
      "Epoch: 9, Batch: 159, Loss: 2971.46875\n",
      "Epoch: 9, Batch: 160, Loss: 2695.3154296875\n",
      "Epoch: 9, Batch: 161, Loss: 2721.87353515625\n",
      "Epoch: 9, Batch: 162, Loss: 2793.906005859375\n",
      "Epoch: 9, Batch: 163, Loss: 2719.95556640625\n",
      "Epoch: 9, Batch: 164, Loss: 2669.46728515625\n",
      "Epoch: 9, Batch: 165, Loss: 2763.079833984375\n",
      "Epoch: 9, Batch: 166, Loss: 2687.782958984375\n",
      "Epoch: 9, Batch: 167, Loss: 2775.1611328125\n",
      "Epoch: 9, Batch: 168, Loss: 2811.6767578125\n",
      "Epoch: 9, Batch: 169, Loss: 2339.4404296875\n",
      "Epoch: 9, Batch: 170, Loss: 2358.3369140625\n",
      "Epoch: 9, Batch: 171, Loss: 2378.17236328125\n",
      "Epoch: 9, Batch: 172, Loss: 2537.263427734375\n",
      "Epoch: 9, Batch: 173, Loss: 2556.000732421875\n",
      "Epoch: 9, Batch: 174, Loss: 2850.582763671875\n",
      "Epoch: 9, Batch: 175, Loss: 2748.635986328125\n",
      "Epoch: 9, Batch: 176, Loss: 2707.857666015625\n",
      "Epoch: 9, Batch: 177, Loss: 2424.264892578125\n",
      "Epoch: 9, Batch: 178, Loss: 2677.650146484375\n",
      "Epoch: 9, Batch: 179, Loss: 2880.552734375\n",
      "Epoch: 9, Batch: 180, Loss: 2645.673095703125\n",
      "Epoch: 9, Batch: 181, Loss: 3427.012939453125\n",
      "Epoch: 9, Batch: 182, Loss: 2464.703857421875\n",
      "Epoch: 9, Batch: 183, Loss: 2252.2099609375\n",
      "Epoch: 9, Batch: 184, Loss: 2297.56005859375\n",
      "Epoch: 9, Batch: 185, Loss: 2835.283935546875\n",
      "Epoch: 9, Batch: 186, Loss: 2282.881591796875\n",
      "Epoch: 9, Batch: 187, Loss: 2886.446533203125\n",
      "Epoch: 9, Batch: 188, Loss: 3276.34423828125\n",
      "Epoch: 9, Batch: 189, Loss: 2785.177490234375\n",
      "Epoch: 9, Batch: 190, Loss: 2283.177490234375\n",
      "Epoch: 9, Batch: 191, Loss: 2410.01171875\n",
      "Epoch: 9, Batch: 192, Loss: 2243.513916015625\n",
      "Epoch: 9, Batch: 193, Loss: 2851.740478515625\n",
      "Epoch: 9, Batch: 194, Loss: 2512.725341796875\n",
      "Epoch: 9, Batch: 195, Loss: 2280.943603515625\n",
      "Epoch: 9, Batch: 196, Loss: 2158.686767578125\n",
      "Epoch: 9, Batch: 197, Loss: 2390.02392578125\n",
      "Epoch: 9, Batch: 198, Loss: 2937.166259765625\n",
      "Epoch: 9, Batch: 199, Loss: 2564.066650390625\n",
      "Epoch: 9, Batch: 200, Loss: 2591.772216796875\n",
      "Epoch: 9, Batch: 201, Loss: 2984.12744140625\n",
      "Epoch: 9, Batch: 202, Loss: 2663.46923828125\n",
      "Epoch: 9, Batch: 203, Loss: 2022.6402587890625\n",
      "Epoch: 9, Batch: 204, Loss: 2090.81884765625\n",
      "Epoch: 9, Batch: 205, Loss: 2528.98974609375\n",
      "Epoch: 9, Batch: 206, Loss: 2719.157958984375\n",
      "Epoch: 9, Batch: 207, Loss: 2645.40087890625\n",
      "Epoch: 9, Batch: 208, Loss: 2530.133056640625\n",
      "Epoch: 9, Batch: 209, Loss: 2606.72314453125\n",
      "Epoch: 9, Batch: 210, Loss: 2498.126953125\n",
      "Epoch: 9, Batch: 211, Loss: 3109.745361328125\n",
      "Epoch: 9, Batch: 212, Loss: 2659.76806640625\n",
      "Epoch: 9, Batch: 213, Loss: 3096.935546875\n",
      "Epoch: 9, Batch: 214, Loss: 2165.644287109375\n",
      "Epoch: 9, Batch: 215, Loss: 2903.150390625\n",
      "Epoch: 9, Batch: 216, Loss: 2932.587890625\n",
      "Epoch: 9, Batch: 217, Loss: 2815.05029296875\n",
      "Epoch: 9, Batch: 218, Loss: 2760.333251953125\n",
      "Epoch: 9, Batch: 219, Loss: 2277.8583984375\n",
      "Epoch: 9, Batch: 220, Loss: 2403.3203125\n",
      "Epoch: 9, Batch: 221, Loss: 2754.41845703125\n",
      "Epoch: 9, Batch: 222, Loss: 2360.745849609375\n",
      "Epoch: 9, Batch: 223, Loss: 3040.385498046875\n",
      "Epoch: 9, Batch: 224, Loss: 2799.391845703125\n",
      "Epoch: 9, Batch: 225, Loss: 2398.386474609375\n",
      "Epoch: 9, Batch: 226, Loss: 2798.27099609375\n",
      "Epoch: 9, Batch: 227, Loss: 2682.19140625\n",
      "Epoch: 9, Batch: 228, Loss: 2833.002685546875\n",
      "Epoch: 9, Batch: 229, Loss: 2490.85009765625\n",
      "Epoch: 9, Batch: 230, Loss: 2963.93212890625\n",
      "Epoch: 9, Batch: 231, Loss: 2894.22412109375\n",
      "Epoch: 9, Batch: 232, Loss: 2637.433349609375\n",
      "Epoch: 9, Batch: 233, Loss: 2776.735595703125\n",
      "Epoch: 9, Batch: 234, Loss: 2701.083984375\n",
      "Epoch: 9, Batch: 235, Loss: 2362.113037109375\n",
      "Epoch: 9, Batch: 236, Loss: 2273.681640625\n",
      "Epoch: 9, Batch: 237, Loss: 2067.546875\n",
      "Epoch: 9, Batch: 238, Loss: 2477.049560546875\n",
      "Epoch: 9, Batch: 239, Loss: 2652.35791015625\n",
      "Epoch: 9, Batch: 240, Loss: 2789.30810546875\n",
      "Epoch: 9, Batch: 241, Loss: 2541.590087890625\n",
      "Epoch: 9, Batch: 242, Loss: 2661.085693359375\n",
      "Epoch: 9, Batch: 243, Loss: 2995.808349609375\n",
      "Epoch: 9, Batch: 244, Loss: 2215.18896484375\n",
      "Epoch: 9, Batch: 245, Loss: 2584.63427734375\n",
      "Epoch: 9, Batch: 246, Loss: 2781.0576171875\n",
      "Epoch: 9, Batch: 247, Loss: 3052.463623046875\n",
      "Epoch: 9, Batch: 248, Loss: 2381.539794921875\n",
      "Epoch: 9, Batch: 249, Loss: 2811.958984375\n",
      "Epoch: 9, Batch: 250, Loss: 2538.19970703125\n",
      "Epoch: 9, Batch: 251, Loss: 2366.491455078125\n",
      "Epoch: 9, Batch: 252, Loss: 2888.5615234375\n",
      "Epoch: 9, Batch: 253, Loss: 2868.7861328125\n",
      "Epoch: 9, Batch: 254, Loss: 1963.4007568359375\n",
      "Epoch: 9, Batch: 255, Loss: 2566.578125\n",
      "Epoch: 9, Batch: 256, Loss: 2429.2978515625\n",
      "Epoch: 9, Batch: 257, Loss: 2531.060546875\n",
      "Epoch: 9, Batch: 258, Loss: 2672.7783203125\n",
      "Epoch: 9, Batch: 259, Loss: 2205.05615234375\n",
      "Epoch: 9, Batch: 260, Loss: 2881.83544921875\n",
      "Epoch: 9, Batch: 261, Loss: 2892.673095703125\n",
      "Epoch: 9, Batch: 262, Loss: 2808.6455078125\n",
      "Epoch: 9, Batch: 263, Loss: 2714.650146484375\n",
      "Epoch: 9, Batch: 264, Loss: 2739.76611328125\n",
      "Epoch: 9, Batch: 265, Loss: 2386.24609375\n",
      "Epoch: 9, Batch: 266, Loss: 2706.91552734375\n",
      "Epoch: 9, Batch: 267, Loss: 2725.60498046875\n",
      "Epoch: 9, Batch: 268, Loss: 2268.31591796875\n",
      "Epoch: 9, Batch: 269, Loss: 2401.821533203125\n",
      "Epoch: 9, Batch: 270, Loss: 2427.907470703125\n",
      "Epoch: 9, Batch: 271, Loss: 2434.1708984375\n",
      "Epoch: 9, Batch: 272, Loss: 2665.42138671875\n",
      "Epoch: 9, Batch: 273, Loss: 2839.682861328125\n",
      "Epoch: 9, Batch: 274, Loss: 3124.83349609375\n",
      "Epoch: 9, Batch: 275, Loss: 2451.31494140625\n",
      "Epoch: 9, Batch: 276, Loss: 3254.502685546875\n",
      "Epoch: 9, Batch: 277, Loss: 2849.4609375\n",
      "Epoch: 9, Batch: 278, Loss: 2602.14404296875\n",
      "Epoch: 9, Batch: 279, Loss: 2076.19775390625\n",
      "Epoch: 9, Batch: 280, Loss: 2994.8603515625\n",
      "Epoch: 9, Batch: 281, Loss: 3179.137451171875\n",
      "Epoch: 9, Batch: 282, Loss: 2828.185791015625\n",
      "Epoch: 9, Batch: 283, Loss: 2971.943115234375\n",
      "Epoch: 9, Batch: 284, Loss: 2781.80517578125\n",
      "Epoch: 9, Batch: 285, Loss: 2661.476318359375\n",
      "Epoch: 9, Batch: 286, Loss: 2747.091552734375\n",
      "Epoch: 9, Batch: 287, Loss: 2897.319091796875\n",
      "Epoch: 9, Batch: 288, Loss: 2464.92236328125\n",
      "Epoch: 9, Batch: 289, Loss: 3076.58251953125\n",
      "Epoch: 9, Batch: 290, Loss: 1948.2928466796875\n",
      "Epoch: 9, Batch: 291, Loss: 2316.1650390625\n",
      "Epoch: 9, Batch: 292, Loss: 2954.9560546875\n",
      "Epoch: 9, Batch: 293, Loss: 2459.38916015625\n",
      "Epoch: 9, Batch: 294, Loss: 2283.768310546875\n",
      "Epoch: 9, Batch: 295, Loss: 2638.73876953125\n",
      "Epoch: 9, Batch: 296, Loss: 3077.964111328125\n",
      "Epoch: 9, Batch: 297, Loss: 2669.91455078125\n",
      "Epoch: 9, Batch: 298, Loss: 2875.705078125\n",
      "Epoch: 9, Batch: 299, Loss: 3325.809814453125\n",
      "Epoch: 9, Batch: 300, Loss: 2809.95068359375\n",
      "Epoch: 9, Batch: 301, Loss: 2761.41259765625\n",
      "Epoch: 9, Batch: 302, Loss: 2135.437255859375\n",
      "Epoch: 9, Batch: 303, Loss: 2331.30126953125\n",
      "Epoch: 9, Batch: 304, Loss: 2829.015869140625\n",
      "Epoch: 9, Batch: 305, Loss: 2410.01220703125\n",
      "Epoch: 9, Batch: 306, Loss: 2862.2216796875\n",
      "Epoch: 9, Batch: 307, Loss: 2191.25830078125\n",
      "Epoch: 9, Batch: 308, Loss: 2752.52880859375\n",
      "Epoch: 9, Batch: 309, Loss: 2530.854736328125\n",
      "Epoch: 9, Batch: 310, Loss: 3288.916259765625\n",
      "Epoch: 9, Batch: 311, Loss: 2742.994384765625\n",
      "Epoch: 9, Batch: 312, Loss: 2871.544921875\n",
      "Epoch: 9, Batch: 313, Loss: 2359.52587890625\n",
      "Epoch: 9, Batch: 314, Loss: 2223.372802734375\n",
      "Epoch: 9, Batch: 315, Loss: 2662.017822265625\n",
      "Epoch: 9, Batch: 316, Loss: 2870.433349609375\n",
      "Epoch: 9, Batch: 317, Loss: 2684.59814453125\n",
      "Epoch: 9, Batch: 318, Loss: 2726.1865234375\n",
      "Epoch: 9, Batch: 319, Loss: 2464.906982421875\n",
      "Epoch: 9, Batch: 320, Loss: 2610.66162109375\n",
      "Epoch: 9, Batch: 321, Loss: 2604.319091796875\n",
      "Epoch: 9, Batch: 322, Loss: 2303.447021484375\n",
      "Epoch: 9, Batch: 323, Loss: 2968.67529296875\n",
      "Epoch: 9, Batch: 324, Loss: 2365.945556640625\n",
      "Epoch: 9, Batch: 325, Loss: 2196.67236328125\n",
      "Epoch: 9, Batch: 326, Loss: 2128.399658203125\n",
      "Epoch: 9, Batch: 327, Loss: 2215.368408203125\n",
      "Epoch: 9, Batch: 328, Loss: 3105.26318359375\n",
      "Epoch: 9, Batch: 329, Loss: 2484.7138671875\n",
      "Epoch: 9, Batch: 330, Loss: 2646.67578125\n",
      "Epoch: 9, Batch: 331, Loss: 3099.849609375\n",
      "Epoch: 9, Batch: 332, Loss: 2595.425537109375\n",
      "Epoch: 9, Batch: 333, Loss: 2350.011474609375\n",
      "Epoch: 9, Batch: 334, Loss: 2149.011474609375\n",
      "Epoch: 9, Batch: 335, Loss: 2825.5087890625\n",
      "Epoch: 9, Batch: 336, Loss: 2962.6220703125\n",
      "Epoch: 9, Batch: 337, Loss: 2951.69189453125\n",
      "Epoch: 9, Batch: 338, Loss: 3217.14599609375\n",
      "Epoch: 9, Batch: 339, Loss: 2588.942626953125\n",
      "Epoch: 9, Batch: 340, Loss: 2191.805419921875\n",
      "Epoch: 9, Batch: 341, Loss: 2877.712158203125\n",
      "Epoch: 9, Batch: 342, Loss: 2578.392578125\n",
      "Epoch: 9, Batch: 343, Loss: 2986.41015625\n",
      "Epoch: 9, Batch: 344, Loss: 2403.220947265625\n",
      "Epoch: 9, Batch: 345, Loss: 2539.56103515625\n",
      "Epoch: 9, Batch: 346, Loss: 2384.50732421875\n",
      "Epoch: 9, Batch: 347, Loss: 1917.070556640625\n",
      "Epoch: 9, Batch: 348, Loss: 2417.693115234375\n",
      "Epoch: 9, Batch: 349, Loss: 3156.824462890625\n",
      "Epoch: 9, Batch: 350, Loss: 3230.098876953125\n",
      "Epoch: 9, Batch: 351, Loss: 2812.9990234375\n",
      "Epoch: 9, Batch: 352, Loss: 2517.910400390625\n",
      "Epoch: 9, Batch: 353, Loss: 2773.9130859375\n",
      "Epoch: 9, Batch: 354, Loss: 2433.72607421875\n",
      "Epoch: 9, Batch: 355, Loss: 2685.692138671875\n",
      "Epoch: 9, Batch: 356, Loss: 2675.60791015625\n",
      "Epoch: 9, Batch: 357, Loss: 2848.419677734375\n",
      "Epoch: 9, Batch: 358, Loss: 2203.02294921875\n",
      "Epoch: 9, Batch: 359, Loss: 2847.685302734375\n",
      "Epoch: 9, Batch: 360, Loss: 2672.05224609375\n",
      "Epoch: 9, Batch: 361, Loss: 2609.806884765625\n",
      "Epoch: 9, Batch: 362, Loss: 2531.99072265625\n",
      "Epoch: 9, Batch: 363, Loss: 2208.23046875\n",
      "Epoch: 9, Batch: 364, Loss: 2888.975830078125\n",
      "Epoch: 9, Batch: 365, Loss: 2336.53515625\n",
      "Epoch: 9, Batch: 366, Loss: 1826.61669921875\n",
      "Epoch: 9, Batch: 367, Loss: 2943.806396484375\n",
      "Epoch: 9, Batch: 368, Loss: 2943.267578125\n",
      "Epoch: 9, Batch: 369, Loss: 2784.28369140625\n",
      "Epoch: 9, Batch: 370, Loss: 2574.3720703125\n",
      "Epoch: 9, Batch: 371, Loss: 2229.13818359375\n",
      "Epoch: 9, Batch: 372, Loss: 2549.49609375\n",
      "Epoch: 9, Batch: 373, Loss: 1811.4033203125\n",
      "Epoch: 9, Batch: 374, Loss: 2350.628173828125\n",
      "Epoch: 9, Batch: 375, Loss: 2459.155029296875\n",
      "Epoch: 9, Batch: 376, Loss: 2787.509521484375\n",
      "Epoch: 9, Batch: 377, Loss: 2743.72705078125\n",
      "Epoch: 9, Batch: 378, Loss: 2313.506591796875\n",
      "Epoch: 9, Batch: 379, Loss: 3275.180908203125\n",
      "Epoch: 9, Batch: 380, Loss: 3127.248291015625\n",
      "Epoch: 9, Batch: 381, Loss: 2073.610595703125\n",
      "Epoch: 9, Batch: 382, Loss: 2320.272216796875\n",
      "Epoch: 9, Batch: 383, Loss: 2316.09423828125\n",
      "Epoch: 9, Batch: 384, Loss: 2987.271728515625\n",
      "Epoch: 9, Batch: 385, Loss: 2701.26318359375\n",
      "Epoch: 9, Batch: 386, Loss: 2866.979736328125\n",
      "Epoch: 9, Batch: 387, Loss: 2636.95947265625\n",
      "Epoch: 9, Batch: 388, Loss: 2398.6328125\n",
      "Epoch: 9, Batch: 389, Loss: 2746.552001953125\n",
      "Epoch: 9, Batch: 390, Loss: 2349.7275390625\n",
      "Epoch: 9, Batch: 391, Loss: 2305.09228515625\n",
      "Epoch: 9, Batch: 392, Loss: 2842.524169921875\n",
      "Epoch: 9, Batch: 393, Loss: 2280.85400390625\n",
      "Epoch: 9, Batch: 394, Loss: 2667.731201171875\n",
      "Epoch: 9, Batch: 395, Loss: 2660.83544921875\n",
      "Epoch: 9, Batch: 396, Loss: 2479.223388671875\n",
      "Epoch: 9, Batch: 397, Loss: 2450.4921875\n",
      "Epoch: 9, Batch: 398, Loss: 3154.9248046875\n",
      "Epoch: 9, Batch: 399, Loss: 2819.041259765625\n",
      "Epoch: 9, Batch: 400, Loss: 2542.847412109375\n",
      "Epoch: 9, Batch: 401, Loss: 2542.706298828125\n",
      "Epoch: 9, Batch: 402, Loss: 2727.848388671875\n",
      "Epoch: 9, Batch: 403, Loss: 3004.518798828125\n",
      "Epoch: 9, Batch: 404, Loss: 3474.347900390625\n",
      "Epoch: 9, Batch: 405, Loss: 2304.39697265625\n",
      "Epoch: 9, Batch: 406, Loss: 2292.051025390625\n",
      "Epoch: 9, Batch: 407, Loss: 2705.6767578125\n",
      "Epoch: 9, Batch: 408, Loss: 3450.962158203125\n",
      "Epoch: 9, Batch: 409, Loss: 2938.492431640625\n",
      "Epoch: 9, Batch: 410, Loss: 2555.72314453125\n",
      "Epoch: 9, Batch: 411, Loss: 2542.218017578125\n",
      "Epoch: 9, Batch: 412, Loss: 2378.994873046875\n",
      "Epoch: 9, Batch: 413, Loss: 2412.384521484375\n",
      "Epoch: 9, Batch: 414, Loss: 2525.023681640625\n",
      "Epoch: 9, Batch: 415, Loss: 2716.79541015625\n",
      "Epoch: 9, Batch: 416, Loss: 1957.5343017578125\n",
      "Epoch: 9, Batch: 417, Loss: 2432.60107421875\n",
      "Epoch: 9, Batch: 418, Loss: 2591.365478515625\n",
      "Epoch: 9, Batch: 419, Loss: 2172.966796875\n",
      "Epoch: 9, Batch: 420, Loss: 2375.255615234375\n",
      "Epoch: 9, Batch: 421, Loss: 2192.921142578125\n",
      "Epoch: 9, Batch: 422, Loss: 2702.6123046875\n",
      "Epoch: 9, Batch: 423, Loss: 3462.871826171875\n",
      "Epoch: 9, Batch: 424, Loss: 2812.473388671875\n",
      "Epoch: 9, Batch: 425, Loss: 2982.57080078125\n",
      "Epoch: 9, Batch: 426, Loss: 2599.917236328125\n",
      "Epoch: 9, Batch: 427, Loss: 2892.009521484375\n",
      "Epoch: 9, Batch: 428, Loss: 3390.808837890625\n",
      "Epoch: 9, Batch: 429, Loss: 2313.615234375\n",
      "Epoch: 9, Batch: 430, Loss: 2775.2431640625\n",
      "Epoch: 9, Batch: 431, Loss: 3072.095947265625\n",
      "Epoch: 9, Batch: 432, Loss: 2554.366943359375\n",
      "Epoch: 9, Batch: 433, Loss: 2311.387939453125\n",
      "Epoch: 9, Batch: 434, Loss: 2101.00537109375\n",
      "Epoch: 9, Batch: 435, Loss: 2234.71240234375\n",
      "Epoch: 9, Batch: 436, Loss: 2524.090087890625\n",
      "Epoch: 9, Batch: 437, Loss: 3187.801025390625\n",
      "Epoch: 9, Batch: 438, Loss: 2372.350341796875\n",
      "Epoch: 9, Batch: 439, Loss: 2303.234130859375\n",
      "Epoch: 9, Batch: 440, Loss: 3469.17041015625\n",
      "Epoch: 9, Batch: 441, Loss: 2738.22265625\n",
      "Epoch: 9, Batch: 442, Loss: 2467.625244140625\n",
      "Epoch: 9, Batch: 443, Loss: 2566.492919921875\n",
      "Epoch: 9, Batch: 444, Loss: 2925.694580078125\n",
      "Epoch: 9, Batch: 445, Loss: 2733.79833984375\n",
      "Epoch: 9, Batch: 446, Loss: 2386.85888671875\n",
      "Epoch: 9, Batch: 447, Loss: 2960.704345703125\n",
      "Epoch: 9, Batch: 448, Loss: 2246.33154296875\n",
      "Epoch: 9, Batch: 449, Loss: 3776.17919921875\n",
      "Epoch: 9, Batch: 450, Loss: 2709.82568359375\n",
      "Epoch: 9, Batch: 451, Loss: 2955.094482421875\n",
      "Epoch: 9, Batch: 452, Loss: 3038.454345703125\n",
      "Epoch: 9, Batch: 453, Loss: 2490.474853515625\n",
      "Epoch: 9, Batch: 454, Loss: 3018.972900390625\n",
      "Epoch: 9, Batch: 455, Loss: 2736.10107421875\n",
      "Epoch: 9, Batch: 456, Loss: 2410.12109375\n",
      "Epoch: 9, Batch: 457, Loss: 2451.606689453125\n",
      "Epoch: 9, Batch: 458, Loss: 2440.17529296875\n",
      "Epoch: 9, Batch: 459, Loss: 3184.29833984375\n",
      "Epoch: 9, Batch: 460, Loss: 3536.955810546875\n",
      "Epoch: 9, Batch: 461, Loss: 2629.17041015625\n",
      "Epoch: 9, Batch: 462, Loss: 2742.928955078125\n",
      "Epoch: 9, Batch: 463, Loss: 2416.238037109375\n",
      "Epoch: 9, Batch: 464, Loss: 2519.464599609375\n",
      "Epoch: 9, Batch: 465, Loss: 2337.81298828125\n",
      "Epoch: 9, Batch: 466, Loss: 2624.452392578125\n",
      "Epoch: 9, Batch: 467, Loss: 2412.224853515625\n",
      "Epoch: 9, Batch: 468, Loss: 2639.23486328125\n",
      "Epoch: 9, Batch: 469, Loss: 2837.164794921875\n",
      "Epoch: 9, Batch: 470, Loss: 2370.0166015625\n",
      "Epoch: 9, Batch: 471, Loss: 2851.16357421875\n",
      "Epoch: 9, Batch: 472, Loss: 2657.011474609375\n",
      "Epoch: 9, Batch: 473, Loss: 2333.676025390625\n",
      "Epoch: 9, Batch: 474, Loss: 2797.850830078125\n",
      "Epoch: 9, Batch: 475, Loss: 2967.935791015625\n",
      "Epoch: 9, Batch: 476, Loss: 2767.302001953125\n",
      "Epoch: 9, Batch: 477, Loss: 2370.254638671875\n",
      "Epoch: 9, Batch: 478, Loss: 2556.928466796875\n",
      "Epoch: 9, Batch: 479, Loss: 2650.5966796875\n",
      "Epoch: 9, Batch: 480, Loss: 2345.20556640625\n",
      "Epoch: 9, Batch: 481, Loss: 2795.606689453125\n",
      "Epoch: 9, Batch: 482, Loss: 2013.5511474609375\n",
      "Epoch: 9, Batch: 483, Loss: 2346.168701171875\n",
      "Epoch: 9, Batch: 484, Loss: 2969.26904296875\n",
      "Epoch: 9, Batch: 485, Loss: 2436.038818359375\n",
      "Epoch: 9, Batch: 486, Loss: 2489.840576171875\n",
      "Epoch: 9, Batch: 487, Loss: 2593.328369140625\n",
      "Epoch: 9, Batch: 488, Loss: 2973.38037109375\n",
      "Epoch: 9, Batch: 489, Loss: 2694.07470703125\n",
      "Epoch: 9, Batch: 490, Loss: 2073.52099609375\n",
      "Epoch: 9, Batch: 491, Loss: 2926.637939453125\n",
      "Epoch: 9, Batch: 492, Loss: 2539.494873046875\n",
      "Epoch: 9, Batch: 493, Loss: 2126.715576171875\n",
      "Epoch: 9, Batch: 494, Loss: 2556.862060546875\n",
      "Epoch: 9, Batch: 495, Loss: 2407.15234375\n",
      "Epoch: 9, Batch: 496, Loss: 2735.54150390625\n",
      "Epoch: 9, Batch: 497, Loss: 2516.55859375\n",
      "Epoch: 9, Batch: 498, Loss: 1851.6624755859375\n",
      "Epoch: 9, Batch: 499, Loss: 2661.739501953125\n",
      "Epoch: 9, Batch: 500, Loss: 2773.4951171875\n",
      "Epoch: 9, Batch: 501, Loss: 3076.4638671875\n",
      "Epoch: 9, Batch: 502, Loss: 2611.842041015625\n",
      "Epoch: 9, Batch: 503, Loss: 2122.584228515625\n",
      "Epoch: 9, Batch: 504, Loss: 2167.103515625\n",
      "Epoch: 9, Batch: 505, Loss: 2352.07568359375\n",
      "Epoch: 9, Batch: 506, Loss: 2805.78271484375\n",
      "Epoch: 9, Batch: 507, Loss: 2910.73095703125\n",
      "Epoch: 9, Batch: 508, Loss: 2563.645751953125\n",
      "Epoch: 9, Batch: 509, Loss: 3022.611328125\n",
      "Epoch: 9, Batch: 510, Loss: 2211.787109375\n",
      "Epoch: 9, Batch: 511, Loss: 2284.1201171875\n",
      "Epoch: 9, Batch: 512, Loss: 2697.715576171875\n",
      "Epoch: 9, Batch: 513, Loss: 2142.93310546875\n",
      "Epoch: 9, Batch: 514, Loss: 2938.5224609375\n",
      "Epoch: 9, Batch: 515, Loss: 2858.015380859375\n",
      "Epoch: 9, Batch: 516, Loss: 2534.53173828125\n",
      "Epoch: 9, Batch: 517, Loss: 2629.749755859375\n",
      "Epoch: 9, Batch: 518, Loss: 2649.395263671875\n",
      "Epoch: 9, Batch: 519, Loss: 2892.787841796875\n",
      "Epoch: 9, Batch: 520, Loss: 3110.879638671875\n",
      "Epoch: 9, Batch: 521, Loss: 2217.973388671875\n",
      "Epoch: 9, Batch: 522, Loss: 2930.08984375\n",
      "Epoch: 9, Batch: 523, Loss: 2819.72607421875\n",
      "Epoch: 9, Batch: 524, Loss: 2381.541259765625\n",
      "Epoch: 9, Batch: 525, Loss: 2577.537109375\n",
      "Epoch: 9, Batch: 526, Loss: 2212.84521484375\n",
      "Epoch: 9, Batch: 527, Loss: 2768.74462890625\n",
      "Epoch: 9, Batch: 528, Loss: 3186.990478515625\n",
      "Epoch: 9, Batch: 529, Loss: 2565.626708984375\n",
      "Epoch: 9, Batch: 530, Loss: 2631.993896484375\n",
      "Epoch: 9, Batch: 531, Loss: 2558.12353515625\n",
      "Epoch: 9, Batch: 532, Loss: 2924.109375\n",
      "Epoch: 9, Batch: 533, Loss: 2420.810791015625\n",
      "Epoch: 9, Batch: 534, Loss: 2504.144287109375\n",
      "Epoch: 9, Batch: 535, Loss: 2399.915771484375\n",
      "Epoch: 9, Batch: 536, Loss: 2790.869140625\n",
      "Epoch: 9, Batch: 537, Loss: 2568.939697265625\n",
      "Epoch: 9, Batch: 538, Loss: 2791.435791015625\n",
      "Epoch: 9, Batch: 539, Loss: 3074.026611328125\n",
      "Epoch: 9, Batch: 540, Loss: 2396.510986328125\n",
      "Epoch: 9, Batch: 541, Loss: 2529.00830078125\n",
      "Epoch: 9, Batch: 542, Loss: 3041.965576171875\n",
      "Epoch: 9, Batch: 543, Loss: 2486.962890625\n",
      "Epoch: 9, Batch: 544, Loss: 3010.12744140625\n",
      "Epoch: 9, Batch: 545, Loss: 2358.039794921875\n",
      "Epoch: 9, Batch: 546, Loss: 2662.2275390625\n",
      "Epoch: 9, Batch: 547, Loss: 2357.148193359375\n",
      "Epoch: 9, Batch: 548, Loss: 2652.510009765625\n",
      "Epoch: 9, Batch: 549, Loss: 2830.1083984375\n",
      "Epoch: 9, Batch: 550, Loss: 2344.970947265625\n",
      "Epoch: 9, Batch: 551, Loss: 2526.703857421875\n",
      "Epoch: 9, Batch: 552, Loss: 3313.728271484375\n",
      "Epoch: 9, Batch: 553, Loss: 2202.11181640625\n",
      "Epoch: 9, Batch: 554, Loss: 3076.068359375\n",
      "Epoch: 9, Batch: 555, Loss: 3137.335693359375\n",
      "Epoch: 9, Batch: 556, Loss: 2820.373779296875\n",
      "Epoch: 9, Batch: 557, Loss: 2712.056396484375\n",
      "Epoch: 9, Batch: 558, Loss: 2647.152099609375\n",
      "Epoch: 9, Batch: 559, Loss: 2621.2021484375\n",
      "Epoch: 9, Batch: 560, Loss: 2233.55712890625\n",
      "Epoch: 9, Batch: 561, Loss: 2806.7314453125\n",
      "Epoch: 9, Batch: 562, Loss: 2556.14990234375\n",
      "Epoch: 9, Batch: 563, Loss: 2484.74072265625\n",
      "Epoch: 9, Batch: 564, Loss: 2468.62353515625\n",
      "Epoch: 9, Batch: 565, Loss: 3003.218994140625\n",
      "Epoch: 9, Batch: 566, Loss: 2379.76416015625\n",
      "Epoch: 9, Batch: 567, Loss: 2482.5830078125\n",
      "Epoch: 9, Batch: 568, Loss: 2444.726318359375\n",
      "Epoch: 9, Batch: 569, Loss: 2952.52001953125\n",
      "Epoch: 9, Batch: 570, Loss: 2480.238037109375\n",
      "Epoch: 9, Batch: 571, Loss: 2526.614990234375\n",
      "Epoch: 9, Batch: 572, Loss: 3022.4306640625\n",
      "Epoch: 9, Batch: 573, Loss: 2735.31298828125\n",
      "Epoch: 9, Batch: 574, Loss: 3110.5654296875\n",
      "Epoch: 9, Batch: 575, Loss: 3205.145263671875\n",
      "Epoch: 9, Batch: 576, Loss: 2661.630615234375\n",
      "Epoch: 9, Batch: 577, Loss: 3284.384033203125\n",
      "Epoch: 9, Batch: 578, Loss: 2030.1009521484375\n",
      "Epoch: 9, Batch: 579, Loss: 2797.890625\n",
      "Epoch: 9, Batch: 580, Loss: 3158.1142578125\n",
      "Epoch: 9, Batch: 581, Loss: 2805.95947265625\n",
      "Epoch: 9, Batch: 582, Loss: 2695.683349609375\n",
      "Epoch: 9, Batch: 583, Loss: 2900.2431640625\n",
      "Epoch: 9, Batch: 584, Loss: 2573.62744140625\n",
      "Epoch: 9, Batch: 585, Loss: 2815.94287109375\n",
      "Epoch: 9, Batch: 586, Loss: 2698.7333984375\n",
      "Epoch: 9, Batch: 587, Loss: 2408.361328125\n",
      "Epoch: 9, Batch: 588, Loss: 2541.5693359375\n",
      "Epoch: 9, Batch: 589, Loss: 2772.559814453125\n",
      "Epoch: 9, Batch: 590, Loss: 2593.08251953125\n",
      "Epoch: 9, Batch: 591, Loss: 2655.302001953125\n",
      "Epoch: 9, Batch: 592, Loss: 2636.334716796875\n",
      "Epoch: 9, Batch: 593, Loss: 2316.53759765625\n",
      "Epoch: 9, Batch: 594, Loss: 2184.733154296875\n",
      "Epoch: 9, Batch: 595, Loss: 2178.052978515625\n",
      "Epoch: 9, Batch: 596, Loss: 2670.390869140625\n",
      "Epoch: 9, Batch: 597, Loss: 2562.776123046875\n",
      "Epoch: 9, Batch: 598, Loss: 2047.084716796875\n",
      "Epoch: 9, Batch: 599, Loss: 3004.80419921875\n",
      "Epoch: 9, Batch: 600, Loss: 2873.039794921875\n",
      "Epoch: 9, Batch: 601, Loss: 2550.83740234375\n",
      "Epoch: 9, Batch: 602, Loss: 2565.602294921875\n",
      "Epoch: 9, Batch: 603, Loss: 2841.46142578125\n",
      "Epoch: 9, Batch: 604, Loss: 2342.072998046875\n",
      "Epoch: 9, Batch: 605, Loss: 3145.154052734375\n",
      "Epoch: 9, Batch: 606, Loss: 2494.370849609375\n",
      "Epoch: 9, Batch: 607, Loss: 2877.96142578125\n",
      "Epoch: 9, Batch: 608, Loss: 2460.744140625\n",
      "Epoch: 9, Batch: 609, Loss: 2610.9111328125\n",
      "Epoch: 9, Batch: 610, Loss: 2321.015625\n",
      "Epoch: 9, Batch: 611, Loss: 3080.099609375\n",
      "Epoch: 9, Batch: 612, Loss: 2678.36865234375\n",
      "Epoch: 9, Batch: 613, Loss: 2261.91845703125\n",
      "Epoch: 9, Batch: 614, Loss: 2284.871826171875\n",
      "Epoch: 9, Batch: 615, Loss: 2438.2412109375\n",
      "Epoch: 9, Batch: 616, Loss: 2862.61865234375\n",
      "Epoch: 9, Batch: 617, Loss: 2759.551025390625\n",
      "Epoch: 9, Batch: 618, Loss: 2394.895263671875\n",
      "Epoch: 9, Batch: 619, Loss: 2501.234619140625\n",
      "Epoch: 9, Batch: 620, Loss: 2404.510498046875\n",
      "Epoch: 9, Batch: 621, Loss: 2458.4375\n",
      "Epoch: 9, Batch: 622, Loss: 2592.115478515625\n",
      "Epoch: 9, Batch: 623, Loss: 3079.894775390625\n",
      "Epoch: 9, Batch: 624, Loss: 2776.896728515625\n",
      "Epoch: 9, Batch: 625, Loss: 2614.006103515625\n",
      "Epoch: 9, Batch: 626, Loss: 2523.50830078125\n",
      "Epoch: 9, Batch: 627, Loss: 3221.440185546875\n",
      "Epoch: 9, Batch: 628, Loss: 2935.994140625\n",
      "Epoch: 9, Batch: 629, Loss: 2866.54541015625\n",
      "Epoch: 9, Batch: 630, Loss: 2820.1015625\n",
      "Epoch: 9, Batch: 631, Loss: 2053.80224609375\n",
      "Epoch: 9, Batch: 632, Loss: 2833.53564453125\n",
      "Epoch: 9, Batch: 633, Loss: 2651.529296875\n",
      "Epoch: 9, Batch: 634, Loss: 3134.175537109375\n",
      "Epoch: 9, Batch: 635, Loss: 2438.731201171875\n",
      "Epoch: 9, Batch: 636, Loss: 2937.95361328125\n",
      "Epoch: 9, Batch: 637, Loss: 2906.36962890625\n",
      "Epoch: 9, Batch: 638, Loss: 2499.6796875\n",
      "Epoch: 9, Batch: 639, Loss: 2574.5546875\n",
      "Epoch: 9, Batch: 640, Loss: 2559.12646484375\n",
      "Epoch: 9, Batch: 641, Loss: 2630.0205078125\n",
      "Epoch: 9, Batch: 642, Loss: 2663.79248046875\n",
      "Epoch: 9, Batch: 643, Loss: 2950.632080078125\n",
      "Epoch: 9, Batch: 644, Loss: 3021.35791015625\n",
      "Epoch: 9, Batch: 645, Loss: 3157.110107421875\n",
      "Epoch: 9, Batch: 646, Loss: 2157.932861328125\n",
      "Epoch: 9, Batch: 647, Loss: 2340.51318359375\n",
      "Epoch: 9, Batch: 648, Loss: 3062.54833984375\n",
      "Epoch: 9, Batch: 649, Loss: 2703.1005859375\n",
      "Epoch: 9, Batch: 650, Loss: 2640.27490234375\n",
      "Epoch: 9, Batch: 651, Loss: 2846.953125\n",
      "Epoch: 9, Batch: 652, Loss: 2846.243896484375\n",
      "Epoch: 9, Batch: 653, Loss: 2554.006591796875\n",
      "Epoch: 9, Batch: 654, Loss: 2735.92431640625\n",
      "Epoch: 9, Batch: 655, Loss: 2821.23779296875\n",
      "Epoch: 9, Batch: 656, Loss: 2566.572998046875\n",
      "Epoch: 9, Batch: 657, Loss: 3466.0703125\n",
      "Epoch: 9, Batch: 658, Loss: 3070.51416015625\n",
      "Epoch: 9, Batch: 659, Loss: 2591.292236328125\n",
      "Epoch: 9, Batch: 660, Loss: 2872.50341796875\n",
      "Epoch: 9, Batch: 661, Loss: 2639.3974609375\n",
      "Epoch: 9, Batch: 662, Loss: 2079.589111328125\n",
      "Epoch: 9, Batch: 663, Loss: 2721.603515625\n",
      "Epoch: 9, Batch: 664, Loss: 2579.877197265625\n",
      "Epoch: 9, Batch: 665, Loss: 2824.583740234375\n",
      "Epoch: 9, Batch: 666, Loss: 2645.579345703125\n",
      "Epoch: 9, Batch: 667, Loss: 2396.975341796875\n",
      "Epoch: 9, Batch: 668, Loss: 2145.063720703125\n",
      "Epoch: 9, Batch: 669, Loss: 2317.68505859375\n",
      "Epoch: 9, Batch: 670, Loss: 2590.08251953125\n",
      "Epoch: 9, Batch: 671, Loss: 2816.514892578125\n",
      "Epoch: 9, Batch: 672, Loss: 2464.290283203125\n",
      "Epoch: 9, Batch: 673, Loss: 3001.332275390625\n",
      "Epoch: 9, Batch: 674, Loss: 3002.7763671875\n",
      "Epoch: 9, Batch: 675, Loss: 2955.28857421875\n",
      "Epoch: 9, Batch: 676, Loss: 3045.2451171875\n",
      "Epoch: 9, Batch: 677, Loss: 2706.25830078125\n",
      "Epoch: 9, Batch: 678, Loss: 2792.52978515625\n",
      "Epoch: 9, Batch: 679, Loss: 2473.9853515625\n",
      "Epoch: 9, Batch: 680, Loss: 2861.042724609375\n",
      "Epoch: 9, Batch: 681, Loss: 3181.374755859375\n",
      "Epoch: 9, Batch: 682, Loss: 2592.197509765625\n",
      "Epoch: 9, Batch: 683, Loss: 2321.8408203125\n",
      "Epoch: 9, Batch: 684, Loss: 2609.77294921875\n",
      "Epoch: 9, Batch: 685, Loss: 2671.5595703125\n",
      "Epoch: 9, Batch: 686, Loss: 2258.814208984375\n",
      "Epoch: 9, Batch: 687, Loss: 2601.289306640625\n",
      "Epoch: 9, Batch: 688, Loss: 2872.5244140625\n",
      "Epoch: 9, Batch: 689, Loss: 2975.9931640625\n",
      "Epoch: 9, Batch: 690, Loss: 2756.95361328125\n",
      "Epoch: 9, Batch: 691, Loss: 2708.4716796875\n",
      "Epoch: 9, Batch: 692, Loss: 2766.16845703125\n",
      "Epoch: 9, Batch: 693, Loss: 2858.66845703125\n",
      "Epoch: 9, Batch: 694, Loss: 2713.819091796875\n",
      "Epoch: 9, Batch: 695, Loss: 2280.00634765625\n",
      "Epoch: 9, Batch: 696, Loss: 3062.185302734375\n",
      "Epoch: 9, Batch: 697, Loss: 2432.3701171875\n",
      "Epoch: 9, Batch: 698, Loss: 2804.8720703125\n",
      "Epoch: 9, Batch: 699, Loss: 2177.249267578125\n",
      "Epoch: 9, Batch: 700, Loss: 2462.961181640625\n",
      "Epoch: 9, Batch: 701, Loss: 2213.09033203125\n",
      "Epoch: 9, Batch: 702, Loss: 3188.978759765625\n",
      "Epoch: 9, Batch: 703, Loss: 2035.47216796875\n",
      "Epoch: 9, Batch: 704, Loss: 2542.79931640625\n",
      "Epoch: 9, Batch: 705, Loss: 1644.504150390625\n",
      "Epoch: 9, Batch: 706, Loss: 2305.672119140625\n",
      "Epoch: 9, Batch: 707, Loss: 2497.102294921875\n",
      "Epoch: 9, Batch: 708, Loss: 2715.6328125\n",
      "Epoch: 9, Batch: 709, Loss: 2671.771240234375\n",
      "Epoch: 9, Batch: 710, Loss: 2685.94091796875\n",
      "Epoch: 9, Batch: 711, Loss: 2827.554443359375\n",
      "Epoch: 9, Batch: 712, Loss: 2661.486572265625\n",
      "Epoch: 9, Batch: 713, Loss: 3077.2734375\n",
      "Epoch: 9, Batch: 714, Loss: 2734.17041015625\n",
      "Epoch: 9, Batch: 715, Loss: 2857.420166015625\n",
      "Epoch: 9, Batch: 716, Loss: 2910.3271484375\n",
      "Epoch: 9, Batch: 717, Loss: 2826.902587890625\n",
      "Epoch: 9, Batch: 718, Loss: 2685.931884765625\n",
      "Epoch: 9, Batch: 719, Loss: 2634.260009765625\n",
      "Epoch: 9, Batch: 720, Loss: 2566.48095703125\n",
      "Epoch: 9, Batch: 721, Loss: 2686.328125\n",
      "Epoch: 9, Batch: 722, Loss: 2860.5\n",
      "Epoch: 9, Batch: 723, Loss: 2543.337158203125\n",
      "Epoch: 9, Batch: 724, Loss: 2390.164794921875\n",
      "Epoch: 9, Batch: 725, Loss: 2789.552978515625\n",
      "Epoch: 9, Batch: 726, Loss: 2609.552978515625\n",
      "Epoch: 9, Batch: 727, Loss: 2730.887939453125\n",
      "Epoch: 9, Batch: 728, Loss: 2541.615478515625\n",
      "Epoch: 9, Batch: 729, Loss: 2560.953369140625\n",
      "Epoch: 9, Batch: 730, Loss: 2672.057861328125\n",
      "Epoch: 9, Batch: 731, Loss: 2628.70751953125\n",
      "Epoch: 9, Batch: 732, Loss: 2332.74462890625\n",
      "Epoch: 9, Batch: 733, Loss: 3387.01708984375\n",
      "Epoch: 9, Batch: 734, Loss: 3163.168212890625\n",
      "Epoch: 9, Batch: 735, Loss: 2880.189453125\n",
      "Epoch: 9, Batch: 736, Loss: 2870.58251953125\n",
      "Epoch: 9, Batch: 737, Loss: 2519.0390625\n",
      "Epoch: 9, Batch: 738, Loss: 2627.302734375\n",
      "Epoch: 9, Batch: 739, Loss: 3004.188232421875\n",
      "Epoch: 9, Batch: 740, Loss: 2623.859619140625\n",
      "Epoch: 9, Batch: 741, Loss: 2733.34375\n",
      "Epoch: 9, Batch: 742, Loss: 2753.49853515625\n",
      "Epoch: 9, Batch: 743, Loss: 2974.94970703125\n",
      "Epoch: 9, Batch: 744, Loss: 2444.22265625\n",
      "Epoch: 9, Batch: 745, Loss: 2346.339599609375\n",
      "Epoch: 9, Batch: 746, Loss: 2393.081787109375\n",
      "Epoch: 9, Batch: 747, Loss: 2406.655029296875\n",
      "Epoch: 9, Batch: 748, Loss: 2964.7705078125\n",
      "Epoch: 9, Batch: 749, Loss: 2406.30322265625\n",
      "Epoch: 9, Batch: 750, Loss: 3011.023681640625\n",
      "Epoch: 9, Batch: 751, Loss: 2344.26025390625\n",
      "Epoch: 9, Batch: 752, Loss: 2345.370361328125\n",
      "Epoch: 9, Batch: 753, Loss: 2199.734130859375\n",
      "Epoch: 9, Batch: 754, Loss: 2578.838134765625\n",
      "Epoch: 9, Batch: 755, Loss: 2908.3427734375\n",
      "Epoch: 9, Batch: 756, Loss: 2418.0859375\n",
      "Epoch: 9, Batch: 757, Loss: 2440.10693359375\n",
      "Epoch: 9, Batch: 758, Loss: 2295.51611328125\n",
      "Epoch: 9, Batch: 759, Loss: 2843.76220703125\n",
      "Epoch: 9, Batch: 760, Loss: 2780.2529296875\n",
      "Epoch: 9, Batch: 761, Loss: 2272.7529296875\n",
      "Epoch: 9, Batch: 762, Loss: 2486.331298828125\n",
      "Epoch: 9, Batch: 763, Loss: 2636.14794921875\n",
      "Epoch: 9, Batch: 764, Loss: 2666.243408203125\n",
      "Epoch: 9, Batch: 765, Loss: 2932.4130859375\n",
      "Epoch: 9, Batch: 766, Loss: 2732.80224609375\n",
      "Epoch: 9, Batch: 767, Loss: 2662.649169921875\n",
      "Epoch: 9, Batch: 768, Loss: 2388.556884765625\n",
      "Epoch: 9, Batch: 769, Loss: 2421.010009765625\n",
      "Epoch: 9, Batch: 770, Loss: 2615.0634765625\n",
      "Epoch: 9, Batch: 771, Loss: 2710.906494140625\n",
      "Epoch: 9, Batch: 772, Loss: 3480.86376953125\n",
      "Epoch: 9, Batch: 773, Loss: 2595.892822265625\n",
      "Epoch: 9, Batch: 774, Loss: 2882.76123046875\n",
      "Epoch: 9, Batch: 775, Loss: 2679.916015625\n",
      "Epoch: 9, Batch: 776, Loss: 2700.0185546875\n",
      "Epoch: 9, Batch: 777, Loss: 2518.33544921875\n",
      "Epoch: 9, Batch: 778, Loss: 2689.733154296875\n",
      "Epoch: 9, Batch: 779, Loss: 2888.22021484375\n",
      "Epoch: 9, Batch: 780, Loss: 1947.1551513671875\n",
      "Epoch: 9, Batch: 781, Loss: 3075.377197265625\n",
      "Epoch: 9, Batch: 782, Loss: 2178.165771484375\n",
      "Epoch: 9, Batch: 783, Loss: 3104.264404296875\n",
      "Epoch: 9, Batch: 784, Loss: 2790.54443359375\n",
      "Epoch: 9, Batch: 785, Loss: 2324.361572265625\n",
      "Epoch: 9, Batch: 786, Loss: 2478.05419921875\n",
      "Epoch: 9, Batch: 787, Loss: 2795.909912109375\n",
      "Epoch: 9, Batch: 788, Loss: 2815.571044921875\n",
      "Epoch: 9, Batch: 789, Loss: 2082.67724609375\n",
      "Epoch: 9, Batch: 790, Loss: 2534.961181640625\n",
      "Epoch: 9, Batch: 791, Loss: 2733.64892578125\n",
      "Epoch: 9, Batch: 792, Loss: 2839.493896484375\n",
      "Epoch: 9, Batch: 793, Loss: 2971.884033203125\n",
      "Epoch: 9, Batch: 794, Loss: 2380.012451171875\n",
      "Epoch: 9, Batch: 795, Loss: 2512.588134765625\n",
      "Epoch: 9, Batch: 796, Loss: 2559.001220703125\n",
      "Epoch: 9, Batch: 797, Loss: 2452.359130859375\n",
      "Epoch: 9, Batch: 798, Loss: 2320.964111328125\n",
      "Epoch: 9, Batch: 799, Loss: 2418.179931640625\n",
      "Epoch: 9, Batch: 800, Loss: 3054.09130859375\n",
      "Epoch: 9, Batch: 801, Loss: 2441.701171875\n",
      "Epoch: 9, Batch: 802, Loss: 3073.905517578125\n",
      "Epoch: 9, Batch: 803, Loss: 2938.197998046875\n",
      "Epoch: 9, Batch: 804, Loss: 2930.2158203125\n",
      "Epoch: 9, Batch: 805, Loss: 2964.89111328125\n",
      "Epoch: 9, Batch: 806, Loss: 3020.6630859375\n",
      "Epoch: 9, Batch: 807, Loss: 3066.1533203125\n",
      "Epoch: 9, Batch: 808, Loss: 2252.541015625\n",
      "Epoch: 9, Batch: 809, Loss: 3031.15673828125\n",
      "Epoch: 9, Batch: 810, Loss: 2939.875732421875\n",
      "Epoch: 9, Batch: 811, Loss: 2724.6689453125\n",
      "Epoch: 9, Batch: 812, Loss: 2560.8623046875\n",
      "Epoch: 9, Batch: 813, Loss: 2996.844482421875\n",
      "Epoch: 9, Batch: 814, Loss: 2283.167236328125\n",
      "Epoch: 9, Batch: 815, Loss: 2987.21142578125\n",
      "Epoch: 9, Batch: 816, Loss: 2380.55029296875\n",
      "Epoch: 9, Batch: 817, Loss: 2505.843994140625\n",
      "Epoch: 9, Batch: 818, Loss: 2285.62548828125\n",
      "Epoch: 9, Batch: 819, Loss: 3141.5703125\n",
      "Epoch: 9, Batch: 820, Loss: 2562.404296875\n",
      "Epoch: 9, Batch: 821, Loss: 2241.40478515625\n",
      "Epoch: 9, Batch: 822, Loss: 2824.70703125\n",
      "Epoch: 9, Batch: 823, Loss: 3004.007080078125\n",
      "Epoch: 9, Batch: 824, Loss: 2792.84619140625\n",
      "Epoch: 9, Batch: 825, Loss: 2735.470458984375\n",
      "Epoch: 9, Batch: 826, Loss: 2231.22021484375\n",
      "Epoch: 9, Batch: 827, Loss: 3271.73046875\n",
      "Epoch: 9, Batch: 828, Loss: 2735.849609375\n",
      "Epoch: 9, Batch: 829, Loss: 2909.959228515625\n",
      "Epoch: 9, Batch: 830, Loss: 2740.375\n",
      "Epoch: 9, Batch: 831, Loss: 2333.397705078125\n",
      "Epoch: 9, Batch: 832, Loss: 2630.93408203125\n",
      "Epoch: 9, Batch: 833, Loss: 2358.18896484375\n",
      "Epoch: 9, Batch: 834, Loss: 2117.576416015625\n",
      "Epoch: 9, Batch: 835, Loss: 2053.286376953125\n",
      "Epoch: 9, Batch: 836, Loss: 2820.759765625\n",
      "Epoch: 9, Batch: 837, Loss: 3099.162109375\n",
      "Epoch: 9, Batch: 838, Loss: 2770.514404296875\n",
      "Epoch: 9, Batch: 839, Loss: 2686.995849609375\n",
      "Epoch: 9, Batch: 840, Loss: 2507.155517578125\n",
      "Epoch: 9, Batch: 841, Loss: 2087.5234375\n",
      "Epoch: 9, Batch: 842, Loss: 2587.673583984375\n",
      "Epoch: 9, Batch: 843, Loss: 2395.1318359375\n",
      "Epoch: 9, Batch: 844, Loss: 3191.560302734375\n",
      "Epoch: 9, Batch: 845, Loss: 2430.672119140625\n",
      "Epoch: 9, Batch: 846, Loss: 2951.447998046875\n",
      "Epoch: 9, Batch: 847, Loss: 2674.37353515625\n",
      "Epoch: 9, Batch: 848, Loss: 3091.5615234375\n",
      "Epoch: 9, Batch: 849, Loss: 2845.1650390625\n",
      "Epoch: 9, Batch: 850, Loss: 2440.93408203125\n",
      "Epoch: 9, Batch: 851, Loss: 2489.374755859375\n",
      "Epoch: 9, Batch: 852, Loss: 2402.57177734375\n",
      "Epoch: 9, Batch: 853, Loss: 2977.15625\n",
      "Epoch: 9, Batch: 854, Loss: 2930.6494140625\n",
      "Epoch: 9, Batch: 855, Loss: 3050.485595703125\n",
      "Epoch: 9, Batch: 856, Loss: 2352.56494140625\n",
      "Epoch: 9, Batch: 857, Loss: 2840.44189453125\n",
      "Epoch: 9, Batch: 858, Loss: 3035.1728515625\n",
      "Epoch: 9, Batch: 859, Loss: 2716.37548828125\n",
      "Epoch: 9, Batch: 860, Loss: 2582.749267578125\n",
      "Epoch: 9, Batch: 861, Loss: 2200.269775390625\n",
      "Epoch: 9, Batch: 862, Loss: 2629.00146484375\n",
      "Epoch: 9, Batch: 863, Loss: 2553.264404296875\n",
      "Epoch: 9, Batch: 864, Loss: 2616.21337890625\n",
      "Epoch: 9, Batch: 865, Loss: 3048.6640625\n",
      "Epoch: 9, Batch: 866, Loss: 2296.08056640625\n",
      "Epoch: 9, Batch: 867, Loss: 2616.292724609375\n",
      "Epoch: 9, Batch: 868, Loss: 2993.66162109375\n",
      "Epoch: 9, Batch: 869, Loss: 2717.3359375\n",
      "Epoch: 9, Batch: 870, Loss: 2420.3193359375\n",
      "Epoch: 9, Batch: 871, Loss: 2960.146240234375\n",
      "Epoch: 9, Batch: 872, Loss: 3792.26318359375\n",
      "Epoch: 9, Batch: 873, Loss: 2676.18359375\n",
      "Epoch: 9, Batch: 874, Loss: 2854.693603515625\n",
      "Epoch: 9, Batch: 875, Loss: 2539.78857421875\n",
      "Epoch: 9, Batch: 876, Loss: 3046.58349609375\n",
      "Epoch: 9, Batch: 877, Loss: 2994.681396484375\n",
      "Epoch: 9, Batch: 878, Loss: 3106.343017578125\n",
      "Epoch: 9, Batch: 879, Loss: 2552.736572265625\n",
      "Epoch: 9, Batch: 880, Loss: 2355.790771484375\n",
      "Epoch: 9, Batch: 881, Loss: 2506.082763671875\n",
      "Epoch: 9, Batch: 882, Loss: 2656.50390625\n",
      "Epoch: 9, Batch: 883, Loss: 2942.890380859375\n",
      "Epoch: 9, Batch: 884, Loss: 2781.506591796875\n",
      "Epoch: 9, Batch: 885, Loss: 2765.18359375\n",
      "Epoch: 9, Batch: 886, Loss: 2166.9638671875\n",
      "Epoch: 9, Batch: 887, Loss: 2553.298095703125\n",
      "Epoch: 9, Batch: 888, Loss: 2913.0361328125\n",
      "Epoch: 9, Batch: 889, Loss: 2738.93408203125\n",
      "Epoch: 9, Batch: 890, Loss: 2255.742919921875\n",
      "Epoch: 9, Batch: 891, Loss: 2629.662841796875\n",
      "Epoch: 9, Batch: 892, Loss: 2587.11376953125\n",
      "Epoch: 9, Batch: 893, Loss: 2095.4384765625\n",
      "Epoch: 9, Batch: 894, Loss: 2883.9970703125\n",
      "Epoch: 9, Batch: 895, Loss: 2555.716796875\n",
      "Epoch: 9, Batch: 896, Loss: 2082.643798828125\n",
      "Epoch: 9, Batch: 897, Loss: 2303.535400390625\n",
      "Epoch: 9, Batch: 898, Loss: 2426.1318359375\n",
      "Epoch: 9, Batch: 899, Loss: 2462.892333984375\n",
      "Epoch: 9, Batch: 900, Loss: 2633.2177734375\n",
      "Epoch: 9, Batch: 901, Loss: 2322.750244140625\n",
      "Epoch: 9, Batch: 902, Loss: 2833.8291015625\n",
      "Epoch: 9, Batch: 903, Loss: 3048.864990234375\n",
      "Epoch: 9, Batch: 904, Loss: 2430.9814453125\n",
      "Epoch: 9, Batch: 905, Loss: 2501.615478515625\n",
      "Epoch: 9, Batch: 906, Loss: 2222.19677734375\n",
      "Epoch: 9, Batch: 907, Loss: 3205.976806640625\n",
      "Epoch: 9, Batch: 908, Loss: 2776.421630859375\n",
      "Epoch: 9, Batch: 909, Loss: 2451.904052734375\n",
      "Epoch: 9, Batch: 910, Loss: 2163.10009765625\n",
      "Epoch: 9, Batch: 911, Loss: 2871.33056640625\n",
      "Epoch: 9, Batch: 912, Loss: 3146.18701171875\n",
      "Epoch: 9, Batch: 913, Loss: 2785.132568359375\n",
      "Epoch: 9, Batch: 914, Loss: 3123.71435546875\n",
      "Epoch: 9, Batch: 915, Loss: 2430.219970703125\n",
      "Epoch: 9, Batch: 916, Loss: 3155.63818359375\n",
      "Epoch: 9, Batch: 917, Loss: 1996.21728515625\n",
      "Epoch: 9, Batch: 918, Loss: 2693.92529296875\n",
      "Epoch: 9, Batch: 919, Loss: 2851.18896484375\n",
      "Epoch: 9, Batch: 920, Loss: 2649.86767578125\n",
      "Epoch: 9, Batch: 921, Loss: 2604.15625\n",
      "Epoch: 9, Batch: 922, Loss: 1937.04345703125\n",
      "Epoch: 9, Batch: 923, Loss: 2655.25537109375\n",
      "Epoch: 9, Batch: 924, Loss: 2550.311279296875\n",
      "Epoch: 9, Batch: 925, Loss: 2625.37353515625\n",
      "Epoch: 9, Batch: 926, Loss: 2862.75732421875\n",
      "Epoch: 9, Batch: 927, Loss: 2267.8095703125\n",
      "Epoch: 9, Batch: 928, Loss: 2604.19580078125\n",
      "Epoch: 9, Batch: 929, Loss: 2750.40478515625\n",
      "Epoch: 9, Batch: 930, Loss: 2634.98974609375\n",
      "Epoch: 9, Batch: 931, Loss: 2331.45849609375\n",
      "Epoch: 9, Batch: 932, Loss: 2535.314453125\n",
      "Epoch: 9, Batch: 933, Loss: 2623.958251953125\n",
      "Epoch: 9, Batch: 934, Loss: 2444.690185546875\n",
      "Epoch: 9, Batch: 935, Loss: 3141.68212890625\n",
      "Epoch: 9, Batch: 936, Loss: 2716.920654296875\n",
      "Epoch: 9, Batch: 937, Loss: 2540.02197265625\n",
      "Epoch: 9, Batch: 938, Loss: 2825.93896484375\n",
      "Epoch: 9, Batch: 939, Loss: 2079.552734375\n",
      "Epoch: 9, Batch: 940, Loss: 2114.46240234375\n",
      "Epoch: 9, Batch: 941, Loss: 2564.64306640625\n",
      "Epoch: 9, Batch: 942, Loss: 2247.438232421875\n",
      "Epoch: 9, Batch: 943, Loss: 2812.3955078125\n",
      "Epoch: 9, Batch: 944, Loss: 2332.7353515625\n",
      "Epoch: 9, Batch: 945, Loss: 2857.900634765625\n",
      "Epoch: 9, Batch: 946, Loss: 2213.9677734375\n",
      "Epoch: 9, Batch: 947, Loss: 2936.590576171875\n",
      "Epoch: 9, Batch: 948, Loss: 2985.9716796875\n",
      "Epoch: 9, Batch: 949, Loss: 2849.40673828125\n",
      "Epoch: 9, Batch: 950, Loss: 2695.675537109375\n",
      "Epoch: 9, Batch: 951, Loss: 2290.5244140625\n",
      "Epoch: 9, Batch: 952, Loss: 2712.494384765625\n",
      "Epoch: 9, Batch: 953, Loss: 2436.117431640625\n",
      "Epoch: 9, Batch: 954, Loss: 2519.182373046875\n",
      "Epoch: 9, Batch: 955, Loss: 2909.8818359375\n",
      "Epoch: 9, Batch: 956, Loss: 2654.112060546875\n",
      "Epoch: 9, Batch: 957, Loss: 2395.925537109375\n",
      "Epoch: 9, Batch: 958, Loss: 2800.060791015625\n",
      "Epoch: 9, Batch: 959, Loss: 2337.89892578125\n",
      "Epoch: 9, Batch: 960, Loss: 2541.533447265625\n",
      "Epoch: 9, Batch: 961, Loss: 2862.846923828125\n",
      "Epoch: 9, Batch: 962, Loss: 2251.283203125\n",
      "Epoch: 9, Batch: 963, Loss: 2275.96923828125\n",
      "Epoch: 9, Batch: 964, Loss: 2058.197998046875\n",
      "Epoch: 9, Batch: 965, Loss: 2651.14990234375\n",
      "Epoch: 9, Batch: 966, Loss: 2316.755126953125\n",
      "Epoch: 9, Batch: 967, Loss: 2465.280029296875\n",
      "Epoch: 9, Batch: 968, Loss: 2473.797119140625\n",
      "Epoch: 9, Batch: 969, Loss: 2645.298095703125\n",
      "Epoch: 9, Batch: 970, Loss: 3318.93017578125\n",
      "Epoch: 9, Batch: 971, Loss: 2554.496337890625\n",
      "Epoch: 9, Batch: 972, Loss: 2173.142333984375\n",
      "Epoch: 9, Batch: 973, Loss: 2765.970947265625\n",
      "Epoch: 9, Batch: 974, Loss: 2616.26220703125\n",
      "Epoch: 9, Batch: 975, Loss: 3000.95654296875\n",
      "Epoch: 9, Batch: 976, Loss: 1956.09423828125\n",
      "Epoch: 9, Batch: 977, Loss: 3080.207275390625\n",
      "Epoch: 9, Batch: 978, Loss: 2918.706298828125\n",
      "Epoch: 9, Batch: 979, Loss: 3135.5390625\n",
      "Epoch: 9, Batch: 980, Loss: 2700.805419921875\n",
      "Epoch: 9, Batch: 981, Loss: 2618.76708984375\n",
      "Epoch: 9, Batch: 982, Loss: 3356.610595703125\n",
      "Epoch: 9, Batch: 983, Loss: 2607.689697265625\n",
      "Epoch: 9, Batch: 984, Loss: 2611.3046875\n",
      "Epoch: 9, Batch: 985, Loss: 2634.34765625\n",
      "Epoch: 9, Batch: 986, Loss: 2406.0703125\n",
      "Epoch: 9, Batch: 987, Loss: 2142.119140625\n",
      "Epoch: 9, Batch: 988, Loss: 2646.177490234375\n",
      "Epoch: 9, Batch: 989, Loss: 2643.5205078125\n",
      "Epoch: 9, Batch: 990, Loss: 2501.730712890625\n",
      "Epoch: 9, Batch: 991, Loss: 2852.640380859375\n",
      "Epoch: 9, Batch: 992, Loss: 2323.76513671875\n",
      "Epoch: 9, Batch: 993, Loss: 2659.96630859375\n",
      "Epoch: 9, Batch: 994, Loss: 2211.675048828125\n",
      "Epoch: 9, Batch: 995, Loss: 2177.16552734375\n",
      "Epoch: 9, Batch: 996, Loss: 2462.370361328125\n",
      "Epoch: 9, Batch: 997, Loss: 1501.802490234375\n",
      "Epoch: 9, Batch: 998, Loss: 2861.83056640625\n",
      "Epoch: 9, Batch: 999, Loss: 2385.682861328125\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "class ParamsDownloader:\n",
=======
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "def pp(a1,a2):\n",
    "            print(a1[0,0:5])\n",
    "            print(a2[0,0:5])\n",
    "class DataLoaderModule:\n",
>>>>>>> b0f20bf4c5cbcdc6f9eb36deae02c00b2e9caa7d
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
<<<<<<< HEAD
    "        self.ln1b = np.load(f'{self.data_path}/ln1b.npy')\n",
    "        self.ln1w = np.load(f'{self.data_path}/ln1w.npy')\n",
    "        self.ln2b = np.load(f'{self.data_path}/ln2b.npy')\n",
    "        self.ln2w = np.load(f'{self.data_path}/ln2w.npy')\n",
    "        \n",
    "\n",
=======
    "        self.a1 = np.load(f'{self.data_path}/a1.npy')\n",
    "        self.da1 = np.load(f'{self.data_path}/da1.npy')\n",
    "        self.dln1 = np.load(f'{self.data_path}/dln1.npy')\n",
    "        self.dln2 = np.load(f'{self.data_path}/dln2.npy')\n",
    "        self.dsm = np.load(f'{self.data_path}/dsm.npy')\n",
    "        self.ln1 = np.load(f'{self.data_path}/ln1.npy')\n",
    "        self.ln1b_grad = np.load(f'{self.data_path}/ln1b_grad.npy')\n",
    "        self.ln1b = np.load(f'{self.data_path}/ln1b.npy')\n",
    "        self.ln1w_grad = np.load(f'{self.data_path}/ln1w_grad.npy')\n",
    "        self.ln1w = np.load(f'{self.data_path}/ln1w.npy')\n",
    "        self.ln2 = np.load(f'{self.data_path}/ln2.npy')\n",
    "        self.ln2b_grad = np.load(f'{self.data_path}/ln2b_grad.npy')\n",
    "        self.ln2b = np.load(f'{self.data_path}/ln2b.npy')\n",
    "        self.ln2w_grad = np.load(f'{self.data_path}/ln2w_grad.npy')\n",
    "        self.ln2w = np.load(f'{self.data_path}/ln2w.npy')\n",
    "        \n",
    "        # pp(self.ln1w, self.ln1w)\n",
    "        \n",
    "        self.target = np.load(f'{self.data_path}/target.npy')\n",
    "        self.X_c = np.load(f'{self.data_path}/X_c.npy')\n",
    "        self.updated_ln1b = np.load(f'{self.data_path}/updated_ln1b.npy')\n",
    "        self.updated_ln1w = np.load(f'{self.data_path}/updated_ln1w.npy')\n",
    "        self.updated_ln2b = np.load(f'{self.data_path}/updated_ln2b.npy')\n",
    "        self.updated_ln2w = np.load(f'{self.data_path}/updated_ln2w.npy')\n",
>>>>>>> b0f20bf4c5cbcdc6f9eb36deae02c00b2e9caa7d
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ln1w, ln1b, ln2w, ln2b):\n",
    "        super(Model, self).__init__()\n",
    "        N, H1 = ln1w.shape\n",
    "        H2, _ = ln2w.shape\n",
    "        \n",
    "        self.l1 = nn.Linear(N, H1)\n",
    "        self.l1.weight.data = torch.from_numpy(ln1w).float()\n",
    "        self.l1.bias.data = torch.from_numpy(ln1b).float()\n",
    "\n",
    "        self.l2 = nn.Linear(H1, H2)\n",
    "        self.l2.weight.data = torch.from_numpy(ln2w).float()\n",
    "        self.l2.bias.data = torch.from_numpy(ln2b).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.l1(x)\n",
    "        y1_relu = F.relu(y1)\n",
    "        y2 = self.l2(y1_relu)\n",
    "        return y1, y1_relu, y2\n",
<<<<<<< HEAD
    "    \n",
    "    \n",
    "X_train = np.load('../dataset/x_train.npy')\n",
    "y_train = np.load('../dataset/y_train.npy')\n",
    "\n",
    "# X_test = np.load('../dataset/x_test.npy')\n",
    "# y_test = np.load('../dataset/y_test.npy')\n",
    "\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long()), batch_size=BATCH_SIZE, shuffle=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "data_loader = ParamsDownloader('../with-torch-tests/trained-model')\n",
    "model = Model(data_loader.ln1w, data_loader.ln1b, data_loader.ln2w, data_loader.ln2b)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y1, y1_relu, y2 = model(X)\n",
    "        loss = criterion(y2, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
=======
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, data_loader, criterion, optimizer):\n",
    "        self.model = model\n",
    "        self.data_loader = data_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def train(self):\n",
    "        X = torch.from_numpy(self.data_loader.X_c).float().requires_grad_(True)\n",
    "        target = torch.from_numpy(self.data_loader.target).long()\n",
    "        \n",
    "        y1, y1_relu, y2 = self.model(X)\n",
    "\n",
    "        # Retain gradients\n",
    "        y1.retain_grad()\n",
    "        y1_relu.retain_grad()\n",
    "        y2.retain_grad()\n",
    "\n",
    "        loss = self.criterion(y2, target)\n",
    "        print(\"loss \", loss.item())\n",
    "\n",
    "        # Forward pass comparison\n",
    "        print(\"Forward\")\n",
    "        print(np.allclose(y1.detach().numpy(), self.data_loader.ln1, atol=1e-6))\n",
    "        print(np.allclose(y1_relu.detach().numpy(), self.data_loader.a1, atol=1e-6))\n",
    "        print(np.allclose(y2.detach().numpy(), self.data_loader.ln2, atol=1e-4))\n",
    "\n",
    "        # Backward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Compare the gradients\n",
    "        print(\"Back\")\n",
    "        print(np.allclose(y2.grad.numpy(), self.data_loader.dsm, atol=1e-4))\n",
    "        print(np.allclose(y1_relu.grad.numpy(), self.data_loader.dln2, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.weight.grad.numpy(), self.data_loader.ln2w_grad, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.bias.grad.numpy(), self.data_loader.ln2b_grad, atol=1e-4))\n",
    "        print(np.allclose(y1.grad.numpy(), self.data_loader.da1, atol=1e-4))\n",
    "        print(np.allclose(self.model.l1.weight.grad.numpy(), self.data_loader.ln1w_grad, atol=1e-4))\n",
    "        print(np.allclose(self.model.l1.bias.grad.numpy(), self.data_loader.ln1b_grad, atol=1e-4))\n",
    "        \n",
    "        \n",
    "        # optimzer \n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # print the updated weights\n",
    "        print(\"Updated weights\")\n",
    "        print(np.allclose(self.model.l1.weight.detach().numpy(), self.data_loader.updated_ln1w, atol=1e-2))\n",
    "        # print first elements in both \n",
    "        \n",
    "        # pp(self.model.l1.weight.detach().numpy(), self.data_loader.updated_ln1w)\n",
    "        \n",
    "        print(np.allclose(self.model.l1.bias.detach().numpy(), self.data_loader.updated_ln1b, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.weight.detach().numpy(), self.data_loader.updated_ln2w, atol=1e-4))\n",
    "        print(np.allclose(self.model.l2.bias.detach().numpy(), self.data_loader.updated_ln2b, atol=1e-4))\n",
    "def main():\n",
    "    data_loader = DataLoaderModule('../with-torch-tests/all-model-cpu')\n",
    "    \n",
    "    model = Model(data_loader.ln1w, data_loader.ln1b, data_loader.ln2w, data_loader.ln2b)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    trainer = Trainer(model, data_loader, criterion, optimizer)\n",
    "    trainer.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
>>>>>>> b0f20bf4c5cbcdc6f9eb36deae02c00b2e9caa7d
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read arrays from .npy files and func Linear to compare\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "X = np.load('../with-torch-tests/linear-layer/X_C.npy')\n",
    "W = np.load('../with-torch-tests/linear-layer/W_C.npy')\n",
    "bias = np.load('../with-torch-tests/linear-layer/bias_C.npy')\n",
    "Y = np.load('../with-torch-tests/linear-layer/out_C.npy')\n",
    "B,N = X.shape\n",
    "_,M = Y.shape\n",
    "l = nn.Linear(M,N)\n",
    "l.weight.data = torch.from_numpy(W).to(torch.float32)\n",
    "l.bias.data = torch.from_numpy(bias).to(torch.float32)\n",
    "X_torch = torch.from_numpy(X).to(torch.float32)\n",
    "Y_torch = l(X_torch)\n",
    "\n",
    "print(Y[0,0:5])\n",
    "print(Y_torch[0,0:5])\n",
    "print( np.allclose(Y, Y_torch.detach().numpy(), atol=1e-4, rtol=1e-4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 250) (250, 250) (250, 250) (250, 250)\n",
      "Forward pass comparison:\n",
      "Y (numpy): [0.8740196  0.         0.         0.         0.19394517]\n",
      "Y_torch: [0.8740196  0.         0.         0.         0.19394517]\n",
      "Match: True\n",
      "\n",
      "Backward pass comparison:\n",
      "dX (numpy): [-0.9976806   0.          0.          0.         -0.45951718]\n",
      "dX_torch: [-0.9976806   0.          0.          0.         -0.45951718]\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Relu forward and backward tests\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load data\n",
    "X = np.load(r'../with-torch-tests/relu-layer/X_relu.npy')\n",
    "Y = np.load(r'../with-torch-tests/relu-layer/out_relu.npy')\n",
    "dY = np.load(r'../with-torch-tests/relu-layer/up_grad_relu.npy')\n",
    "dX = np.load(r'../with-torch-tests/relu-layer/down_grad_relu.npy')\n",
    "print(X.shape, Y.shape, dY.shape, dX.shape)\n",
    "# Convert to PyTorch tensors\n",
    "# make sure to set requires_grad=True for the input tensor so that the Autograd engine can compute the gradients\n",
    "X_torch = torch.from_numpy(X).to(torch.float32).requires_grad_(True)\n",
    "dY_torch = torch.from_numpy(dY).to(torch.float32)\n",
    "\n",
    "# Forward pass with ReLU\n",
    "relu = nn.ReLU()\n",
    "Y_torch = relu(X_torch)\n",
    "\n",
    "# Compare the forward pass results\n",
    "print(\"Forward pass comparison:\")\n",
    "print(\"Y (numpy):\", Y[0, 0:5])\n",
    "print(\"Y_torch:\", Y_torch.detach().numpy()[0, 0:5])\n",
    "print(\"Match:\", np.allclose(Y, Y_torch.detach().numpy(), atol=1e-4, rtol=1e-4))\n",
    "\n",
    "\n",
    "# Validate the backward pass\n",
    "Y_torch.backward(dY_torch)\n",
    "\n",
    "# Get the gradients from X_torch\n",
    "dX_torch = X_torch.grad\n",
    "\n",
    "# Compare the backward pass results\n",
    "print(\"\\nBackward pass comparison:\")\n",
    "print(\"dX (numpy):\", dX[0, 0:5])\n",
    "print(\"dX_torch:\", dX_torch.numpy()[0, 0:5])\n",
    "print(\"Match:\", np.allclose(dX, dX_torch.numpy(), atol=1e-4, rtol=1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C = 3 x 5\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.tensor([1, 0, 4])\n",
    "print(target.dtype)\n",
    "output = loss(m(input), target)\n",
    "output.backward()\n",
    "# 2D loss example (used, for example, with image inputs)\n",
    "N, C = 5, 4\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C x height x width\n",
    "data = torch.randn(N, 16, 10, 10)\n",
    "conv = nn.Conv2d(16, C, (3, 3))\n",
    "m = nn.LogSoftmax(dim=1)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\n",
    "output = loss(m(conv(data)), target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048, 1048) (1048, 1048) (1048, 1048)\n",
      "[[  8.910468   11.451632   10.183503    0.3938987  -5.9635134]\n",
      " [ -4.0297785 -14.136522    6.281192  -19.720121   23.324287 ]\n",
      " [ -1.1606363  -8.906321    7.2213197  -9.779897   -7.0447254]\n",
      " [ -4.011693  -17.447046  -12.836028   -3.1065748  -7.2245293]\n",
      " [-22.06999   -12.904112  -11.059555    6.7847285  20.716738 ]]\n",
      "[[  8.910467    11.451638    10.1835       0.39389753  -5.9635115 ]\n",
      " [ -4.0297775  -14.136522     6.281187   -19.720123    23.324268  ]\n",
      " [ -1.1606376   -8.9063225    7.2213106   -9.779913    -7.044721  ]\n",
      " [ -4.01169    -17.447031   -12.836032    -3.1065707   -7.224536  ]\n",
      " [-22.07       -12.904118   -11.059553     6.784727    20.716742  ]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.load(r'../with-torch-tests/matmul/A.npy')\n",
    "B = np.load(r'../with-torch-tests/matmul/B.npy')\n",
    "C = np.load(r'../with-torch-tests/matmul/C.npy')\n",
    "print(A.shape, B.shape, C.shape)\n",
    "C_py = A @ B\n",
    "print(C[:5,:5])\n",
    "print(C_py[:5,:5])\n",
    "print(np.allclose(C, C_py, atol=1e-4, rtol=1e-4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../with-torch-tests/linear-backward/X_c.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the input data\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../with-torch-tests/linear-backward/X_c.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m W \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../with-torch-tests/linear-backward/W_c.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m bias \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../with-torch-tests/linear-backward/bias_c.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../with-torch-tests/linear-backward/X_c.npy'"
     ]
    }
   ],
   "source": [
    "# Test backward pass of the Linear layer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the input data\n",
    "X = np.load('../with-torch-tests/linear-backward/X_c.npy')\n",
    "W = np.load('../with-torch-tests/linear-backward/W_c.npy')\n",
    "bias = np.load('../with-torch-tests/linear-backward/bias_c.npy')\n",
    "upgrad = np.load('../with-torch-tests/linear-backward/up_grad.npy')\n",
    "\n",
    "\n",
    "# out to comoare to\n",
    "dLdb = np.load('../with-torch-tests/linear-backward/dLdb.npy')\n",
    "dLdW = np.load('../with-torch-tests/linear-backward/dLdW.npy')\n",
    "dLdX = np.load('../with-torch-tests/linear-backward/dLdX.npy')\n",
    "\n",
    "# get sizes\n",
    "B,N = X.shape\n",
    "M,_ = W.shape\n",
    "\n",
    "print(X.shape, W.shape, bias.shape, upgrad.shape)\n",
    "\n",
    "lin = nn.Linear(N,M)\n",
    "lin.weight.data = torch.from_numpy(W).to(torch.float32)\n",
    "lin.bias.data = torch.from_numpy(bias).to(torch.float32)\n",
    "# X must be a tensor with requires_grad=True\n",
    "X_torch = torch.from_numpy(X).to(torch.float32).requires_grad_(True)\n",
    "upgrad_torch = torch.from_numpy(upgrad).to(torch.float32)\n",
    "\n",
    "# Forward pass\n",
    "Y = lin(X_torch)\n",
    "\n",
    "# Backward pass\n",
    "Y.backward(upgrad_torch)\n",
    "\n",
    "# Get the gradients\n",
    "dLdW_torch = lin.weight.grad\n",
    "dLdb_torch = lin.bias.grad\n",
    "dLdX_torch = X_torch.grad\n",
    "\n",
    "# Compare the gradients\n",
    "# print(\"dLdW (numpy):\", dLdW[0, 0:5])\n",
    "# print(\"dLdW_torch:\", dLdW_torch.numpy()[0, 0:5])\n",
    "print(\"Match:\", np.allclose(dLdW, dLdW_torch.numpy(), atol=1e-4, rtol=1e-4))\n",
    "\n",
    "# print(\"dLdb (numpy):\", dLdb[0:10].reshape(-1, 1))\n",
    "# print(\"dLdb_torch:\", dLdb_torch.numpy()[0:10].reshape(-1, 1))\n",
    "print(\"Match:\", np.allclose(dLdb.reshape(-1, 1), dLdb_torch.numpy().reshape(-1, 1), atol=1e-2, rtol=1e-2))\n",
    "\n",
    "# print(\"dLdX (numpy):\", dLdX[0, 0:5])\n",
    "# print(\"dLdX_torch:\", dLdX_torch.numpy()[0, 0:5])\n",
    "print(\"Match:\", np.allclose(dLdX, dLdX_torch.numpy(), atol=1e-4, rtol=1e-4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
