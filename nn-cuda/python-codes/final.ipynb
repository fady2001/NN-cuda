{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "class ParamsDownloader:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.ln1b = np.load(f'{self.data_path}/ln1b.npy')\n",
    "        self.ln1w = np.load(f'{self.data_path}/ln1w.npy')\n",
    "        self.ln2b = np.load(f'{self.data_path}/ln2b.npy')\n",
    "        self.ln2w = np.load(f'{self.data_path}/ln2w.npy')\n",
    "        \n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ln1w, ln1b, ln2w, ln2b):\n",
    "        super(Model, self).__init__()\n",
    "        N, H1 = ln1w.shape\n",
    "        H2, _ = ln2w.shape\n",
    "        \n",
    "        self.l1 = nn.Linear(N, H1)\n",
    "        self.l1.weight.data = torch.from_numpy(ln1w).float()\n",
    "        self.l1.bias.data = torch.from_numpy(ln1b).float()\n",
    "\n",
    "        self.l2 = nn.Linear(H1, H2)\n",
    "        self.l2.weight.data = torch.from_numpy(ln2w).float()\n",
    "        self.l2.bias.data = torch.from_numpy(ln2b).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.l1(x)\n",
    "        y1_relu = F.relu(y1)\n",
    "        y2 = self.l2(y1_relu)\n",
    "        return y1, y1_relu, y2\n",
    "    \n",
    "    \n",
    "X_train = np.load('../dataset/x_train.npy')\n",
    "y_train = np.load('../dataset/y_train.npy').astype(np.int64)\n",
    "print(X_train [0,0:5])\n",
    "# X_test = np.load('../dataset/x_test.npy')\n",
    "# y_test = np.load('../dataset/y_test.npy')\n",
    "\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long()), batch_size=BATCH_SIZE, shuffle=False)\n",
    "data_loader = ParamsDownloader('../with-torch-tests/trained-model-cpu')\n",
    "model = Model(data_loader.ln1w, data_loader.ln1b, data_loader.ln2w, data_loader.ln2b)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y1, y1_relu, y2 = model(X)\n",
    "        loss = criterion(y2, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "x_test = np.load('../dataset/x_test.npy')\n",
    "y_test = np.load('../dataset/y_test.npy')\n",
    "y1, y1_relu, y2 = model(torch.from_numpy(x_test).float())\n",
    "y_pred = y2.argmax(dim=1).numpy()\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "class ParamsDownloader:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.ln1b = np.load(f'{self.data_path}/ln1b.npy')\n",
    "        self.ln1w = np.load(f'{self.data_path}/ln1w.npy')\n",
    "        self.ln2b = np.load(f'{self.data_path}/ln2b.npy')\n",
    "        self.ln2w = np.load(f'{self.data_path}/ln2w.npy')\n",
    "        \n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ln1w, ln1b, ln2w, ln2b):\n",
    "        super(Model, self).__init__()\n",
    "        N, H1 = ln1w.shape\n",
    "        H2, _ = ln2w.shape\n",
    "        \n",
    "        self.l1 = nn.Linear(N, H1)\n",
    "        self.l1.weight.data = torch.from_numpy(ln1w).float()\n",
    "        self.l1.bias.data = torch.from_numpy(ln1b).float()\n",
    "\n",
    "        self.l2 = nn.Linear(H1, H2)\n",
    "        self.l2.weight.data = torch.from_numpy(ln2w).float()\n",
    "        self.l2.bias.data = torch.from_numpy(ln2b).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.l1(x)\n",
    "        y1_relu = F.relu(y1)\n",
    "        y2 = self.l2(y1_relu)\n",
    "        return y1, y1_relu, y2\n",
    "    \n",
    "    \n",
    "X_train = np.load('../dataset/x_train.npy')\n",
    "y_train = np.load('../dataset/y_train.npy').astype(np.int64)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long()), batch_size=BATCH_SIZE, shuffle=False)\n",
    "data_loader = ParamsDownloader('../with-torch-tests/trained-model-cpu')\n",
    "model = Model(data_loader.ln1w, data_loader.ln1b, data_loader.ln2w, data_loader.ln2b)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    with profiler.profile(record_shapes=True, use_cuda=False) as prof:\n",
    "        for i, (X, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            y1, y1_relu, y2 = model(X)\n",
    "            loss = criterion(y2, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch: {epoch+1}, loss: {loss.item()}\")\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "x_test = np.load('../dataset/x_test.npy')\n",
    "y_test = np.load('../dataset/y_test.npy')\n",
    "y1, y1_relu, y2 = model(torch.from_numpy(x_test).float())\n",
    "y_pred = y2.argmax(dim=1).numpy()\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class ParamsDownloader:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.ln1b = np.load(f'{self.data_path}/ln1b.npy')\n",
    "        self.ln1w = np.load(f'{self.data_path}/ln1w.npy')\n",
    "        self.ln2b = np.load(f'{self.data_path}/ln2b.npy')\n",
    "        self.ln2w = np.load(f'{self.data_path}/ln2w.npy')\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ln1w, ln1b, ln2w, ln2b):\n",
    "        super(Model, self).__init__()\n",
    "        N, H1 = ln1w.shape\n",
    "        H2, _ = ln2w.shape\n",
    "        \n",
    "        self.l1 = nn.Linear(N, H1)\n",
    "        self.l1.weight.data = torch.from_numpy(ln1w).float().to(device)\n",
    "        self.l1.bias.data = torch.from_numpy(ln1b).float().to(device)\n",
    "\n",
    "        self.l2 = nn.Linear(H1, H2)\n",
    "        self.l2.weight.data = torch.from_numpy(ln2w).float().to(device)\n",
    "        self.l2.bias.data = torch.from_numpy(ln2b).float().to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.l1(x)\n",
    "        y1_relu = F.relu(y1)\n",
    "        y2 = self.l2(y1_relu)\n",
    "        return y1, y1_relu, y2\n",
    "    \n",
    "# Load data and move to device\n",
    "X_train = np.load('../dataset/x_train.npy')\n",
    "y_train = np.load('../dataset/y_train.npy').astype(np.int64)\n",
    "\n",
    "print(X_train[0, 0:5])\n",
    "\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train).float().to(device), \n",
    "                                        torch.from_numpy(y_train).long().to(device)), \n",
    "                          batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "data_loader = ParamsDownloader('../with-torch-tests/trained-model-cpu')\n",
    "model = Model(data_loader.ln1w, data_loader.ln1b, data_loader.ln2w, data_loader.ln2b).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y1, y1_relu, y2 = model(X)\n",
    "        loss = criterion(y2, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Testing the model\n",
    "x_test = np.load('../dataset/x_test.npy')\n",
    "y_test = np.load('../dataset/y_test.npy')\n",
    "\n",
    "y1, y1_relu, y2 = model(torch.from_numpy(x_test).float().to(device))\n",
    "y_pred = y2.argmax(dim=1).cpu().numpy()\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[0.78198105 0.4786313  0.7654065  0.05289226 0.815995  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 3.9396262168884277\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Print profiling results\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mprof\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_averages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtable(sort_by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu_time_total\u001b[39m\u001b[38;5;124m\"\u001b[39m, row_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Testing the model\u001b[39;00m\n\u001b[0;32m     75\u001b[0m x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../dataset/x_test.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\autograd\\profiler.py:365\u001b[0m, in \u001b[0;36mprofile.key_averages\u001b[1;34m(self, group_by_input_shape, group_by_stack_n)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_finish()\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_events \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected profiling results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_events\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_averages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_by_input_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_by_stack_n\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\autograd\\profiler_util.py:324\u001b[0m, in \u001b[0;36mEventList.key_averages\u001b[1;34m(self, group_by_input_shapes, group_by_stack_n)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(key)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m evt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m     \u001b[43mstats\u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_by_input_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_by_stack_n\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m avg_list \u001b[38;5;241m=\u001b[39m EventList(\n\u001b[0;32m    327\u001b[0m     stats\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    328\u001b[0m     use_cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_cuda,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m     with_flops\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_flops,\n\u001b[0;32m    332\u001b[0m )\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m evt \u001b[38;5;129;01min\u001b[39;00m avg_list:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\autograd\\profiler_util.py:708\u001b[0m, in \u001b[0;36mFunctionEventAvg.add\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m other\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpu_time_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mcpu_time_total\n\u001b[1;32m--> 708\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_time_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda_time_total\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprivateuse1_time_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mprivateuse1_time_total\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_cpu_time_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mself_cpu_time_total\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\autograd\\profiler_util.py:556\u001b[0m, in \u001b[0;36mFunctionEvent.cuda_time_total\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_type \u001b[38;5;241m==\u001b[39m DeviceType\u001b[38;5;241m.\u001b[39mCPU:\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_legacy:\n\u001b[0;32m    555\u001b[0m         \u001b[38;5;66;03m# account for the kernels in the children ops\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkinfo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(\n\u001b[0;32m    557\u001b[0m             ch\u001b[38;5;241m.\u001b[39mcuda_time_total \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpu_children\n\u001b[0;32m    558\u001b[0m         )\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;66;03m# each legacy cpu events has a single (fake) kernel\u001b[39;00m\n\u001b[0;32m    561\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(kinfo\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;28;01mfor\u001b[39;00m kinfo \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernels)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class ParamsDownloader:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        self.ln1b = np.load(f'{self.data_path}/ln1b.npy')\n",
    "        self.ln1w = np.load(f'{self.data_path}/ln1w.npy')\n",
    "        self.ln2b = np.load(f'{self.data_path}/ln2b.npy')\n",
    "        self.ln2w = np.load(f'{self.data_path}/ln2w.npy')\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, ln1w, ln1b, ln2w, ln2b):\n",
    "        super(Model, self).__init__()\n",
    "        N, H1 = ln1w.shape\n",
    "        H2, _ = ln2w.shape\n",
    "        \n",
    "        self.l1 = nn.Linear(N, H1)\n",
    "        self.l1.weight.data = torch.from_numpy(ln1w).float().to(device)\n",
    "        self.l1.bias.data = torch.from_numpy(ln1b).float().to(device)\n",
    "\n",
    "        self.l2 = nn.Linear(H1, H2)\n",
    "        self.l2.weight.data = torch.from_numpy(ln2w).float().to(device)\n",
    "        self.l2.bias.data = torch.from_numpy(ln2b).float().to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.l1(x)\n",
    "        y1_relu = F.relu(y1)\n",
    "        y2 = self.l2(y1_relu)\n",
    "        return y1, y1_relu, y2\n",
    "    \n",
    "# Load data and move to device\n",
    "X_train = np.load('../dataset/x_train.npy')\n",
    "y_train = np.load('../dataset/y_train.npy').astype(np.int64)\n",
    "\n",
    "print(X_train[0, 0:5])\n",
    "\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train).float().to(device), \n",
    "                                        torch.from_numpy(y_train).long().to(device)), \n",
    "                          batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "data_loader = ParamsDownloader('../with-torch-tests/trained-model-cpu')\n",
    "model = Model(data_loader.ln1w, data_loader.ln1b, data_loader.ln2w, data_loader.ln2b).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(N_EPOCHS):\n",
    "    with profiler.profile(record_shapes=True) as prof:\n",
    "        for i, (X, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            y1, y1_relu, y2 = model(X)\n",
    "            loss = criterion(y2, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "    # Print profiling results\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "# Testing the model\n",
    "x_test = np.load('../dataset/x_test.npy')\n",
    "y_test = np.load('../dataset/y_test.npy')\n",
    "\n",
    "y1, y1_relu, y2 = model(torch.from_numpy(x_test).float().to(device))\n",
    "y_pred = y2.argmax(dim=1).cpu().numpy()\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "SOFTMAX\n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "     aten::log_softmax         4.88%       1.955ms       100.00%      40.026ms     400.260us     590.000us         0.07%     822.587ms       8.226ms           100  \n",
      "    aten::_log_softmax        95.12%      38.071ms        95.12%      38.071ms     380.710us     821.997ms        99.93%     821.997ms       8.220ms           100  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 40.026ms\n",
      "Self CUDA time total: 822.587ms\n",
      "\n",
      "NLLLoss\n",
      "--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         aten::log_softmax        84.03%     182.821ms        85.13%     185.215ms       1.852ms     379.000us         0.05%     779.067ms       7.791ms           100  \n",
      "        aten::_log_softmax         1.10%       2.394ms         1.10%       2.394ms      23.940us     778.688ms        96.31%     778.688ms       7.787ms           100  \n",
      "         aten::nll_loss_nd         0.71%       1.539ms        14.87%      32.350ms     323.500us     344.000us         0.04%      29.497ms     294.970us           100  \n",
      "            aten::nll_loss         0.87%       1.897ms        14.16%      30.811ms     308.110us     425.000us         0.05%      29.153ms     291.530us           100  \n",
      "    aten::nll_loss_forward        13.28%      28.888ms        13.29%      28.914ms     289.140us      28.569ms         3.53%      28.728ms     287.280us           100  \n",
      "             aten::resize_         0.01%      26.000us         0.01%      26.000us       0.260us     159.000us         0.02%     159.000us       1.590us           100  \n",
      "--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 217.565ms\n",
      "Self CUDA time total: 808.564ms\n",
      "\n",
      "CrossEntropyLoss\n",
      "----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                        Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "    aten::cross_entropy_loss        27.80%       4.213ms       100.00%      15.156ms     151.560us     702.000us         0.09%     805.285ms       8.053ms           100  \n",
      "           aten::log_softmax        17.76%       2.691ms        35.10%       5.320ms      53.200us     532.000us         0.07%     779.456ms       7.795ms           100  \n",
      "          aten::_log_softmax        16.96%       2.571ms        16.96%       2.571ms      25.710us     778.737ms        96.70%     778.737ms       7.787ms           100  \n",
      "           aten::nll_loss_nd         9.03%       1.369ms        37.10%       5.623ms      56.230us     327.000us         0.04%      25.127ms     251.270us           100  \n",
      "              aten::nll_loss         8.33%       1.262ms        28.07%       4.254ms      42.540us     370.000us         0.05%      24.800ms     248.000us           100  \n",
      "      aten::nll_loss_forward        19.40%       2.940ms        19.74%       2.992ms      29.920us      24.267ms         3.01%      24.430ms     244.300us           100  \n",
      "                    aten::to         0.38%      58.000us         0.38%      58.000us       0.580us     187.000us         0.02%     187.000us       1.870us           100  \n",
      "               aten::resize_         0.34%      52.000us         0.34%      52.000us       0.520us     163.000us         0.02%     163.000us       1.630us           100  \n",
      "----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 15.156ms\n",
      "Self CUDA time total: 805.285ms\n",
      "\n",
      "Linear\n",
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        aten::linear         1.00%       2.561ms       100.00%     257.090ms       2.571ms     587.000us         0.11%     541.927ms       5.419ms           100  \n",
      "         aten::addmm        36.50%      93.839ms        97.83%     251.521ms       2.515ms     532.061ms        98.18%     540.367ms       5.404ms           100  \n",
      "        aten::expand        61.32%     157.650ms        61.33%     157.682ms       1.577ms       7.719ms         1.42%       8.306ms      83.060us           100  \n",
      "             aten::t         0.60%       1.540ms         1.17%       3.008ms      30.080us     433.000us         0.08%     973.000us       9.730us           100  \n",
      "    aten::as_strided         0.05%     131.000us         0.05%     131.000us       0.655us     769.000us         0.14%     769.000us       3.845us           200  \n",
      "     aten::transpose         0.53%       1.369ms         0.57%       1.468ms      14.680us     358.000us         0.07%     540.000us       5.400us           100  \n",
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 257.090ms\n",
      "Self CUDA time total: 541.927ms\n",
      "\n",
      "ReLU\n",
      "-------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "               Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         aten::relu        15.25%       3.418ms       100.00%      22.414ms     224.140us       1.904ms         0.42%     455.096ms       4.551ms           100  \n",
      "    aten::clamp_min        84.75%      18.996ms        84.75%      18.996ms     189.960us     453.192ms        99.58%     453.192ms       4.532ms           100  \n",
      "-------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 22.414ms\n",
      "Self CUDA time total: 455.096ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "# test kernels speed \n",
    "repeats = 100\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# softmax \n",
    "x = torch.randn(10000, 10000).to(device)\n",
    "with profiler.profile(record_shapes=True, use_cuda=True) as prof:\n",
    "    for _ in range(repeats):\n",
    "        y = F.log_softmax(x, dim=1)\n",
    "print(\"SOFTMAX\")\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "\n",
    "\n",
    "# NLLLoss\n",
    "x = torch.randn(10000, 10000).to(device)\n",
    "y = torch.randint(0, 10000, (10000,)).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "with profiler.profile(record_shapes=True, use_cuda=True) as prof:\n",
    "    for _ in range(repeats):\n",
    "        loss = criterion(F.log_softmax(x, dim=1), y)\n",
    "print(\"NLLLoss\")\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "\n",
    "\n",
    "# cross entropy\n",
    "x = torch.randn(10000, 10000).to(device)\n",
    "y = torch.randint(0, 10000, (10000,)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "with profiler.profile(record_shapes=True, use_cuda=True) as prof:\n",
    "    for _ in range(repeats):\n",
    "        loss = criterion(x, y)\n",
    "print(\"CrossEntropyLoss\")\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "\n",
    "\n",
    "# Linear layer\n",
    "x = torch.randn(2048, 2048).to(device)\n",
    "linear = nn.Linear(2048, 2048).to(device)\n",
    "with profiler.profile(record_shapes=True, use_cuda=True) as prof:\n",
    "    for _ in range(repeats):\n",
    "        y = linear(x)\n",
    "print(\"Linear\")\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "\n",
    "\n",
    "# relu \n",
    "x = torch.randn(10000, 10000).to(device)\n",
    "with profiler.profile(record_shapes=True, use_cuda=True) as prof:\n",
    "    for _ in range(repeats):\n",
    "        y = F.relu(x)\n",
    "print(\"ReLU\")\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
